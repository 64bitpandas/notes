{"/":{"title":"Welcome!","content":"\n## Introduction\n\nHi there! Seems like you stumbled upon my archive of course notes! \n\nOver the years, I've found that the most effective way for me to learn and process information was to teach it. Since this isn't always practical or possible, I've ended up creating these production-quality notes as an alternative.\n\nAlthough many courses at Berkeley (especially CS courses) have excellent materials and often already have a full set of course notes, I've found that many students- myself included- often struggle to process information when it's that dense. My hope is that these notes can serve as a secondary, lighter perspective on things. \n\nHere, you'll find a wide variety of content from basic concepts, practice problems, and example algorithm walkthroughs. Since they were all made at various times over 4 years, the quality and style may be wildly different from page to page. I intend to go through these notes and resolve any inconsistencies over (a long period of) time.\n\n## Index\n\nHere are the courses that I currently have notes available for, and their statuses:\n\n - [CS 61B: Data Structures and Algorithms](cs61b/): full guide available for all course content, based on the Spring 2020 offering\n\n\nHere are courses that I am currently working on publishing notes for:\n - CS 70: Discrete Math notes available, Probability notes are nonexistent due to how good the Data 140 textbook is\n - CS 61A: creating an incomplete guide (will not cover all course content, since)\n - CS 186: currently under review\n - Data 102: complete, needs review\n - CS 168: complete, needs review\n - CS 188: mostly complete, needs review\n - CS 162: mostly complete, needs review\n - MCB C61: textbook companion available, needs introduction\n\nHere are some future notes that I may work on at some point:\n - Comprehensive psychology major notes (Psych 101, 114, 124, C126, C127, 131, 140, C143, 150)\n - Other CS courses that I have incomplete notes for (61C, 170, 161)\n\n## Basic Principles\n\nHere are some principles that I try to follow when creating notes. I'll probably make a blog post at some point to go over this in more detail, but for now this outline should be enough to show what I hope to accomplish.\n\n1. **Content is more fun when it's important:** Answer the question \"why should I care about this?\" before actually spending time on whatever topic is at hand. If answering it is a struggle, then it's probably not important enough to need to remember in the future.\n2. **Make it interactive:** It's way easier to concentrate on something if it's directly applicable to a problem, question, or situation at hand. Interject conceptual notes with illustrated examples and practice problems whenever possible.\n3. **Notes are rarely self-contained:** It's impossible to fully cover most topics on a single page, and topics may be deeply related to content from other courses. Link to external resources or further learning opportunities whenever possible, just in case it becomes necessary to research the topic further in the future.\n4. **Type a lot of stuff really fast:** For this verbose style of note-taking to be effective for me, I need to be able to completely put down thoughts on the page before I lose them. If you're thinking of doing this on your own, I'd recommend getting good at touch typing, and hitting up [monkeytype](https://monkeytype.com/) for some practice. I'm going against all the research that suggests handwriting is more effective than typing, because the purpose of my notes is not for memorizing or even remembering any of the content, but rather to create a complete repository of knowledge that I and others can easily search in the future.\n\n## About this website\n\nMy notes are hosted on [Netlify](https://www.netlify.com/) and are built on my custom [Amethyst theme](https://github.com/64bitpandas/amethyst) for [Hugo](https://https://gohugo.io/). You can view the source code [here](https://github.com/64bitpandas/notes).\n\nAll of the notes here are formatted in Markdown, and the majority was created using [Obsidian](https://obsidian.md/). These notes are a small fraction of my Obsidian vault; I intend to publish other small bits of it in various places such as my [blog](https://blog.bencuan.me), [devlog](https://devlog.bencuan.me), or [mastodon](https://hachyderm.io/@bencuan) if you're curious.\n\nIf you're interested in contributing, take a look at the [contribution guide](/contributing.md).\n\n## Contact me\n\nWant to chat with me about these notes, or something else? You can find my contact info [here](https://bencuan.me/contact).","lastmodified":"2023-01-06T11:02:32.07128696Z","tags":null},"/contributing":{"title":"Contributing","content":"\nThanks for your interest in contributing to my notes! There's a lot of room for improvement, and I don't have the time to fix everything. If there's something that you'd like to add, please do so!\n\n## Making Requests\n\nI use GitHub for issue tracking. Please make an [issue](https://github.com/64bitpandas/notes/issues) before editing anything or creating a pull request, so I can comment on it before you start working on a feature.\n\n## Editing Content\n\nThis website is built with [Hugo](https://gohugo.io/) using the [Amethyst theme](https://amethyst.bencuan.me/). \n\nFirst, fork the main repository (github.com/64bitpandas/notes).\n\nInstructions on how to format new files and set up a live development server can be found [here](https://amethyst.bencuan.me/setup/editing/). \nA guide on how to use the various features (tabs, callouts, links...) can also be found on the Amethyst website.\n\nIf you have something you want to contribute but it's in another format (like a Google Doc), and you are unable to convert it yourself, create an issue linking the unformatted content and I will take a look.\n\n## Attributions and Academic Integrity\n\nAlthough some of my older notes may be missing citations or attributions to the content they reference, I'm doing my best to link back to the original source moving forwards. If you use public course content (such as screenshots from slides, code snippets from a project skeleton, or practice problems from a past exam), please add a link to where you found it!\n\n**Do not under any circumstances publish private course content** (that can't be found elsewhere for free online, from an official source). This includes homework/project/discussion solutions, textbooks, and readers.\n\nIf you are an instructor or TA for a course that I have notes for and find something that shouldn't be published, please send me an email at [contact@bencuan.me](mailto:contact@bencuan.me) so I can remove it and scrub it from the git history.\n\n\n## Credits\nHere's a list of individuals who have made meaningful contributions to these notes over the years! If you make a pull request, feel free to add your name here as well.\n - [Arin Chang](https://github.com/arinchang)\n - [Zachary Zollman](https://github.com/zacharyzollman)","lastmodified":"2023-01-06T11:02:32.07128696Z","tags":null},"/cs61b/":{"title":"Welcome to CS61B!","content":"\n# Welcome to my CS61B Guide!\n\nThis is a **non-comprehensive** guide to data structures written with an intention to supplement learning and reviewing of Berkeley's [CS61B](https://inst.eecs.berkeley.edu/\\~cs61b) material. Main topics include:\n\n* Object oriented programming basics\n* Abstract data types\n* Asymptotics and runtime analysis\n* Sorting algorithms\n* Search algorithms\n* And some more miscellaneous topics thrown in!\n\nThis guide is written to be as easy to follow and digestible as possibleüòÄI've included lots of diagrams, practice problems, and more intuitive explanations instead of the more straightforward approach most textbooks use. **This isn't a replacement for lectures and other course content.** You probably need to look at those first, and come here if something isn't sticking!\n\n### The 61B Concept Map\n\n![](\u003cimg/assets/image (6).png\u003e)\n\n\n\n## Who is this for?\n\nMostly me; making unnecessarily detailed guides is my goto method of making sure I understand everythingüòÅ But you are welcome to use it as well for reviewing for 61B exams, touching up on data structures knowledge, or whatever you want!\n\n**Basic programming knowledge gained from** [**CS61A**](https://cs61a.org/) **or equivalent is assumed.** [[notes/cs61a|Click here]] for my notes for that!\n\n## How to use this guide\n\nAgain, I will emphasize that this **isn't a textbook.** While I try to be as comprehensive as possible, I'm sure I missed plenty of important concepts or assume you know others. Please [open an issue](https://github.com/64bitpandas/notes/issues) if you think something's wrong!\n\nThis content was ported from my original [61B Notes](https://cs61b.bencuan.me), so you may see some strange formatting here and there. Again, please create an issue if you spot anything overly egregious.\n\n\u003e [!note] Content Note\n\u003e\n\u003e For more difficult topics, I'll put a warning like this at the top of the page with links to prerequisites or supporting topics!\n\n\nThere are also plenty of practice problems to try out! Here's an non-exhaustive list of pages with those if you are mostly interested in them and not the conceptual content.\n\n* [Access Control](oop/access-control.md#practice)\n* [Dynamic Method Selection](oop/dynamic-method-selection.md)\n* [Generic Types](oop/generics.md#generic-subtypes)\n* [Asymptotics Practice](asymptotics/asymptotics-practice.md)\n\n\n\n## How to contribute\n\nSee the [contributing guide](/contributing) for more details!\n\nThe pages that could be most improved (in no particular order) are [Union Find (Disjoint Sets)](abstract-data-types/union-find-disjoint-sets.md), [Stacks and Queues](abstract-data-types/collections/stacks-and-queues.md), [Linked Lists](abstract-data-types/collections/linked-lists.md), [Sets](abstract-data-types/collections/sets.md), [Sorting](algorithms/sorting.md), [Searching](algorithms/searching.md), [Binary Search](algorithms/searching/binary-search.md), [Shortest Paths](algorithms/shortest-paths/), and [Exceptions](misc-topics/exceptions.md). Feel free to add whatever content you like (explanations, examples, practice problems, memes...) to these!\n\nAdditionally, there are plenty of topics (Regex, Testing, Files/Scanners, Ranges, GUI just to name a few) that aren't currently covered in this guide. If you want to add one of these topics, please create an issue first but it will almost certainly be approved.\n\n### Credits\n\n* [Ben Cuan](https://github.com/64bitpandas)\n* [Arin Chang](https://github.com/arinchang)\n","lastmodified":"2023-01-06T11:02:32.07128696Z","tags":null},"/cs61b/abstract-data-types/":{"title":"","content":"","lastmodified":"2023-01-06T11:02:32.07128696Z","tags":null},"/cs61b/abstract-data-types/binary-trees/":{"title":"","content":"\n\u003e [!quote] \u0026nbsp;\n\u003e\n\u003e \"The most important concept in computer science\" - Josh Hug\n\n## Humble Origins\n\nLinked lists are great, but we can do better! Let's try **rearranging the pointers** in an interesting way.\n\nInstead of starting at one end of the list, let's set our first pointer at the **middle** of the list!\n\n![](\u003c../../img/assets/image (69).png\u003e)\n\nNow, let's make new pointers going to the **center** of each **sublist** on the left and right of the center.\n\n![](\u003c../../img/assets/image (70).png\u003e)\n\nLet's do it again!\n\n![](\u003c../../img/assets/image (71).png\u003e)\n\nWould ya look at that, we've got a **tree**! üå≤\n\n![üå≤üå≤üå≤üå≤üå≤](\u003c../../img/assets/image (73).png\u003e)\n\n## Types of Trees\n\nRight now, we can determine some properties that all trees have.\n\n* All trees have a **root node**.\n* All nodes can point to **child nodes.** Or, if they don't have any children, they are **leaves.**\n\nWe can add more and more constraints to our tree to make them more useful!\n\nFirst, let's add the constraint that **node can only have 2 or fewer children** to create a **binary tree.**\n\nThen, let's **ensure our tree is sorted** to create a **binary search tree.** A tree is sorted if it has these properties:\n\n* Every value in the **left subtree** of a node is **less than** the node's value.\n* Every value in the **right subtree** of a node is **greater than** the node's value.\n* Values are **transitive** - there are **no duplicate values**.\n* The tree is **complete** - it is possible to **compare any two values** in the tree and say that one is **either less than or greater than the other.**\n* The tree is **antisymmetric** - If `p \u003c q` is true and `q \u003c r` is also true, then it must follow that `p \u003c r`.\n\n## Tree Operations\n\nThere are **three important operations** that trees should support: **find, insert, and delete.**\n\n### **Find**\n\nFinding a value in a tree uses the [Binary Search](../../algorithms/searching/binary-search.md) algorithm. \n\n\n### Insert\n\nThe insert algorithm is **very similar to binary search.** Here are the steps to take:\n\n* Search for the item. **If it's found, then do nothing** since the value is already in the tree.\n* If it's not found (search would return null in this case), then create a node and put it where it should be found. If using recursion, this last step is already done- all we need to do is return a new node!\n\nHere's the algorithm:\n\n```java\npublic BST insert(BST T, Key sk) {\n    if (T == null) {\n        // Create new leaf with given key. Different from search\n        return new BST(sk, null, null); \n    }\n    if (sk.equals(T.key)) {\n        return T;\n    } else if (sk \u003c T.key) {\n        T.left = find(T.left, sk); // Different from search\n    } else {\n        T.right = find(T.right, sk); // Different from search\n    }\n}\n```\n\n### Delete\n\nThis one's a bit trickier because we need to make sure that the new tree still **preserves the binary search tree structure.** That means that we might have to shuffle around nodes after the deletion. There are **three cases:**\n\nA) The node to delete is a **leaf**. This is an easy case- just remove that node and you're done!\n\n![Deleting a leaf.](\u003c../../img/assets/image (64).png\u003e)\n\nB) The node to delete has **one child.** In this case, **swap** the node with its child, then **delete the node.**\n\n![Deleting a node with one child.](\u003c../../img/assets/image (65).png\u003e)\n\nC) The node to delete has **two children.** This one's trickier, because we still need to preserve the tree structure! In this case, we have to **traverse the node's children** to find the **next biggest value** and swap that up to replace the old node.\n\n![Deleting a node with two children.](\u003c../../img/assets/image (66).png\u003e)\n\n## Asymptotic Analysis\n\nA binary tree can be **bushy** or **spindly.** These two cases have dramatically different performances!\n\n**Bushy** trees are the **best case.** A tree is bushy if **every parent has exactly 2 children.**\n\nA bushy tree is guaranteed to have a height of $\\Theta(\\log(n))$ which means that the runtimes for adding and searching will also be $\\Theta(\\log(n))$ .\n\n**Spindly** trees are the **worst case.** A tree is spindly if **every parent has exactly 1 child.** This makes the tree essentially just a linked list!\n\nA spindly tree has a height of  $\\Theta(n)$ which means that the runtimes for adding and searching will also be $\\Theta(n)$ .\n\n![](\u003c../../img/assets/image (67).png\u003e)\n\nIn [Balanced BSTs](balanced-search-structures.md), we will explore ways of guaranteeing that a tree is bushy!\n\n## Limits of Trees\n\nWhile trees are extremely versatile and fantastic for a variety of applications, trees have some limitations that make it difficult to use in some situations.\n\n* **All items in a tree need to be comparable.** We can't construct a binary tree out of categorical data, like models of cars, for example.\n* **The data must be hierarchical.** If data can be traversed through in multiple ways, or forms loops, [Graphs](../graphs.md) are probably better.\n* **The best case runtime is** $\\Theta(\\log(n))$ . This might seem good, but other data structures like [Tries](tries.md) and [Hash Tables](../hashing.md) can be as good as **** $\\Theta(1)$ !\n\n## Tree Traversals\n\nCheck out these pages for information on how to go through each element of a tree!\n\n[Depth First Search](../../algorithms/searching/depth-first-search-dfs.md)\n\n[Breadth First Search](../../algorithms/searching/breadth-first-search-bfs.md)\n\n","lastmodified":"2023-01-06T11:02:32.07128696Z","tags":null},"/cs61b/abstract-data-types/binary-trees/balanced-search-structures":{"title":"","content":"\n\u003e [!info] Content Note\n\u003e\n\u003e Please read [Binary Trees](./) before continuing!\n\n\n**Balanced Binary Search Trees** are an even more specific subcategory of binary trees that have an important property: **they are always bushy.**\n\n## B Trees (2-4 Trees)\n\n**The basic idea:** Nodes can hold multiple values now! When nodes have too many values, we will split it.\n\nA **2-4 tree** is named such because each parent can have **2 to 4 children.** Another constraint we will put on is a **limit on the** **number of items allowed in a single node**, so that we can guarantee that searching a single node will always be $\\Theta(n).$\n\n### **Adding Values to a B-Tree**\n\nAdding values to a B Tree can be a bit tricky because we need to make sure all the properties are still followed. Here are some example scenarios:\n\nIf a node already has 2 or more children, place the new value in one of its existing children.\n\n![](\u003c../../img/assets/image (81).png\u003e)\n\nIf a node is full (reaches the limit), we must **split the node** by **moving one value up to the parent** and **creating another child node**. Here, we'll use a limit of **3**.\n\n![](\u003c../../img/assets/image (82).png\u003e)\n\n### Properties of B Trees\n\n* Searching in a single node is **constant runtime** since the limit is a constant.\n* All leaves must be the **same distance** from the root.\n* A non-leaf node with **k** items must have **k+1** children.\n* The height of a B tree is guaranteed to be $\\Theta(\\log(n))$ because it is bushy.\n\n## Red-Black Trees and Tree Rotation\n\n**The basic idea:** Let's try to represent B trees in a **binary tree format.** That means that every parent can only have 2 children! In order to do this, we'll **add an extra color property** to each node.\n\n**Black nodes** are just like any normal binary tree node, but **Red nodes** represent the nodes in B Trees that have **more than one value.** For example, let's convert the B Tree we were working with before into a RB Tree.\n\n![](\u003c../../img/assets/image (83).png\u003e)\n\nIn order to make our lives easier, we'll restrict our Red Black trees into **left leaning red black trees** which can **only have red nodes on the left.**\n\n### **Tree Rotation**\n\nIn order to ensure that adding new nodes won't break the Red Black Tree structure, we will use a concept called **tree rotation** which swaps around nodes. There are two rotations, a **left rotation** and a **right rotation,** which move a child node up to replace its parent. For example, a **left rotation** moves the **right node up and left** to replace the parent.\n\nA \"left rotation on 7\" looks like this:\n\n![](\u003c../../img/assets/image (84).png\u003e)\n\nNotice that the **8** gets moved to be a **right child** of **7** after the rotation! This is necessary to preserve the binary tree structure.\n\nA \"right rotation on 7\" looks like this:\n\n![](\u003c../../img/assets/image (85).png\u003e)\n\nHere, the **6** gets moved to be a **left child** of **7.**\n\nIf you want to see how these rotations can be implemented into the `insert` algorithm, [try the homework](https://inst.eecs.berkeley.edu/\\~cs61b/sp20/materials/hw/hw8/index.html) on implementing a LLRB Tree! Below is a brief outline on how insert works:\n\n* **Always add values to a leaf node as a red node first.** Follow normal sorted binary tree rules.\n* If the link is leaning right, rotate the tree to make it left leaning.\n* If a node already has a red link to the left, temporarily add it to the right also as a red link.\n  * Then, flip the color of all links connected to the node (if previously black, turn red; if previously red, turn black)\n  * Might need to fix right-leaning red nodes that are created as a result\n* If a node has red links to both parent and child, rotate it such that it becomes the above case, and then handle that case like you did before.\n\n### Properties of Red Black Trees\n\nLike B Trees, Red Black Trees have some important properties that allow them to be easily distinguishable.\n\n* Red Black trees have a **one-to-one correspondence** with B trees. That means for every Red Black tree, there is exactly one B Tree that represents the same connections. This also means that a Red Black Tree will have the same runtimes as their corresponding B Trees. (Take a linear algebra course to learn more about isomorphisms üôÇ )\n* **Every node must have the same number of black nodes in between itself and the root.** This might be a bit surprising at first, but remember that their corresponding B Tree is always bushy, and red links mean a multi-value node in a B Tree.\n","lastmodified":"2023-01-06T11:02:32.07128696Z","tags":null},"/cs61b/abstract-data-types/binary-trees/heaps":{"title":"","content":"## What are Heaps?\n\nA heap is a **specific order of storing data,** often in a list. Heaps are very similar to binary trees, but have some differences:\n\n* Unlike trees, heaps **only care about the root node.** Usually, the root node is either the **largest** or **smallest** value in the heap (corresponding with max-heaps and min-heaps), and we don't care too much about the rest.\n* Every element in the heap must be **larger than all its children** (in a max-heap) or **smaller than all its children** (in a min-heap). This is known as the **heap property.**\n\nWhen stored in a list, there is an **important rule** to figure out how to identify parent nodes and their children: **a node's parent has an index equal to half of that node's index.** More specifically, `parentIndex = nodeIndex / 2` where `/` has floor-division properties.\n\n![Converting a heapified list into a min-heap diagram.](\u003c../../img/assets/image (60).png\u003e)\n\n## The Heapify Algorithm\n\nThe most important heap algorithm is **heapify**, which converts any non-heap list into a heap. This algorithm is vital to most heap functions like insert or remove, since these functions often break the heap structure before fixing it with heapify.\n\n**Here's how it works:**\\\n****(This example is an excerpt from my [Sorting Guide](https://docs.google.com/document/d/1dUfzdh5V3okrwFbB9o0PgtEBaLHyCqJFwpQWyQ53IeU/edit). The example provided is a max-heap \\[5,6,2,4,1].)\n\nStart with the element in the middle of the array (which is the root of the heap).\n\n![](\u003c../../img/assets/image (61).png\u003e)\n\nIf the root is smaller than either of its children (larger for a min-heap), swap it with its largest child (smallest for a max-heap).\n\n![](\u003c../../img/assets/image (62).png\u003e)\n\n\n\nIf the root was swapped, recursively call heapify on the new position. Otherwise, stop recursion.\n\nAfter heapify is complete, it should look like this:\n\n![](\u003c../../img/assets/image (63).png\u003e)\n\n## Practical Applications\n\n[Lab 9](https://inst.eecs.berkeley.edu/\\~cs61b/sp20/materials/lab/lab9/index.html) is a fantastic resource for practicing heap implementations and working with the algorithms that are needed to work with heaps (like heapify, insert, remove). Since this lab goes into plenty of detail about how each of these algorithms work, I won't explain them too much here.\n\nHeap sort relies on the heap structure to provide consistent nlogn sorting! I have more information about this on page 11 in my [sorting guide](https://docs.google.com/document/d/1dUfzdh5V3okrwFbB9o0PgtEBaLHyCqJFwpQWyQ53IeU/edit).\n","lastmodified":"2023-01-06T11:02:32.07128696Z","tags":null},"/cs61b/abstract-data-types/binary-trees/tries":{"title":"","content":"## Main Ideas\n\nA **trie** is a specific implementation of a set and is short for **retrieval tree.**\n\nIt only works on sets with a **finite alphabet**, like digits or ASCII characters, for example. The idea is that each node can act like an **array containing all characters in the alphabet** and we can just access the branches super fast by indexing into them!\n\nTries are fantastic for searching to see if a word is contained in a set. Here's an example:\n\n![This trie contains the words 'batcat', 'batman', and 'banana'.](\u003c../../img/assets/image (74).png\u003e)\n\nThis is great because it makes the `add()` and `contains()` functions run in $\\Theta(1)$ time! Additionally, it makes special string operations like prefix matching or autocomplete very efficient.\n\nWe can improve this data structure a lot- for instance, we can condense the leaves to reduce the number of nodes like this:\n\n![](\u003c../../img/assets/image (75).png\u003e)\n\nI won't go into too much detail on how to optimize it further, or how to implement the actual functions efficiently, but hopefully you'll have a good sense of how to do it yourself after learning about concepts like [Hashing and Hash Tables](../hashing.md) or [Sets](../collections/sets.md) etc.\n","lastmodified":"2023-01-06T11:02:32.07128696Z","tags":null},"/cs61b/abstract-data-types/collections/":{"title":"","content":"\n![An overview of all the Collections in Java.](\u003c../../img/assets/image (3).png\u003e)\n\n**Collection** is a Java interface for common abstract data types that store multiple items in them.\n\n## Sub-Interfaces\n\n* **Lists** are indexed sequences with duplication. The two most common types are [**ArrayLists**](arrays.md#array-lists)  and [**Linked Lists**](linked-lists.md).\n* [**Sets**](sets.md)  are non-indexed sequences with no duplication. (That is, every value in a set is unique.)\n* **Maps** are key-value pairs. See [Hashing and Hash Tables](../hashing.md) for a description on one common map implementation, the HashMap. All keys in a map must be unique, but values can be duplicated.\n* [**Stacks and Queues**](stacks-and-queues.md)  are two ordered collections that have two core behaviors:\n  * push(T x): puts x on the top.\n  * pop(): Removes the first item. (See the stacks and queues page for more information.)\n\n## Common Functions\n\n* **Membership tests** `contains()` and `containsAll()` that can determine whether or not an element is in the collection.\n* `size()` to get the number of items in the collection.\n* `isEmpty()` returns true if there is nothing in the collection.\n* `iterator()` returns an Iterator object to go through all the values in the collection.\n* `toArray()` converts the collection to a standard Java array.\n* **Optional** functions that aren't implemented in the interface: `add, addAll, clear, remove, removeAll, retainAll (intersection)`\n  * Throws `UnsupportedOperationException` if not implemented.\n","lastmodified":"2023-01-06T11:02:32.07128696Z","tags":null},"/cs61b/abstract-data-types/collections/arrays":{"title":"","content":"\n\u003e [!info] Content Note\n\u003e\n\u003e This page assumes prior knowledge of Python lists from CS61A or equivalent.\n\nArrays are a very popular data structure that stores an indexed list of data. \n\n\n![An artistic interpretation of a new int\\[5\\] {6, 1, 2, 3, 99};](\u003c../../img/assets/image (37).png\u003e)\n\n## Properties\n\n* **Fixed length:** after instantiation, the length of an array cannot be changed.\n* Every value in array is the **same type** and holds the **same amount of bits** in memory.\n* **Zero-indexed.** That means `arr[0]` returns the first value, and `arr[arr.length]` is out of bounds.\n* **No methods.** Helper methods from other libraries (like `System.arraycopy`) need to be used to manipulate arrays.\n* **Retrieval is independent of size** and takes constant time regardless of how big arrays are.\n\n## Using Arrays in Java\n\n**Instantiation:**\n\n* `int[] a = {1, 2, 3, 4, 5};` assigns values.\n* `int b = new int[3];` creates array of provided length populated with default values.\n\n**Copying**\n\n* Simply assigning `int[] c = b` will copy the **pointer** to array b! Not the values! See [Java Objects](../../oop/objects.md) for a discussion on why this is significant.\n* Use `System.arraycopy(source, start, target, startTarget, amountToCopy)` to **shallow copy** the values (or pointers) in the array. That is, if an array is holding **reference types,** only the pointers will be copied and not the actual values of the reference objects being held.\n* `System.arraycopy(b, 0, x, 3, 2)` is equivalent to `x[3:5] = b[0:2]` in Python.\n\n**Multidimensional Arrays**\n\n* `int[][] 2d = new int[4][4];`or `int[][] 2d = new int[][] {{1}, {2, 3}, {4, 5, 6}};`will create **arrays inside of an array.** This is useful for storing matrices, coordinate maps, or any other multidimensional data!\n\n**Generic Arrays**\n\n* Arrays of generic objects are NOT allowed! Use ArrayLists instead.\n* Or, this workaround can be used:`Type[] items = (Type[]) new Object[length]`\n\n## Array Lists\n\nJava has another built-in type that uses an array under the hood, which is the `ArrayList`. Here's how ArrayLists are different from normal arrays:\n\n* ArrayLists can resize arbitrarily. (They use something similar to the array case study in the [Amortization](../../asymptotics/amortization.md#what-if-we-doubled-the-size-instead-of-adding-one) page.\n* ArrayLists use [Generic Types](../../oop/generics.md) and therefore do not support primitive types like `int`.\n* ArrayLists have all behaviors expected from the [Collections](./) interface.\n","lastmodified":"2023-01-06T11:02:32.07128696Z","tags":null},"/cs61b/abstract-data-types/collections/linked-lists":{"title":"","content":"\n\u003e [!info] Content Note\n\u003e\n\u003e This page assumes prior knowledge of linked lists from CS61A or equivalent. I'll assume you have already worked with basic singly linked lists before.\n\n\nThe linked list is an extremely common recursive data structure that allows storage and access of an arbitrary amount of data.\n\n## Feature List of an Effective Linked List\n\n1. **Rebranding**- represents Node as an individual object rather than having one monolithic List type.\n2. **Bureacracy:** Create an abstraction barrier so that users do not need to know how methods or Nodes work, only how to call them.\n3. **Access Control:** Data cannot be accessed directly to prevent dangerous behavior; only the provided methods are used.\n4. **Nested Class:** Nodes are nested within the List object since other classes do not need it.\n5. **Caching:** The size of the list is incremented every time a node is added, so running size() is O(1) and traversal is not needed.\n6. **Generalizing:** A **sentinel node** represents an empty list and remains the first node of the list. When getFirst() is called, the second node is actually returned (since the first node is always the sentinel).\n7. **Doubly Linked:** Nodes have both first and last pointers for even faster traversal.\n8. **Circular list:** Sentinel last pointer points to the last value in the node, allowing for fast removeLast().\n\n![An illustration of an effective linked list.](\u003c../../img/assets/image (36).png\u003e)\n\n## Method List\n\n| Method                                                               | Description                                      | Optimal Runtime |\n| -------------------------------------------------------------------- | ------------------------------------------------ | --------------- |\n| \u003cp\u003e\u003ccode\u003eaddFirst(T x)\u003c/code\u003e\u003c/p\u003e\u003cp\u003e\u003ccode\u003eaddLast(T x)\u003c/code\u003e\u003c/p\u003e    | Adds a node to the front/back of the list.       | $\\Theta(1)$   |\n| \u003cp\u003e\u003ccode\u003egetFirst()\u003c/code\u003e\u003c/p\u003e\u003cp\u003e\u003ccode\u003egetLast()\u003c/code\u003e\u003c/p\u003e          | Gets the node at the front/back of the list.     | $\\Theta(1)$   |\n| \u003cp\u003e\u003ccode\u003eremoveFirst()\u003c/code\u003e\u003c/p\u003e\u003cp\u003e\u003ccode\u003eremoveLast()\u003c/code\u003e\u003c/p\u003e    | Removes the node at the front/back of the list.  | $\\Theta(1)$   |\n| `size()`                                                             | Returns the number of nodes in the list.         | $\\Theta(1)$   |\n| `contains(T x)`                                                      | Returns true if the list contains element `x`.   | $\\Theta(n)$   |\n| \u003cp\u003e\u003ccode\u003eadd(T x, int pos)\u003c/code\u003e\u003c/p\u003e\u003cp\u003e\u003ccode\u003eremove(T x)\u003c/code\u003e\u003c/p\u003e | Adds/remove an element at an arbitrary location. | $\\Theta(n)$   |\n\n## Limitation: Arbitrary Retrieval\n\nYou may have noticed in the chart above that it takes $\\Theta(n)$  time to retrieve arbitrary values from the list. This will get really slow if the list is large! If arbitrary values need to be accessed frequently, [Arrays](arrays.md) are much better.\n\n## The Java List Interface\n\nJava has a built-in `LinkedList` class so you don't have to implement it yourself! Read up on the [official docs](https://docs.oracle.com/javase/8/docs/api/java/util/LinkedList.html/) to learn more about the specific methods and behaviors provided.\n\n","lastmodified":"2023-01-06T11:02:32.07128696Z","tags":null},"/cs61b/abstract-data-types/collections/sets":{"title":"","content":"\n\u003e [!warning] Warning\n\u003e\n\u003e This page is incomplete. [help make it better!](contributing.md)\n\n## Basics\n\nA Set stores a collection of values with **no duplicates.** Sets have no inherent order, so you can't rely on expecting any value to come before any other value when iterating through them.\n\nSome set functions include:\n\n* `add(T x)`\n* `contains(T x)`\n* `size()`\n\n## ArraySet\n\nAn ArraySet is an array-based solution to a set implementation.\n\n* Objects get added to an array that gets [resized](../../asymptotics/amortization.md) when it's too full.\n* In order to allow for iteration, we can use one of two methods:\n  *   One method is to use **iterators** which work very similarly to Python iterators:\n\n      ```java\n      Iterator\u003cInteger\u003e seer = set.iterator();\n      while (seer.hasNext()) {\n        System.out.println(seer.next());\n      }\n      ```\n  * Another method is to implement the `Iterator` and `Iterable` interface.\n    * Iterator must implement `hasNext()` and `next()` methods\n    * Requires generic type\n    * Iterable must implement `iterator()` method which returns the Iterable object\n    * Allows usage of for/foreach loops\n","lastmodified":"2023-01-06T11:02:32.07128696Z","tags":null},"/cs61b/abstract-data-types/collections/stacks-and-queues":{"title":"","content":"\nStacks and queues are two very common data structures used for a variety of applications from [CPU processes](https://www.tutorialspoint.com/operating\\_system/os\\_processes.htm) to [finding shortest paths using Dijkstra's Algorithm](../../algorithms/shortest-paths/dijkstras-algorithm.md). Fundamentally, they are very similar in structure and **only differ by the order in which items are popped from them**.\n\n## Pushing and Popping\n\n### Pushing\n\nAdding an item to a stack or queue is called **pushing**. This will either put the item on the **top** of a stack or in the **back** of a queue.\n\nYou can think of a stack like a pile of pizza boxes- the one on the top is the first one you have to take off if you need one!\n\n![](\u003c../../img/assets/image (52).png\u003e)\n\nOn the other hand, you can think of a queue like lining up for a ride at Disneyland. The first person who gets in line will get to go first, and the last person who gets in will go last. (Of course, we all know people cut and stuff- see [Priority Queues](stacks-and-queues.md#priority-queues) to see how this is better handled.)\n\n![those lines tho](\u003c../../img/assets/image (54).png\u003e)\n\n### Popping\n\nTaking an item out of a stack or queue is called **popping.**\n\nStacks are **last in, first out (LIFO).** That means the last item that you put in will be the first item that gets popped.\n\nQueues are **first in, first out (FIFO).** That means that the first item that you put in will be the first item that gets popped.\n\n## Priority Queues\n\nLet's say you bought a VIP pass and get to cut to the front of the line for your favorite Disneyland ride! Well, a normal Queue won't be able to model this behavior since it puts everything in the back by default.\n\nA priority queue will solve this design need by introducing a new **priority** **tracking system** for each item in the queue! **If an item has a lower priority number, it will get to go first.**\n\n![gotta grab those fastpasses yEEt üéü](\u003c../../img/assets/image (53).png\u003e)\n","lastmodified":"2023-01-06T11:02:32.07128696Z","tags":null},"/cs61b/abstract-data-types/comparables-and-comparators":{"title":"","content":"\n## What is it?\n\nA **Comparable** is a **generic type** that allows standardized comparisons between objects.\n\nIn other words, anything that has a `compareTo()` method can be a Comparable!\n\nMany Java libraries already use Comparable without you knowing! Some of the more well-known ones are `Collection` and `String`.\n\n### CompareTo can't return anything you want!\n\nThere are some very specific properties CompareTo needs to have! Usually, we take them for granted but might forget about them when making our own.\n\n* If `x` and `y` are the **same object**, `y.compareTo(x)` must return **0.**\n* `x.compareTo(y)` must return the **negative** of `y.compareTo(x)`. (if one throws an error, the other must too!)\n* If `x` and `y` are the **same object**, `x.compareTo(z)` must **equal** `y.compareTo(z)` **for all z.**\n\n### Defining a Comparable subclass\n\n```java\npublic class MyComparable implements Comparable\u003cMyComparable\u003e {\n    public int foo;\n    ...\n\n    /** Instance method that has nothing to do with comparable */\n    public void doSomething() {\n        ...\n    }\n\n    /** Comparable method used to compare objects of this type */\n    public int compareTo(Object o) {\n        MyComparable mc = (MyComparable) o;\n        return ...\n    }\n}\n```\n\n## **Comparators**\n\nComparators are used instead of higher order functions in order to provide a **callback** function to methods. One example of where it is used commonly is `Collections.sort`. You can pass in a comparator here to change how items are sorted- for example, you could sort `Person` objects by their `height` variable.\n\n**The interface is as follows:**\n\n```java\npublic interface Comparable\u003cT\u003e {\n int compare(T o1, T o2);\n}\n```\n\n### How is it different from Comparables???\n\nComparable is used to compare **itself** to **other objects**; a Comparator compares **two other objects but not itself.**\n\n","lastmodified":"2023-01-06T11:02:32.07128696Z","tags":null},"/cs61b/abstract-data-types/graphs":{"title":"","content":"\n## Introduction\n\nGraphs are simply a collection of **vertices** connected by **edges.** They're very similar to trees, but are much more versatile and don't require hierarchical relationships like trees do.\n\n![A very simple graph.](\u003c../img/assets/image (55).png\u003e)\n\nFor most purposes, we will be working with **simple graphs** that follow two rules:\n\n* There are **no loops** (a connection of a node to itself).\n* There are **no parallel edges** (two edges that connect the same two vertices).\n\n![Don't make these graphs pls. Keep life simple!](\u003c../img/assets/image (56).png\u003e)\n\n## Graph Properties\n\nGraphs can be described by some properties that they could have. Here are the important ones:\n\nA graph can be **directed** if edges are arrows and have a direction, or **undirected** if you can cross edges in any direction.\n\nA graph is **cyclic** if the edges form a loop, or **acyclic** if there are no loops (like in a tree).\n\n![Direction vs. Cycles](\u003c../img/assets/image (57).png\u003e)\n\nGraphs can have **edge labels** if edges are numbered (great for distances). They can also have **vertex weights** if vertices are numbered (great for priorities or costs).\n\n![Edge labels vs. Weights](\u003c../img/assets/image (58).png\u003e)\n\nGraphs are **connected** if all of the vertices are connected with edges, such that you can freely move from one vertex to any other vertex.\n\n![](\u003c../img/assets/image (59).png\u003e)\n\n## Graph Queries\n\nHere are some cool things you can do with graphs:\n\n* Is there a path between two vertices? (s-t path)\n* What is the shortest route between two vertices? (shortest s-t path)\n* Are there cycles? (cycle detection)\n* Can you visit each vertex/edge exactly once? (Euler tour / Hamilton tour)\n* Is a graph connected? (connectivity problem)\n* Is a vertex that disconnects the graph when removed? (single point of failure / biconnectivity)\n* Are two graphs isomorphic?\n* Can a graph be drawn with no crossing edges? (planarity)\n\n## More on Graphs\n\n[Depth First Search (DFS)](../algorithms/searching/depth-first-search-dfs.md), [Breadth First Search (BFS)](../algorithms/searching/breadth-first-search-bfs.md), [Minimum Spanning Trees](../algorithms/minimum-spanning-trees/), [Shortest Paths](../algorithms/shortest-paths/), [Dijkstra's Algorithm](../algorithms/shortest-paths/dijkstras-algorithm.md), [A\\* Search](../algorithms/shortest-paths/a-search.md), [Prim's Algorithm](../algorithms/minimum-spanning-trees/prims-algorithm.md), and [Kruskal's Algorithm](../algorithms/minimum-spanning-trees/kruskals-algorithm.md) all rely on graphs. Graphs are a super useful concept!!!\n","lastmodified":"2023-01-06T11:02:32.07128696Z","tags":null},"/cs61b/abstract-data-types/hashing":{"title":"Hashing and Hash Tables","content":"\n## Data Indexed Sets: Introduction\n\nSo far, we've explored a whole bunch of ways we can store items, but they aren't really optimized for general searching. What if we could get searching in $\\Theta(1)$ time??? Wouldn't that be nice!\n\nLet's try something: **putting all of our data in a massive array.** Let's say that we know all our data falls into the range from 0 to 10,000 and make an array of 10,000 length to hold stuff.\n\n![](\u003c../img/assets/image (86).png\u003e)\n\nHere, it doesn't matter what index each item is stored in- if we want to get \"eecs\" which is stored at key 3, it will be as instantly accessible as \"haas\" which is all the way in 9998.\n\nOf course, this has a **major design flaw** that you can probably see right away. **It takes way too much memory!**\n\n## Hash Codes\n\nLet's figure out a way to get around the issue of space, but still not lose our awesome constant-time property. One way we can do this is to represent each item with a **hash code** and store them into the index with that hash code.\n\nFor instance, let's use the **first letter of a word** as the hash code. We have just turned a nearly infinite space of possibilities into something that can be stored in just **26** **buckets.**\n\n![](\u003c../img/assets/image (87).png\u003e)\n\nWhile this solution is great, it still has another **major drawback**, which can be illustrated with this example:\n\n![](\u003c../img/assets/image (88).png\u003e)\n\nIn the worst case, this just turns back into a **linked list!** That means the runtime just went from O(1) to O(n), and that's no good.\n\n## Good Hash Codes\n\nIf we can somehow create a \"good\" hash code, we can prevent things like the example above from happening because there shouldn't be a clear pattern in what buckets different objects go to. More specifically, a good hash code:\n\n* Ensures that two objects that are **equal** have the **same hash code.**\n* Ensures that **no distinguishable pattern** can be made out of hash codes from different objects.\n* Returns a **wide variety** of hash codes (not just putting everything into a single bucket, for example).\n\nLuckily, Java already handles hash code generation for us using the `hashCode()` function in the Object class. This function returns an **integer** that can be used to create good hash tables.\n\n## Dynamic Resizing\n\nLet's add another feature to our hash table: **dynamic resizing.** This means that the number of buckets will increase proportionally to the number of items in the set.\n\nOne fairly simple way to do this with a numerical hash code is to mod the hash code by the number of buckets to get which bucket an item is stored in. For example, if a item has hash code `129382981` and we have `10` buckets, then we put it in bucket `1`, or `129382981 % 10`.\n\nIn order to do this, we'll choose a **load ratio** at which to resize. This load ratio is calculated as `N/M`, where N is the number of items and M is the number of buckets. For example, a load ratio of 2 will mean the table resizes when, on average, each bucket has 2 items in it.\n\nWhen resizing, we must **recompute all the hash codes** so that we can balance out all of the buckets again.\n\nThis has some cool runtime implications that are closely related to [Amortization](../asymptotics/amortization.md). Like what happened in the dynamically resizing array, resizing hash tables like this is also a $\\Theta(1)$ operation. Nice!\n\n## Java Hash Tables\n\nIn Java, hash tables are used in the data structures `HashSet` and `HashMap` which are the most popular implementation of sets and maps.\n\nThese two implementations provide **fantastic performance** and **don't require values to be comparable** like trees do.\n\nHowever, they have a drawback that must be considered: **objects cannot be modified after they are put into the hash table.** This is because mutating an object will change its hash code, which means that the object will be lost forever since its bucket doesn't match the current hash code!\n\nIf the built-in hash code generator isn't what is needed (like you want two objects to be equal if they have the same size, for instance), you can override the `hashCode()` method. **Be careful when doing this** because `hashCode()` relies on `equals()` to find which bucket objects are in! So, if hashCode is overridden, it is highly recommended to override equals as well to ensure that they are compatible.\n","lastmodified":"2023-01-06T11:02:32.07128696Z","tags":null},"/cs61b/abstract-data-types/union-find-disjoint-sets":{"title":"Union Find (Disjoint Sets)","content":"\n# Union Find (Disjoint Sets)\n\n\u003e [!info] Content Note\n\u003e\n\u003e This is not a complete entry, because I feel like existing course materials already cover this in an extremely intuitive manner. See[ lab 14](https://inst.eecs.berkeley.edu/~cs61b/sp20/materials/lab/lab14/index.html) for an guide on how to implement your own Union Find structure!\n\nThe Union Find data structure is a way of representing a bunch of nodes that are connected to each other in subsets. It's used in [Kruskal's Algorithm](../algorithms/minimum-spanning-trees/kruskals-algorithm.md) among other things.\n\nUnion Find is named as such because it supports two functions, **find** (which returns the group that a value is contained in), and **union** (which connects two values to form a single group).\n\nUnion Find tracks each set with an ID, typically **the value of the root of each set.** In the sections below, we'll discuss how to add an item to a set, as well as figure out which set an existing item is in.\n\n## Union\n\nIn order to **join two values together,** we need to use the **union** function. Let's see what it does visually:\n\n![Calling union(1,2).](\u003c../img/assets/image (78).png\u003e)\n\nThere are lots of ways to represent this behavior. One possible method is to keep an **array of parent values** corresponding to each actual value. In the example above, for instance, we can choose 1 as our parent and make 2 fall under that. Let's see how this might work:\n\n![Parents list.](\u003c../img/assets/image (79).png\u003e)\n\nNow, let's say we call `union(3,2)`. We can just set the parent of 3 to 2, as to create a structure like this:\n\n![union(1,2) followed by union(3,2)](\u003c../img/assets/image (80).png\u003e)\n\nThis looks a lot like a tree!\n\nYou might have noticed that this looks like a **spindly tree** though, which is bad for runtime! Perhaps we can convert it to the equivalent of a bushy tree- the union function can be made much more efficient using tricks such as WeightedQuickUnion and Path Compression. Watch [this playlist](https://www.youtube.com/watch?v=JNa8BRRs8L4\\\u0026list=PL8FaHk7qbOD59HbdZE3x52KOhJJS54BlT\\\u0026index=1) for more information!\n\n## Find\n\nFirst, let's explore how to implement an efficient way to **find which set a value is in.** Using the union function from above, we can do this pretty easily with this simple algorithm:\n\n* If the parent is 0, simply return the value.\n* If the parent is not 0, return the result of calling the function on the parent value.\n\nIf we follow this algorithm on the example in the Union section, we can see that calling `find(3)` will go to `2`, then finally to `1` and return `1`.\n","lastmodified":"2023-01-06T11:02:32.07128696Z","tags":null},"/cs61b/algorithms/":{"title":"","content":"","lastmodified":"2023-01-06T11:02:32.07128696Z","tags":null},"/cs61b/algorithms/minimax":{"title":"Minimax Algorithm","content":"\n## Game Trees\n\nThe Minimax algorithm is often used for making AI's for turn-based games. It relies on the use of a type of **game tree,** which maps out all of the possible moves that players can make.\n\nIn the tree, there are two types of nodes: **maximizing nodes** and **minimizing nodes.** The max-nodes represent **you**- you want to make your position as advantageous as possible (maximizing your score). The min-nodes represent **your opponent-** they want to make you do as poorly as possible (minimizing your score).\n\nThe scores themselves are generated using a **heuristic function** that assesses the current game state and returns a number based on which player has an advantage, and to what extent. **This heuristic is totally up to you to figure out and has very few constraints.** There are a couple rules, however:\n\n* Heuristic functions must return **positive values** if you're doing better than your opponent, and **negative values** if your opponent is doing better.\n* Heuristic functions must return the **maximum value** for a state in which you won, and the **minimum value** for a state in which your opponent won.\n\nIn most games, you and your opponent will take turns, so each layer will alternate node type, like this:\n\n![](\u003c../img/assets/image (99).png\u003e)\n\nIn most games, this tree will spiral out of control because there are far too many nodes to possibly analyze (maybe even an infinite number)! Therefore, we need to set a **depth** to stop searching and compute a heuristic. For example, if the depth is **3**, it'll look something like this:\n\n![](\u003c../img/assets/image (100).png\u003e)\n\nNow that the tree has bottomed out at the heuristic layer, we can start going back up to figure out which move we should make! The rules are simple: **min-nodes take the smallest of the values** while **max-nodes take the largest of the values.** Here's the first layer, for example:\n\n![](\u003c../img/assets/image (101).png\u003e)\n\nHere's the entire tree filled out:\n\n![](\u003c../img/assets/image (102).png\u003e)\n\nAnd here's the minimax algorithm in pseudocode format:\n\n```python\ndef minimax_value(s: MinimaxNode):\n    if is_terminal(s):\n        return s.value\n    elif s.player == Maximizing:\n        return max(minimax_value(c) for c in s.children)\n    elif s.player == Minimizing:\n        return min(minimax_value(c) for c in s.children)\n```\n\n## **Alpha-Beta Pruning**\n\nWe can make our tree **even more efficient** by simply ignoring all of the branches that will lead to results that will **never be chosen.** Here, we'll assume that **both players play optimally** (choose the best move for their particular node).\n\nIn the example above, we can see that the 7 on the right will **never need to be visited** because we **already know that 5 will be chosen.**\n\nIn order to do this, we'll introduce two additional parameters, **alpha** and **beta.** Here are the rules:\n\n* **Alpha** starts out as **negative infinity** and is set by **max nodes** to their current value.\n* **Beta** starts out as **positive infinity** and is set by **min nodes** to their current value.\n* A node **passes its alpha and beta values** onto its children.\n* If **alpha is greater than beta (**$\\alpha \\ge \\beta$**),** the branch will be **pruned** (no longer visited).\n\nHere are the step-by-step instructions on how to process a node:\n\n1. Copy the alpha and beta values from the parent node. (If no parent node exists, then initialize alpha to negative infinity and beta to positive infinity.\n2. For every branch:\n   1. Recursively process the branch.\n   2. Update the current alpha/beta value depending on the value of the branch after processing. (MaxNodes can only update alpha, and MinNodes can only update beta.)\n   3. If $\\alpha \\ge \\beta$**,** then prune the rest of the branches (stop this loop).\n3. Set the value of this node to the biggest (MaxNode) or smallest (MinNode) value seen.\n\nThis is a pretty tough concept to grasp, and that's why I've illustrated how it works below. Read on!\n\n## A Story of Minimax Nodes: An Intuitive Understanding\n\nMinimax is quite difficult to understand just by studying its rules. In order to really know what's going on, we need to know why we have all of these rules and what everything represents. Here's how I think about it:\n\n![](\u003c../img/assets/image (24).png\u003e)\n\n![](\u003c../img/assets/image (25).png\u003e)\n\n![](\u003c../img/assets/image (27).png\u003e)\n\n![](\u003c../img/assets/image (28).png\u003e)\n\n![](\u003c../img/assets/image (29).png\u003e)\n\n![](\u003c../img/assets/image (30).png\u003e)\n\n![](\u003c../img/assets/image (31).png\u003e)\n\n![](\u003c../img/assets/image (33).png\u003e)\n\n_NOTE: The 5's in the above image should all be 7's. This will be corrected soon (tm)._\n\n\n\n## Practice Problems\n\n{{\u003c tabs \"minimax-q1\" \u003e}}\n{{\u003c tab \"Question 1\" \u003e}}\nHere's a tree. Figure out:\n\n* What values each of the nodes report\n* Which branches are pruned\n* The alpha and beta values at each visited node\n\n![](\u003c../img/assets/image (34).png\u003e)\n{{\u003c /tab \u003e}}\n\n{{% tab \"Q1 Answer\" %}}\nHere's my answer! The green arrows denote the order in which the nodes are visited. Note that the branches are pruned every time **alpha is greater than beta.**\n\n![](\u003c../img/assets/image (35).png\u003e)\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\nThis was just an ordinary problem and **might not be enough to ensure that you fully understand minimax trees**! Here are some checks you can do to ensure that your understanding is strong:\n\n* Figure out what the tree returns and prunes intuitively _without_ finding any alpha or beta values.\n* Make your own minimax tree problem like the one above and solve it. Are you confident in your answer (since no answer key exists)?\n* Make a minimax tree that's missing some values, and try to find all possible values that fit in there such that the branch will become pruned.\n* Implement the minimax algorithm in Java.\n","lastmodified":"2023-01-06T11:02:32.07128696Z","tags":null},"/cs61b/algorithms/minimum-spanning-trees/":{"title":"","content":"\n## Spanning Tree Definition\n\nA **spanning tree** $T$ is a subgraph of a graph $G$ where $T$:\n\n* Is connected (there's a path to every vertex)\n* Is acyclic (no cycles)\n* Includes every vertex (spanning property)\n\n**Notice:** the first two properties defines a tree structure, and the last property makes the tree spanning.\n\nA **minimum spanning tree** is a spanning tree with minimum total edge weight.\n\nExample: I want to connect an entire town with wiring and would like to find the optimal wiring connection that connects everyone but uses the least wire.\n\n## MST vs. Shortest Path Tree\n\nIn contrast to a shortest path tree, which is essentially the solution tree to running Dijkstra‚Äôs with root node = source vertex, a MST has no source. However, it is possible for the MST to be the same as the SPT.\n\nWe can think of the MST as a global property for the entire graph, as opposed to SPT which depends on which node is the source node.\n\nIf the edges of the graph are not unique, there‚Äôs a chance that the MST is not unique.\n\n## Cuts Property\n\n* A **cut** is defined as assigning the nodes in a graph into two sets.\n* A **crossing edge** is an edge that connects two nodes that are in different sets\n* The smallest crossing edge is the crossing edge with smallest weight\n\nThe **Cut Property** states that the smallest crossing edge is always going to be in the MST, no matter how the cut is made.\n\n![](\u003c../../img/assets/image (109).png\u003e)","lastmodified":"2023-01-06T11:02:32.07128696Z","tags":null},"/cs61b/algorithms/minimum-spanning-trees/kruskals-algorithm":{"title":"Kruskal's Algorithm","content":"\n\u003e [!info] Content Note\n\u003e\n\u003e Before reading, review [Minimum Spanning Trees](./) and [Union Find (Disjoint Sets)](../../abstract-data-types/union-find-disjoint-sets.md) as they both make Kruskal's algorithm possible!\n\n\n## Conceptual Overview\n\nKruskal's algorithm is another optimal way to construct a **minimum spanning tree**. It's benefits are that it is conceptually very simple, and easy to implement. The idea is that first we sort all the edges of the graph in order of increasing weight. Then, add the smallest edge to the MST we are constructing unless this creates a cycle in the MST. Repeat until V - 1 edges total.\n\n## Detailed Breakdown\n\nIn order to optimally check if adding an edge to our MST creates a cycle, we will use a **WeightedQuickUnion** object. (See [Union Find (Disjoint Sets)](../../abstract-data-types/union-find-disjoint-sets.md) for a recap on what this is.) This is used because checking if a cycle exists using a WeightedUnionFind object boils down to one `isConnected()` call, which we know takes $\\Theta(\\log(N))$.\n\nTo run the algorithm, we start by adding all the edges into a [PriorityQueue](../../abstract-data-types/collections/stacks-and-queues.md). This gives us our edges in sorted order. Now, we iterate through the PriorityQueue by removing the edge with highest priority, checking if adding it forms a cycle, and adding it to our MST if it doesn't form a cycle.\n\nLet's see an example of Kruskal's Algorithm in action!\n\nHere, we start with a simple graph and have sorted all of its edges into a priority queue.\n\n![](\u003c../../img/assets/image (103).png\u003e)\n\nSince the edge **DE** is the shortest, we'll add that to our UnionFind first. In the process, we'll **remove DE from the priority queue.**\n\n![](\u003c../../img/assets/image (104).png\u003e)\n\nWe'll do the same thing with the next shortest path, **DC.**\n\n![](\u003c../../img/assets/image (105).png\u003e)\n\nNow, let's move on to **AB.** Notice that this time, connecting A and B creates another **disjoint set!** Unlike Prim's Algorithm, Kruskal's Algorithm does not guarantee that a solution will form a tree structure until the very end.\n\n![](\u003c../../img/assets/image (106).png\u003e)\n\nNow, let's connect **BC.**\n\n![](\u003c../../img/assets/image (107).png\u003e)\n\nSince **CE** and **BD** would both form cycles if connected, **we are done üòÑ** Here's the final tree:\n\n![](\u003c../../img/assets/image (108).png\u003e)\n\n## PseudoCode\n\n```java\npublic class Kruskals() {\n\n    public Kruskals() {\n        PQ edges = new PriorityQueue\u003c\u003e();\n        ArrayList\u003cEdge\u003e mst = new ArrayList\u003c\u003e();\n    }\n\n    public void doKruskals(Graph G) {\n        for (e : G.edges()) {\n            PQ.add(e);\n        }\n        WeightedQU uf = new WeightedQU(G.V());\n        Edge e = PQ.removeSmallest();\n        int v = e.from();\n        int w = e.to();\n        if (!uf.isConnected(v, w)) {\n            uf.union(v, w);\n            mst.add(e);\n        }\n\n    }\n}\n```\n\n## Runtime Analysis\n\nLeft as an exercise to the reader üòâ\n\n{% hint style=\"info\" %}\nSomeone's been reading too much [LADR](https://www.springer.com/gp/book/9783319110790)...\\\n(The answer is $\\Theta(E\\log(E))$by the way. Try to convince yourself why!)\n{% endhint %}\n","lastmodified":"2023-01-06T11:02:32.07128696Z","tags":null},"/cs61b/algorithms/minimum-spanning-trees/prims-algorithm":{"title":"Prim's Algorithm","content":"\n\u003e [!info] Content Note\n\u003e\n\u003e Before reading, review [Minimum Spanning Trees](./), as that is the foundation of Prim's algorithm!\n\n## Conceptual Overview\n\nPrim's algorithm is an optimal way to construct a **minimum spanning tree**. It basically starts from an arbitrary vertex, then considers all its immediate neighbors and picks the edge with smallest weight to be part of the MST. **Note:** this creates a cut in the graph, where the two nodes in the MST being constructed are in one set, and every other vertex of the graph is in another set.\n\nNow, the edges taken into consideration include all immediate neighbors of every node in the MST. Add the edge that has the smallest weight to the MST. Repeat until every vertex has been visited. The result is an MST for the graph.\n\n## Detailed Breakdown\n\nThe way Prim's algorithm is usually implemented is via [PriorityQueue](../../abstract-data-types/collections/stacks-and-queues.md), `edgeTo` array, and` distTo` array. You will soon see its similarities to [Dijkstra's](../shortest-paths/dijkstras-algorithm.md).\n\nFirst, insert all vertices into the PriorityQueue, storing vertices in order of **distance from MST**. Then, remove vertex with highest priority in the PriorityQueue and relax its edges. In each of these iterations, the distTo and edgeTo arrays will be updated for each vertex v if the **weight of the edge is smaller than the current value in distTo\\[v]**. In other words, only update if the distance from the MST to the vertex is the best seen so far. This is a very important point, and is one of the subtleties that makes Prim's algorithm fundamentally different from Dijkstra's.\n\n## Useful Properties/Invariants\n\nThe MST under construction is **always connected.**\n\n## Pseudocode\n\n```java\npublic class Prims() {\n\n    public Prims() {\n        PQ = new PriorityQueue\u003c\u003e();\n        edgeTo = new Edge[numVertices];\n        distTo = new Dist[numVertices];\n        marked = new boolean[numVertices];\n    }\n\n    public void doPrims() {\n        PQ.add(sourceVertex, 0);\n        for(v : allOtherVertices) {\n            PQ.add(v, INFINITY);\n        }\n        while (!PQ.isEmpty()) {\n            Vertex p = PQ.removeSmallest();\n            marked[p] = true;\n            relax(p);\n        }\n    }\n\n    public void relax(Vertex p) {\n        for (q : p.neighbors()) {\n            if (marked[q]) { continue; }\n            if (q.edgeWeight \u003c distTo[q]) {\n                distTo[q] = q.edgeWeigth;\n                edgeTo[q] = p;\n                PQ.changePriority(q, distTo[q]);\n            }\n        }\n    }\n}\n```\n\nLooking at this pseudocode, the resemblance to Dijkstra's makes them seem nearly identical. But hopefully you've read the conceptual overviews first, and you understand the remarkable subtlety that leads to two very fundamentally different algorithms.\n\n## Runtime Analysis\n\nThis is the same as for Dijkstra's Algorithm.\n\n**Unsimplified:**\n\n$\n\\theta(V * log(V) + V * log(V) + E * log(V))\n$\n\n**Simplified:**\n\n$\n\\theta(E * log(V))\n$\n\n**Explanation:**\n\n* each add operation to PQ takes log(V), and perform this V times\n* each removeFirst operation to PQ takes log(V) and perform this V times\n* each change priority operation to PQ takes log(V), perform this at most as many times as there are edges\n* everything else = O(1)\n* usually, there are more or equal edges compared to the number of vertices.\n\n## Demo\n\n[https://docs.google.com/presentation/d/1GPizbySYMsUhnXSXKvbqV4UhPCvrt750MiqPPgU-eCY/edit#slide=id.g9a60b2f52\\_0\\_0](https://docs.google.com/presentation/d/1GPizbySYMsUhnXSXKvbqV4UhPCvrt750MiqPPgU-eCY/edit#slide=id.g9a60b2f52\\_0\\_0)\n","lastmodified":"2023-01-06T11:02:32.07128696Z","tags":null},"/cs61b/algorithms/searching/":{"title":"","content":"\nThis section will cover some ways to find values in a set.\n\n{{\u003c section \u003e}}","lastmodified":"2023-01-06T11:02:32.075286962Z","tags":null},"/cs61b/algorithms/searching/binary-search":{"title":"","content":"# Binary Search\n\nBinary search is a way of finding a specific node in a tree. It only works on [binary trees](../../abstract-data-types/binary-trees/) due to its helpful sorted property. It simply traverses the tree, moving left if the current node is too large or right if it is too small.\n\nBinary search runs in $\\Theta(\\log(n))$ time for bushy trees, which is also the number of layers in a tree.\n\n## The Algorithm\n\n```java\npublic BST find(BST T, Key sk) {\n    if (T == null) {\n        return null;\n    }\n    if (sk.equals(T.key)) {\n        return T;\n    } else if (sk \u003c T.key) {\n        return find(T.left, sk);\n    } else {\n        return find(T.right, sk);\n    }\n}\n```\n","lastmodified":"2023-01-06T11:02:32.075286962Z","tags":null},"/cs61b/algorithms/searching/breadth-first-search-bfs":{"title":"Breadth First Search (DFS)","content":"\nBreadth First Search (BFS), like [Depth First Search (DFS)](depth-first-search-dfs.md), is a method of **traversing a graph.** BFS simply traverses in a different order, but otherwise is very similar to DFS.\n\nThe main difference is that BFS **visits all children before any subgraphs.** In a tree, we call this **level order.**\n\n![](\u003c../../img/assets/image (110).png\u003e)\n\nFor the example tree above, a level order traversal would go in this order: **D B F A C E G.**\n\n## Step by Step\n\n**Let's see how we might implement BFS.**\n\nSome data structures we will need are:\n\n* A graph to traverse.\n* A queue **Q** to keep track of which nodes need to be processed next.\n* A list of booleans **marked** to keep track of which nodes were already visited.\n* (Optional) **edgeTo** and **distTo** to keep track of information that might be useful for other applications (like [Dijkstra's Algorithm](../shortest-paths/dijkstras-algorithm.md)).\n\nFirst, let's start with a vertex in the graph by marking it and adding it to the queue.\n\n![](\u003c../../img/assets/image (111).png\u003e)\n\nThe next step is to **remove A from the queue** and **add its children** (B and C) **to the queue.** Also, we need to **mark all of the children.**\n\n![](\u003c../../img/assets/image (112).png\u003e)\n\nNext, we'll move onto the **next item on the queue** (B). We'll do the same thing that we did with A: remove B, mark all its children, and add its children to the queue. **Since C is already marked, we do not add it to the queue again.**\n\n![](\u003c../../img/assets/image (113).png\u003e)\n\nNow, we'll move on to the next item on the queue, C, and do the same thing. Again, we won't add C or A because they are both marked.\n\n![](\u003c../../img/assets/image (114).png\u003e)\n\nFinally, we'll visit the two remaining nodes in the queue, D and E. Since all of the nodes are marked now, there aren't any other nodes to visit.\n\n","lastmodified":"2023-01-06T11:02:32.075286962Z","tags":null},"/cs61b/algorithms/searching/depth-first-search-dfs":{"title":"Depth First Search (DFS)","content":"\n## Depth First Traversal\n\nBefore we move on to searching, let's talk about **traversing. Traversal** is the act of **visiting nodes in a specific order.** This can be done either in trees or in graphs.\n\nFor trees in particular, there are **three main ways** to traverse.\n\n![The example tree we will use for traversal illustrations.](\u003c../../img/assets/image (89).png\u003e)\n\nThe first way is **inorder** traversal, which visits **all left children**, then **the node itself,** then **all right children.** The end result should be that the nodes were visited in **sorted order.**\n\nThe second way is **preorder** traversal, which visits **the node itself first,** then **all left children,** then **all right children.** This method is useful for applications such as printing a directory tree structure.\n\nThe third way is **postorder** traversal, which visits **all left children,** then **all right children,** then **finally the node itself.** This method is useful for when operations need to be done on all children before the result can be read in the node, for instance getting the sizes of all items in the folder.\n\nHere are some pseudocodey algorithms for tree traversals.\n\n```java\n// INORDER will print A B C D E F G\nvoid inOrder(Node x) {\n    if (x == null) return;\n    inOrder(x.left);\n    print(x);\n    inOrder(x.right);\n}\n\n// PREORDER will print D B A C F E G\nvoid preOrder(Node x) {\n    if (x == null) return;\n    print(x);\n    preOrder(x.left);\n    preOrder(x.right);\n}\n\n// PREORDER will print A C B E G F D\nvoid postOrder(Node x) {\n    if (x == null) return;\n    preOrder(x.left);\n    preOrder(x.right);\n    print(x);\n}\n```\n\n## Depth First Search in Graphs\n\nGraphs are a little more complicated to traverse due to the fact that they could have **cycles** in them, unlike trees. This means that we need to **keep track of all the nodes already visited** and add to that list whenever we encounter a new node.\n\nDepth First Search is great for determining if everything in a graph is connected.\n\nHere's an outline of how this might go:\n\n* Keep an array of 'marks' (true if node has been visited) and, optionally, an edgeTo array that will automatically keep track of how to get to each connected node from a source node\n* When each vertex is visited:\n  * Mark the vertex\n  * For each adjacent unmarked vertex:\n    * Set edgeTo of that vertex equal to this current vertex\n    * Call the recursive method on that vertex\n\nLike trees, DFS can be done **inorder, preorder, or postorder.** It's nearly identical behavior to trees, with the addition of the marks array.\n","lastmodified":"2023-01-06T11:02:32.075286962Z","tags":null},"/cs61b/algorithms/shortest-paths/":{"title":"","content":"\nWe've seen that Breadth-First Search can help us find the shortest path in an unweighted graph, where the shortest path was just defined to be the fewest number of edges traveled along a path. In the following shortest-paths algorithms, we will discover how we can generalize the breadth-first traversal to find the path with the lowest total cost, where the cost is determined by different weights on the edges.","lastmodified":"2023-01-06T11:02:32.075286962Z","tags":null},"/cs61b/algorithms/shortest-paths/a-search":{"title":"A* Search","content":"\n\u003e [!info] Content Note\n\u003e\n\u003e In order to understand A\\*, you'll need to be comfortable [Dijkstra's Algorithm](dijkstras-algorithm.md) first!\n\n\n## A\\* Algorithm\n\nThe A\\* Search Algorithm is **incredibly similar to Dijkstra's Algorithm** with one addition: a **heuristic function.**\n\nThis heuristic function calculates weights of a path **from a vertex to a goal vertex.** This way, we can help bias our algorithm in the right direction so that it doesn‚Äôt make a bunch of bad moves.\n\nThis has an important implication: **not all vertices get visited.** The algorithm only cares about finding the best path to the goal, and not any other vertex (assuming we design our heuristic well).\n\nThe **order** that the vertices get visited is lowest **distance + heuristic**. This is basically the same as Dijkstra's, just with that added heuristic term.\n\n## What's a good heuristic?\n\nHeuristic functions can be really tricky to design, since there isn't much to go off of.\n\n**A good heuristic has these two properties:**\n\n* **Admissible** - heuristic of each vertex returns a cost that is \u003c= the true cost/distance i.e. h(A) \u003c= cost(A, goal)\n* **Consistent** - difference between heuristics of two vertices \u003c= true cost between them i.e. h(A) - h(B) \u003c= cost(A, B)\n\n## **Want more?**\n\n[Here's a cool demo!](https://docs.google.com/presentation/d/177bRUTdCa60fjExdr9eO04NHm0MRfPtCzvEup1iMccM/edit#slide=id.g369665031c\\_0\\_350)\n\n","lastmodified":"2023-01-06T11:02:32.075286962Z","tags":null},"/cs61b/algorithms/shortest-paths/dijkstras-algorithm":{"title":"Dijkstra's Algorithm","content":"\n\u003e [!info] Content Note\n\u003e\n\u003e Before continuing, make sure you're comfortable with [Graphs](../../abstract-data-types/graphs.md), [Stacks and Queues](../../abstract-data-types/collections/stacks-and-queues.md), and [Shortest Paths](./).\n\n\n## One sentence overview\n\nVisit vertices in order of best-known distance from source; on visit, relax every edge from the visited vertex.\n\n## Detailed Breakdown\n\nDjikstras uses a **PriorityQueue** to maintain the path with lowest cost from the starting node to every other node, an **edgeTo** array to keep track of the best known predecessor for each vertex, and a **distTo** array to keep track of the best known distance from the source vertex to every other vertex.\n\n**Relaxing** the edges of a vertex v just refers to the process of updating edgeTo\\[n] for each neighbor n to v.\n\nYou'll see in the pseudocode and diagrams below that succesful relaxation only occurs when the edge connecting the vertex being visited to one of its neighbors yields a smaller total distance than the current shortest path to that neighboring vertex that the algorithm has seen.\n\nNow, here's a demonstration on how it works! Let's start out with this graph:\n\n![](\u003c../../img/assets/image (92).png\u003e)\n\nWe'll start at node A and try to figure out the shortest path from A to each node. Since we have no idea how far each node is, we'll take the conservative guess that everything is infinitely far away ‚ôæüòé\n\nThe first thing we have to do is update A's adjacent nodes, which are **B** and **D**. Since there's only one known path to each, it shouldn't be too hard to see why we need to update the values below. One thing to note is that the priority queue **sorts the vertices by the distance it takes to get there.**\n\n![](\u003c../../img/assets/image (93).png\u003e)\n\nNow, we have a choice to move on to either **B** or **D**. Since B has a **shorter distance,** we'll move on to that first. When we move on, we have to **remove that value from the priority queue** and **update all of its neighbors.** Here, we see that going from **B to D** is **shorter** than **A to D**, so we have to **update distTo AND edgeTo of D** to reflect this new, shorter path. **This process** (updating each adjacent node) **is called relaxing the edges of a node.**\n\n![](\u003c../../img/assets/image (94).png\u003e)\n\nNow, let's move onto **D** since it has the next shortest path. Again, we **remove D from the priority queue** and **relax C** since we found a shorter path.\n\n![](\u003c../../img/assets/image (95).png\u003e)\n\nFinally, we'll move onto **C** as that has the next shortest path in the priority queue. This will reveal our final node, **E**.\n\n![](\u003c../../img/assets/image (96).png\u003e)\n\nSince **the priority queue is now empty,** our search is done! üòÑ Here's what the final solution looks like **in a tree form**:\n\n![Dijkstra's Algorithm ALWAYS produces a solution in a tree format.](\u003c../../img/assets/image (98).png\u003e)\n\nIt's a very spindly tree indeed, but hopefully it demonstrates that the result is **acyclic**.\n\n## Properties of Dijkstra's Algorithm\n\n**Dijkstra's Algorithm has some invariants (things that must always be true):**\n\n1. edgeTo\\[v] always contains best known predecessor for v\n2. distTo\\[v] contains best known distance from source to v\n3. PQ contains all unvisited vertices in order of distTo\n\n**Additionally, there are some properties that are good to know:**\n\n* always visits vertices **in order of total distance from source**\n* relaxation always **fails on edges to visited vertices**\n* guarantees to work optimally **as long as** **edges are all non-negative**\n* solution always creates a **tree form.**\n* can think of as **union of shortest paths to all vertices**\n* **edges in solution tree always has V-1 edges**, where V = the number of vertices. This is because every vertex in the tree except the root should have **exactly one input.**\n\n## Pseudocode\n\n```java\npublic Class Djikstra() {\n\n    public Djikstra() {\n        PQ = new PriorityQueue\u003c\u003e();\n        distTo = new Distance[numVertices];\n        edgeTo = new Edge[numVertices];\n    }\n\n    public void doDijkstras(Vertex sourceVertex) {\n        PQ.add(sourceVertex, 0);\n        for(v : allOtherVertices) {\n            PQ.add(v, INFINITY);\n        }\n        while (!PQ.isEmpty()) {\n            Vertex p = PQ.removeSmallest();\n            relax(p);\n        }\n    }\n    // Relaxes all edges of p\n    void relax(Vertex p) {\n        for (q : p.neighbors()) {\n            if (distTo[p] + q.edgeWeight \u003c distTo[q]) {\n                distTo[q] = distTo[p] + q.edgeWeight;\n                edgeTo[q] = p;\n                PQ.changePriority(q, distTo[q]);\n            }\n        }\n    }\n}\n```\n\n## Runtime Analysis\n\n**Unsimplified:**\n\n$\n\\theta(V * log(V) + V * log(V) + E * log(V))\n$\n\n**Simplified:**\n\n$\n\\theta(E * log(V))\n$\n\n**Explanation:**\n\n* each add operation to PQ takes log(V), and perform this V times\n* each removeFirst operation to PQ takes log(V) and perform this V times\n* each change priority operation to PQ takes log(V), perform this at most as many times as there are edges\n* everything else = O(1)\n* usually, there are more or equal edges compared to the number of vertices.\n","lastmodified":"2023-01-06T11:02:32.075286962Z","tags":null},"/cs61b/algorithms/sorting":{"title":"Sorting","content":"\n\u003e [!important] Sorting Guide\n\u003e\n\u003e For more information about specific sorting algorithms covered in 61B, see my [guide on sorting](https://docs.google.com/document/d/1dUfzdh5V3okrwFbB9o0PgtEBaLHyCqJFwpQWyQ53IeU/edit) that covers all of the sorts in far greater detail üôÇ\n\n## Why sort?\n\n* It makes searching for a specific value much faster (e.g. binary search). Typically, searching through an unsorted list requires a full scan ($\\Theta(N)$‚Äã runtime).\n* It's easy to see if two items in list are equal: just compare to see if any neighboring values are the same.\n\n## Properties of a Sorting Algorithm\n\nA sorting algorithm changes a sequence based on a **total order.** A total order is:\n\n* **Total:** All items can be compared with one another\n* **Reflexive:** An item can be compared to itself\n* **Antisymmetric:** x \u003c= y AND y \u003c= x IFF y == x\n* **Transitive:** If x \u003c= y and y \u003c= z, then x must be \u003c= z\n\nA sorting algorithm could be **stable** if it does not change relative order of equivalent entries. For example, if Bob and I both owned Toyota Corollas, and the list of cars were sorted by model, if Bob's car came before mine originally it must also come before mine in the sorted list after a stable sort.\n\n\n\n## Sorting Algorithm Classifications\n\n* **Internal sort:** Keeps all data in primary memory\n* vs. **External sort:** Processes data in batches, then merges them together at the end\n* **Comparison-based sort:** The only thing we know about keys are their relative orders\n* **Radix sort:** Uses information other than keys\n* **Insertion sort:** Insert items at their appropriate positions one at a time\n* **Selection sort:** Chooses items and places them in order\n\n## Sorting in Java\n\nJava automatically chooses the best sorting algorithm for a given list if you call the `Arrays.sort` method.\n\n```java\nString[] x = new String[] {\"Vat\", \"Bat\", \"Cat\"};\n\nArrays.sort(x); // mutates x into Bat, Cat, Vat\nArrays.sort(x, Collections.reverseOrder()); // mutates x into Vat, Cat, Bat\nArrays.sort(x, 0, 2) // sorts the first two elements, leaving the rest unchanged (Cat, Vat, Bat)\n```\n\n## Inversions\n\nInversions are used as a measure for how sorted a list is. For every two elements that are swapped compared to a sorted list, we add one inversion.\n\n* As an example, if `1 2 3 4 5` is a sorted list, `1 4 3 2 5` would have one inversion (`4` and `2` are swapped).\n* 0 inversions mean a list is perfectly sorted.\n* In the worst case, a reversed list will have $(N \\cdot (N-1))/2$ inversions.\n\n## The Guide to Sorting Algorithms\n\n[A comprehensive guide to sorting algorithms, now with memes!](https://docs.google.com/document/d/1dUfzdh5V3okrwFbB9o0PgtEBaLHyCqJFwpQWyQ53IeU/edit)\n","lastmodified":"2023-01-06T11:02:32.075286962Z","tags":null},"/cs61b/asymptotics/":{"title":"","content":"","lastmodified":"2023-01-06T11:02:32.075286962Z","tags":null},"/cs61b/asymptotics/amortization":{"title":"","content":"# Amortization\n\n\u003e [!info] Content Note\n\u003e\n\u003e Please read [Asymptotic Analysis Basics](asymptotics.md) first. If you don't, none of this will make any sense!\n\n**Amortization** means **spreading out.**\n\nSometimes, an operation takes different amounts of time for different values of $n$. Rather than having to report runtimes for each different case, we can instead average all of them out and report the **amortized runtime.**\n\nThis is especially good for functions where most actions have a low cost, but a few have a high cost. We'll see an example of this further down the page!\n\n## A Case Study: Resizing Arrays\n\nAs you probably know, normal Java arrays don't resize. If we create a `new int[5]` then that array will always have a length of 5.\n\nBut what if we wanted to make an array resize itself every time it reaches capacity? (Like a `List`!) Let's see what happens when we **add one to the array size:**\n\nFirst, we have to make a new array with a new size:\n\n![](\u003c../img/assets/image (16).png\u003e)\n\nThen, we have to copy over all of the old elements over:\n\n![](\u003c../img/assets/image (17).png\u003e)\n\nFinally, we can add in the new element!\n\n![](\u003c../img/assets/image (19).png\u003e)\n\n**Let's analyze the runtime of this operation.**\n\n* A single resizing will take $\\Theta(n)$ time.\n* Adding a single element will take $\\Theta(1)$ time.\n* Together, a single operation will take $\\Theta(n+1)$ time, which simplifies into  $\\Theta(n)$ .\n* Since we're doing a n-operation n times, **the end result is a resizing function that is**$\\Theta(n^2)$. **We can do better with the power of amortization!**\n\n### **What if we doubled the size instead of adding one?**\n\n* A single resizing will take $\\Theta(2n)$ time \\_\\*\\*\\_which simplifies into $\\Theta(n)$ time.\n  * We do this every time the array hits a power of 2 (2, 4, 8, 16, 32 ...).\n* Adding a single element will take $\\Theta(1)$ time.\n  * We do this every time we add a new element, so in all we add n elements. Therefore, this is an\n    * $\\Theta(n)$operation.\n\n**Therefore, the unsimplified function is:** $\\Theta(n + (2 + 4 + 8 ... +2^i))$ where $2^i$ is the largest power of two less than n. This might not seem clear on its own, so let's rewrite it:\n\n$\n\\theta(n + (\\frac{n}{2} + \\frac{n}{4} + ... + 8 + 4 + 2))\n$\n\nIntuitively, this looks like this:\n\n![](\u003c../img/assets/image (39).png\u003e)\n\nMathematically, it looks like this:\n\n$\nn + n\\sum_{n=1}^{n}(\\frac{1}{2})^n\n$\n\nWhich simplifies to $2n$if you recall your power series properties . **Therefore, this approach is** $\\Theta(n)$ **!!**\n\n![](\u003c../img/assets/image (116).png\u003e)\n\n\n\n\n\n","lastmodified":"2023-01-06T11:02:32.075286962Z","tags":null},"/cs61b/asymptotics/asymptotics":{"title":"Asymptotic Analysis Basics","content":"\n\u003e [!info] Content Note\n\u003e\n\u003e This concept is a big reason why a strong math background is helpful for computer science, even when it's not obvious that there are connections! Make sure you're comfortable with Calculus concepts up to [power series](http://tutorial.math.lamar.edu/Classes/CalcII/PowerSeries.aspx).\n\n\n## An Abstract Introduction to Asymptotic Analysis\n\nThe term **asymptotics,** or **asymptotic analysis,** refers to the idea of **analyzing functions when their inputs get really big.** This is like the **asymptotes** you might remember learning in math classes, where functions approach a value when they get very large inputs.\n\n![](\u003c../img/assets/image (13).png\u003e)\n\nHere, we can see that $y= \\dfrac{x^3}{x^2 + 1}$ looks basically identical to $y = x$ when x gets really big. Asymptotics is all about reducing functions to their eventual behaviors exactly like this!\n\n## That's cool, but how is it useful?\n\nGraphs and functions are great and all, but at this point it's still a mystery as to how we can use these concepts for more practical uses. Now, we'll see how we can **represent programs as mathematical functions** so that we can do cool things like:\n\n* **Figure out how much time or space a program will use**\n* **Objectively tell how one program is better than another program**\n* **Choose the optimal data structures for a specific purpose**\n\nAs you can see, this concept is **absolutely fundamental** to ensuring that you write **efficient algorithms** and choose the **correct data structures.** With the power of asymptotics, you can figure out if a program will take 100 seconds or 100 years to run without actually running it!\n\n## How to Measure Programs\n\nIn order to convert your `public static void Main(String[] args)` or whatever into `y = log(x)`, we need to figure out what `x` and `y` even represent!\n\n**TLDR:** It depends, but the three most common measurements are **time, space,** and **complexity**.\n\n**Time** is almost always useful to minimize because it could mean the difference between a program being able to run on a smartphone and needing a supercomputer. Time usually increases with the **number of operations** being run. Loops and recursion will increase this metric substantially. On Linux, the `time` command can be used for measuring this.\n\n**Space** is also often nice to reduce, but has become a smaller concern now that we can get terabytes (or even petabytes) of storage pretty easily! Usually, the things that take up lots of space are **big lists** and **a very large number of individual objects.** Reducing the size of lists to hold only what you need will be very helpful for this metric!\n\nThere is another common metric, which is known as **complexity** or **computational cost.** This is a less concrete concept compared to time or space, and cannot be measured easily; however, it is highly generalized and usually easier to think about. For complexity, we can simply assign basic operations (like println, adding, absolute value) a complexity of **1** and add up how many basic operation calls there are in a program.\n\n## Simplifying Functions\n\nSince we **only care about the general shape of the function,** we can keep things as simple as possible! Here are the main rules:\n\n* **Only keep the** **fastest growing term.** For example,  $log(n) + n$ can be simplified to just $n$since $n$ grows faster out of the two terms.\n* **Remove all constants.** For example,  $5log(3n)$ can just be simplified to $log(n)$since constants don't change the overall shape of a function.\n* **Remove all other variables.** If a function is really $log(n + m)$ but we only care about n, then we can simply it into  $log(n)$.\n\nThere are two cases where we can't remove other variables and constants though, and they are:\n\n* A polynomial term $n^c$(because $n^2$grows slower than $n^3$, for example), and\n* An exponential term $c^n$(because $2^n$grows slower than $3^n$, for example).\n\n## The Big Bounds\n\nThere are **three** important types of runtime bounds that can be used to describe functions. These bounds put restrictions on how slow or fast we can expect that function to grow!\n\n**Big O** is an **upper bound** for a function growth rate. That means that **the function grows slower or the same rate as the Big O function.** For example, a valid Big O bound for $log(n) + n$ is $O(n^2)$ since $n^2$ grows at a faster rate.\n\n**Big Omega** is a **lower bound** for a function growth rate. That means that **the function grows faster or the same rate as the Big Omega function.** For example, a valid Big Omega bound for  $log(n) + n$ is $\\Omega(1)$ since $1$ (a constant) grows at a slower rate.\n\n**Big Theta** is a **middle ground** that describes the function that grows at the **same rate** as the actual function. **Big Theta only exists if there is a valid Big O that is equal to a valid Big Omega.** For example, a valid Big Theta bound for  $log(n) + n$ is $\\Theta(n)$ since $n$ grows at the same rate (log n is much slower so it adds an insignificant amount).\n\n\n\n![A comparison of the three bounds.](\u003c../img/assets/image (15).png\u003e)\n\n## Orders of Growth\n\nThere are some **common functions** that many runtimes will simply into. Here they are, from fastest to slowest:\n\n| Function              | Name        | Examples                                               |\n| --------------------- | ----------- | ------------------------------------------------------ |\n| $\\Theta(1)$         | Constant    | System.out.println, +, array accessing                 |\n| $\\Theta(\\log(n))$   | Log         | Binary search                                          |\n| $\\Theta(n)$         | Linear      | Iterating through each element of a list               |\n| $\\Theta(n\\log(n))$  | nlogn üòÖ    | Quicksort, merge sort                                  |\n| $\\Theta(n^2)$       | Quadratic   | Bubble sort, nested for loops                          |\n| $\\Theta(2^n)$       | Exponential | Finding all possible subsets of a list, tree recursion |\n| $\\Theta(n!)$        | Factorial   | Bogo sort, getting all permutations of a list          |\n| $\\Theta(n^n)$       | n^n üòÖüòÖ    | [Tetration](https://en.wikipedia.org/wiki/Tetration)   |\n\nDon't worry about the examples you aren't familiar with- I will go into much more detail on their respective pages.\n\n![Source: bigocheatsheat.com. Check it out, it's great!](\u003c../img/assets/image (14).png\u003e)\n\n## Asymptotic Analysis: Step by Step\n\n1. Identify the function that needs to be analyzed.\n2. Identify the parameter to use as $n$.\n3. Identify the measurement that needs to be taken. (Time, space, etc.)\n4. Generate a function that represents the complexity. If you need help with this step, [try some problems!](asymptotics-practice.md)\n5. [Simplify](asymptotics.md#simplifying-functions) the function (remove constants, smaller terms, and other variables).\n6. Select the correct bounds (O, Omega, Theta) for particular cases (best, worst, overall).\n","lastmodified":"2023-01-06T11:02:32.075286962Z","tags":null},"/cs61b/asymptotics/asymptotics-practice":{"title":"","content":"# Asymptotics Practice\n\n\u003e [!info] Content Note\n\u003e\n\u003e Make sure to review [Asymptotic Analysis Basics](asymptotics.md) before proceeding with these problems.\n\n## Introduction\n\nAsymptotics is a very intuition-based concept that often doesn't have a set algorithm for computing. The best way to get good at analyzing programs is to practice!\n\nWith that said, here are some problems of increasing difficulty for you to enjoy üòä\n\n\u003e [!hint] Read before you do the problems!\n\u003e\n\u003e For all of the below problems, assume that all undefined functions have a constant O(1) complexity.\n\n## Loops\n\n{{\u003c tabs \"q1\" \u003e}}\n{{\u003c tab \"Question 1\" \u003e}}\nWhat runtime does this function have?\n\n```java\nvoid throwHalfOfMyItems(int n) {\n    for (int i = 0; i \u003c n; i += 1) {\n        if (i % 2 == 0)\n            throwItem(n);\n    }\n}\n```\n{{\u003c /tab \u003e}}\n\n{{\u003c tab \"Q1 Answer\" \u003e}}\n$\n\\Theta(n)\n$\n\n**Explanation:** The method `throwItem()` runs `n/2` times. Using the simplification rules, we can extract the constant `1/2` to simply get `n`.\n\n![Keep the change, ya filthy animal.](\u003c../img/assets/image (40).png\u003e)\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n{{\u003c tabs \"q2a\" \u003e}}\n{{\u003c tab \"Question 2a\" \u003e}}\nWhat runtime does this function have?\n\n```java\nvoid lootShulkerBoxes(int n) {\n    for (int box = n; box \u003e 0; box -= 1) {\n        for (int stack = 0; stack \u003c n; stack += 1) {\n            for (int i = 0; i \u003c 64; i += 1) {\n                lootItem(i * stack * box);\n            }\n        }\n    }       \n}\n```\n{{\u003c /tab \u003e}}\n\n{{\u003c tab \"Q2a Answer\" \u003e}}\n$\n\\Theta(n^2)\n$\n\n**Explanation:** There are **three** nested loops in this problem. Whenever there are nested loops whose runtimes are independent of each other, we need to **multiply** the runtimes in each loop.\\\nSo, we get: $\\Theta(n * n * 64)$ which simplifies into `n^2`\n\n![That's a lot of items to loot...](\u003c../img/assets/image (41).png\u003e)\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n{{\u003c tabs \"q2b\" \u003e}}\n{{\u003c tab \"Question 2b\" \u003e}}\nI've tweaked the previous problem a little üòÅ Try to spot the difference and see if it changes the runtime at all!\n\n```java\nvoid lootShulkerBoxes(int n, int stacksToLoot) {\n    for (int box = n; box \u003e 0; box -= 1) {\n        for (int stack = stacksToLoot; stack \u003e 0; stack -= 1) {\n            for (int i = 0; i \u003c 64; i += 1) {\n                lootItem(i * stack * box);\n            }\n        }\n    }       \n}\n```\n{{\u003c /tab \u003e}}\n\n{{\u003c tab \"Q2b Answer\" \u003e}}\n$\n\\Theta(n)\n$\n\n**Explanation:** Even though `stacksToLoot` is a user input, we're only concerned about finding the runtime for `n` so `stacksToLoot` can be treated like a constant! Therefore, we now have $\\Theta(n * s* 64)$ where `s = stacksToLoot` which simplifies into `n`.\n\n![ok now this is getting a bit overboard](\u003c../img/assets/image (42).png\u003e)\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n## Recursion\n\nThe following two problems are inspired by [this worksheet](https://inst.eecs.berkeley.edu/\\~cs61b/sp20/materials/disc/discussion8.pdf).\n\n{{\u003c tabs \"q3\" \u003e}}\n{{\u003c tab \"Question 3\" \u003e}}\nTREEEEEEEEE recursion üå≥üå≤üå¥\n\n```java\nvoid plantJungleSaplings(int n) {\n    if (n \u003e 0) {\n        for (int i = 0; i \u003c 4; i += 1) {\n            plantJungleSaplings(n - 1);\n        }\n    }\n}\n```\n{{\u003c /tab \u003e}}\n\n{{\u003c tab \"Q3 Answer\" \u003e}}\n$\n\\Theta(4^n)\n$\n\n**Explanation:** This tree recursion creates a tree with `n` layers. Each layer you go down, the number of calls multiplies by 4!\n\n![Tree diagram for method calls.](\u003c../img/assets/image (48).png\u003e)\n\nThis means that the number of calls in total will look like this:\n\n$\n\\sum_{i=1}^{n}4^i\n$\n\nAnd if you remember your power series, you'll know that this sum is equal to $4^{n+1}-1$ which simplifies into the final answer.\n\n![an image that makes you long for TreeCapacitator](\u003c../img/assets/image (49).png\u003e)\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n{{\u003c tabs \"q4\" \u003e}}\n{{\u003c tab \"Question 4\" \u003e}}\nLet's replace the 4 in the previous problem with **n** and see what insanity ensues.\n\n```java\nvoid plantCrazySaplings(int n) {\n    if (n \u003e 0) {\n        for (int i = 0; i \u003c n; i += 1) { // This line changed\n            plantCrazySaplings(n - 1);\n        }\n    }\n}\n```\n{{\u003c /tab \u003e}}\n\n{{\u003c tab \"Q4 Answer\" \u003e}}\n$\n\\Theta(n!)\n$\n\n**Explanation:** This tree recursion creates a tree with `n` layers. Each layer you go down, the number of calls multiplies by `n-1`...\n\n![What a mess (!)](\u003c../img/assets/image (51).png\u003e)\n\nThis means that the number of calls in total will look like this:\n\n$\n\\sum_{i=1}^{n} \\frac{n!}{i!}\n$\n\nSince `n!` is not dependent on `i` it can be factored out of the sum to produce this:\n\n$\nn!\\sum_{i=1}^{n} \\frac{1}{i!}\n$\n\nHey, that looks a lot like the Taylor series for $e$! Since `e` is a constant, it simply reduces to `n!`.\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n## Best and Worst Case Runtimes\n\n{{\u003c tabs \"q5\" \u003e}}\n{{\u003c tab \"Question 5\" \u003e}}\nHere's a case where the best case and worst case runtimes are different. Can you figure out what they are? (Let `n = items.length`).\n\n```java\nItem[] hopperSort(Item[] items) {\n    int n = arr.length; \n    for (int i = 1; i \u003c n; ++i) { \n        int key = items[i]; \n        int j = i - 1; \n        while (j \u003e= 0 \u0026\u0026 items[j].compareTo(key) \u003e 0) { \n            items[j + 1] = items[j]; \n            j = j - 1; \n        } \n        items[j + 1] = key; \n    } \n}\n```\n{{\u003c /tab \u003e}}\n\n{{\u003c tab \"Q5 Answer\" \u003e}}\n**Best Case:** $\\Theta(n)$ if the array is nearly sorted except for a couple values. In this case, the `while` loop will only run a small number of times, so the only loop left is the for loop.\n\n**Worst Case:** $\\Theta(n^2)$if the array is totally reversed. This will cause the `while` loop to run on the order of `O(n)` times, resulting in a nested loop.\n\n**Note:** HopperSort is literally just Insertion Sort üòéü§£\n\n![hoppers rate 64/64](\u003c../img/assets/image (45).png\u003e)\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n{{\u003c tabs \"q6\" \u003e}}\n{{\u003c tab \"Question 6\" \u003e}}\nHere's a mutual recursion problem! What are the best and worst cases for `explodeTNT(n)`? What are their runtimes?\n\n```java\nvoid explodeTNT(int n) {\n    if (n % 2 == 0) {\n        digDirts(n - 1, true);\n        digDirts(n - 2, false);\n    } else {\n        digDirts(n / 2, true);\n    }\n}\n\nvoid digDirts(int n, boolean isTNT) {\n    if (isTNT) {\n        explodeTNT(n / 2);\n    }\n    removeDirt(); // not implemented, assume O(1) runtime\n}\n```\n{{\u003c /tab \u003e}}\n\n{{\u003c tab \"Q6 Answer\" \u003e}}\n**Best Case:** $\\Theta(\\log(n))$ if n is even. This will result in n being halved every function call.\n\n**Worst Case:** $\\Theta(n)$if n is odd. See the tree below for an illustration of what happens in this case- hopefully the diagram will make it clearer as to why it's O(n).\n\n![A diagram of what happens in the worst and best cases.](\u003c../img/assets/image (46).png\u003e)\n\n![don't play with tnt, kids](\u003c../img/assets/image (47).png\u003e)\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n## Challenge Problems\n\nThese problems are quite difficult. Don't be concerned if you don't feel confident in solving them (I certainly don't).\n\n{{\u003c tabs \"q7\" \u003e}}\n{{\u003c tab \"Question 7\" \u003e}}\nA huge disaster :ooo\n\n```java\n//initially start is 0, end is arr.length.\npublic int PNH(char[] arr, int start, int end) {\n    if (end \u003c= start) {\n        return 1;\n    }\n    int counter = 0; \n    int result = 0;\n    for (int i = start; i \u003c end; i += 1) {\n        if (arr[i] == 'a') {\n            counter += 1;\n        }\n    }\n    for (int i = 0; i \u003c counter; i += 1) {\n        result += PNH(arr, start + 1, end);\n    }\n    int mid = start + (end - start) / 2;\n    return PNH(arr, start, mid) + PNH(arr, mid + 1, end);\n}\n```\n{{\u003c /tab \u003e}}\n\n{{\u003c tab \"Q7 Answer\" \u003e}}\n**Best Case:** $\\Theta(n\\log(n))$ If none of the characters in char\\[] is 'a', then each call to PNH does $\\Theta(n)$ work. Total work per layer is always N, with logN layers total.\n\n**Worst Case:** $\\Theta(n!)$ All of characters in char\\[] is 'a'. In this case, the for loop recursive calls will dominate the runtime, because it'll be the main part of the recursive tree. The interval start to end is decreased by one in the for loop recursive calls, while that interval is halved in the return statement recursive calls. This means the return statement recursive calls will reach the base case in logn levels, while the recursive calls in the for loop will take n levels. Thus, we can proceed with the same analysis as question 4.\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n{{\u003c tabs \"q8\" \u003e}}\n{{\u003c tab \"Question 8\" \u003e}}\nCongrats for making it this far! By now you should be an expert in asymptotic analysis :P Here's one last problem:\n\n```java\n//initially start is 0, end is arr.length.\npublic int lastOne(char[] arr, int start, int end) {\n    if (end \u003c= start) {\n        return 1;\n    }\n    else if (arr[start] \u003c= arr[end]) {\n        return lastOne(arr, start + 1, end - 1);\n    } else {\n        int temp = arr[start];\n        arr[start] = arr[end];\n        arr[end] = temp;\n\n        return lastOne(arr, start + 1, end) \n        + lastOne(arr, start, end - 1) \n        + lastOne(arr, start + 1, end - 1);\n    }\n}\n```\n{{\u003c /tab \u003e}}\n\n{{\u003c tab \"Q8 Answer\" \u003e}}\n**Best Case:** $\\Theta(n)$ if the else if case is always true. This will produce a tree with height n/2, where each height does constant work.\n\n**Worst Case:** $\\Theta(3^n)$ if else if case is never true. Sorry no diagram yet :((\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n","lastmodified":"2023-01-06T11:02:32.075286962Z","tags":null},"/cs61b/misc-topics/":{"title":"","content":"","lastmodified":"2023-01-06T11:02:32.215287014Z","tags":null},"/cs61b/misc-topics/exceptions":{"title":"","content":"# Exceptions\n\n## Basics\n\nAn **exception** occurs when something unintended occurs and the interpreter must exit.\n\nWhile this might sound like a bad thing, we can often throw our own exceptions to handle known errors or edge cases more gracefully.\n\n### Exceptions in Java\n\nIn Java, there are two types of exceptions: **checked** and **unchecked.**\n\n**Checked** exceptions are handled during compile time, and are included in the method declaration. As an example:\n\n```java\npublic void openFile() throws IOException {\n    ...\n}\n```\n\n* All children that override this method must also throw the same exceptions.\n\n**Unchecked** exceptions are not handled during compile time, and thus are thrown during runtime. All `Error` or `RuntimeException` types are unchecked; all other exceptions are checked. Some examples of unchecked exceptions are dividing by zero (`ArithmeticException`), or accessing an index that doesn't exist (`IndexOutOfBoundsException`).\n\n![Some of the more common Exception types in Java.](\u003c../img/assets/image (4).png\u003e)\n\n## Creating Custom Exceptions\n\nWe can use the `throw` keyword to create exceptions with custom error messages as follows:\n\n```java\npublic void divide(int a, int b) {\n    if (b == 0) {\n        throw new Exception(\"Error Message\");\n    } else {\n        return a / b;\n    }\n}\n```\n\nThis is often used within a `try catch` block, as such:\n\n```java\npublic void divide2() {\n    int a = 0;\n    try {\n        return 10 / 0;\n    } catch(Exception e) {\n        System.out.println(\"oops!\");\n    }\n }\n```\n\nAn alternate to custom exceptions is to simply handle exception cases. For example, we can add a check to make sure a number is not zero before running a division operation.\n\n## Try/Catch/Finally Example\n\nLet's check your understanding of exception handling!\n\n```java\nstatic String tryCatchFinally() {\n        try {\n            System.out.println(\"trying\");\n            throw new Exception();\n        } catch (Exception e) {\n            System.out.println(\"catching\");\n            return \"done catch\";\n        } finally {\n            System.out.println(\"finally\");\n        }\n    }\n```\n\n{% tabs %}\n{% tab title=\"Q1\" %}\nWhat will be printed (and in what order) when `tryCatchFinally()` is run?\n{% endtab %}\n\n{% tab title=\"Q1 Answer\" %}\nFirst, `trying` will be printed.\n\nSince an Exception is thrown, the catch block will run next, so `catching` is printed next.\n\nSince finally blocks _always_ run regardless of result, `finally` is printed last.\n{% endtab %}\n{% endtabs %}\n\n{% tabs %}\n{% tab title=\"Q2\" %}\nSuppose the same code were run, but without the `catch` block. What would this code do?\n\n```java\nstatic String tryFinally() {\n        try {\n            System.out.println(\"trying\");\n            throw new Exception();\n        } finally {\n            System.out.println(\"finally\");\n        }\n}\n```\n{% endtab %}\n\n{% tab title=\"Q2 Answer\" %}\nIf the try block throws an uncaught Exception (i.e. if catch block does not exist or catch block does not handle the type of Exception that is thrown in the try block), Java halts execution of the try block, **executes the finally block**, then raises a runtime error.\\\n\\\nSo, the following sequence would occur:\\\n1\\. `trying` is printed.\\\n2\\. `finally` is printed.\\\n3\\. The program exits with a `RuntimeException`.\n{% endtab %}\n{% endtabs %}\n","lastmodified":"2023-01-06T11:02:32.215287014Z","tags":null},"/cs61b/misc-topics/modular-arithmetic":{"title":"","content":"# Modular Arithmetic and Bit Manipulation\n\n{% hint style=\"warning\" %}\nMake sure you're comfortable working with binary numbers (adding, subtracting, converting to decimal) before continuing.\n{% endhint %}\n\n## Integer Types\n\nThis is an excerpt from the chart in [Java Objects](../oop/objects.md). Go there to review primitive types first!\n\n| Type  | Bits | Signed | Literals                      |\n| ----- | ---- | ------ | ----------------------------- |\n| byte  | 8    | yes    | 3, (int)17                    |\n| short | 16   | yes    | None - must cast from int     |\n| char  | 16   | no     | 'a', '\\n'                     |\n| int   | 32   | yes    | 123, 0100 (octal), 0xff (hex) |\n| long  | 64   | yes    | 123L, 0100L, 0xffL            |\n\n## Signed Numbers\n\nA type is **signed** if it can be **positive** **or** **negative.** Unsigned types can _only_ be positive.\n\nIn signed types, the **first bit** is reserved for determining the sign of the number (0 is positive, 1 is negative). This means that there is one fewer bit for the actual number. For example, ints only have **31** bits for the number.\n\n### Reading negative numbers\n\nLet's say you are given a number like `10100`and want to convert it to decimal. We know that the 1 in the front means it's a negative number! However, we can't just discard that 1 and read the rest like a positive number. Instead, we have to **flip all the bits** and then **add one** to the result. So, `10100` flipped will become `01011`. Adding one will result in `01100`, which is the correct answer (12).\n\n**Why do we have to do this?** Read on to the next section to find out!\n\n## Two's Complement\n\n**Two's Complement** is a a method of storing negative numbers in a way that supports proper arithmetic. Here's how it works:\n\n1. Start with a binary number we want to negate, like `0101`, which is 5.\n2. Flip all the bits to make `1010`.\n3. Add one to make `1011`.\n\nAlthough it makes negative numbers harder to read, the benefits are much more significant- it allows addition and subtraction to work between positive and negative numbers.\n\nIf you want to see firsthand why simply flipping the signed bit doesn't work, try out some problems in [this worksheet](https://d1b10bmlvqabco.cloudfront.net/attach/k5eevxebzpj25b/jcaul3qcivh6kh/k8g51ayfl9ui/GuerillaSection2.pdf) ([solutions](https://d1b10bmlvqabco.cloudfront.net/attach/k5eevxebzpj25b/jcaul3qcivh6kh/k8g53zthgevk/GuerillaSection2Sols.pdf)).\n\n## Modular Arithmetic\n\nSince primitive types have a fixed number of bits, it is possible to **overflow** them if we add numbers that are too large. For example, if we add `01000000`(a byte) with itself, we'd need 9 bits to store the result!\n\nThis will cause lots of issues, so we use **modular arithmetic** to **wrap around to the largest negative version** and keep the number in bounds. For example, `(byte)128 == (byte)(127+1) == (byte)(-128)`**.**\n\n## Bit Operations\n\n**Mask: \u0026**\n\n* `A \u0026 B` will only keep the bits that are 1 in A **AND** B\n* Example: `00101100 \u0026 10100111 == 00100100`\n\n**Set: |**\n\n* `A | B` will keep the bits that are 1 in A **OR** B\n* Example: `00101100 | 10100111 == 10101111`\n\n**Flip: ^**\n\n* `A ^ B` will keep the bits that are 1 in A **XOR** B\n* In other words, 1 if bits are unequal in A and B, 0 otherwise\n* Example: `00101100 ^ 10100111 == 10001011`\n\n**Flip all: \\~**\n\n* `~A` will flip all the bits from 1 to 0 or 0 to 1 in A\n* Example: `~10100111 == 01011000`\n\n**Shift Left: \u003c\u003c**\n\n* `A \u003c\u003c n` will shift all bits left n places\n* All newly introduced bits are 0\n* Example: `10101101 \u003c\u003c 3 == 01001000`\n* `x \u003c\u003c n` is equal to x \\* 2^n\n\n**Arithmetic Right: \u003e\u003e**\n\n* `A \u003e\u003e n` will shift all bits **except for the signed bit** right n times\n* Newly introduced bits are the same as the signed bit\n* Example: `10101101 \u003e\u003e 3 == 11110101`\n\n**Logical Right: \u003e\u003e\u003e**\n\n* `A \u003e\u003e\u003e n` will shift ALL bits right n times\n* Newly introduced bits are 0\n* Example: `10101101 \u003e\u003e\u003e 3 == 00010101`\n* Another example: `(-1) \u003e\u003e\u003e 29 == 7` because it leaves 3 1-bits- ints are 32 bits\n\n## Why is this useful?\n\nJust looking at these obscure operations, it may be unclear as to why we need to use these at all.\n\nWell, [here's a massive list of bit twiddling hacks](https://graphics.stanford.edu/\\~seander/bithacks.html) that should demonstrate plenty of ways to use these simple operations to do some things really efficiently.\n\nThese operations are also the **building blocks for almost all operations done by a computer.** You'll see firsthand how these are used to construct ALU's in [61C](https://cs61c.org/).\n","lastmodified":"2023-01-06T11:02:32.215287014Z","tags":null},"/cs61b/misc-topics/more-resources":{"title":"","content":"# More Resources\n\nHere are some more cool things to look at!\n\n* [Big O Cheat Sheet ](https://www.bigocheatsheet.com/)- complexities of sorting and common data structure operations\n* [Toptal Sorting Algorithm Animations ](https://www.toptal.com/developers/sorting-algorithms)- animations, pseudocode, and property summaries\n* [Josh Hug's 61B Playlist](https://www.youtube.com/channel/UC7FzTMO4rKvlqIyU5vwzFKQ/playlists) - concise video lectures for most 61B topics\n* [Balanced Search Demos](https://inst.eecs.berkeley.edu/\\~cs61b/sp20/materials/lectures/lect29/) - play around with balanced search structures and see how they work\n","lastmodified":"2023-01-06T11:02:32.215287014Z","tags":null},"/cs61b/oop/":{"title":"","content":"","lastmodified":"2023-01-06T11:02:32.215287014Z","tags":null},"/cs61b/oop/access-control":{"title":"","content":"\n## What is Access Control?\n\nIn Java, we can specify the **level of access** certain variables and methods have. With this power, we can show or hide these variables to other classes and references on demand!\n\nThere are **4** modifier levels that get progressively more open:\n\n* **Private:** Only this class can see it.\n* **Package Protected (the default level):** All classes in the **same package** can see it.\n* **Protected: Subclasses** (that inherit from the parent) can also see it.\n* **Public:** All classes in the program can see it.\n\n![A chart comparing the different access modifiers. The black bar is the default (\"package protected\").](\u003c../img/assets/image (5).png\u003e)\n\n## Why do we need access control?\n\nAccess control works really well with other OOP concepts to help structure programs better and make them easier to understand. Here are some of the major benefits:\n\n* Access control is **self documenting.** Usually, there's a reason for making certain variables private and others public, and no more needs to be said for that to be understood.\n* **It's safe to change private methods without worrying about breaking things.** If a method is private, we know that the only references are within the same class, so we can edit them however we want without making other classes error as well.\n* **Private/protected variables don't need to be understood by users.** If someone needs to use your program, they don't need to learn how to use any private methods since those will be hidden to them.\n\n## Practice\n\nLet's see how access control can be used to hide variables in different situations:\n\n```java\npackage P;\npublic class A {\n    int def; // Variable with default access\n    protected int prot; // Variable with protected access\n    private int priv; // Variable with private access\n    \n    static class NestedA { ... }\n}\n\npublic class B extends A { ... }\n\n===================\npackage Q;\npublic class C extends P.A { ... }\n\n```\n\n{{\u003c tabs \"q1\" \u003e}}\n{{\u003c tab \"Question 1\" \u003e}}\nWhich variables can be accessed in B?\n{{\u003c /tab \u003e}}\n\n{{\u003c tab \"Answer\" \u003e}}\n`def` and `prot` since B is in the same package as A.\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n{{\u003c tabs \"q2\" \u003e}}\n{{\u003c tab \"Question 2\" \u003e}}\nWhich variables can be accessed in C?\n{{\u003c /tab \u003e}}\n\n{{\u003c tab \"Answer\" \u003e}}\n`prot` only, since C is in a different package but extends A.\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n{{\u003c tabs \"q3\" \u003e}}\n{{\u003c tab \"Question 3\" \u003e}}\nWhich variables can be accessed in NestedA?\n{{\u003c /tab \u003e}}\n\n{{\u003c tab \"Answer\" \u003e}}\nNone of them, because NestedA is static and cannot reference any non-static variables.\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n","lastmodified":"2023-01-06T11:02:32.215287014Z","tags":null},"/cs61b/oop/dynamic-method-selection":{"title":"","content":"# Dynamic Method Selection\n\n\u003e [!warning] Content Note\n\u003e\n\u003e This is a **very tricky topic**. Make sure you are comfortable with [inheritance](inheritance.md) and [access control](access-control.md)before proceeding!\n\nInheritance is great and all, but it does have some issues. One of the biggest issues lies in overriding: **if two methods have exactly the same name and signature, which one do we call?**\n\nIn a standard use case, this is a pretty simple answer: whichever one is in the class we want! Let's look at some basic examples.\n\n```java\npublic class Dog {\n    public void eat() { ... } // A\n}\n\npublic class Shiba extends Dog {\n    @Override\n    public void eat() { ... } // C\n}\n```\n\n{{\u003c tabs \"q1\" \u003e}}\n{{\u003c tab \"Question 1\" \u003e}}\nWhich method is called when we run:\n\n```java\nDog rarePupper = new Dog();\nrarePupper.eat();\n```\n{{\u003c /tab \u003e}}\n\n{{\u003c tab \"Q1 Answer\" \u003e}}\nIt's **A** üêï Dog doesn't know anything about `Shiba` or any other classes, so we can just look at the Dog.\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n{{\u003c tabs \"q2\" \u003e}}\n{{\u003c tab \"Question 2\" \u003e}}\nWhat about when we call:\n\n```java\nShiba doge = new Shiba();\nrarePupper.eat();\n```\n{{\u003c /tab \u003e}}\n\n{{\u003c tab \"Q2 Answer\" \u003e}}\nThis calls **C**! This works intuitively because `Shiba` overrides `Dog` so all `Shibas` will use C instead of A.\n\n![](\u003c../img/assets/image (8).png\u003e)\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n## Things Get Wonky: Mismatched Types\n\nThere's an interesting case that actually works in Java:\n\n```java\nDog confuzzled = new Shiba();\n```\n\nWhat??? Shouldn't this error because `Dog` is incompatible with `Shiba`?\n\nIt turns out that **subclasses can be assigned to superclasses.** In other words, `Parent p = new Child()` works fine. This is really useful for things like [Interfaces](inheritance.md#interfaces) and generic [Collections](../abstract-data-types/collections/) because we might only care about using generic methods, and not the specific implementation that users chose to provide.\n\nHowever, **it is important to note that it doesn't work the other way.** `Child c = new Parent()` will error because the child might have new methods that don't exist in the parent.\n\n**Let's see how this makes inheritance really tricky:**\n\n```java\n/** The following problems are inspired by Spring 2020 Exam Prep 5. */\n\npublic class Dog {\n    public void playWith(Dog d) { ... } // D\n}\n\npublic class Shiba extends Dog {\n    @Override\n    public void playWith(Dog d) { ... } // E\n    public void playWith(Shiba s) { ... } // F\n}\n```\n\n{{\u003c tabs \"q3\" \u003e}}\n{{\u003c tab \"Question 3\" \u003e}}\nWhich method(s) run when we call:\n\n```java\nDog rarePupper = new Shiba();\nrarePupper.playWith(rarePupper); // aww rarePupper is lonely :(\n```\n{{\u003c /tab \u003e}}\n\n{{\u003c tab \"Q3 Answer\" \u003e}}\n**E** is called! What happens is that the **dynamic type** is chosen to **select the method from,** but the **static type** is used to **select the parameters.** `rarePupper`'s **** dynamic type is `Shiba` but its static type is `Dog` so `Shiba.playWith(Dog)` is chosen as the method.\n\n![rarePupper in action](\u003c../img/assets/image (10).png\u003e)\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n{{\u003c tabs \"q4\" \u003e}}\n{{\u003c tab \"Question 4\" \u003e}}\nWhich is called when we run**:**\n\n```java\nDog rarePupper = new Shiba();\nShiba doge = new Shiba();\nrarePupper.playWith(doge); // rarePupper is happy :) borks all around\n```\n{{\u003c /tab \u003e}}\n\n{{\u003c tab \"Q4 Answer\" \u003e}}\n**E** is called again! Bet ya didn't see that coming üòé\n\n**Why is it not F? I thought doge and rarePupper were both** `Shiba`**?**\\\n****When the compiler chooses a method, it **always** starts at the **static method.** Then, it keeps going down the inheritance tree until it hits the **dynamic method.** Since F has a **different signature** than D, it isn't an **overriding method** and thus the compiler won't see it. But E is (since it has the same signature as D), so that is why it is chosen instead.\n\n![bork bork bork :DDD](\u003c../img/assets/image (11).png\u003e)\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n## Adding more insanity: Static vs. Dynamic\n\nBy now, you should have a pretty good understanding of the **method selection** part of DMS. But why is it **dynamic?**\n\nYou may have noticed that there are **two** type specifiers in an instantiation. For example, `Dog s = new Shiba()` has type `Dog` on the left and `Shiba` on the right.\n\nHere, `Dog` is the **static type** of `s`: it's what the compiler believes the type should be when the program is compiled. Since the program hasn't run yet, Java doesn't know what exactly it is- it just knows it has to be some type of `Dog`.\n\nConversely, `Shiba` is the **dynamic type:** it gets assigned during runtime.\n\n### The type rules\n\nJust remember: **like chooses like.** If a method is **static**, then choose the method from the **static type.** Likewise, if a method is **not static,** choose the corresponding method from the **dynamic type.**\n\nLet's try some examples!\n\n```java\npublic class Dog {\n    public static String getType() {\n        return \"cute doggo\";\n \n    @Override // Remember, all objects extend Object class!   \n    public String toString() {\n        return getType();\n    }\n}\n\npublic class Shiba extends Dog {\n    public static String getType() {\n        return \"shiba inu\";\n    }\n}\n```\n\n{{\u003c tabs \"q5\" \u003e}}\n{{\u003c tab \"Question 5\" \u003e}}\nWhat prints out when we run:\n\n```java\nDog d = new Shiba();\nSystem.out.println(d.getType());\n```\n{{\u003c /tab \u003e}}\n\n{{\u003c tab \"Q5 Answer\" \u003e}}\n`cute doggo` gets printed because `getType()` is a static method! Therefore, Java looks at the **static type** of `d`, which is `Dog`. \\\n(If `getType()` weren't static, then `shiba inu` would have been printed as usual.)\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n{{\u003c tabs \"q6\" \u003e}}\n{{\u003c tab \"Question 6\" \u003e}}\nWhat prints out when we run:\n\n```java\nShiba s = new Shiba();\nSystem.out.println(s);\n```\n{{\u003c /tab \u003e}}\n\n{{\u003c tab \"Q6 Answer\" \u003e}}\n`cute doggo` also gets printed!! This is because static methods **cannot be overridden.** When `toString()` is called in `Dog`, it doesn't choose `Shiba`'s `getType()` because `getType()` is static and the static type is `Dog`.\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n{{\u003c tabs \"q7\" \u003e}}\n{{\u003c tab \"Question 7\" \u003e}}\nWhat prints out when we run:\n\n```java\nDog d = new Shiba();\nSystem.out.println(((Shiba)d).getType());\n```\n{{\u003c /tab \u003e}}\n\n{{\u003c tab \"Q7 Answer\" \u003e}}\nThis time, `shiba inu` gets printed. This is because casting temporarily changes the **static type:** since the static type of `d` is `Shiba` in line 2, it chooses the `getType()` from `Shiba`.\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n## That's all, folks!\n\nIf you want some **even harder** problems, [check this out](https://inst.eecs.berkeley.edu/\\~cs61b/sp20/materials/disc/examprep5.pdf) and also [this](https://inst.eecs.berkeley.edu/\\~cs61b/sp20/materials/disc/examprep6.pdf).\n\n![bai bai!](\u003c../img/assets/image (12).png\u003e)\n","lastmodified":"2023-01-06T11:02:32.215287014Z","tags":null},"/cs61b/oop/generics":{"title":"Generic Types","content":"\nSometimes, we want things to support **any type**, including user defined types that we don't know about! For example, it would make sense that we don't care what type we make a `List` out of, since it's just a whole bunch of objects put together.\n\nThe Java solution is **generics!** Generic types are denoted by a `\u003c\u003e` and can be appended to **methods and classes.** Here's an example with classes:\n\n```java\n/**\n  * Creates a type SomeClass that takes * in a generic SomeType. SomeType can * be named anything.\n*/\npublic class SomeClass\u003cSomeType\u003e {\n    private SomeType someThing;\n\n    public void someMethod(SomeType stuff) {\n        doStuff(stuff);\n    }\n}\n\n...\n/** Creates a new instance of SomeClass, setting SomeType to String.\n    We don't need to put the type on the right since it's already\n    defined on the left. */\nSomeClass\u003cString\u003e aClass = new SomeClass\u003c\u003e();\n```\n\nIn this example, `SomeType` is a **Generic Type Variable** that is not a real type, but can still be used inside the class as normal.\n\nOn the other hand, `String` is an **Actual Type Argument** that replaces `SomeType` during runtime. Now, every time `SomeType` is used in `SomeClass` Java treats it exactly like a `String`.\n\n## Generic Subtypes\n\nLike in [Dynamic Method Selection](dynamic-method-selection.md), adding inheritance makes things tricky! Let's look at an example:\n\n```java\nList\u003cString\u003e LS = new ArrayList\u003cString\u003e();\nList\u003cObject\u003e LO = LS; // Line 3\nLO.add(42); // Line 4\nString s = LS.get(0); // Line 5\n```\n{{\u003c tabs \"q1\" \u003e}}\n{{\u003c tab \"Question 1\" \u003e}}\nWill **line 3** error?\n{{\u003c /tab \u003e}}\n{{\u003c tab \"Q1 Answer\" \u003e}}\n**No**, line 3 is valid and will not error! This is because Object is a **superclass** of String. Generics work in a very similar way to the [inheritance rules](inheritance.md).\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n{{\u003c tabs \"q2\" \u003e}}\n{{\u003c tab \"Question 2\" \u003e}}\nWill **line 4** error?\n{{\u003c /tab \u003e}}\n\n{{\u003c tab \"Q2 Answer\" \u003e}}\n**No**, line 4 is valid and will not error! This is because LO is a **list of Objects** and integers are a **subtype** of Object, as all things are.\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n{{\u003c tabs \"q3\" \u003e}}\n{{\u003c tab \"Question 3\" \u003e}}\nWill **line 5** error?\n{{\u003c /tab \u003e}}\n\n{{\u003c tab \"Q3 Answer\" \u003e}}\n**Yes,** line 5 will error! This is because we put 42 into LO, which is an integer. Since LO is pointing to the same object as LS, 42 is also in LS! That means we are trying to assign a String equal to an integer.\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n\u003e [!info] Content Note\n\u003e\n\u003e Arrays have slightly different behavior than this and will throw an `ArrayStoreException` if types are mismatched in any way.\n\n## Type Bounds\n\nSometimes, we want to **put constraints** on what kinds of types can be passed into a generic type.\n\nOne way of doing is is to specify that a generic type must fit within a **type bound**: here, T must be some subtype of a specified type `Number`.\n\nWe can also do it the other way and specify that a type can be a **supertype** of a specified type. Both of these examples are shown below:\n\n```java\nclass SomeClass\u003cT extends Number\u003e {\n    // A method that takes a type parameter T and takes any SUPERCLASS\n    // of T as a list generic type.\n    static \u003cT\u003e void doSomething(List\u003c? super T\u003e L) { ... }\n}\n```\n\n## Limitations of Generic Types\n\nThe biggest limitation is that **primitive types cannot be used as generic types.** For example, `List\u003cint\u003e` is invalid and will not work!\n\nOne workaround to this is to use the reference-type counterparts to primitives, such as `Integer`, `Boolean`, `Character` and so on. However, converting between these types and primitive types, which is called **autoboxing,** has significant performance penalties that must be taken into consideration.\n\nAnother limitation is that **instanceof** does not work properly with generic types. For instance, `new List\u003cX\u003e() instanceof List\u003cY\u003e` will always be true regardless of what types X and Y are.\n","lastmodified":"2023-01-06T11:02:32.215287014Z","tags":null},"/cs61b/oop/inheritance":{"title":"","content":"\n## What is inheritance?\n\nEssentially, it's a way of putting similar objects together to **generalize behavior.** Inheritance is best used with relating **subtypes** to larger categories. For example, an :tangerine:orange **is a** fruit (so it's a **subtype** of fruit).\n\nLet's say that a supermarket named _Jrader Toe's_ asks us to simulate fruits for them in an online system. We could do it like this:\n\n![The naive approach.](../img/assets/image.png)\n\nNow, every fruit would need some of the same properties- like cost, weight, and name! So we would need to do something like:\n\n```java\npublic class Orange {\n    private String name = \"Orange\";\n    private int cost;\n    ...\n    public Orange(int cost, ...) {\n        this.cost = cost;\n        ...\n    }\n    // lots of methods\n    public String getName() { ...\n```\n\nThis would be _really annoying_ to do for every single fruit. And they're all the same properties for every fruit so it would also be incredibly inefficient code-wise. **Inheritance gives a much better solution!**\n\nLet's make a **Fruit** class and have all of our fruits **inherit from** that class.\n\n![uwu inheritance is cool and good](\u003c../img/assets/image (1).png\u003e)\n\nThis does amazing things because we can just create one single Fruit class that has all of the properties we need, and simply make our specific fruits inherit those properties. (Side note: making multiple things inherit from one generic interface like this is called **polymorphism.**)\n\n```java\npublic class Fruit {\n    private String name;\n    private int cost;\n    ...\n    public Orange(String name, int cost, ...) {\n        this.name = name;\n        this.cost = cost;\n        ...\n    }\n    // lots of methods\n    public String getName() { ...\n}\n\n// Now for a very simple Orange method!\npublic class Orange extends Fruit {\n    public Orange(int cost,...) {\n        super(\"Orange\", cost, ...);\n    }\n}\n```\n\nWith only those 4 lines, :tangerine:Orange now has all of the same methods and properties that Fruit has!\n\n## Implementation Inheritance (\"Extends\")\n\nYou may have noticed the `extends` keyword being used to specify that an object **inherits** from another object. This is called **implementation inheritance** since an object takes all of the behaviors from its parent and can use them like its own.\n\nWhen `extends` is used, these are the things that are inherited:\n\n* All instance and static variables that are **not private** (see [Access Control](access-control.md) for more information)\n* All non-private methods\n* All nested classes\n\nThese are **not** inherited:\n\n* Any **private** variables and methods\n* All constructors\n\n\n\u003e [!info] **Quick sidenote!**\n\u003e \n\u003e All objects automatically extend the `Object` class whether you like it or not. See [References, Objects, and Types in Java](objects.md) for more about this behavior.\n\n### Constructor magic üèó\n\nWhen an object `extends` another object, its constructor will **automatically call the parent's constructor.** However, this does have some limitations:\n\n* It will only call the **default** (no-argument) constructor in the parent.\n* Calling the constructor is the **first thing that is done** in the child constructor.\n\nBut what if we want to call another constructor? That's where the `super` keyword comes in! When `super` is called, Java will know to **not** call the default constructor anymore. Here's an example:\n\n```java\npublic class Parent {\n    public Parent() {\n        System.out.println(\"Default constructor\");\n    }\n    public Parent(String say) {\n        System.out.println(say);\n    }\n    void doStuff() { ... }\n}\n\n// Child inherits doStuff(), but not the constructors.\npublic class Child extends Parent {\n    public Child() {\n        System.out.println(\"Child\")\n    }\n    public Child(String say) {\n        super(say);\n    }\n}\n    \npublic static void Main(String[] args) {\n    Child c1 = new Child(); // will print \"Default constructor\" then \"Child\" !!!\n    Child c2 = new Child(\"Hi\"); // will print \"Hi\"\n}\n```\n\n## Method Overriding\n\nLet's say that _Jrader Toe's_ is running a promotion for üçêpears and wants to make them 20% off normal pears! This poses a problem because **we want to inherit everything that normal pears have, but change only one behavior** (getPrice). Well I've got the solution for you!!! And it's called **overriding.**\n\n```java\npublic class PromoPear extends Pear {\n    public PromoPear(int cost, ...) {\n        super(cost, ...);\n    }\n    \n    // Overriding the getPrice to have a new behavior only for PromoPears!\n    @Override\n    public int getPrice() {\n        return super.getPrice() * 0.8;\n    }\n    ...\n}   \n```\n\nThe `@Override` tag is technically optional, but it's highly suggested because it makes sure that you are indeed overriding something and not just making a new method! (Remember, it has to have the **same name and parameters as a method in one of its parents**.)\n\n## **Method Overloading**\n\nSometimes, you want to take in **different parameters** into the **same method.** For instance, what if we wanted to create a method `getCount(Fruit fruit)` that counts how many fruits of that type we have? We might also want to allow users to pass in the name of the fruit to do the same thing- `getCount(String fruit)`. Java will allow us to make **both** of these methods in the same class!\n\nHowever, this has some major downsides that should be considered.\n\n* It's repetitive.\n* It requires maintaining more code- changing one overload won't change the others!\n* You can't handle any data types other than the ones you explicitly specify will work.\n\nWe'll discuss better solutions further down the page as well as in the [Generic Types](generics.md) page!\n\n### How is overriding different from overloading?\n\nThey have very similar names but pretty different uses!\n\nOverriding is for methods of the same name, **same parameters**, and **different classes.** If you can remember when you use the `@Override` tag, you can relate it back to this concept!\n\nOverloading is for methods of the same name, **different parameters**, in the **same class**.\n\n## Interfaces\n\nInterfaces are like **blueprints üìò** for objects- they tell you what an object needs, but not how to implement them.\n\nThey are very similar to normal classes except for some major differences:\n\n* **All variables are constants** (public static final).\n* **Methods have no body**- just a signature (like `void doStuff();`)\n* **Classes can inherit from multiple interfaces.**\n\nTypically, interfaces will not have any implemented methods whatsoever. This limitation can technically be removed using the [default keyword](https://stackoverflow.com/questions/31578427/what-is-the-purpose-of-the-default-keyword-in-java/31579210), but this is **not recommended** because abstract classes handle this much better.\n\nHere's an example of interfaces in the wild:\n\n```java\npublic interface AnInterface\u003cItem\u003e {\n  public void doStuff(Item x);\n  public Item getItem();\n  ...\n}\n\npublic class Something implements AnInterface\u003cItem\u003e { // Note the IMPLEMENTS!\n @Override\n public void doStuff(Item x) {\n     // implement method\n }\n\n @Override\n public void getItem() {\n     // implement method\n }\n}\n\npublic class MainClass {\n  public static void main(String[] args) {\n      AnInterface\u003cString\u003e smth = new AnInterface\u003c\u003e(); // ERROR!!\n      // (new can't be used with interfaces.)\n      AnInterface\u003cString\u003e smthElse = new Something\u003cString\u003e(); // Will not error!\n      smth.getItem();\n      ...\n  }\n}\n```\n\n## Abstract Classes\n\nAbstract classes live in the place **in between** interfaces and concrete classes. In a way, they get the best of both worlds- you can implement whichever methods you want, and leave the rest as **abstract** methods (same behavior as interface methods)!\n\nHere are some properties:\n\n* **Variables behave just like a concrete class.**\n* **Normal methods can be created like any other concrete class.**\n* **Abstract methods** (`abstract void doSomething()`) **behave just like methods in interfaces.**\n* Classes can only inherit from **one** abstract class.\n\nHere's the same example from the interfaces section, but implemented using an abstract class.\n\n```java\npublic abstract class AnAbstract\u003cItem\u003e {\n  public abstract void doStuff(Item x);\n  public abstract Item getItem();\n  ...\n}\n\npublic class Something extends AnAbstract\u003cItem\u003e { // EXTENDS, not implements!\n @Override\n public void doStuff(Item x) {\n     // implement method\n }\n\n @Override\n public void getItem() {\n     // implement method\n }\n}\n\npublic class MainClass {\n  public static void main(String[] args) {\n      AnAbstract\u003cString\u003e smth = new AnAbstract\u003c\u003e(); // ERROR!!\n      // (new can't be used with abstract classes, just like interfaces.)\n      AnAbstract\u003cString\u003e smthElse = new Something\u003cString\u003e(); // Will not error!\n      smth.getItem();\n      ...\n  }\n}\n```\n\n![A chart comparing the differences between the types of classes.](\u003c../img/assets/image (2).png\u003e)\n\n## Still not satisfied?\n\nWatch [Josh Hug's video lecture](https://www.youtube.com/watch?v=IaEq\\_fogI08\\\u0026list=PL8FaHk7qbOD6km6LlaHLWgRl9SbhlTHk2) about inheritance.\n\nOr, move onto an advanced application of inheritance concepts, [Dynamic Method Selection](dynamic-method-selection.md).\n","lastmodified":"2023-01-06T11:02:32.215287014Z","tags":null},"/cs61b/oop/objects":{"title":"Java Objects","content":"\nThere are two main categories of objects in Java: **Primitive Types** and **Reference Types.** This page will give a brief overview of both, and close off with some info about the mystical **Object** class.\n\n## Primitive Types\n\n**Primitive types** are built in to Java and have **fixed memory sizes.** Different types require different amounts of memory.\n\nIf you remember [environment diagrams](http://albertwu.org/cs61a/notes/environments), you may recall that some variables are put straight into the boxes, while others have an arrow pointing to them. The reason for this is that it actually denotes primitive vs. reference types! **Primitive types go straight in the box** because they aren't mutable (i.e. you can't change the objects contained in the box since they're just constant literals like numbers).\n\n**There are 8 primitive types in Java.** Here's a table of their properties! (If you don't know what \"signed\" means, go to [Modular Arithmetic and Bit Manipulation](../misc-topics/modular-arithmetic.md).)\n\n| Type    | Bits | Signed | Default | Examples                      |\n| ------- | ---- | ------ | ------- | ----------------------------- |\n| boolean | 1    | no     | false   | true, false                   |\n| byte    | 8    | yes    | 0       | 3, (int)17                    |\n| short   | 16   | yes    | 0       | None - must cast from int     |\n| char    | 16   | no     | \\u0000  | 'a', '\\n'                     |\n| int     | 32   | yes    | 0       | 123, 0100 (octal), 0xff (hex) |\n| long    | 64   | yes    | 0       | 123L, 0100L, 0xffL            |\n| float   | 32   | yes    | 0.0     | 1.23f, -1.23e10f, .001f       |\n| double  | 64   | yes    | 0.0     | 1.23e256d, 1e1d, 1.2e-10d     |\n\n{% hint style=\"info\" %}\n**A quick aside on Strings üßµ**\\\nYou may have noticed that strings are not on this list. That is because unlike in Python, they aren't a primitive type! Under the hood, Strings are a reference type that are very similar to a char array.\n{% endhint %}\n\n## Type Conversion\n\nJava will automatically convert between primitive types if **no information is lost** (\nfrom byte to int).\n\nConversion in the other direction (from a larger to smaller container) requires an explicit cast (e.g., `(char) int`). The compiler will treat a cast object as though its static type is the cast type, but this will only work if the cast type is the same as or a parent of the dynamic type. However, relative to the assigned static type, the cast type could be a child of the static type or a parent of the static type.\n\n**Assignment statements are an exception to this**: `aByte = 10` is fine even though 10 is an int literal. This is because arithmetic operations (+, \\*, ...) automatically promote operands (e.g., `'A' + 2` is equivalent to `(int)'A' + 2`)\n\nHowever, **this doesn't work if you are trying to add a larger type to a smaller type** (e.g., `aByte = aByte + 1` since operands become an int type which cannot be set equal to a byte type. **But += works**!\n\n## Reference Types\n\nA **reference type** refers to basically anything that's not primitive üòÖ\n\nThis includes **user-defined objects** as well as many common Java built-in types such as **arrays, strings, and** [**collections**](../abstract-data-types/collections/)**.**\n\nHere are some major differences that set them apart from primitive types:\n\n* Reference types can take an **arbitrary amount of memory.** Unlike primitives which have a fixed memory for each type, objects like arrays can expand to hold lots of things inside it.\n* Reference types are referred to using **addresses.** When you say something like `int[] arr = new int[5]`, `arr` only stores a 64-bit **memory address** which **points** to the real object, a 5-length integer array. Again, think back to the arrow in environment diagrams, and how those work.\n* By default, reference types can be set to **null** which is represented as an **address of all zeroes.** Or, the **new** keyword can be used to set it to a specific address.\n* Reference objects can be **lost** if all pointers to it are reassigned. For example, if I now enter `arr = null;`, the original 5-length array still exists, but just has nothing to refer to it.\n\n## The Equals Sign\n\nThe assignment operator (`=`) has **different behaviors** for primitive types and references types.\n\nFor **primitive types,** `y = x` means \"**copy** **the bits** from y into a new location, then call them x\". Here, the **entire object** is copied- this means that changing y will NOT change x even though they are set \"equal\".\n\nFor **reference types,** `obj1 = obj2` means \"**copy the address** stored in obj1 to obj2\". Here, `obj1` and `obj2` are referring to the **exact same object,** and mutating one will change the other.\n\n{% hint style=\"info\" %}\n**A clarification on reference type assignment**\n\nBy mutating, I mean changing the **internals** of an object (for example, accessing an array index or doing something like `obj1.value = 1`. If you change the actual **address** of `obj2`, as in `obj2 = obj3`, this does **not** change `obj1` because `obj2` is now referring to a completely different object!\n{% endhint %}\n\n## The Object Class\n\nIn Java, **all objects inherit from the master Object class.** Here are some important properties of Object that will be useful to know:\n\n* `String toString()`: By default, this prints out the class name followed by the memory address (e.g., `Object@192c38f`). This can be overridden to make more user-friendly names for objects.\n* `boolean equals(Object obj)`: By default, this checks if the two objects are actually the same object (same memory address). This can be overridden to check if specific contents of objects are the same, rather than checking if they are literally the same object. (Like `\"foo\"` should equal `new String(\"foo\")`)\n* `int hashCode()`: Returns a numeric hash code for the object that should differentiate it from other objects. **This should be overridden if** **`equals()` is overridden** since `x.hashCode()` should equal `y.hashCode()` if `x.equals(y)` is true!\n* `Class\u003c?\u003e getClass()`: Returns the class of this object.\n\nObject has plenty of other methods and properties as well, but these aren't as important. If you want to learn about them, feel free to refer to the [Java documentation](https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html).\n","lastmodified":"2023-01-06T11:02:32.215287014Z","tags":null}}