<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Data102s on</title><link>https://notes.bencuan.me/data102/</link><description>Recent content in Data102s on</description><generator>Hugo -- gohugo.io</generator><atom:link href="https://notes.bencuan.me/data102/index.xml" rel="self" type="application/rss+xml"/><item><title/><link>https://notes.bencuan.me/data102/bandits/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://notes.bencuan.me/data102/bandits/</guid><description>Main idea: making repeated decisions based on feedback, factoring in the tradeoff between exploring new decisions or keeping existing good decisions
Multi-Armed Bandit Framework # The Multi-Armed bandit problem arises when the following are true:
We need to get the data as a part of the process Exploration/exploitation tradeoff (both have a cost) Stochastic: rewards are random Setup:
Selection rounds $1, \cdots, T$ Arms (choices) $1, \cdots, K$ $P_i$: reward distribution for arm $i$ $\mu_i$: mean reward for $P_i$ distribution At each round $t$, choose an arm $A_t$ such that a reward $X_t \sim P_{A_t}$ is procured Define pseudo-regret at time $T$ as $\bar R_t = \sum_{t=1}^T (\mu^* - \mu_{A_t})$ where $\mu^*$ is the best mean possible.</description></item><item><title/><link>https://notes.bencuan.me/data102/binary-decision-making/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://notes.bencuan.me/data102/binary-decision-making/</guid><description>Intro # Binary Decision Making is the simplest kind of decision we can make: 1 or 0, yes or now, true or false&amp;hellip;
Setup # In reality, a value is either 0 or 1. However, we observe noisy data that isn&amp;rsquo;t always 100% accurate. Given this noisy data, we make a decision (also either 0 or 1).
Some examples of binary decisions are:
COVID testing (positive or negative) Fraud detection (fraud or no fraud) Confusion Matrix # A 2x2 table that helps us evaluate how effective our predictions were (columns) given reality (rows).</description></item><item><title/><link>https://notes.bencuan.me/data102/causality/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://notes.bencuan.me/data102/causality/</guid><description>Prediction vs Causality # Prediction: using $X$ data, can we guess what $y$ will be?
Causation: does X cause y to change?
Affects decisions Typically established via randomized experiments Case Studies in Causality # Confounding Factor # A Martian comes to Earth and observes that people using umbrellas have a higher probability of getting wet than people who do not. They infer that using an umbrella causes people to get wet.</description></item><item><title/><link>https://notes.bencuan.me/data102/concentration-inequalities/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://notes.bencuan.me/data102/concentration-inequalities/</guid><description>The goal of concentration inequalities is to provide bounds on the probability of a random variable taking values in its tail (regions farthest away from the mean).
This is especially useful when we don&amp;rsquo;t know the distribution of a random variable, or we have a combination of other random variables (sample mean, quicksort, multi-arm bandit&amp;hellip;).
Markov&amp;rsquo;s Inequality # If $X$ is a non-negative random variable with expectation $\mu$, then $$P(X \ge t) \le \frac{\mu}{t}$$</description></item><item><title/><link>https://notes.bencuan.me/data102/decision-theory/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://notes.bencuan.me/data102/decision-theory/</guid><description>So far, in [[binary decision making]] and [[hypothesis testing]], we&amp;rsquo;ve explored how to make as few mistakes as possible when making binary predictions.
Intro to Decision Theory # We can generalize a decision problem to the following:
Suppose there is some unknown quantity of interest $\theta$. $\theta$ is random under a Bayesian approach, and fixed if frequentist. We collect/observe some data $X$. There is some true distribution that the data is drawn from, $p(X | \theta)$.</description></item><item><title/><link>https://notes.bencuan.me/data102/hypothesis-testing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://notes.bencuan.me/data102/hypothesis-testing/</guid><description>Hypothesis Testing # Hypothesis testing is a form of [[binary decision making]] (do we accept or reject the null hypothesis?).
Formulate null hypothesis, alternate hypothesis, and test statistic Compute value of test statistic based on data Simulate test statistic under null hypothesis many times Compare results to determine likelihood of result As an example of how this relates to binary decision making:
Null hypothesis true: reality = 0 Alternative hypothesis true: reality = 1 Fail to reject null: decision = 0 Reject null: decision = 1 So if the null hypothesis is actually true but we end up rejecting it, then a false positive result has occurred.</description></item><item><title/><link>https://notes.bencuan.me/data102/interpretability/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://notes.bencuan.me/data102/interpretability/</guid><description>What do we look for in predictions? # Accuracy: We want predictions to be close to the true values. Simplicity: We want the model to be easy to understand and trust. Interpretability: We want to be able to explain why the model behaved the way it did.
Components of interpretability # What is it?
transparency: understanding the model explanations: understanding the predictions When and why do we care?</description></item><item><title/><link>https://notes.bencuan.me/data102/introduction/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://notes.bencuan.me/data102/introduction/</guid><description>Main Ideas # 1. Making Decisions Under Uncertainty
2. Modeling in the Real World
Assumptions and Robustnessr Problem Solving # ![[Pasted image 20220825115110.png]] Typically, we observe data $x$ and $y$, and want to understand some hidden state in the world $\theta$.
Assumptions # Frequentist: $y$ is random, $\theta$ is fixed Bayesian: $y$ is random, $\theta$ is fixed
Parametric: Make assumptions about the relationship between $\theta$ and $y$, then use these assumptions to find the best value of $\theta$ given $y$ Nonparametric: Don&amp;rsquo;t make any assumptions, and find any good function $f$ such that $\theta = f(y)$</description></item><item><title/><link>https://notes.bencuan.me/data102/MIDTERM-1-INDEX/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://notes.bencuan.me/data102/MIDTERM-1-INDEX/</guid><description>[[review]]:
What is PDF and CDF? Bayes Rule Linearity of expectation and variance (d1.2) Least squares (d1.3a) RMSE (d1.3c) [[binary decision making]]:
confusion matrix (TP TN FP FN) sensitivity, specificity, TPR, TNR, FPR, FNR, FDP (d2.1d) given FPR/TPR, find proportion of positive results conditioned on positive test (d2.3, h1.1a) relating column-wise and row-wise rates with bayes rule (FDP formula) [[hypothesis testing]]
null/alternative distributions and p-values (d2.</description></item><item><title/><link>https://notes.bencuan.me/data102/MIDTERM-2-INDEX/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://notes.bencuan.me/data102/MIDTERM-2-INDEX/</guid><description>[[nonparametric methods]]
logistic regression (parametric) vs KNN (non-parametric) decision trees random forests neural networks gradient ascent/descent relu, gelu, sigmoid 7.1a: ![[Pasted image 20221115163858.png|300]]
7.1b: bias and variance of different methods
[[interpretability]]
interpretability explainability [[causality]]
prediction vs causation three martian examples collider vs confounder structural causal models 8.1 8.2: success rates example 8.3: backdoor criterion correlation coefficient regression coefficient risk difference, risk ratio, odds ratio simpson&amp;rsquo;s paradox, berkson&amp;rsquo;s paradox potential outcomes framework summary slide ITE, ATE, SDO SUTVA natural experiments linear structural model instrumental variables simple ratio vs two stage least squares conditional independence assumption (unconfoundedness assumption 9.</description></item><item><title/><link>https://notes.bencuan.me/data102/nonparametric-methods/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://notes.bencuan.me/data102/nonparametric-methods/</guid><description>What does nonparametric mean? # Nonparametric methods make no assumptions about the distribution of the data or parameters; the null hypothesis is solely generated based on the data.
In some other contexts, the number of parameters in a nonparametric method is either infinite or grows with the number of data points.
Supposing the true state of the world is $\theta$ and our data is $x$, parametric/forward models attempt to make some assumptions about $\theta$ that make us most likely to see the data $x$.</description></item><item><title/><link>https://notes.bencuan.me/data102/parameter-estimation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://notes.bencuan.me/data102/parameter-estimation/</guid><description>Suppose we observe $n$ data points ($x_1$ to $x_n$). Let $\theta$ be some unknown parameter that describes the distribution the data points were sampled from.
As an example, let&amp;rsquo;s say we are trying to quantify how good a product is based on how many positive and negative reviews it has.
This means that data $x_i$ is either $0$ (bad review) or $1$ (good review) Let $p(x_i | \theta) = \theta^{x_i} (1-\theta)^{1-x_i}$.</description></item><item><title/><link>https://notes.bencuan.me/data102/regression-and-glms/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://notes.bencuan.me/data102/regression-and-glms/</guid><description>Posterior Predictive Distribution # Posterior Predictive Distribution: &amp;ldquo;if we saw some data, what future data might we expect?&amp;rdquo;
$P(x_{n+1}|x_1,\cdots,x_n)$ = $\int P(x_{n+1}|\theta)P(\theta|x_1,\cdots,x_n)d\theta$ $= E_{\theta|X}(P(x_{n+1}|\theta))$, which is an average with respect to the posterior. In practice, the posterior component is estimated.
Linear Regression # $$Y = X\beta + \epsilon$$ where $Y$ is a $n \times 1$ vector, $X$ is a $n \times d$ matrix,
$Y$ is unknown and fixed, $X$ is known and fixed, $\epsilon$ is unknown and random (sampled from i.</description></item><item><title/><link>https://notes.bencuan.me/data102/review/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://notes.bencuan.me/data102/review/</guid><description>PDF = probability density function = probability that $X=x$ CDF = cumulative density function = $P(X \le t) = \int_{-\infty}^t f(x)dx$
Bayes Rule: $$P(A|B) = \frac{P(B|A)P(A)}{P(B)}$$ Alternate form for binary decision making (total probability): $$P(A=1) = P(A=1|B=0)P(B=0) + P(A=1|B=1)P(B=1)$$
![[Pasted image 20220928190049.png]] ![[Pasted image 20221018001126.png]] ![[Pasted image 20221018001145.png]]
![[Pasted image 20221028161106.png]]
![[Pasted image 20221028161315.png]] IPW formula: 4 possibilities for values of $y_i$ and $z_i$. Sum up number of times each possibility occurs and divide them by how likely they are to be treated ($e(x)$).</description></item><item><title/><link>https://notes.bencuan.me/data102/sampling/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://notes.bencuan.me/data102/sampling/</guid><description>Some 188 review # ![[04 Bayes Nets#Sampling]]
Markov Chains # http://prob140.org/textbook/content/Chapter_10/01_Transitions.html
Markov chains are sequences of random variables, typically indexed by time. Each possible value is a state.
Markov chains follow the Markov property: each random variable only depends on the previous one.
Another property of Markov chains is that the transition probabilities between states are known and constant over time.
The steady state distribution is one that describes the probability of being at each state $x$ at time $</description></item></channel></rss>