<!doctype html><html lang=en dir=ltr><head><meta property="og:title" content><meta property="og:description" content="Prediction vs Causality #  Prediction: using $X$ data, can we guess what $y$ will be?
Causation: does X cause y to change?
 Affects decisions Typically established via randomized experiments  Case Studies in Causality #  Confounding Factor #  A Martian comes to Earth and observes that people using umbrellas have a higher probability of getting wet than people who do not. They infer that using an umbrella causes people to get wet."><meta property="og:type" content="article"><meta property="og:url" content="https://notes.bencuan.me/data102/causality/"><meta property="article:section" content="data102"><meta property="article:modified_time" content="2023-01-10T12:28:45-08:00"><meta property="og:site_name" content="üóíÔ∏è Ben's Notes"><title>Causality | üóíÔ∏è Ben's Notes</title><link rel=manifest href=/manifest.json><link rel=icon href=/favicon.png type=image/x-icon><link rel=stylesheet href=/book.min.4c35079369dcb636c1f2ee6d9d89b3ea930d29398065746c2a5856a3b3133e82.css integrity="sha256-TDUHk2nctjbB8u5tnYmz6pMNKTmAZXRsKlhWo7MTPoI=" crossorigin=anonymous><meta charset=utf-8><meta name=description content="Prediction vs Causality #  Prediction: using $X$ data, can we guess what $y$ will be?
Causation: does X cause y to change?
 Affects decisions Typically established via randomized experiments  Case Studies in Causality #  Confounding Factor #  A Martian comes to Earth and observes that people using umbrellas have a higher probability of getting wet than people who do not. They infer that using an umbrella causes people to get wet."><title>üóíÔ∏è Ben's Notes</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" type=image/png href=https://notes.bencuan.me//favicon.png><link href=https://notes.bencuan.me/styles.e08ceb33360cec132feb69cfb982e2a4.min.css rel=stylesheet><link href=https://notes.bencuan.me/quartz/styles/_light_syntax.86a48a52faebeaaf42158b72922b1c90.min.css rel=stylesheet id=theme-link><link rel=preload href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css as=style onload='this.onload=null,this.rel="stylesheet"' integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/copy-tex.min.js integrity=sha384-ww/583aHhxWkz5DEVn6OKtNiIaLi2iBRNZXfJRiY1Ai7tnJ9UXpEsyvOITVpTl4A crossorigin=anonymous></script>
<script src=https://notes.bencuan.me/quartz/js/darkmode.9d3e1c1ebec61822893ee54cff5423d0.min.js></script>
<script src=https://notes.bencuan.me/quartz/js/util.c69e233dc1cc331a30b0f670e657b425.min.js></script>
<script async src=https://unpkg.com/@floating-ui/core@0.7.3></script>
<script async src=https://unpkg.com/@floating-ui/dom@0.5.4></script>
<script src=https://notes.bencuan.me/quartz/js/popover.f03552ccb84d99ca615d1cfb9abde59e.min.js></script>
<script defer src=https://notes.bencuan.me/quartz/js/code-title.ce4a43f09239a9efb48fee342e8ef2df.min.js></script>
<script defer src=https://notes.bencuan.me/quartz/js/clipboard.2913da76d3cb21c5deaa4bae7da38c9f.min.js></script>
<script defer src=https://notes.bencuan.me/quartz/js/callouts.7723cac461d613d118ee8bb8216b9838.min.js></script>
<script>const SEARCH_ENABLED=!1,LATEX_ENABLED=!0,PRODUCTION=!0,BASE_URL="https://notes.bencuan.me/",fetchData=Promise.all([fetch("https://notes.bencuan.me/indices/linkIndex.cb63c20646beb5aca392f94aa4ac4f05.min.json").then(e=>e.json()).then(e=>({index:e.index,links:e.links})),fetch("https://notes.bencuan.me/indices/contentIndex.4be2d3c1931df649350650e12e20a899.min.json").then(e=>e.json())]).then(([{index:e,links:t},n])=>({index:e,links:t,content:n})),render=()=>{const e=new URL(BASE_URL),t=e.pathname,n=window.location.pathname,s=t==n;addCopyButtons(),addCollapsibleCallouts(),initPopover("https://notes.bencuan.me",!0);const o=document.getElementById("footer");if(o){const e=document.getElementById("graph-container");if(!e)return requestAnimationFrame(render);e.textContent="";const t=s&&!0;drawGraph("https://notes.bencuan.me",t,[{"/moc":"#4388cc"}],t?{centerForce:1,depth:-1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.5,linkDistance:1,opacityScale:3,repelForce:1,scale:1.4}:{centerForce:1,depth:1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.6,linkDistance:1,opacityScale:3,repelForce:2,scale:1.2})}var i=document.getElementsByClassName("mermaid");i.length>0&&import("https://unpkg.com/mermaid@9/dist/mermaid.esm.min.mjs").then(e=>{e.default.init()})},init=(e=document)=>{addCopyButtons(),addTitleToCodeBlocks(),renderMathInElement(e.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],macros:{'‚Äô':"'"},throwOnError:!1})}</script><script>window.Million={navigate:e=>window.location.href=e,prefetch:()=>{}},window.addEventListener("DOMContentLoaded",()=>{init(),render()})</script></head><div id=search-container><div id=search-space><input autocomplete=off id=search-bar name=search type=text aria-label=Search placeholder="Search for something..."><div id=results-container></div></div></div><script src=https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js integrity="sha256-i3A0NZGkhsKjVMzFxv3ksk0DZh3aXqu0l49Bbh0MdjE=" crossorigin=anonymous defer></script>
<script defer src=https://notes.bencuan.me/quartz/js/full-text-search.e6e2e0c213187ca0c703d6e2c7a77fcd.min.js></script><header class=book-header><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu></label><h1 id=page-title><a href=https://notes.bencuan.me/>üóíÔ∏è Ben's Notes</a></h1><div class=spacer></div><div id=search-icon class=quartz-search><p>Search</p><svg tabindex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg></div><div class=darkmode><input class=toggle id=darkmode-toggle type=checkbox tabindex=-1>
<label id=toggle-label-light for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="dayIcon" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35"><title>Light Mode</title><path d="M6 17.5C6 16.672 5.328 16 4.5 16h-3C.672 16 0 16.672.0 17.5S.672 19 1.5 19h3C5.328 19 6 18.328 6 17.5zM7.5 26c-.414.0-.789.168-1.061.439l-2 2C4.168 28.711 4 29.086 4 29.5 4 30.328 4.671 31 5.5 31c.414.0.789-.168 1.06-.44l2-2C8.832 28.289 9 27.914 9 27.5 9 26.672 8.329 26 7.5 26zm10-20C18.329 6 19 5.328 19 4.5v-3C19 .672 18.329.0 17.5.0S16 .672 16 1.5v3C16 5.328 16.671 6 17.5 6zm10 3c.414.0.789-.168 1.06-.439l2-2C30.832 6.289 31 5.914 31 5.5 31 4.672 30.329 4 29.5 4c-.414.0-.789.168-1.061.44l-2 2C26.168 6.711 26 7.086 26 7.5 26 8.328 26.671 9 27.5 9zM6.439 8.561C6.711 8.832 7.086 9 7.5 9 8.328 9 9 8.328 9 7.5c0-.414-.168-.789-.439-1.061l-2-2C6.289 4.168 5.914 4 5.5 4 4.672 4 4 4.672 4 5.5c0 .414.168.789.439 1.06l2 2.001zM33.5 16h-3c-.828.0-1.5.672-1.5 1.5s.672 1.5 1.5 1.5h3c.828.0 1.5-.672 1.5-1.5S34.328 16 33.5 16zM28.561 26.439C28.289 26.168 27.914 26 27.5 26c-.828.0-1.5.672-1.5 1.5.0.414.168.789.439 1.06l2 2C28.711 30.832 29.086 31 29.5 31c.828.0 1.5-.672 1.5-1.5.0-.414-.168-.789-.439-1.061l-2-2zM17.5 29c-.829.0-1.5.672-1.5 1.5v3c0 .828.671 1.5 1.5 1.5s1.5-.672 1.5-1.5v-3C19 29.672 18.329 29 17.5 29zm0-22C11.71 7 7 11.71 7 17.5S11.71 28 17.5 28 28 23.29 28 17.5 23.29 7 17.5 7zm0 18c-4.136.0-7.5-3.364-7.5-7.5s3.364-7.5 7.5-7.5 7.5 3.364 7.5 7.5S21.636 25 17.5 25z"/></svg></label><label id=toggle-label-dark for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="nightIcon" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'"><title>Dark Mode</title><path d="M96.76 66.458c-.853-.852-2.15-1.064-3.23-.534-6.063 2.991-12.858 4.571-19.655 4.571C62.022 70.495 50.88 65.88 42.5 57.5 29.043 44.043 25.658 23.536 34.076 6.47c.532-1.08.318-2.379-.534-3.23-.851-.852-2.15-1.064-3.23-.534-4.918 2.427-9.375 5.619-13.246 9.491-9.447 9.447-14.65 22.008-14.65 35.369.0 13.36 5.203 25.921 14.65 35.368s22.008 14.65 35.368 14.65c13.361.0 25.921-5.203 35.369-14.65 3.872-3.871 7.064-8.328 9.491-13.246C97.826 68.608 97.611 67.309 96.76 66.458z"/></svg></label></div></header><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control><main class=flex><aside class=book-menu><div class=book-menu-content><nav><div class=menu-search><div id=search-icon class=quartz-search><p>Search</p><svg tabindex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg></div></div><ul><li><input type=checkbox id=section-da99de074169576d9f77860d41691a68 class=toggle>
<label for=section-da99de074169576d9f77860d41691a68 class="flex justify-between"><a href=/cs61b/ class=book-collapse-toggle>CS 61B</a></label><ul><li><span class=book-menu-title>Object Oriented Programming</span><ul><li><a href=/cs61b/oop/inheritance/>Inheritance</a></li><li><a href=/cs61b/oop/access-control/>Access Control</a></li><li><a href=/cs61b/oop/dynamic-method-selection/>Dynamic Method Selection</a></li><li><a href=/cs61b/oop/objects/>Java Objects</a></li><li><a href=/cs61b/oop/generics/>Generic Types</a></li></ul></li><li><span class=book-menu-title>Asymptotics</span><ul><li><a href=/cs61b/asymptotics/asymptotics/>Asymptotic Analysis Basics</a></li><li><a href=/cs61b/asymptotics/amortization/>Amortization</a></li><li><a href=/cs61b/asymptotics/asymptotics-practice/>Asymptotics Practice</a></li></ul></li><li><span class=book-menu-title>Abstract Data Types</span><ul><li><input type=checkbox id=section-70dba6a254ce0b2bcdb77dd58dbf6cdc class=toggle>
<label for=section-70dba6a254ce0b2bcdb77dd58dbf6cdc class="flex justify-between"><a href=/cs61b/abstract-data-types/collections/ class=book-collapse-toggle>Collections</a></label><ul><li><a href=/cs61b/abstract-data-types/collections/arrays/>Arrays</a></li><li><a href=/cs61b/abstract-data-types/collections/linked-lists/>Linked Lists</a></li><li><a href=/cs61b/abstract-data-types/collections/sets/>Sets</a></li><li><a href=/cs61b/abstract-data-types/collections/stacks-and-queues/>Stacks and Queues</a></li></ul></li><li><input type=checkbox id=section-5eb2d5b415a82a45c7861774887e844b class=toggle>
<label for=section-5eb2d5b415a82a45c7861774887e844b class="flex justify-between"><a href=/cs61b/abstract-data-types/binary-trees/ class=book-collapse-toggle>Binary Trees</a></label><ul><li><a href=/cs61b/abstract-data-types/binary-trees/balanced-search-structures/>Balanced Search Structures</a></li><li><a href=/cs61b/abstract-data-types/binary-trees/heaps/>Heaps</a></li><li><a href=/cs61b/abstract-data-types/binary-trees/tries/>Tries</a></li></ul></li><li><a href=/cs61b/abstract-data-types/graphs/>Graphs</a></li><li><a href=/cs61b/abstract-data-types/hashing/>Hashing and Hash Tables</a></li><li><a href=/cs61b/abstract-data-types/union-find-disjoint-sets/>Union Find (Disjoint Sets)</a></li><li><a href=/cs61b/abstract-data-types/comparables-and-comparators/>Comparables and Comparators</a></li></ul></li><li><span class=book-menu-title>Algorithms</span><ul><li><input type=checkbox id=section-26838f44377a3dfc0925929b8b82de69 class=toggle>
<label for=section-26838f44377a3dfc0925929b8b82de69 class="flex justify-between"><a href=/cs61b/algorithms/searching/ class=book-collapse-toggle>Searching</a></label><ul><li><a href=/cs61b/algorithms/searching/binary-search/>Binary Search</a></li><li><a href=/cs61b/algorithms/searching/breadth-first-search-bfs/>Breadth First Search (DFS)</a></li><li><a href=/cs61b/algorithms/searching/depth-first-search-dfs/>Depth First Search (DFS)</a></li></ul></li><li><input type=checkbox id=section-fd5238a874e42ff4e1ab0e65c20a9824 class=toggle>
<label for=section-fd5238a874e42ff4e1ab0e65c20a9824 class="flex justify-between"><a href=/cs61b/algorithms/shortest-paths/ class=book-collapse-toggle>Shortest Paths</a></label><ul><li><a href=/cs61b/algorithms/shortest-paths/dijkstras-algorithm/>Dijkstra's Algorithm</a></li><li><a href=/cs61b/algorithms/shortest-paths/a-search/>A* Search</a></li></ul></li><li><input type=checkbox id=section-434cf8cf80558e0886666bff24d740d1 class=toggle>
<label for=section-434cf8cf80558e0886666bff24d740d1 class="flex justify-between"><a href=/cs61b/algorithms/minimum-spanning-trees/ class=book-collapse-toggle>Minimum Spanning Trees</a></label><ul><li><a href=/cs61b/algorithms/minimum-spanning-trees/kruskals-algorithm/>Kruskal's Algorithm</a></li><li><a href=/cs61b/algorithms/minimum-spanning-trees/prims-algorithm/>Prim's Algorithm</a></li></ul></li><li><a href=/cs61b/algorithms/sorting/>Sorting</a></li><li><a href=/cs61b/algorithms/minimax/>Minimax Algorithm</a></li></ul></li><li><span class=book-menu-title>Misc. Topics</span><ul><li><a href=/cs61b/misc-topics/exceptions/>Exceptions</a></li><li><a href=/cs61b/misc-topics/modular-arithmetic/>Modular Arithmetic</a></li><li><a href=/cs61b/misc-topics/more-resources/>More Resources</a></li></ul></li></ul></li><li><input type=checkbox id=section-6d80b867b0e7b10bf4afdb6cb30147b7 class=toggle>
<label for=section-6d80b867b0e7b10bf4afdb6cb30147b7 class="flex justify-between"><a href=/cs186/ class=book-collapse-toggle>CS 186</a></label><ul><li><a href=/cs186/io/>What is an I/O and why should I care?</a></li><li><a href=/cs186/00-SQL-Basics/>SQL Basics</a></li><li><a href=/cs186/01-Disks-Buffers-Files/>Disks, Buffers, and Files</a></li><li><a href=/cs186/02-B+-Trees/>B+ Trees</a></li><li><a href=/cs186/03-Buffer-Management/>Buffer Management</a></li><li><a href=/cs186/04-Sorting-and-Hashing/>Sorting and Hashing</a></li><li><a href=/cs186/05-Iterators-and-Joins/>Iterators and Joins</a></li><li><a href=/cs186/06-Relational-Algebra/>Relational Algebra</a></li><li><a href=/cs186/07-Query-Optimization/>Query Optimization</a></li><li><a href=/cs186/08-Transactions/>Transactions and ACID</a></li><li><a href=/cs186/09-Parallel-Query-Processing/>Parallel Query Processing</a></li><li><a href=/cs186/10-Recovery/>Recovery</a></li><li><a href=/cs186/11-Distributed-Transactions/>Distributed Transactions</a></li><li><a href=/cs186/12-ER-Diagrams/>E-R Diagrams</a></li></ul></li><li><input type=checkbox id=section-ee67b82ee54e976a9f81e3e41661ae13 class=toggle>
<label for=section-ee67b82ee54e976a9f81e3e41661ae13 class="flex justify-between"><a href=/cs70/ class=book-collapse-toggle>CS 70</a></label><ul><li><a href=/cs70/latex-reference/>LaTeX Reference</a></li><li><a href=/cs70/SUMMARY/>Summary</a></li><li><span class=book-menu-title>Discrete Math</span><ul><li><a href=/cs70/discrete-math/overview/>Discrete Math Overview</a></li><li><a href=/cs70/discrete-math/propositional-logic/>Propositional Logic</a></li><li><a href=/cs70/discrete-math/proofs/>Proofs</a></li><li><a href=/cs70/discrete-math/stable-matching/>Stable Matching</a></li><li><a href=/cs70/discrete-math/graphs/>Graphs</a></li><li><a href=/cs70/discrete-math/modular-arithmetic/>Modular Arithmetic</a></li><li><a href=/cs70/discrete-math/rsa-cryptography/>RSA Cryptography</a></li><li><a href=/cs70/discrete-math/polynomials/>Polynomials</a></li><li><a href=/cs70/discrete-math/countability/>Countability</a></li><li><a href=/cs70/discrete-math/computability/>Computability</a></li></ul></li><li><span class=book-menu-title>Probability</span><ul><li><a href=/cs70/probability/probability-overview/>Probability Overview</a></li><li><a href=/cs70/probability/counting/>Counting</a></li><li><a href=/cs70/probability/discrete-probability/>Discrete Probability</a></li><li><a href=/cs70/probability/hashing-and-the-union-bound/>Hashing and the Union Bound</a></li><li><a href=/cs70/probability/expectation-and-variance/>Expectation and Variance</a></li><li><a href=/cs70/probability/concentration-inequalities/>Concentration Inequalities</a></li><li><a href=/cs70/probability/continuous-probability/>Continuous Probability</a></li><li><a href=/cs70/probability/markov-chains/>Markov Chains</a></li><li><a href=/cs70/probability/the-beta-family/>The Beta Family</a></li><li><a href=/cs70/probability/conditional-expectation-and-variance/>Conditional Expectation and Variance</a></li></ul></li></ul></li><li><span class=book-menu-title>Cs162s</span><ul><li><a href=/cs162/Appendix-A-GDB-foobars/>Appendix a Gdb Foobars</a></li><li><a href=/cs162/Appendix-B-Midterm-Reference/>Appendix B Midterm Reference</a></li><li><a href=/cs162/Chapter-1-OS-Basics/>Chapter 1 Os Basics</a></li><li><a href=/cs162/Chapter-2-Processes/>Chapter 2 Processes</a></li><li><a href=/cs162/Chapter-3-Threads/>Chapter 3 Threads</a></li><li><a href=/cs162/Chapter-4-I-O/>Chapter 4 I O</a></li><li><a href=/cs162/Chapter-5-Synchronization/>Chapter 5 Synchronization</a></li><li><a href=/cs162/Chapter-6-Scheduling/>Chapter 6 Scheduling</a></li><li><a href=/cs162/Chapter-7-Address-Translation/>Chapter 7 Address Translation</a></li><li><a href=/cs162/Chapter-8-Caching/>Chapter 8 Caching</a></li><li><a href=/cs162/Chapter-9-File-Systems/>Chapter 9 File Systems</a></li><li><a href=/cs162/CS162-Index/>Cs162 Index</a></li></ul></li><li><span class=book-menu-title>Cs168s</span><ul><li><a href=/cs168/addressing-ip/>Addressing (Ip)</a></li><li><a href=/cs168/cli/>CLI</a></li><li><a href=/cs168/congestion-control/>Congestion Control</a></li><li><a href=/cs168/dns/>DNS</a></li><li><a href=/cs168/end-to-end-operation/>End to End Operation</a></li><li><a href=/cs168/ethernet/>Ethernet</a></li><li><a href=/cs168/final-review/>Final Review</a></li><li><a href=/cs168/interdomain-routing-bgp/>Interdomain Routing (Bgp)</a></li><li><a href=/cs168/internet-organization-and-layers/>Internet Organization and Layers</a></li><li><a href=/cs168/intradomain-routing/>Intradomain Routing</a></li><li><a href=/cs168/intro-to-the-internet/>Intro to the Internet</a></li><li><a href=/cs168/measuring-link-performance/>Measuring Link Performance</a></li><li><a href=/cs168/reliability/>Reliability</a></li><li><a href=/cs168/resource-sharing-packet-and-circuit-switching/>Resource Sharing (Packet and Circuit Switching)</a></li><li><a href=/cs168/sockets-and-ports/>Sockets and Ports</a></li><li><a href=/cs168/special-topics/>Special Topics</a></li><li><a href=/cs168/TCP/>Tcp</a></li><li><a href=/cs168/web/>Web</a></li></ul></li><li><span class=book-menu-title>Data102s</span><ul><li><a href=/data102/bandits/>Bandits</a></li><li><a href=/data102/binary-decision-making/>Binary Decision Making</a></li><li><a href=/data102/causality/ class=active>Causality</a></li><li><a href=/data102/concentration-inequalities/>Concentration Inequalities</a></li><li><a href=/data102/decision-theory/>Decision Theory</a></li><li><a href=/data102/hypothesis-testing/>Hypothesis Testing</a></li><li><a href=/data102/interpretability/>Interpretability</a></li><li><a href=/data102/introduction/>Introduction</a></li><li><a href=/data102/MIDTERM-1-INDEX/>Midterm 1 Index</a></li><li><a href=/data102/MIDTERM-2-INDEX/>Midterm 2 Index</a></li><li><a href=/data102/nonparametric-methods/>Nonparametric Methods</a></li><li><a href=/data102/parameter-estimation/>Parameter Estimation</a></li><li><a href=/data102/regression-and-glms/>Regression and Glms</a></li><li><a href=/data102/review/>Review</a></li><li><a href=/data102/sampling/>Sampling</a></li></ul></li></ul><ul><li><a href=/contributing target=_blank rel=noopener>Contribute</a></li><li><a href=https://github.com/64bitpandas/notes/issues target=_blank rel=noopener>Feedback</a></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class="book-page container"><article class=markdown><h1 class=title>Causality</h1><h2 id=prediction-vs-causality>Prediction vs Causality
<a class=anchor href=#prediction-vs-causality>#</a></h2><p><strong>Prediction:</strong> using $X$ data, can we guess what $y$ will be?</p><p><strong>Causation:</strong> does X cause y to change?</p><ul><li>Affects decisions</li><li>Typically established via randomized experiments</li></ul><h2 id=case-studies-in-causality>Case Studies in Causality
<a class=anchor href=#case-studies-in-causality>#</a></h2><h3 id=confounding-factor>Confounding Factor
<a class=anchor href=#confounding-factor>#</a></h3><p>A Martian comes to Earth and observes that people using umbrellas have a higher probability of getting wet than people who do not. They infer that using an umbrella causes people to get wet.</p><p>This is an example of a confounding factor (rain) impacting both the independent and dependent variables. In reality, this third factor explains both of the observed factors (umbrella usage and getting wet)</p><h3 id=time-and-causality>Time and Causality
<a class=anchor href=#time-and-causality>#</a></h3><p>Another martian observes that movies at a movie theater start after a group of people arrive and sit down. They conclude that people sitting down causes the movie to start.</p><p>This is an example of causality not always going forward in time: in this case, the movie being scheduled for a certain time actually caused the people to arrive and sit down, not the other way around.</p><h3 id=zero-correlation>Zero correlation
<a class=anchor href=#zero-correlation>#</a></h3><p>A third martian observes an expert sailor moving the rudder a lot, as the boat continues in a straight line despite heavy winds. The martian concludes that moving the rudder has no effect on the direction of the boat.</p><p>This is an example of variables with zero correlation still having a causal relationship.</p><h2 id=structural-causal-models>Structural Causal Models
<a class=anchor href=#structural-causal-models>#</a></h2><p>Structural Causal Models (SCMs, Graphical Models, Causal DAGs) are similar to <a class="internal-link broken">04 Bayes Nets</a>, except that arrows show causality in addition to dependence.</p><p><a class="internal-link broken">Pasted image 20221019224955.png</a></p><h2 id=quantifying-association>Quantifying Association
<a class=anchor href=#quantifying-association>#</a></h2><h3 id=pearson-correlation-coefficient>Pearson Correlation Coefficient
<a class=anchor href=#pearson-correlation-coefficient>#</a></h3><p>The Pearson Correlation Coefficient $\rho_{Z,Y}$ between two variables $Z$ and $Y$ can be described below:
$$\rho_{Z,Y} = \frac{cov(Z,Y)}{\sqrt{var(Z)var(Y)}}$$
where $cov(X,Y)$ is the
<a href=http://prob140.org/textbook/content/Chapter_13/01_Covariance.html rel=noopener>covariance</a>. $\rho$ is between -1 (perfect negative correlation) and 1 (perfect correlation).</p><h3 id=regression-coefficient>Regression Coefficient
<a class=anchor href=#regression-coefficient>#</a></h3><p>Suppose we have a linear regression $Y = \alpha + \beta Z + \epsilon$.
$\epsilon$ is the error, where $E[\epsilon] = 0$ and $cov(Z, \epsilon) = 0$.</p><p>The regression coefficient $\beta$ is described as follows:
$$\beta = \rho_{Z,Y} \cdot \frac{\sigma_Y}{\sigma_Z} = \frac{cov(Z,Y)}{var(Z)}$$</p><p>If we introduce another variable (i.e. $Y = \alpha + \beta Z + \gamma X)$, then $\beta$ describes the effect of $Z$ on $Y$ while adjusting for the effects of $X$.</p><h3 id=risk-differences-and-risk-ratio>Risk Differences and Risk Ratio
<a class=anchor href=#risk-differences-and-risk-ratio>#</a></h3><p>If in a binary situation (either the result $Y$ is $1$ or $0$), then we can quantify association using three methods:</p><p><strong>Risk Difference:</strong> $P(Y=1|Z=1) - P(Y=1|Z=0)$
<strong>Risk Ratio:</strong> $P(Y=1|Z=1)/P(Y=1|Z=0)$
<strong>Odds Ratio:</strong>
$$\frac{P(Y=1|Z=1)/P(Y=0|Z=1)}{P(Y=1|Z=0)/P(Y=0|Z=0)}$$</p><h2 id=paradoxes>Paradoxes
<a class=anchor href=#paradoxes>#</a></h2><h3 id=simpsons-paradox>Simpson&rsquo;s Paradox
<a class=anchor href=#simpsons-paradox>#</a></h3><p>Aggregated data and disaggregated data create different conclusions.</p><p>For example, suppose two restaurants were rated as follows:<a class="internal-link broken">200</a>
Clearly, Restaurant B is better since it received a higher ratio of positive reviews.</p><p>However, if we break up the data by year, the following is observed:
<a class="internal-link broken">400</a>
Now, Restaurant A looks clearly better since it performed better in both 2019 and 2020.</p><p>Simpson&rsquo;s Paradox isn&rsquo;t really a paradox, since it just occurs due to a confounding variable. In the example above, the confounding variable is the effect of the COVID-19 pandemic on making reviews more negative overall: <a class="internal-link broken">300</a>
If we only look at the bottom half of this causal DAG, we can observe the results that we saw above without understanding why it occurs.</p><p>If a confounding variable is present, we should condition on it and draw conclusions based on the disaggregated results.</p><h3 id=berksons-paradox>Berkson&rsquo;s Paradox
<a class=anchor href=#berksons-paradox>#</a></h3><p>Berkson&rsquo;s Paradox is very similar to Simpson&rsquo;s Paradox, but acts on a <strong>collider</strong> variable rather than a confounding variable.</p><p>For instance, only plotting perceived flavor with perceived appearance for bread at a bakery could seem to show no correlation:</p><p><a class="internal-link broken">Pasted image 20221019231326.png</a></p><p>However, if we split the bread on display with the bread in the back, the following occurs:
<a class="internal-link broken">Pasted image 20221019231348.png</a></p><p>The DAG looks like the following.</p><p><a class="internal-link broken">Pasted image 20221019231220.png</a></p><h2 id=potential-outcomes-framework>Potential Outcomes Framework
<a class=anchor href=#potential-outcomes-framework>#</a></h2><p>In the Potential Outcomes Framework, we construct universes under the assumption that no confounding variables exist.</p><p>Suppose we have two universes, 0 and 1, where one has a treatment and one has a control in completely identical conditions. The outcomes are Y(0) and Y(1) respectively. The <strong>Individual Treatment Effect</strong> is equal to $Y(1) - Y(0)$.</p><p>This attempts to mitigate the fundamental problem of causal inference, which is that we can never truly compute the individual treatment effect in the real world since it&rsquo;s impossible to fully replicate a particular situation and only change one variable.</p><p>Since the ITE is impossible to compute, we&rsquo;ll try to find the <strong>average treatment effect (ATE)</strong>, $E[Y(1) - Y(0)]$, which expands to $E[Y(1) | Z=1] P(Z=1) - E[Y(0)|Z=1] P(Z=1) + E[Y(1)|Z=0] P(Z=0) - E[Y(0)|Z=0]P(Z=0)$. In most cases, this value is also impossible to compute because of the non-matching $Y$ and $Z$ terms (in the treatment case, what would have happened if they didn&rsquo;t actually receive the treatment).</p><p>An attempt to make this computable is the <strong>Simple Difference in Observed Means (SDO)</strong> which is simply $E[Y(1)|Z=1] - E[Y(0)|Z=0]$. This would only be equal to the ATE if $Y$ and $Z$ are independent (if $A$ and $B$ are independent, then $E[A|B] = E[A]$). This is true in a randomized experiment.</p><p>A <strong>unit</strong> is a single data point that we&rsquo;re trying to make causal inferences on. For example, the unit in a drug test could be one person.</p><ul><li>Each unit has three random variables $(Z_i, Y_i(0), Y_i(1))$ where $Z$ is $1$ if the treatment was applied, $0$ otherwise.</li><li><strong>superpopulation model:</strong> units are i.i.d. (newer framework)</li><li><strong>fixed-sample model</strong>: $Z_i$ are i.i.d, $Y$ are fixed and unknown (traditional)</li></ul><p><strong>Science Table:</strong> displays units in a table. In reality, we can&rsquo;t observe the $Y$ corresponding to the outcome that didn&rsquo;t happen; the problem we need to solve is how we can fill these values in.
<a class="internal-link broken">Pasted image 20221025225351.png</a></p><p><strong>Stable Unit Treatment Value Assumption (SUTVA):</strong></p><ul><li>The same treatment is applied to all units<ul><li>Example: surgery outcomes do not follow this assumption because some surgeons could be more skiilled than others</li></ul></li><li>Units do not affect each other<ul><li>Example: social media influencers may affect the behaviors of their followers</li></ul></li></ul><h2 id=causal-inference-in-observational-studies>Causal Inference in Observational Studies
<a class=anchor href=#causal-inference-in-observational-studies>#</a></h2><p>Since we can&rsquo;t truly randomize treatments in observational studies, it&rsquo;s often difficult to find causality.</p><p>There are two main categories of methods for establishing causal inference:</p><p><strong>Unconfoundedness (conditional independence):</strong> Consider all confounding variables $X$, then assume $Z$ and $Y$ are conditionally independent given $X$.</p><ul><li>Matching, outcome regression, propensity weighting</li></ul><p><strong>Natrual experiments:</strong> Find natural sources of randomness and use these to get around the confound</p><ul><li>Instrumental variables, regression discontinuity, difference in differences</li></ul><h3 id=linear-structural-model>Linear Structural Model
<a class=anchor href=#linear-structural-model>#</a></h3><p>$$Y = \alpha + \beta X + \tau Z + \epsilon$$</p><ul><li>$E[\epsilon] = 0$, and $\epsilon$ is independent of $Z$ and $X$.</li><li>$X$ is the confounder, $Y$ is the outcome, and $Z$ is the treatment.<ul><li><a class="internal-link broken">300</a></li></ul></li><li>Assume we can&rsquo;t know $X$ (too many considerations).</li><li>The ATE is equal to $\tau$.</li><li>Using ordinary least squares, $\hat\tau = cov(Y,Z)/var(Z) = cov(\tau Z, Z)/var(Z) + cov(\beta X, Z)/var(Z)$.
$$\hat\tau_{OLS} = \tau + \beta \frac{cov(X,Z)}{var(Z)}$$ where the second term is the <strong>omitted variable bias</strong>.</li></ul><h3 id=instrumental-variables>Instrumental Variables
<a class=anchor href=#instrumental-variables>#</a></h3><p>If there exists a truly random variable $W$, we may be able to take advantage of it in the model above. Certain conditions are required:</p><ul><li>W is independent of $X$.</li><li>$W$ only affects $Y$ through $Z$.
One example of an instrumental variable is the Vietnam War draft lottery system, where individuals were selected for service based on their birthday. This would directly affect whether or not the individual served in the lottery independent of other confounding factors, which could then be used to establish causality between military service and another variable.</li></ul><p><strong>Simple ratio of regression coefficients:</strong></p><ul><li>First, fit $Z$ from $W$ to get $\gamma$.</li><li>Then, fit Y from W to get $\tau \times \gamma$.</li><li>Divide the two values to get $\tau$ which is equal to the ATE.</li></ul><p><strong>Two Stage Least Squares:</strong> first predict $Z$ from $W$, then fit $Y$ from the predictions of $Z$ to get $\tau$ (ATE).
$$Y = \alpha + \beta X + \tau Z + \epsilon$$
$$Z = \alpha&rsquo; + \gamma W + \eta X + \delta$$</p><h3 id=conditional-independence-assumption>Conditional Independence Assumption
<a class=anchor href=#conditional-independence-assumption>#</a></h3><p>If we know the confounder, then the treatment and potentials might be independent (Z is independent of Y given X). This is also known as <strong>unconfoundedness</strong>.</p><p>Let the <strong>Conditional ATE</strong> be equal to $\tau(x) = E(Y(1) - Y(0) | X=x)$ such that $\tau = E(\tau(X))$ by the
<a href=https://en.wikipedia.org/wiki/Law_of_total_expectation rel=noopener>tower property</a>.</p><p><strong>Outcome regression:</strong> compute $\tau(x)$ for every $x$ and take the average. This is simple for binary variables or linear relationships (where $Y = aX + \tau Z)$, but is difficult for nonlinear or higher dimensional relationships.</p><p><strong>Matching:</strong> for every treated unit where $Z_i = 1$, find an untreated unit that has the same confounder values, and subtract their $Y$ values to estimate individual effect. Repeat this for every untreated unit, and average overall units to estiamte ATE.</p><p>This only works if there happen to be exact matches; approximate matching gets messy and requires additional assumptions.</p><h3 id=inverse-propensity-score-weighting>Inverse Propensity Score Weighting
<a class=anchor href=#inverse-propensity-score-weighting>#</a></h3><p>Main idea: reweight the population to approximate the true potential outcome averages E(Y(0)) and E(Y(1)).</p><p><a class="internal-link broken">Pasted image 20221028161315.png</a>
IPW formula: 4 possibilities for values of $y_i$ and $z_i$. Sum up number of times each possibility occurs and divide them by how likely they are to be treated ($e(x)$).</p><ul><li>The propensity score $e(X) = P(Z=1|X=x)$</li><li>Strategy:<ul><li>make a table of all possible values of X and Z</li><li>divide each one by how likely it is to occur, and sum them all together</li><li>divide the whole result by $n$</li></ul></li></ul><hr><div class=page-end id=footer><div class=backlinks-container><h3>Backlinks</h3><ul class=backlinks><li>No backlinks found</li></ul></div><div><script src=https://cdn.jsdelivr.net/npm/d3@6.7.0/dist/d3.min.js integrity="sha256-+7jaYCp29O1JusNWHaYtgUn6EhuP0VaFuswhNV06MyI=" crossorigin=anonymous></script><h3>Interactive Graph</h3><div id=graph-container></div><style>:root{--g-node:var(--secondary);--g-node-active:var(--primary);--g-node-inactive:var(--visited);--g-link:var(--outlinegray);--g-link-active:#5a7282}</style><script src=https://notes.bencuan.me/quartz/js/graph.cbd78cfa87df7d3e230d16fc24f06548.js></script></div></div><div id=contact_buttons><footer><p>Made with <a href=https://github.com/64bitpandas/amethyst>Amethyst</a>, ¬© 2023 Ben Cuan</p><ul><li><a href=https://notes.bencuan.me/>Home</a></li><li><a href=https://github.com/64bitpandas/notes/issues>Feedback</a></li><li><a href=https://bencuan.me>Website</a></li></ul></footer></div></article><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><ul><li><a href=#prediction-vs-causality>Prediction vs Causality</a></li><li><a href=#case-studies-in-causality>Case Studies in Causality</a><ul><li><a href=#confounding-factor>Confounding Factor</a></li><li><a href=#time-and-causality>Time and Causality</a></li><li><a href=#zero-correlation>Zero correlation</a></li></ul></li><li><a href=#structural-causal-models>Structural Causal Models</a></li><li><a href=#quantifying-association>Quantifying Association</a><ul><li><a href=#pearson-correlation-coefficient>Pearson Correlation Coefficient</a></li><li><a href=#regression-coefficient>Regression Coefficient</a></li><li><a href=#risk-differences-and-risk-ratio>Risk Differences and Risk Ratio</a></li></ul></li><li><a href=#paradoxes>Paradoxes</a><ul><li><a href=#simpsons-paradox>Simpson&rsquo;s Paradox</a></li><li><a href=#berksons-paradox>Berkson&rsquo;s Paradox</a></li></ul></li><li><a href=#potential-outcomes-framework>Potential Outcomes Framework</a></li><li><a href=#causal-inference-in-observational-studies>Causal Inference in Observational Studies</a><ul><li><a href=#linear-structural-model>Linear Structural Model</a></li><li><a href=#instrumental-variables>Instrumental Variables</a></li><li><a href=#conditional-independence-assumption>Conditional Independence Assumption</a></li><li><a href=#inverse-propensity-score-weighting>Inverse Propensity Score Weighting</a></li></ul></li></ul></li></ul></nav></div></aside></main></body></html>