{
  "/": {
    "title": "Welcome!",
    "content": "\n## Introduction\n\nHi there! Seems like you stumbled upon my archive of course notes! \n\nOver the years, I've found that the most effective way for me to learn and process information was to teach it. Since this isn't always practical or possible, I've ended up creating these production-quality notes as an alternative.\n\nAlthough many courses at Berkeley (especially CS courses) have excellent materials and often already have a full set of course notes, I've found that many students- myself included- often struggle to process information when it's that dense. My hope is that these notes can serve as a secondary, lighter perspective on things. \n\nHere, you'll find a wide variety of content from basic concepts, practice problems, and example algorithm walkthroughs. Since they were all made at various times over 4 years, the quality and style may be wildly different from page to page. I intend to go through these notes and resolve any inconsistencies over (a long period of) time.\n\n## Index\n\nHere are the courses that I currently have notes available for, and their statuses:\n\n - [CS 61B: Data Structures and Algorithms](cs61b/): full guide available for all course content, based on the Spring 2020 offering\n - [CS 70: Discrete Math](cs70/): full guide available for discrete math; partial index available for probability. Based on the Fall 2020 offering\n - [CS 186: Intro to Databases](cs186/): full guide available for all topics except NoSQL and FD's/Normalization. Based on the Fall 2022 offering\n - [CS 162: Operating Systems](cs162/): course notes available for most topics. Based on the Fall 2021 offering\n - [CS 168: Intro to the Internet](cs168/): course notes available for most topics. Based on the Fall 2022 offering\n - [CS 61A: Structure and Interpretation of Computer Programs](cs61a/): resource index and meta-guide available. No course notes.\n - [Data 102: Data, Inference, Decisions](data102/): course notes available for most topics. Based on the Fall 2022 offering\n\nAlthough I have personal notes for many other classes, they do not meet my quality standards for making them public at this time. If I have time at some point in the distant future, they may make an appearance, but don't count on this happening anytime soon.\n\nIf you made your own notes/resources for a CS, Data Science, or EE course and would like me to put a link to them here, let me know ([[contributing]])!\n\n## Basic Principles\n\nHere are some principles that I try to follow when creating notes. I'll probably make a blog post at some point to go over this in more detail, but for now this outline should be enough to show what I hope to accomplish.\n\n1. **Content is more fun when it's important:** Answer the question \"why should I care about this?\" before actually spending time on whatever topic is at hand. If answering it is a struggle, then it's probably not important enough to need to remember in the future.\n2. **Make it interactive:** It's way easier to concentrate on something if it's directly applicable to a problem, question, or situation at hand. Interject conceptual notes with illustrated examples and practice problems whenever possible.\n3. **Notes are rarely self-contained:** It's impossible to fully cover most topics on a single page, and topics may be deeply related to content from other courses. Link to external resources or further learning opportunities whenever possible, just in case it becomes necessary to research the topic further in the future.\n4. **Type a lot of stuff really fast:** For this verbose style of note-taking to be effective for me, I need to be able to completely put down thoughts on the page before I lose them. If you're thinking of doing this on your own, I'd recommend getting good at touch typing, and hitting up [monkeytype](https://monkeytype.com/) for some practice. I'm going against all the research that suggests handwriting is more effective than typing, because the purpose of my notes is not for memorizing or even remembering any of the content, but rather to create a complete repository of knowledge that I and others can easily search in the future.\n\n## About this website\n\nMy notes are hosted on [Netlify](https://www.netlify.com/) and are built on my custom [Amethyst theme](https://github.com/64bitpandas/amethyst) for [Hugo](https://https://gohugo.io/). You can view the source code [here](https://github.com/64bitpandas/notes).\n\nAll of the notes here are formatted in Markdown, and the majority was created using [Obsidian](https://obsidian.md/). These notes are a small fraction of my Obsidian vault; I intend to publish other small bits of it in various places such as my [blog](https://blog.bencuan.me), [devlog](https://devlog.bencuan.me), or [mastodon](https://hachyderm.io/@bencuan) if you're curious.\n\nIf you're interested in contributing, take a look at the [contribution guide](/contributing.md).\n\n## Contact me\n\nWant to chat with me about these notes, or something else? You can find my contact info [here](https://bencuan.me/contact).",
    "lastmodified": "2023-01-12T02:31:33.187601833Z",
    "tags": null
  },
  "/contributing": {
    "title": "Contributing",
    "content": "\nThanks for your interest in contributing to my notes! There's a lot of room for improvement, and I don't have the time to fix everything. If there's something that you'd like to add, please do so!\n\n## Making Requests\n\nI use GitHub for issue tracking. Please make an [issue](https://github.com/64bitpandas/notes/issues) before editing anything or creating a pull request, so I can comment on it before you start working on a feature.\n\n## Editing Content\n\nThis website is built with [Hugo](https://gohugo.io/) using the [Amethyst theme](https://amethyst.bencuan.me/). \n\nFirst, fork the main repository (github.com/64bitpandas/notes).\n\nInstructions on how to format new files and set up a live development server can be found [here](https://amethyst.bencuan.me/setup/editing/). \nA guide on how to use the various features (tabs, callouts, links...) can also be found on the Amethyst website.\n\nIf you have something you want to contribute but it's in another format (like a Google Doc), and you are unable to convert it yourself, create an issue linking the unformatted content and I will take a look.\n\n## Attributions and Academic Integrity\n\nAlthough some of my older notes may be missing citations or attributions to the content they reference, I'm doing my best to link back to the original source moving forwards. If you use public course content (such as screenshots from slides, code snippets from a project skeleton, or practice problems from a past exam), please add a link to where you found it!\n\n**Do not under any circumstances publish private course content** (that can't be found elsewhere for free online, from an official source). This includes homework/project/discussion solutions, textbooks, and readers.\n\nIf you are an instructor or TA for a course that I have notes for and find something that shouldn't be published, please send me an email at [contact@bencuan.me](mailto:contact@bencuan.me) so I can remove it and scrub it from the git history.\n\n\n## Credits\nHere's a list of individuals who have made meaningful contributions to these notes over the years! If you make a pull request, feel free to add your name here as well.\n - [Arin Chang](https://github.com/arinchang): CS61B\n - [Zachary Zollman](https://github.com/zacharyzollman): CS61B, CS70",
    "lastmodified": "2023-01-11T22:15:42.346320523Z",
    "tags": null
  },
  "/cs162/": {
    "title": "CS 162: Operating Systems",
    "content": "\n## CS162 Notes\n\nHere are my notes for the Fall 2021 offering of [CS162](https://cs162.org/), Berkeley's OS course, based on Anderson and Dahlin's textbook \"Operating Systems: Principles and Practice\". \n\n## Table of Contents\n - [[Chapter 1 OS Basics|OS Basics]] - What is an OS, kernels, concurrency.\n - [[Chapter 2 Processes|Processes]] - The process abstraction, fork/exec/wait/pipe.\n - [[Chapter 3 Threads|Threads]] - Fork-join parallelism, multithreading, TCB, race conditions.\n - [[Chapter 4 I O|IO]] - Everything Is A File, streams, file descriptors, pipes, signals, sockets.\n - [[Chapter 5 Synchronization|Synchronization]] - Locks, semaphores, condition variables, atomic operations.\n - [[Chapter 6 Scheduling|Scheduling]] - Scheduling algorithms (FIFO, MLFQS, etc); deadlock.\n - [[Chapter 7 Address Translation|Address Translation]] - Virtual memory, paging, page tables.\n - [[Chapter 8 Caching|Caching]] - Everything you need to know about caches; page replacement policies.\n - [[Chapter 9 File Systems|File Systems]] - Storage, queuing theory, FFS, FAT, NTFS, RAID, 2PC, networks.\n - [[Appendix A GDB foobars|GDB Reference]]\n\n \n## How to contribute\n\nSee the [contributing guide](/contributing) for more details!\n\nYou might notice that some sections are empty (specifically, buffer management policies in [Caching](\u003ccs162/Chapter 8 Caching\u003e) and most of [Synchronization](\u003ccs162/Chapter 5 Synchronization\u003e)). Any contributions for these sections would be greatly appreciated!!\n\n#### Credits\n\n* [Ben Cuan](https://github.com/64bitpandas)\n\n\n\n\n\n\n",
    "lastmodified": "2023-01-12T02:22:44.017028181Z",
    "tags": null
  },
  "/cs162/Appendix-A-GDB-foobars": {
    "title": "GDB Reference",
    "content": "\nRun with args: `r \u003cargs\u003e`\n\nBreakpoint: `b \u003cn\u003e`\n\nConditional breakpoint: `b \u003cn\u003e if \u003ccondition\u003e` or `condition \u003cn\u003e \u003ccondition\u003e` on existing\n\nStep into: `step` or `s` (`si` for assembly)\n\nStep over: `next` or `n` (for assembly, `ni`)\n\nSee all registers: `info registers` (can also do `info frame`, `info args`, `info locals`)\n\nView split mode: `ctrl+x ctrl+a`\n\nSwitch between code and assembly: `layout asm`, `layout src`. `Ctrl+X A` to exit split\n\nView hex memory: `x \u003cname\u003e` or `x/Nx \u003cname\u003e` to view `N` bytes after name\n\nEnable logging: `set logging on` , to change directory `set logging file`",
    "lastmodified": "2023-01-10T23:47:03.261736798Z",
    "tags": null
  },
  "/cs162/Chapter-1-OS-Basics": {
    "title": "Chapter 1: OS Basics",
    "content": "\n# What is an operating system?\n\nAn operating system has three main roles:\n\n- **Referee:** The OS manages protection, isolation,  and allocation of resources between processes.\n- **Illusionist:** The OS provides an abstraction between hardware and user programs that provides an illusion ****of easy-to-access resources such as files and available processors.\n- **Glue:** The OS provides common services, sharing, authorization, networking, and communication between processes and external devices.\n\n\u003e Q1.1. Consider a modern web browser (such as Chrome or Firefox) which plays a similar role to an operating system. What considerations does a web browser need to make as a referee, illusionist, and glue?\n\u003e \n\n### Four Fundamental OS Concepts\n\nThe OS uses the four abstractions below to fulfill its roles:\n\n1. **Threads** provide the basic unit of concurrency that fully describes a program.\n2. **Processes** provide an execution environment for thread(s).\n3. **Addresses** provide a way for threads and processes to access physical memory safely.\n4. **Dual Mode Operation** provides a layer of privilege and security for running sensitive operations. \n\nThreads and processes will be covered in depth in future sections.\n\n# The Kernel\n\nOne of the major requirements of an operating system is to provide **protection** from buggy or malicious programs. A design paradigm that allows for this is the **operating system kernel,** which is a fully trusted platform operating at the lowest software level of the system. This has several benefits:\n\n- **Reliability:** Even if user programs crash, the kernel can still be running and handle the exception.\n- **Security:** User programs must first interface through the kernel to request sensitive operations. The kernel can prevent malicious programs from executing undesired behavior.\n- **Privacy:** The kernel facilitates what data can be transferred between user programs, so one program cannot read sensitive information from others.\n- **Fair resource allocation:** The kernel can distribute computing power between user programs, so that one cannot block the others from executing.\n\nThe kernel is only a small portion of the entire operating system, since it is often beneficial to treat system libraries as user programs to allow for safer implementation.\n\n## Dual Mode Operation\n\nIn order to provide protection, the kernel separates instructions into two main modes of execution: **kernel mode** (protected), and **user mode** (normal program execution). The mode is represented as a single state bit in hardware.\n\n### Privileged Instructions\n\n**Privileged instructions** are allowed only in kernel mode. These include changing memory access and handling interrupts, among other things. Attempting to execute privileged instructions in user mode will cause a **processor exception** that prompts the hardware to transfer control to an exception handler.\n\nTypically, every process has two stacks, one for executing privileged instructions in kernel mode, and one for executing user code.\n\n### Memory Protection: Base and Bound (B\u0026B)\n\nBase and Bound is a simple protection scheme for user address spaces, which allows for the operating system to allocate distinct chunks of memory for each program.\n\n![Untitled](Chapter%201%20OS%20Basics/Untitled.png)\n\nIn this scheme, each program's address space has a **base** (where the data starts) and a **bound** (where the data ends).\n\n- To translate from virtual to physical address spaces, the OS can add the base value to every address.\n- If the address requested exceeds the bound, then an exception should occur.\n- Implementing base and bound in software requires relocating the loader (because translation occurs during runtime).\n- The primary benefit of Base and Bound is that it protects OS and isolates program without an addition to the address path (since you cannot physically access addresses outside of bounds).\n\n### Mode Transfer\n\n![Untitled](Chapter%201%20OS%20Basics/Untitled%201.png)\n\n**There are three types of** **unprogrammed control transfer** from user mode to kernel mode:\n\n1. **Syscalls:** When a process requests a system service (like `exit`), then save the requested syscall ID and arguments into registers, switch into kernel mode, and execute the syscall. Syscalls are similar to function calls, except that the function address is not given (so it cannot be exploited).\n2. **Interrupts:** When external asynchronous events trigger a context switch, save the current execution state and jump to a kernel interrupt handler. Some common types of interrupts are **timer interrupts** (triggers at a specific time, typically to kill hung programs) and **IO interrupts** (e.g. triggers when a disk read completes). If multiple interrupts are queued, they are stored in an **interrupt vector** which alternates address of interrupt handler, and properties of the corresponding interrupt. Below is an illustration of an interrupt vector.\n    \n    ![Untitled](Chapter%201%20OS%20Basics/Untitled%202.png)\n    \n3. **Traps/Exceptions:** If a process triggers an internal hardware event, typically caused by undesired behavior, then execution stops and control is transferred to an exception handler in the kernel to allow the system to continue operating normally. Some examples include segfaults, read/write access violations, and divide by zero errors.\n    \n    \n\nThere are several types of control transfer from kernel mode to user mode:\n\n- **Creating a new process:** the kernel copies the desired program into memory, sets the program counter to point to the first instruction, sets the stack pointer to the base of the user stack, and switches to user mode.\n- **Resuming after an unprogrammed control transfer** (syscall, interrupt, exception): the kernel restores the program counter to its original user-mode state, restores the registers, and switches to user mode.\n- **Switching to a different process**: the kernel saves the current process state in the process control block (PCB), and switches to user mode. The previous process can be resumed in the future.\n\n# The Basic Problem of Concurrency\n\nIn hardware, we only have one of each resource (CPU, RAM, etc.) but in software, we have many processes that each need to believe they have exclusive access to hardware.\n\nThe OS needs to coordinate activity using a **multiprogramming API** and virtual machine abstraction.\n\n**Properties of multiprogramming:**\n\n- All virtual CPUs share the same non-CPU resources (IO, memory...)\n- Every thread can access data and instructions for other threads (enables sharing, but bad for protection) but cannot overwrite OS functions\n- To create protection, the OS must ensure processes don't access memory they should not be able to view (segfaults)\n\n### Multiprocessing vs Multiprogramming\n\n**Multiprocessing:** multiple CPUs\n\n**Multiprogramming:** multiple processes\n\n**Multithreading:** multiple threads\n\n![Untitled](Chapter%201%20OS%20Basics/Untitled%203.png)\n\nFrom the user's perspective, multiprocessing and multiprogramming can be indistinguishable.\n\n**Concurrency is not parallelism:** concurrency is MTAO, parallelism is simultaneous.\n\n- Two threads on one core is concurrent, but not parallel\n\n### Addresses\n\n- Every program has a distinct address space for execution (not physical address space).\n- Depending on the address space, different actions can occur on read or write (nothing, regular behavior, ignore writes, IO, fault...)\n\n![Untitled](Chapter%201%20OS%20Basics/Untitled%204.png)\n\n---\n\n# Solutions\n\nQ1.1:\n\n- Referee: Manage multiple tabs/webpages running simultaneously, handle tab switching, allocate computing resources to active tabs, prevent one buggy tab from crashing the entire browser.\n- Illusionist: Even if webpages or parts of a page are served from many different servers or locations, all of the information is available in one place for the user.\n- Glue: Provide a portable environment where webpages work on many different machines (computers, phones, different OS's...)",
    "lastmodified": "2023-01-10T23:45:40.550590688Z",
    "tags": null
  },
  "/cs162/Chapter-2-Processes": {
    "title": "Chapter 2: Processes",
    "content": "\n# The Process Abstraction\n\nA **process** is an execution environment with restricted rights. \n\nA process consists of:\n\n- An address space\n- Thread(s) of control running in that address space\n- System states associated with threads (files, etc)\n\nThe process abstraction creates a tradeoff between protection and efficiency: communication is easier *within* processes, but harder *between* processes.\n\n# UNIX Process Management\n\n## Creating Processes: fork and exec\n\n### Forking\n\nIn UNIX-based systems, the primary way to create new processes is to **fork** an existing process. This creates a child process with a single thread, and copies all code and resources available to the parent process at that point in time.\n\nForking can be done with the C library function `pid_t fork()`. `fork` returns a process ID (pid) that allows us to identify which process is currently running: \n\n- When `pid \u003e 0`, then we are in the parent process, and a new child process was created here.\n- When `pid = 0`, then we are currently inside of a child process that was just created.\n- When `pid \u003c 0`, an error occurred in the original process and no new processes were created.\n\nWhen `fork` is called, the following operations are carried out by the kernel:\n\n1. Create and initialize the process control block (PCB)\n2. Create and initialize a new address space\n3. Copy over the contents of the parent processes' address space\n4. Copy over the execution context of the parent, including the program counter and open files\n5. Mark the new process as ready\n\n### **Forking Pitfalls**\n\n- **Don't fork in a multithreaded process!** Fork only copies one thread, so any other threads will vanish. (The exception to this rule is if `exec` is called within the child process, since this replaces the entire process anyways and the destruction of threads is desired.)\n- **Parent and child processes work with entirely separate address spaces.** For example, take the code below:\n    \n    ```c\n    int main(void) {\n    \tint* alligator = malloc(sizeof(int));\n    \t*alligator = 3;\n    \tpid_t pid = fork();\n    \tprintf(\"%d\"\\n, *alligator);\n    \tif (pid == 0) { // this runs inside child process\n    \t\t*alligator = 100;\n    \t}\n    \treturn 0;\n    }\n    ```\n    \n    Even though we cannot guarantee which order the parent and child processes run in, we can say with certainty that two `3`'s will be printed. This is because the parent and child processes operate on a different stack and heap space, so even if `*alligator` is set to `100` in the child process before the parent process can execute, the parent process still accesses its own version of `alligator` which remains unchanged.\n    \n\n### Exec\n\nWhat if instead of copying a process, we wanted to create a whole new, unrelated one that does something different? \n\nThis is where the `exec` family of functions comes in. These functions consist of:\n\n- `int execl(const char *path, const char *arg, ...);`\n- `int execlp(const char *file, const char *arg, ...);`\n- `int execle(const char *path, const char *arg, ..., char * const envp[]);`\n- `int execv(const char *path, char *const argv[]);`\n- `int execvp(const char *file, char *const argv[]);`\n- `int execvpe(const char *file, char *const argv[], char *const envp[]);`\n\nThe parameters passed in represent:\n\n1. The program that should be executed (in a string format to its file path), such as `/usr/bin/ls`\n2. Any arguments that should be passed into the program. The `execl` family takes in a list of strings as arguments, whereas the `execv` family takes in one array of strings as arguments.\n\nSome of the functions have special behaviors:\n\n- The `execlp` and `execvp` functions search the system's PATH variable (which contains typical locations for executables, like `/usr/bin`) so that you do not need to pass in the full path every time. For example, `execvp(\"ls\")` should work fine, even if `ls` is not inside of the current directory.\n- The `execle` and `execvpe` functions allow specifying custom locations to search for executables in addition to PATH.\n\n### Wait\n\nThe `wait` syscall pauses the parent process until the child process finishes running or is otherwise terminated. In C, this syscall can be made with the following function:\n\n`pid_t wait(int *wstatus)`\n\nHere, `*wstatus` is a pointer to some integer variable. When the child process completes, `wstatus` is set to the return value of the process.\n\nAs an example:\n\n```c\nint main(void) {\n\tpid_t pid = fork();\n\tint exit;\n\tif (pid != 0) {\n\t\twait(\u0026exit);\n\t}\n\tprintf(\"%d\\n\", pid);\n}\n```\n\nThe following code will print `0`, then whatever the child process PID was. This is because the parent must wait until the child process executes in its entirety before continuing from line 5 (wait).\n\nThere is also the `pid_t waitpid(pid_t pid, int *status, int options)` function, which waits for a specific child process to terminate rather than all child processes.\n\n# Communication Between Processes\n\nTypically, processes are protected from each other since they can only access their own portions of physical memory.\n\n![Untitled](Chapter%202%20Processes/Untitled.png)\n\nTo circumvent this protection, there are several methods:\n\n**Use a file.** Processes can share file descriptors.\n\n- Simple, but very expensive for non-persistent communication\n\n**Shared memory:** edit translation maps to support a special portion of shared address space\n\n**POSIX Pipe:** finite memory buffer that can be written to and read from using `pipe`\n\n- If producer tries to write when pipe is full, it gets blocked\n- If consumer tries to read when pipe is empty, it gets blocked\n- Implemented as a fixed-size queue\n- EOF received when the last write descriptor is closed\n\n**Threads are lighter (share data), processes are more strongly isolated**\n",
    "lastmodified": "2023-01-10T23:47:45.985294814Z",
    "tags": null
  },
  "/cs162/Chapter-3-Threads": {
    "title": "Chapter 3: Threads",
    "content": "\n# The Thread Abstraction\n\nA thread is a single unique context, or unit of concurrency, for execution that fully describes the program state. A thread consists of a program counter (PC), registers, execution flags, and a stack.\n\n- All threads in the same process share the same code, data, and file access, but each has its own register state and stack.\n- Certain registers hold the **context** of the thread (such as the stack pointer, heap pointer, or frame pointer).\n- A thread is executing when the processor's registers hold its context\n- Having multiple threads allows the OS to handle multiple things at once (MTAO). This is essential for networked servers with multiple connections, parallel processing for performance, user interface responsiveness, and many more modern computing applications.\n\n![Untitled](Chapter%203%20Threads/Untitled.png)\n\nEach thread has a private state stored in the **Thread Control Block (TCB).** Additionally, each thread has a dedicated portion of the stack that is isolated from other threads:\n\n![Untitled](Chapter%203%20Threads/Untitled%201.png)\n\n### Thread States\n\nOperating systems have a **thread scheduler** that manages multiple threads, and can switch between ready and running threads. Threads can have one of several states:\n\n- **Running:** current being executed\n- **Ready:** can run, but not currently running\n- **Blocked:** cannot run. This typically occurs when thread is waiting for I/O to finish. When the I/O is complete, it becomes ready. As a result, I/O latency can be masked by multithreading (since other threads can run in the meantime).\n    \n    ![The thread lifecycle, from initialization to completion.](Chapter%203%20Threads/Untitled%202.png)\n    \n    The thread lifecycle, from initialization to completion.\n    \n\n### Multithreaded Programs\n\n![Untitled](Chapter%203%20Threads/Untitled%203.png)\n\nBy default, C programs are single-threaded (and when you create a new process, it only has one thread).\n\nOne common method of turning a single-threaded program into a multi-threaded program is through **fork-join parallelism.** Using this paradigm, the main thread creates child threads, and when children exit they join back with the main thread.\n\n![Untitled](Chapter%203%20Threads/Untitled%204.png)\n\n# UNIX Thread Management\n\n### Fork-Join Parallelism\n\nThe function `int pthread_create(pthread_t *restrict thread, const pthread_attr_t *restrict attr, void *(*start_routine)(void *), void *restrict arg)` can be used to create a thread.\n\n- Create and immediately start a new thread in the same address space (i.e. sharing the same variables and references as the parent thread).\n- Saves the thread ID (tid) into the value pointed to by `*thread`.\n- Pass in the arguments pointed to in `*arg` to the function specified in `start_routine`. (The arguments should be cast into a `(void *)` type.)\n- Begin executing the `start_routine` function.\n\nThe function `int pthread_join(pthread_t thread, void **retval)` can be used to join an existing thread back to the main thread. Calling this function will do the following:\n\n- Make the parent thread wait until the specified `thread` completes before continuing.\n- When the thread completes, save the exit status of the thread into the location pointed to by `retval`. This can be set to `NULL` if the value is not needed.\n\nIf a child thread is complete, `int pthread_exit(void *retval)` can be called to terminate the thread early and return a result.\n\nA context switch can be forced using `pthread_yield`, which causes the thread to relinquish the CPU and get placed at the end of the run queue.\n\n### Race Conditions\n\nThreads run in a nondeterministic order, so we must be careful to join them at the correct time. Here's what happens if we don't:\n\n```c\nvoid *helper(void *arg) {\n\tprintf(\"%d\", arg);\n\treturn NULL;\n}\nint main() {\n\tpthread_t thread;\n\tint* param = malloc(sizeof(int));\n\t*param = 1;\n\tpthread_create(\u0026thread, NULL, \u0026helper, (void *)(param));\n\tprintf(\"0\");\n\treturn 0;\n}\n```\n\nThe above code could have multiple outcomes based on the order of thread execution:\n\n1. `helper` runs first: `10` is printed\n2. `main` prints, then `helper`: `01` is printed\n3. `main` returns before `helper` can execute: `0` is printed\n\nIf multiple threads need to modify the same variable at the same time, then locking is required (this will be discussed further in the Concurrency section).",
    "lastmodified": "2023-01-10T23:45:56.318428091Z",
    "tags": null
  },
  "/cs162/Chapter-4-I-O": {
    "title": "Chapter 4: I/O",
    "content": "\n# UNIX Abstraction: Everything is a File\n\nA **file** is a named collection of data in a file system. In the POSIX (Portable Operating System Interface for UNIX) standard, every file includes data (a sequence of bytes) and metadata (such as size, modification time, owner, security, and access control).\n\nFiles are organized into directories, which are folders containing files and other directories. Directories employ hierarchical naming (`/path/to/file.txt`) to ensure that ever file has a unique identifier.\n\nEvery process has a **current working directory (CWD),** which can be set using `int chdir(const char *path)`.\n\nUNIX I/O has several key ideas:\n\n- **Uniformity:** all IO operations use the same syscalls (open, close, read, write).\n- **Open before use:** A device or channel must be opened and checked for permissions before any IO can commence.\n- **Byte Oriented:** Everything can be represented as a series of bytes in an array.\n- **Kernel-buffered reads and writes:** All data, whether incoming or outgoing, is stored in a kernel buffer and returned on request or when devices become available. This frees the processor to perform other tasks while IO is occurring but not ready.\n    - Kernel buffering is typically done in blocks to enable efficient caching; as a consequence, `int fflush(FILE *stream)` must be called to push all buffered contents out of the file and complete the file operation.\n- **Explicit Close:** Applications which are done accessing a file or device must call `close` to signal to the OS that the file is available.\n\n# High level IO: Streams\n\nHigh-level C libraries operate on **streams** (unformatted sequences of bytes with a position). When using high-level IO operations, the libraries automatically provide caching and write buffering to improve performance.\n\n### Reading and Writing\n\nTo read or write using the high-level file API, we must first call `FILE* fopen(const char *filename, const char *mode)` to open the file.\n\nThe `mode` can be set to read (r), write(w), append(a), readwrite existing (r+), readwrite existing or create non-existing (w+), readwrite as append (a+), or binary versions of all stated (such as rb or ab+).\n\nAfter opening the file, `size_t fread(void *restrict ptr, size_t size, size_t nmemb, FILE *restrict stream)` can be called to read contents from the file into the buffer at `*ptr`. This function reads `nmemb` items of data, each `size` bytes long, from `stream`.\n\nThe `fwrite` function can also be used (it has the same signature as `fread`) to write items from the buffer at `ptr` into `stream`.\n\nHere's an example function that copies the file contents from the path `*src` into the file at path `*dest`:\n\n```c\nvoid copy(const char *src, const char *dest) {\n\tchar buffer [100];\n\tFILE* read_file = fopen(src, \"r\");\n\tint buf_size = fread(buffer, 1, sizeof(buffer), read_file);\n\tfclose(read_file);\n\tFILE* write_file = fopen(dest, \"w\");\n\tfwrite(buffer, 1, buf_size, write_file);\n\tfclose(write_file);\n}\n```\n\n### Stream Operations\n\nStreams can be accessed in the same manner as files. Some API Standard Streams include `stdin` (input stream), `stdout` (output stream), and `stderr` (error stream).\n\nThe C libraries include several operations to work with streams:\n\n- `int fputc(int c, FILE *stream)` puts a character `c` at the current position in `*stream`.\n- `fputs` writes a string at the current position.\n- `fgetc` and `fgets` reads the next character/string at the current position.\n\n# Low Level IO: File Descriptors\n\nRather than working with streams, low level IO functions interface with the syscalls directly, and handle file identification using **file descriptors.** Every opened file is assigned an integer index in the kernel's file descriptor table, which can then be used to read and write to and from that file.\n\nUnlike high level IO, where everything will be written at once from a buffer, operations on low-level file descriptors are visible immediately. As such, **mixing high and low level IO can be problematic** because it's very difficult to predict which sections of the file will be accessed at any particular point in time.\n\nBy default, every program starts with the three standard streams `stdin`, `stdout`, and `stderr`, which are assigned the file descriptors `0`, `1`, and `2` respectively. Every future file opened will be assigned some number greater than `2`. These numbers can be accessed with the constants `STDIN_FILENO`, `STDOUT_FILENO`, and `STDERR_FILENO` which require an `#include \u003cunistd.h\u003e`.\n\nTo open a file, use `int open(const char* filename, int flags, mode_t mode)`.\n\n- Flags handle access modes (Rd, Wr, etc), as well as operating modes (Create, append, etc.).\n- The mode is a bit vector of permission bits, bitwise OR'd (`|`) together.\n- For a full list of flags and modes, see the man page ([https://man7.org/linux/man-pages/man2/openat.2.html](https://man7.org/linux/man-pages/man2/openat.2.html)).\n- There is also the `int creat(const char* filename, mode_t mode)` function, which is equivalent to calling `open` with the flags `O_CREAT|O_WRONLY|O_TRUNC` (create the file, write only, replace existing file completely).\n\nTo read and write, use `ssize_t read(int filedes, void *buffer, size_t size)` and `int write(int filedes, void *buffer, size_t size)` respectively. These functions return the number of bytes that were read or written.\n\nTo change the current location within a file, use `lseek(int filedes, off_t offset, int whence)`.\n\n- Several options for `whence` include:\n    - `SEEK_SET`, which interprets the offset from the beginning of the file (position 0),\n    - `SEEK_END`, which subtracts the offset from the end of the file, and\n    - `SEEK_CUR`, which adds the offset to the current position in the file.\n\nTo duplicate descriptors (so that multiple processes can operate on the same file), there are two options:\n\n1. Use `int dup(int oldfd)`, which creates and returns a new file descriptor which acts as an alias for `oldfd`.\n2. Use  `dup2(int old, int new)`, using `new` instead of assigning a new file descriptor. This is useful for redirecting output (for example, specifying `new == STDOUT_FILENO` would print the file to standard output).\n\nAn implementation of the `copy` example from the high-level IO section using low-level IO might look something like this:\n\n```c\nvoid copy(const char *src, const char *dest) {\n\tchar buffer [100];\n\tint read_fd = open(src, O_RDONLY);\n\tint bytes_read = 0;\n\tint buf_size = 0;\n\twhile ((bytes_read = read(read_fd, \u0026buffer[buf_size], sizeof(buffer) - buf_size)) \u003e 0) {\n\t\tbuf_size += bytes_read;\n\t}\n\tclose(read_fd);\n\tint bytes_written = 0;\n\tint write_fd = open(dest, O_WRONLY);\n\twhile (bytes_written \u003c buf_size) {\n\t\tbytes_written += write(write_fd, \u0026buffer[bytes_written], buf_size - bytes_written);\n\t}\n\tclose(write_fd);\n}\n```\n\nFor an example of using `dup2` in the context of forks and pipes to execute processes, see [http://www.cs.loyola.edu/~jglenn/702/S2005/Examples/dup2.html](http://www.cs.loyola.edu/~jglenn/702/S2005/Examples/dup2.html).\n\n### High vs Low Level IO\n\n**High level streams are buffered in user memory:**\n\n## Be careful when mixing high and low level IO\n\nHigh level IO operations interface with the user-level buffer in chunks. However, low-level IO operations interface with the file directly. It is very hard to predict which portions of the file will be edited by which at what time.\n\n# Pipes\n\nUNIX pipes provide a way to communicate information both within and between processes. Using pipes is very similar to reading and writing from a file, with some additional checks involved.\n\nTo create a pipe, use `int pipe(int fileds[2])`, where `fileds[2]` is a two-integer array. When `pipe` is called, it automatically assigns two new file descriptors to the array.\n\nTo read and write to and from a pipe, the `write` and `read` low-level calls can be made on `fileds[1]` and `fileds[0]`, respectively.\n\n![Untitled](Chapter%204%20I%20O/Untitled.png)\n\nIn the kernel, pipes are implemented as a fix-sized queue. This causes some issues when the allocated size is overflowed:\n\n- If the buffer is full and Process A tries to write, then the pipe blocks (process gets put to sleep).\n- If the buffer is empty and Process B tries to read, then the pipe also blocks.\n\n### Closing Pipes\n\nJust like files, pipes should be closed after use with `close(fileds[0])` for the read stream and `close(fileds[1])` for the write stream.\n\nIf a pipe is accessed after it is closed, several things could happen:\n\n- If the write descriptor is closed, then the pipe will continually return EOF's if read from.\n- If the read descriptor is closed, then attempting to write to the pipe will generate a SIGPIPE signal.\n\nHere's an example of how to use pipes to transfer a string:\n\n```c\nint main() {\n\tint fds[2];\n\tpipe(fds);\n\tchar *str = \"hello world\";\n\tsize_t bytes_written = 0;\n\tsize_t total = 0;\n\twhile (bytes_written = write(fds[1], \u0026str[total], strlen(\u0026str[total]) + 1)) {\n\t\ttotal += bytes_written;\n\t\tif (str[total - 1] == ’\\0’) break;\n\t}\n\tclose(fds[1]);\n\tchar *read_str = malloc(strlen(str) + 1);\n\ttotal = 0;\n\tsize_t bytes_read;\n\twhile (bytes_read = read(fds[0], \u0026read_str[total], 50)) {\n\t\ttotal += bytes_read;\n\t}\n\tprintf(\"%s\", read_str);\n\treturn 0;\n}\n```\n\n# Signals\n\nA **signal** is a software interrupt which provides a method of communicating state information about processes, the OS, or hardware. Different signals can have different handlers, or be ignored entirely, depending on the program.\n\nHere is a list of standard Linux signals:\n\n![Untitled](Chapter%204%20I%20O/Untitled%201.png)\n\nCustom signal handlers can be specified using the `int signal(int signum, void (*handler)(int))` function. For example, `signal(SIGINT, printMsg)` will call the `printMsg()` function when the user quits out of the program using Ctrl+C.\n\nInstead of specifying a custom handler, you also have the option of passing in `SIG_IGN`, which ignores the signal, or `SIG_DFL`, which runs the default behavior for that signal.\n\n# Sockets\n\n```c\n#include \u003csys/socket.h\u003e\n\n/* Creates an endpoint for communication and returns a\n\t file descriptor corresponding to that endpoint. */\nint socket(int domain, int type, int protocol);\n\n```\n\n[https://man7.org/linux/man-pages/man2/socket.2.html](https://man7.org/linux/man-pages/man2/socket.2.html)\n\n```c\n#include \u003cnetdb.h\u003e\n\nstruct addrinfo {\n    int ai_flags;\n    int ai_family;\n    int ai_socktype;\n    int ai_protocol;\n    size_t ai_addrlen;\n    char * ai_canonname;\n    struct sockaddr * ai_addr;\n    struct addrinfo * ai_next\n};\n```\n\n```c\n#define BUF_SIZE 1024\nstruct addrinfo *setup_address(char *port) {\n\tstruct addrinfo *server;\n\t// Provides the preferred connection properties. \n\t//If this is NULL, any connection is acceptible\n\tstruct addrinfo hints; \n\tmemset(\u0026hints, 0, sizeof(hints));\n\thints.ai_family = AF_UNSPEC;\n\thints.ai_socktype = SOCK_STREAM;\n\thints.ai_flags = AI_PASSIVE;\n\tint rv = getaddrinfo(NULL, port, \u0026hints, \u0026server); // Connects to loopback (node is NULL)\n\tif (rv != 0) {\n\t\tprintf(\"getaddrinfo failed: %s\\n\", gai_strerror(rv));\n\t\treturn NULL;\n\t}\n\treturn server;\n}\nvoid *serve_client(void *client_socket_arg) {\n\tint client_socket = (int)client_socket_arg;\n\tchar buf[BUF_SIZE];\n\tssize_t n;\n\twhile ((n = read(client_socket, buf, BUF_SIZE)) \u003e 0) {\n\t\tbuf[n] = ’\\0’;\n\t\tprintf(\"Client Sent: %s\\n\", buf);\n\t\tif (write(client_socket, buf, n) == -1) {\n\t\t\tclose(client_socket);\n\t\t\tpthread_exit(NULL);\n\t\t}\n\t}\n\tclose(client_socket);\n\tpthread_exit(NULL);\n}\n\nint main(int argc, char **argv) {\n\tif (argc \u003c 2) {\n\t\tprintf(\"Usage: %s \u003cport\u003e\\n\", argv[0]);\n\t\treturn 1;\n\t}\n\n\tstruct addrinfo *server = setup_address(argv[1]);\n\tif (server == NULL) return 1;\n\tint server_socket = socket(server-\u003eai_family, server-\u003eai_socktype, server-\u003eai_protocol);\n\tif (server_socket == -1) return 1;\n\tif (bind(server_socket, server-\u003eai_addr, server-\u003eai_addrlen) == -1) return 1;\n\tif (listen(server_socket, 1) == -1) return 1;\nwhile (1) {\nint connection_socket = accept(server_socket, NULL, NULL);\nif (connection_socket == -1) {\nperror(\"accept\");\npthread_exit(NULL);\n}\npthread_t handler_thread;\nint err = pthread_create(\u0026handler_thread, NULL,\nserve_client, (void *)connection_socket);\nif (err != 0) {\nprintf(\"pthread_create: %s\\n\", strerror(err));\npthread_exit(NULL);\n}\npthread_detach(handler_thread);\n}\npthread_exit(NULL);\n}\n```",
    "lastmodified": "2023-01-10T23:46:00.882381013Z",
    "tags": null
  },
  "/cs162/Chapter-5-Synchronization": {
    "title": "Chapter 5: Synchronization",
    "content": "\n## Race Conditions and Locks\n\nIf two independent threads need to modify and read the same values, there could be multiple outputs depending on the order that the threads run in. How do we resolve this?\n\n**Synchronization** deals with coordination among threads and their shared data\n\n**Mutual Exclusion:** Only one thread does something at one time (excludes the other threads)\n\n- Subtype of synchronization\n\n**Critical Section:** code that only one thread can execute at once (consequence of mutual exclusion)\n\n# High Level Concurrency API\n\n## Locks\n\n**Lock:** An object that only one thread can hold at a time (provides mutual exclusion)\n\n- `lockacquire()` or `pthread_mutex_lock` waits until lock is free, then marks as busy\n- `lockrelease()` or `pthread_mutex_unlock` frees a lock (calling thread no longer holds the lock)\n\n## Semaphores\n\nA general type of lock that holds a non-negative integer.\n\n- `P()` or `down()`: waits for semaphore to be positive, then decrements by 1\n- `V()` or `up()`: increments semaphore by 1\n\nCan be used for mutual exclusion by setting it down, running critical section, then setting it up.\n\n![Untitled](Chapter%205%20Synchronization/Untitled.png)\n\nSemaphores can also be used for signaling other threads:\n\n![Untitled](Chapter%205%20Synchronization/Untitled%201.png)\n\n## Monitors\n\n## Send/Receive\n\n## Condition Variables\n\n### Readers/Writers\n\n# Atomic Operations\n\n## Load/Store\n\n## Disable Ints\n\n## Test and Set\n\n## Compare and Swap",
    "lastmodified": "2023-01-10T23:46:10.130285591Z",
    "tags": null
  },
  "/cs162/Chapter-6-Scheduling": {
    "title": "Chapter 6: S cheduling",
    "content": "# Introduction\n\nWhen multiple tasks need to be done on a single CPU, we need to figure out a way to distribute the work done by the CPU across all of the tasks. \n\nAt any point there are **running, waiting, and blocked threads.** A processor's scheduling policy determines how and when threads transition between these states.\n\n### Scheduling Goals\n\nThere are three primary goals for an effective scheduling algorithm.\n\n1. **Minimize Response Time:** reduce the amount of total elapsed time required to do any one job. For example, time might be measured from a user's keypress to the event being triggered. If a job has to wait for others to finish first, then response time increases.\n2. **Maximize Throughput:** maximize the number of operations per second. This occurs when as much time is spend on the jobs themselves, rather than on scheduling/context switching.\n3. **Maximize Fairness:** The concept of fairness is somewhat vague, but typically shorter jobs with more IO-bound operations should go first, and time should be somewhat equally distributed across jobs depending on priority.\n\nNo single scheduling policy can achieve every goal; there must be some tradeoffs. For example, minimizing response time results in more context switching, so throughput cannot also be maximized.\n\n### Vocabulary\n\n**Workload:** the input to a scheduling algorithm, which includes the set of tasks to perform, when they arrive, and how long they will take.\n\n**Compute-bound** tasks primarily use the CPU, whereas **IO-bound** tasks spend most of their time blocked by IO and only a small amount of time using the CPU.\n\n**Preemption** is the process of interrupting a running thread to allow for the scheduler to decide which thread runs next.\n\n**Priority Inversion** occurs when a higher priority thread is blocking on a resource (e.g. a lock) that a lower priority resource holds. This may cause **starvation** (when a thread waits indefinitely for another).\n\n**Priority donation** attempts to solve priority inversion by swapping priorities of two threads when priority inversion occurs. This must be done recursively through all chains of dependencies, such that each thread ends with their priority being the max of all donated priorities and its own priority.\n\n**Deadlock** is a specific type of starvation where two or more threads are circularly waiting for each other. For more info, see the section below.\n\n### Deadlock\n\nAs an example of deadlock, consider two threads with two locks, `x` and `y`:\n\n```c\n// THREAD A    // THREAD B\nx.Acquire();   y.Acquire();\ny.Acquire();   x.Acquire();\ny.Release();   x.Release();\nx.Release();   y.Release();\n```\n\nIf Thread A acquires `x` and Thread B acquires `y`, then neither can run the subsequent line because there is a circular wait:\n\n![Untitled](Chapter%206%20Scheduling/Untitled.png)\n\nThere are **four requirements for deadlock to occur:**\n\n1. **Mutual exclusion:** only one thread at a time can use a particular resource.\n2. **Hold and wait:** A thread holding at least one resource is waiting to acquire additional resources from other threads.\n3. **No preemption:** Resources are only released when a thread is finished with it.\n4. **Circular wait:** There exists a set of threads such that $T_1$ is waiting for $T_2$, which is waiting for $T_3$, and so on, until $T_n$ is waiting for $T_1$.\n\nTo avoid deadlock, we can use **Banker's Algorithm** to simulate the allocation for resources, and decide if the current available resources is sufficient for completing the current state of the program. \n\n- To detect safe state, we can pick any thread to simulate a run to completion (i.e. release all of its resources). If there are no threads available to choose that can be run with the current allocation, then the program is in an unsafe state.\n- An *unsafe* state is different from a *deadlocked* state in that it is still possible to recover from one (i.e. a deadlock is sure to happen at some point at the future, but not now).\n- The two resource requests that need to be checked for are `sema_down` and `lock_acquire`.\n\n# Scheduling Algorithms\n\nThe following policies are primarily concerned with uniprocessor scheduling (how to schedule tasks onto a single CPU).\n\n## First-In-First-Out (FIFO)\n\nAlso known as First-Come-First-Served (FCFS), this is a very simple scheduling algorithm that runs processes until completion, then chooses the next process on the queue and repeats.\n\nThe major drawback with FIFO is that the effectiveness depends on the order that jobs enter the queue: if the short jobs go first, then it works well; however, if long jobs take up all of the CPU time, average waiting time and completion time suffer significantly.\n\nFCFS is prone to starvation because if a task at the front of the queue never yields, then tasks at the back will never run.\n\n## Round Robin (RR)\n\nIn Round Robin scheduling, each process gets a **quantum** of CPU time (typically 10-100ms). When the quantum expires, the process is preempted and moved to the back of the ready queue. The performance depends on the value of $q$ (the time quantum):\n\n- If $q$ is infinite, Round Robin becomes FCFS (since jobs will always complete before the end of their quantum).\n- If $q$ is large, then response time decreases since jobs take a long time to get scheduled.\n- If $q$ is very small, then more time will be spent on context switching than executing jobs themselves, resulting in low throughput.\n\nRound Robin is not prone to starvation because it is guaranteed that a process will wait at most $(N - 1) * Q$ time to run, where $N$ is the total number of processes and $Q$ is the length of the quantum.\n\n## Strict Priority Scheduling\n\nStrict Priority Scheduling allows for the incoming job queue to be split across multiple priority levels. Higher priority jobs are always run before lower priority jobs.\n\n![Untitled](Chapter%206%20Scheduling/Untitled%201.png)\n\nIndividual queues of jobs with the same priority can be processed with another scheduling algorithm (for example, RR). \n\nThe major problem with strict priority scheduling is **deadlock:** if a lower priority task has a lock required by a high priority task, and some intermediate priority task is blocking the high priority task from running, then a circular wait dependency is created and the system cannot continue.\n\nAnother problem is **starvation** of lower priority jobs that may not ever run due to always being superceded by higher priority tasks.\n\nSome solutions to deadlock and starvation:\n\n- Dynamic priorities: shift priorities of tasks based on some heuristic\n- Priority donation/inversion\n- **Niceness:** In UNIX, each process has a nice value (-20 to 19). Higher nice-value tasks yield to other tasks more often, so tasks that suffer from starvation can be set as not-nice.\n\n## Shortest Job First (SJF)\n\nAlso known as Shortest Remaning Time First (SRTF).\n\nIf we somehow know how long each job will take, we can schedule the task with the least remaining work first to minimize the average response time.\n\nWhile this is optimal in terms of response time, in practice it is difficult to know exactly how long something will take.\n\nAdditionally, SJF makes starvation more likely (since short tasks may depend on long tasks), and context switches are more frequent.\n\n### Prediction\n\nAlthough we cannot know exactly how long a job will take, we can predict approximately how long it is:\n\n- Program behavior is usually predictable, so if a program was IO bound or had some certain scheduling patterns in the past, it should continue to have these patterns.\n- Burst length: use an estimator function to aggregate past CPU bursts from this program.\n\n### Lottery Scheduling\n\nAnother alternative scheduling algorithm is lottery scheduling, where each job is given some number of lottery tickets.\n\nOn each time slice, randomly pick a winning job to run. This ensures that CPU time is proportional to the number of tickets given to each job.\n\nIn order to approximate SJF, short running jobs get more tickets than long running jobs.\n\n## Multi-Level Feedback Scheduling\n\nMany modern scheduling algorithms are based on a **multi-level feedback queue scheduler (MLFQS).** \n\nEach queue has a different priority (typically for foreground vs. background tasks), and every queue has its own scheduling algorithm.\n\nWhen jobs enter the MLFQ, they start in the highest priority queue. If they do not complete before a timeout, then they drop one level; otherwise, they stay at the same level or move up one level if available.\n\nThis is a good approximation of SRTF since long CPU-bound tasks will drop to the bottom of the queue.\n\n![Untitled](Chapter%206%20Scheduling/Untitled%202.png)\n\n## Multi-Core Scheduling\n\nAlgorithmically, multi-core scheduling is not all too different from single core scheduling. \n\nMos commercial operating systems use a per-processor data structure, in which each CPU has its own task queue.\n\nTo maximize cache reuse, **affinity scheduling** can be used to prioritize scheduling yielded tasks onto the same CPU. \n\n**Rebalancing** occurs when the length of a CPU's queue is long enough to justify moving the task to another CPU.\n\n**Spinlocks** can be used for multiprocessing when disabling interrupts are insufficient. (Other threads on other CPUs can still run concurrently even if one CPU has interrupts disabled.)\n\n```c\nint value = 0;\nAcquire() { while (testAndSet(\u0026value)) {}; // busy wait }\nRelease() { value = 0; }\n```\n\nSpinlocks are inefficient for long periods of waiting, but for brief (context switch level of speed) moments we can use this to ensure locks are acquired successfully before continuing.\n\n### Gang Scheduling\n\nWhen multiple threads need to work together for a task, it makes sense to scheduling them together to make spin waiting more efficient.\n\n## Choosing the Right Scheduler\n\n![Untitled](Chapter%206%20Scheduling/Untitled%203.png)",
    "lastmodified": "2023-01-10T23:46:15.954225485Z",
    "tags": null
  },
  "/cs162/Chapter-7-Address-Translation": {
    "title": "Chapter 7: Address Translation",
    "content": "\n# Introduction\n\nEvery modern computer has physical memory inside of it, that might look something like this:\n\n![Untitled](Chapter%207%20Address%20Translation/Untitled.png)\n\nPhysical RAM modules typically contain anywhere from 4 to 128GB of memory (well, at the time of writing). However, there are only a few sticks of RAM, and possibly hundreds of processes that need to access them at the same time!\n\nThis is where memory management comes in. This chapter will cover several methods to do so, such as **address translation** (virtual memory) and **paging** (breaking memory into chunks).\n\n# Address Translation\n\nFirst, let's solve one of the major problems: **how do we allow many programs to share a single module of physical memory?** \n\nThe TL;DR: **virtual memory,** or an illusionary space given to each program such that they think they're the only one using the memory. Then, we can offload the work of translating virtual memory to physical memory to the kernel.\n\n## Goals of Address Translation\n\nAn effective address translation scheme will have the following:\n\n- **Memory protection:** prevent processes from accessing or overwriting memory it doesn't own, such as from the kernel or other processes.\n- **Memory sharing:** allow multiple processes to access shared sections of memory, if needed.\n- **Controlled overlap and flexible memory placement:** although we should be able to give a process any chunk of physical memory, each process or thread should have its own separate state that do not collide with one another.\n\n## The Basics: Base and Bound\n\nRecall the simple **base and bound** scheme to map process memory to physical memory by adding a certain offset to each memory address:\n\n![Untitled](Chapter%207%20Address%20Translation/Untitled%201.png)\n\nBase and bound, while very easy to implement, has severe limitations. Notably, it does not allow for memory sharing, and dynamically growing memory regions like heaps or stacks are not supported.\n\n## Segmented Memory\n\nThe primary way we can fix these issues: **segmented memory.** Rather than only having one section of memory per process, we could split it up, such that a process' memory is composed of many small chunks of physical memory!\n\n![Untitled](Chapter%207%20Address%20Translation/Untitled%202.png)\n\nUsing segmented memory, we can more easily share memory (just give multiple processes a pointer to the same segment(s). Furthermore, if a growing data structure such as the heap starts to overflow onto another section, we can just work around that and set the next segment to point to an entirely different part of memory.\n\nHowever, segmented memory still has its own limitations. The biggest problem is that of **fragmentation,** or wasted space in memory.\n\n- **External fragmentation** refers to gaps between chunks.\n- **Internal fragmentation** refers to the provisioning of large segments to only store a small amount of data, such that most of the segment is unused.\n- Both are major issues of segmented memory.\n\n## Paged Memory\n\nLet's explore a third option of memory management, **paged memory!** Rather than a list of segments, each process will have fixed-sized **page frames.** This has multiple advantages:\n\n- Page table entries can be much more compact compared to segment tables, because only the top bits need to be stored (the page size is a constant power of two, so we don't need to keep storing those bits).\n- External fragmentation is less frequent, because a page can always fit into an empty space in physical memory. Each page of physical memory can simply have a bit that flips when it becomes used, and turns back off when it gets freed.\n- Support for security measures: address space layout randomization (ASLR), which adds a random space between memory segments (code, heap, etc.) and kernel address space isolation (kernel-only pages) can both be easily implemented.\n\n![Untitled](Chapter%207%20Address%20Translation/Untitled%203.png)\n\n### Page Table Entries\n\n![Untitled](Chapter%207%20Address%20Translation/Untitled%204.png)\n\n![Untitled](Chapter%207%20Address%20Translation/Untitled%205.png)\n\n### Paging Mechanics\n\nNow, let's get more specific about how paging can be implemented, and how to evaluate a particular paging scheme.\n\nTo get acquainted with the numbers we'll be working with, here are a few typical sizes:\n\n- Memory is usually around the order of $2^{30}$ (1GB) to $2^{37}$ (128GB).\n- Page sizes are usually around 4KB ($2^{12}$).\n- Address spaces are either $2^{32}$ for 32-bit systems, or $2^{64}$ for 64-bit systems.\n\nA simple page table will have one entry per page. So in a 32-bit system, we'd have $2^{32}/{2^{12}} = 2^{20}$ number of entries, which is about 16MB of memory assuming each entry is 32 bits long.\n\nAnd for a 64-bit system, the amount of memory needed to store the page table gets absolutely ludicrous (on the order of exabytes)! Luckily, there is a solution:\n\n### Multi-Level Page Tables\n\nEspecially in 64-bit systems, we almost never need to use the entire address space. Thus, the address space is **sparse** (lots of empty memory in between used sections), and most of the page table entries will be pointing to unused areas.\n\nIn order to mitigate the memory issue, we can make **multi-level page tables** where rather than just having one page table, we have **tree** of page tables where the first layer points to a page table in the second layer, and so on.\n\n![Untitled](Chapter%207%20Address%20Translation/Untitled%206.png)\n\nTo make things even less memory-intensive, we can use **inverted page tables** which store mappings in a hash table structure rather than a tree structure. While more complex, this makes the size of the page table independent of the size of the virtual address space.\n\n![Untitled](Chapter%207%20Address%20Translation/Untitled%207.png)\n\n## Address Translation: Summary\n\n![Untitled](Chapter%207%20Address%20Translation/Untitled%208.png)",
    "lastmodified": "2023-01-10T23:46:26.690114656Z",
    "tags": null
  },
  "/cs162/Chapter-8-Caching": {
    "title": "Chapter 8: Caching",
    "content": "\n# Introduction\n\nAt this point, we've solved nearly all of the problems with base and bound memory translation. But there is one major problem left— all of this additional complexity adds lots of memory accesses, which might make things very inefficient! This is where **caching** comes in.\n\nSince programs only care about a very small subset of the total information available, if we identify this subset and place it into more local memory, then we can efficiently perform most memory accesses.\n\nCaches give the benefits of speed from the fastest types of memory while still having the capacity of the largest memory. Ideally, caches are implemented such that they are invisible to programmers: they will automatically move memory between locations.\n\n# Cache Terminology\n\n## Basic Anatomy\n\nCaches have **tags** (addresses) and **blocks** (aligned words that store information).\n\nIn order to simplify the comparison process (so that we don't need to check every tag to see if we have a hit or miss), we can split the cache into **sets**. So we only need to compare a tag to a particular set in order to determine if we have a hit or miss.\n\n![[/Untitled 3.png]]\n\nA **valid bit** is flipped if a particular entry is valid. If the valid bit is not on, then we should treat an access like a cache miss.\n\nA **cache flush** invalidates all entries.\n\nThe **cache capacity** is the total number of bytes in the cache.\n\nA **cache line**, other wise known as a **cache block,** is a single entry in the cache.\n\nThe **block size** is the number of bytes in each cache line/block.\n\nWe can calculate the **number of cache lines** by dividing the cache capacity by the block size.\n\n**Eviction** is the process of removing an entry from the cache.\n\n## Locality\n\nThe primary purpose of caches is to benefit from **locality** of information, which allows data to be accessed faster in common patterns.\n\nThere are two different types of locality:\n\n- **Temporal Locality:** locality in time. If a memory location is referenced, then chances are it might be needed again soon and so we should keep it around.\n- **Spatial Locality:** locality in space. If a memory location is referenced, then chances are the addresses close to that will be needed soon and should be saved to faster memory.\n\n## Hits and Misses\n\nA **cache hit** occurs when the memory address we're looking for is actually stored in the cahce.\n\nA **cache miss** is when we are looking for information that is in the main memory, but not the cache.\n\n- **Compulsory Miss:** cold start; the first time we access a block. These get to be pretty insignificant the more memory you have and the longer you run the program.\n- **Capacity miss:** The cache cannot contain all of the blocks accessed by the program. These can be avoided by increasing the size of the cache.\n    - sizeof(array) \u003e cache size\n- **Conflict miss (collision):** Multiple memory locations map to the same cache set. These could be avoided by increasing the associativity of the cache (these would never happen with a fully associative cache).\n    - Related to spatial locality breakdown: when stride * sizeof(element) ≥ block size. i.e. A block is loaded, but only the first element in the block is accessed before it is overwritten by another block.\n- **Coherence miss:** External processors or devices update a part of memory, making the cached version invalid.\n\n## Types of Caches: Associativity\n\nThe **associativity** of a cache is the number of places each block is allowed to be in. Having a higher associativity increases the total cache capacity (thus reducing AMAT), but becomes more complex.\n\n- **Fully associative cache:** Blocks can go anywhere. This is the most flexible option, but requires a large number of comparators (1 per block).\n- **Direct mapped cache:** Each block goes into one place, such that each set contains exactly one block. This makes it straightforward to check if a block exists (since there is only one place it can possibly go), but is the least flexible.\n- **N-way Set Associative:** There are N places for a block, such that each set has N number of blocks. This is a compromise between fully associative (N = # blocks) and direct mapped (N = 1).\n\n## Tags, Index, Offset: The Address\n\nAddresses in the cache are divided into tag, index, and offset.\n\n![[/Untitled 5.png]]\n\n### Offset\n\nTells us where data exists in the cache line.\n\nContaines $\\log_2(blocksize)$ number of *bytes* (not bits) (for example, 64 byte blocks can be represented using 6 offset bits).\n\n### Index\n\nTells us the where in the cache an address might be stored. \n\nContains $\\log_2$(num cache lines / associativity) number of bits.\n\nFor example, a 4 way associative cache with 512 lines requires 7 index bits.\n\n### Tag\n\nDetermines which memory location in the cache that the data is stored.\n\nThe number of bits in the tag is just the bits remaining (total address bits - index bits - offset bits).\n\n![[/Untitled 6.png]]\n\n## Total Cache Capacity\n\n**Total cache capacity** = Associativity $\\times$ Number of Sets $\\times$ Block Size\n\n**Bytes of memory in cache** = blocks per set $\\times$ number of sets $\\times$ bytes per block\n\n**Increasing associativity:** Increases hit time, decreases miss rate (less conflict misses), does not change miss penalty\n\n**Increasing number of entries:** increases hit time (reading from larger memory), decreases miss rate (2x drop for every 4x increase in capacity), does not change miss penalty.\n\n**Increasing block size:** does not change hit time, decreases miss rate due to spatial locality but increases conflict misses in the long run, larger miss penalty\n\n**Reducing miss penalty:** Use more cache levels!\n\n## Cache Performance\n\n**Hit Time:** the amount of time needed to return data in a cache. This is usually measured in terms of cycles.\n\n**Miss penalty:** The additional time to return an element if it is not in the cache.\n\n**Miss rate:** The proportion of a program's memory requests that cause a cache miss.\n\nThe main measurement of cache performance is **AMAT** (Average Memory Access Time).\n\n**AMAT = Hit Time + Miss Rate * Miss Penalty**\n\nFor example, if a memory access takes 50ns, the cache lookup time is 5ns, and the hit rate is 90%, the AMAT would be:\n\n$0.9 * 5 + 0.1 (5 + 50)$ which is 10ns.\n\nWe can improve AMAT by:\n\n- Reducing the time to hit in the cache (make it smaller)\n- Reduce the miss rate (bigger cache or better programs)\n- Reduce the miss penalty (have multiple cache levels)\n\n## Write-through vs. Write-back\n\nWhen store instructions write to memory, we change the values. We need to then change both the cache value and the memory value to make sure that everything remains consistent.\n\nWe can use the **write-through policy** which states that we need to write values to both cache and memory. Since writing to memory is slow, we can instead write to a **write buffer** which stores the desired value until it is done being written.\n\nThe **write-back policy** states that we should write only to cache and then write the cache block back to memory when the block is evicted from the cache. That way, there is only a single write to memory per block, and writes are collected in the cache. \n\n- Using the write-back policy, we include a \"dirty\" bit to indicate if a block was written to or not.\n\nWrite through is good because:\n\n- It has simpler control logic.\n- There is more predictable timng.\n- It's easier to make reliable since there is memory redundancy (both cache and DRAM have new values).\n\nOn the other hand, write-back:\n\n- Is more complex, with variable timing.\n- Reduces write traffic since we do fewer writes.\n- Sometimes, only cache has data and so cache failure would result in disaster.\n\n---\n\n# Translation Lookaside Buffer (TLB)\n\nTo improve the performance of our address translation scheme from the previous chapter, let's see how we can apply the concept of caches to storing recently used addresses.\n\nWe can store mappings from virtual to physical addresses in a custom cache known as the **translation lookaside buffer.** That way, even if we have a multi-level address translation scheme, stored addresses can be quickly accessed with no further memory lookups required.\n\n![Untitled](Chapter%208%20Caching/Untitled.png)\n\n### Thrashing\n\nWhile great for reducing access times for cache hits, miss times with the TLB are very high because it exists in the critical path, and we would need additional accesses to go around it.\n\nIf the TLB is not big enough, or we otherwise keep evicting entries that are still needed, **thrashing** occurs, where there are continuous conflicts between accesses. To circumvent this, most TLBs are fully associative and have 128 to 512 entries.\n\n### Memory Access Walkthrough\n\nWhen some data needs to be accessed from the disk, the following happens:\n\n1. Check the TLB. If the cached translation exists, then we can simply access the physical memory directly.\n2. Check the page table. If the page exists, then access it directly.\n3. Otherwise, the entry is invalid or missing and a **page fault** occurs.\n4. Load the page into memory.\n5. Update the page table.\n6. Update the TLB to point to the new page entry.\n\n# Demand Paging\n\nThe final application of caching we'll explore in this chapter is **demand paging.** In addition to storing address translations in a cache, we can also store the data from the disk itself!\n\nThe reason why this is useful is because modern computers typically do not use all of their physical memory. Thus, we can take advantage of the unused portions to speed up otherwise slow disk accesses. In other words, we use physical memory as a cache for the disk.\n\n## Demand Paging Mechanisms\n\nHere's how demand paging is typically set up, in cache terms:\n\n- The block size is typically 4KB (1 page each).\n- The cache is fully associative, since it can arbitrarily map any virtual address to any physical address.\n- The cache is write-back, since write-through would defeat the entire purpose of demand paging. This means we need a dirty bit in the cache.\n- On a page fault, the following occurs:\n    - Choose an old page to replace (by a demand paging policy in the next section).\n    - If the old page was modified (i.e. dirty bit set), then write the contents back to the disk before evicting.\n    - Change the old page's page table entry and TLB to be invalid.\n    - Load the new page into memory.\n    - Update the page table entry and invalidate the previous TLB entry for that page.\n    - Continue the current thread. When the thread starts, it will update the TLB.\n\n## The Working Set Model\n\nEvery program has to access a certain amount of memory in its execution. We can call the entire set that needs to be accessed the **working set.** A larger proportion of cache hits generally means that a larger part of the working set is available in the cache.\n\n- The minimum number of entries needed to store the entire working set in the TLB is (working set size)/(page size). For example, if the working set size is 256KB and the page size is 4KB, then 64 entries are required.\n\nAt any point in time, a portion of the demand paging cache (i.e. main memory) is used to store a process. We can call this the **resident set size.**\n\n- If the physical memory size is less than the resident set size, then thrashing is likely to occur.\n\n## Page Replacement Policies\n\n### FIFO\n\n### RANDOM\n\n### MIN\n\n### LRU\n\n### CLOCK",
    "lastmodified": "2023-01-10T23:46:32.658053026Z",
    "tags": null
  },
  "/cs162/Chapter-9-File-Systems": {
    "title": "Chapter 9: File Systems",
    "content": "\n# I/O\n\n## Drivers\n\n![Untitled](Chapter%209%20File%20Systems/Untitled.png)\n\nA computer handles I/O on its end using several mechanisms:\n\n- The **bus,** a common set of communication wires, carries data transfer transactions between devices.\n    - A typical modern bus standard is **PCI** (Peripheral Component Interconnect), which is a parallel bus that can handle one transaction at a time. One major downside to this is that the bus speed must be set to the slowest connected device.\n    - PCI has evolved into PCI-Express, which is a collection of fast serial channels (lanes) in which devices can use as many as necessary to achieve a desired bandwidth. In this ways, devices can still use the old PCI standard, but don't have to share lanes with other devices.\n- **Controllers,** which sit between the CPU and I/O devices and contain a set of registers and memory that can be interfaced with.\n\nA processor can interact with device data in one of two ways:\n\n- **Port-Mapped I/O:** using assembly instructions to directly grab data.\n- **Memory-Mapped I/O:** devices asynchronously read and write data from memory, and the CPU can use standard load and store operations to access this memory. Memory-mapped IO generally requires polling (see below for consequences of this fact).\n\nTransferring data to and from a device controller can be done in one of two ways:\n\n- **Programmed I/O:** every byte is simply transferred via port-mapped or memory-mapped I/O operations.\n    - This is good because it keeps the hardware and software simple, but the amount of processor cycles it requires grows proportionally to the amount of data. (i.e. bad for huge chunks of data)\n- **Direct Memory Access (DMA):** give the device controller direct access to a memory bus (acts on physical memory).\n    - The **top half** of a DMA scheme, the device driver interface, starts a request.\n    - The **bottom half** consists of the code that executes on DMA completion (when the DMA controller interrupts the CPU).\n\nThere are two ways to notify the OS about I/O events:\n\n- **Polling** is when the OS periodically checks device status registers for operations that need to be completed.\n    - This is best for frequent, predictable I/O events, since there is low overhead; however, polling can waste CPU cycles if no I/O events are occurring.\n- **Interrupts** are generated by the device whenever it needs service.\n    \n    This is best for handling infrequent or unpredictable events, since there is high overhead on interrupt.\n    \n\nModern devices usually combine polling and interrupts: for example, network adapters could use interrupts to wait for the first packet, then poll for subsequent packets.\n\nSeveral types of standard interfaces can be implemented to make accessing devices more consistent:\n\n- **Block devices** access blocks of data at one time using `open()`, `read()`, `write()`, and `seek()`.\n    - This type of interface is best used for storage devices such as hard drives or CD readers.\n- **Character devices** access individual bytes at a time using `get()` and `put()`.\n    - This type of interface is most appropriate for devices that use small amounts of data, such as keyboards or printers.\n- **Blocking interfaces** put the process to sleep until the device or data is ready for I/O.\n- **Non-blocking interfaces** return quickly from read or write requests with the number of bytes successfully transferred. These interfaces are not guaranteed to return anything at all.\n- **Asynchronous interfaces** return pointers to buffers that will eventually be filled with data, then notifies the user when the pointer has been obtained.\n\n## Storage Devices\n\n### HDD\n\nHard drives are magnetic disks that contain tracks of data around a cylinder. \n\nHDD's are generally good for sequential reading, but bad for random reads.\n\n![Untitled](../../../CS186%20Notes%204a084a8a0e22428d9443c551eda9dfe0/Untitled%20Database%208925b4d3c6734c3fa260dd5d5e752782/Disks,%20Buffers,%20Files/Untitled%201.png)\n\n**Disk Latency = Queueing Time + Controller Time + Seek Time + Rotation Time + Transfer Time**\n\n- Queuing Time: amount of time it takes for the job to be taken off the OS queue\n- Controller Time: amount of time it takes for information to be sent to disk controller\n- Seek Time: amount of time it takes for the arm to position itself over the correct track\n- Rotation Time (rotational latency): amount of time it takes for the arm to rotate under the head (average is 1/2 a rotation)\n- Transfer Time: time it takes to transfer the required sectors from disk to memory\n\nHDD Question: Calculating size and throughput\n\nSuppose a hard drive has the following spects:\n\n- 4kb sectors\n- 3 million sectors per track\n- 100 tracks per platter\n- 2 platters (1 sided)\n- 5400 rpm\n- 5.6ms average seek time\n- 1ms controller+queue time\n- 140 MB/s transfer rate\n\nThe size of the hard drive is equal to (size of sector) x (num sectors per track) x (num tracks per plattter) * (num platters) = 4096B * 3000000 * 100 * 2, or about 2.46TB.\n\nFor a 64KB read, the throughput can be calculated as bytes/latency, or\n\n64KB/((queue + controller time) + seek time + rotation time + transfer time).\n\n- The queue, controller, and seek times are all given in the problem.\n- Average rotation time is (1/2) * (time for one rotation) = 0.5/5400 = 5.55ms.\n- The transfer time is (bytes)/(transfer rate) = 64/140 = 0.457ms.\n- All together, the throughput is 64KB/(1+ 5.6 + 5.55 + 0.457)ms = 5079KB/s.\n\n### SSD\n\nSolid state drives store data in non-volatile, NAND flash memory cells that don't have any moving parts.\n\n- This means that seek time and rotation time are essentially reduced to a single short access time.\n- Writing data to an SSD can get complex and time-consuming, because writing can only be done to an empty page. Generally, writing takes 10x as long as reading, and erasing blocks takes 10x as long as writing.\n- To mitigate long erasure times and lower NAND durability:\n    - Maintain a **flash translation layer (FTL)** which maps virtual block numbers to physical page numbers in RAM. This way, the SSD can relocate data at will without the OS caring.\n    - **Copy on write:** instead of overwriting the entire page when the OS updates its data, we can write a new version in a free page and update the FTL mapping to point to the new location. This allows writing without the costly erasure step.\n\n**SSD Latency = Queueing Time + Controller Time + Transfer Time**\n\n## Queuing Theory\n\n**Latency** (response time) is the amount of time needed to perform an operation.\n\n**Bandwidth** (throughput) is the rate at which operations are performed.\n\n**Overhead** (startup) is the time taken to initiate an operation.\n\nLatency for an n-byte operation = Overhead + n/Bandwidth (linear with respect to the number of bytes)\n\nA server that processes $N$ jobs per second is better than $N$ servers that process 1 job per second due to load balancing decreasing utilization.\n\n$\\mu$ = average service rate (in jobs per second)\n\n$S$ = $T_s$ = $m$ = average service time = $\\frac{1}{\\mu}$\n\n$C$ = squared coefficient of variance = $\\frac{\\sigma^2}{S^2}$\n\n$\\lambda$ = average arrival rate (in jobs per second)\n\n$U$ = utilization (fraction from 0 to 1) = $\\frac{\\lambda}{\\mu} = \\lambda S$\n\n$T_q$ = average queueing time (waiting time)\n\n$Q$ = $L_q$ average length of queue = $\\lambda T_q$ (Little's Law)\n\nMemoryless service time distribution with $C = 1$ (M/M/1 Queue): $T_q = S \\times \\frac{u}{1-u}$\n\nGeneral service time distribution (M/G/1 Queue): $T_q = S \\times \\frac{1+C}{2} \\times \\frac{u}{1-u}$\n\n### Queuing Theory Questions\n\nA job enters every 5 seconds, and completes in 60 seconds. What is the average queue length?\n\n- $L_q = \\lambda T_q$ (Little's Law).\n- The average arrival rate, $\\lambda$, is 1 job per 5 seconds, or 0.2.\n- $T_q$ is 60 seconds.\n- So $L_q = 0.2 \\times 60 = 12$.\n\nTo solve for $\\lambda$:\n\n# File Systems\n\nBest to worst ranked\n\n**Sequential Access:**\n\n1. Extent-based (NTFS) - files are contiguously allocated\n2. Linked (FAT) - traversing linked list\n3. Indexed (FFS) - nested inodes\n\n**Random Access:**\n\n1. Extent-based\n2. Indexed\n3. Linked\n\n**Disk Capacity:**\n\n1. Linked\n2. Indexed\n3. Extent-based (prone to external fragmentation)\n\n## FAT\n\nFAT stands for File Allocation Table. This file system consists of a table with entries that correspond one-to-one with blocks and stores information in a linked list format. (For example, file number 31 could point to 62, which could point to 53... all of these blocks in the table when read in order create a file.)\n\n- FAT is good for sequential access (due to linked list structure), but terrible for random access (since you have to traverse the list to get to where you want).\n- FAT is not prone to external fragmentation since subsequent blocks can go wherever there is free space, but internal fragmentation is severe in small files since blocks are a fixed size and you need at least one for each file regardless of the size.\n- FAT has poor locality for files and metadata since file information is not stored sequentially.\n\n## Linux FFS\n\n![Untitled](Chapter%209%20File%20Systems/Untitled%201.png)\n\nFFS (Fast File System) was used in early Linux systems and stores file information in **inodes.** \n\nEach inode has file metadata and a list of pointers (direct, indirect, doubly indirect...) to blocks.\n\n- FFS can be optimized for HDDs by splitting up the disk into block groups. All files in the same directory should be placed in the same block group.\n- FFS is pretty good for sequential access if optimized, since inode information is all stored together, and blocks should have some amount of locality if they are in the same block group.\n- Random access is also pretty good because you can just pick the pointer that you want from the inode.\n- There is no external fragmentation due tot the inode structure, but internal fragmentation can be pretty severe due to the overhead and fixed size of inodes.\n\n- Hard link vs soft link\n- \n- Direct pointer, indirect pointer, doubly indirect pointer\n- Inode\n- Calculate maximum filesize\n\n## NTFS\n\nNTFS (New Technology File System) is currently used by Windows. Rather than an inode array like FFS, it uses a Master File Table. Each entry in the MFT contains file metadata and data; the main difference is that MFT entries can have variable size.\n\n- If a file grows too large, then **extents** add extra pointers into a MFT entry.\n\n## Directories\n\nIn the three file system designs above, directories are represented as a file containing name-to-filenumber mappings where one entry in the directory corresponds to a file or subdirectory. (In FAT, file metadata is also stored in the directory.)\n\nName-to-filenumber pairs stored in directories are called **hard links,** which can be created using the `link()` syscall.\n\n- In non-FAT filesystems, a file can have more than one hard link (i.e. be part of two different directories).\n- A file will not be removed unless all hard links to that file are removed (so a reference count is needed to track them).\n\n**Soft links** are a special entry in directory files with name-to-path mappings. Whenever the original name is accessed, the OS will look up the file corresponding to the stored path.\n\n- Soft links can be created using the `symlink()` syscall.\n- There is no reference count needed for soft links: if the path doesn't exist or the file is deleted, then lookup will simply fail.\n\n# Distributed Systems\n\n## Durability\n\n**How do we prevent loss of data due to disk failure?**\n\n### RAID\n\nRedundant Array of Inexpensive Disks. Rather than using one large, expensive, reliable disk, we use a large amount of small, expensive, unreliable disks and duplicate the data across the disks.\n\n- **RAID 0:** No redundancy, striped volumes only. Very unreliable (any one disk failure means data loss).\n- **RAID 1:** Disk mirroring. Every disk is fully duplicated onto its mirror. This produces a very large data availability and optimized read rates, but at the cost of needing 100% overhead.\n- **RAID 3:** Parity disk. For every 3 disks, 1 additional disk is used to store parity information (so 1/4 of the data cost as RAID 1). If any one of the four disks fails, the data will still be intact.\n- **RAID 4:** Disk sectors. Rather than operating at the bit level (like RAID 3), RAID 4 operates on a stripe level. Reads and writes must be done both to the original disk and the parity disk. This works well for small reads, but small writes can be problematic because every modified stripe needs to be parity checked. So the bottleneck becomes the parity disk.\n- **RAID 5:** Interleaved parity. In a larger array, an independent set of parity disks each contain a few stripes for each drive. This cuts down on write bottlenecks since the chance of multiple drives writing to the same parity drive is reduced.\n- **RAID 6:** RAID 5 with two parity blocks per stripe. So the drive array can tolerate 2 disk failures rather than just 1, at the cost of needing additional capacity.\n\n## Reliability\n\nReliability is the guarantee that data remains in a consistent state after recovering from disk failure. This differs from durability since the former deals with the recovery step itself.\n\n### Transactions\n\nA **Transaction** is an atomic sequence that takes a system from one consistent state to another. Transactions follow four properties (ACID):\n\n- Atomicity: transaction must complete in its entirety, or not at all\n- Consistency: transactions go from one consistent state to another, and cannot compromise integrity\n- Isolation: transactions should not interfere with each other if executed concurrently\n- Durability: once a transaction is made, it will not be erased on disk failure.\n\n### Journaling Filesystem\n\nOne way to guarantee reliability in a filesystem is to write operations to a log first. Once the whole transaction is written to the log, the disk will then apply the necessary changes.\n\n- If the system crashes when writing to the log, then the transaction will not be applied.\n- If the system crashes when applying disk changes, then we can simply observe that the log was not completed and re-apply the transaction. This is guaranteed to work for **idempotent** transactions (applying multiple times will have same effect as applying once).\n\nEXT3 is basically FFS but with logging.\n\nA **log structured file system** takes logging to another level by making the entire filesystem one log.\n\n## Consensus Making\n\nPreviously, we talked about transactions on a single machine. But what if we have lots of computers, and need to coordinate transactions between them? It's possible for one machine to be in an inconsistent state while the others are operating normally.\n\n### Two-Phase Commit\n\n2PC is a scheme for distributed consensus making. It proceeds as follows:\n\n- One machine is the coordinator; all others are participants (workers).\n- When the coordinator receives a request, it logs it then sends a `VOTE-REQUEST` to workers.\n- Each worker records their own vote in their log.\n- Each worker then sends a `VOTE-ABORT` or `VOTE-COMMIT`.\n- If all workers send `VOTE-COMMIT`, then the coordinator writes a commit in their log and sends `GLOBAL-COMMIT` to all workers.\n- Workers then perform the commit and send an `ACK` on completion.\n\nIf one or more workers send `VOTE-ABORT` or times out, then the coordinator sends a `GLOBAL-ABORT` and no operation should be completed.\n\n![Untitled](Chapter%209%20File%20Systems/Untitled%202.png)\n\n**General's Paradox:**\n\nMessages over an unreliable network cannot guarantee entities to do something simultaneously. However, this doesn't apply to 2PC because there is no simultaneous operation.\n\n# Network Systems\n\n## Layers\n\n![Untitled](Chapter%209%20File%20Systems/Untitled%203.png)\n\n## TCP vs UDP\n\n![Untitled](Chapter%209%20File%20Systems/Untitled%204.png)\n\n![Untitled](Chapter%209%20File%20Systems/Untitled%205.png)\n\n![Untitled](../../CS161%20Notes%2058b7c6378df74bef8c48f2d39dbe9a72/Notes%208cc979bb2e384250a5fa4b59ec87672e/Networking/Untitled%207.png)\n\n## Remote Procedure Calls\n\n![Untitled](Chapter%209%20File%20Systems/Untitled%206.png)\n\nRPC's (remote procedure calls) are an interface to call functions on another machine. \n\n## Distributed Filesystems\n\n![Untitled](Chapter%209%20File%20Systems/Untitled%207.png)\n\nCreate an abstraction (virtual file system, VFS) that allows the system to interact with remote files as if they were local.\n\n- NFS (network file system) translates read and write calls into RPC's.\n    - These RPC's are stateless and idempotent: they contain information for the entire operation.\n    - Results are cached on the local system. The server is polled periodically to check for changes.\n    - Write-through caching (writing all changes on server before returning to client) is used.\n    - Multiple writes from different clients simultaneously create undefined results.\n\n## End-To-End Argument\n\nThe primary argument is that we can't trust the network, so we need to guarantee services on both ends.",
    "lastmodified": "2023-01-10T23:46:39.973977455Z",
    "tags": null
  },
  "/cs168/": {
    "title": "CS 168: The Internet",
    "content": "\n## CS168 Notes\n\nHere are my notes for the Fall 2022 offering of [CS168](https://cs168.io), Berkeley's Introduction to the Internet course.\n\n## Table of Contents\n - [[Intro to the Internet]]: What is the internet, and why should I care?\n - [[CLI|CLI Tools]]: Tools to explore the internet\n - [[Intradomain Routing]]: Least-Cost routing, Distance-Vector protocols, Link-State routing, Spanning Tree protocol\n - [[Measuring Link Performance]]: Terms to discuss how good a link is\n - [[Resource Sharing (Packet and Circuit Switching)]]: Statistical Multiplexing; packet switching vs. circuit switching\n - [[Internet Organization and Layers]]: The OSI Model and the End to End Princple\n - [[Sockets and Ports]]: Definition of a socket\n - [[Addressing (IP)]]: IPv4, IPv6, CIDR, prefix matching\n - [[Interdomain Routing (BGP)]]: Autonomous Systems, BGP, Gao-Rexford Rules\n - [[TCP]]: Modern TCP implementation for 'reliable' packet delivery\n - [[Reliability]]: Algorithms for implementing reliability\n - [[Congestion Control]]: Algorithms for congestion detection and avoidance\n - [[DNS]]: The Domain Name System protocol\n - [[Web]]: HTTP\n - [[Ethernet]]: ARP, DHCP\n - [[End to End Operation]]: A full example request walkthrough\n - [[Final Review]]: Practice problems and detailed solutions\n\n \n## How to contribute\n\nSee the [contributing guide](/contributing) for more details!\n\nFor the most part, these notes should be pretty complete in terms of content, but could use some cleaning up (as well as more examples).\n\n#### Credits\n\n* [Ben Cuan](https://github.com/64bitpandas)\n\n\n\n\n\n\n",
    "lastmodified": "2023-01-12T02:22:48.736980457Z",
    "tags": null
  },
  "/cs168/TCP": {
    "title": "TCP",
    "content": "\n## The Transport Layer\nThe transport layer (L4) is built directly on top of the networking layer. Many different protocols exist on the transport layer, most notably TCP and UDP.\n\nThe goal of the transport layer is to bridge the gap between tne abstractions application designers want, and the abstractions that networks can easily support. By providing a common implementation, the transport layer makes development easier.\n\nThe main tasks of the transport layer include:\n - **Demultiplexing** (taking a single stream of data and identifying which app it belongs to)\n\t - Port numbers carried in L4 protocol header\n - Providing [[reliability]]\n - Translating from packets to app-level abstractions\n - Avoid overloading the receiver (flow control)\n - Avoid overloading the network\n\n## TCP Segments\n![[/cs168/img/Pasted image 20221017034540.png]]\n\nIndividual bytes in the bytestream are divided into segments, which are sent inside of a packet. (A TCP packet is just an IP packet whose data contains a TCP header and segment data.)\n\nThe **maximum segment size** (MSS) is equal to the MTU - (size of IP header) - (size of TCP header).\n\n\n## TCP Sequence Numbers\n\u003e **Important:** TCP operates on bytes, not packets. Sequence numbers, ACKs, window sizes, etc. are all expressed in terms of bytes.\n\n![[/cs168/img/Pasted image 20221017034958.png]]\n\n\n## TCP Properties\n\n### TCP is connection oriented\nTCP requires keeping state both on the sender and the receiver.\n - Sender keeps track of packets sent but not ACKed, and any timers needed for resending.\n - Receiver keeps track of out-of-order packets.\n\nEach bytestream is called a **connection** or **session**, each with their own connection state stored at end hosts.\n\n### TCP connections are full-duplex\nIf Host A and Host B are connected via TCP, hosts A and B can both be senders and receivers simultaneously. This means that Host A and Host B can be sending and receiving from each other using the same connections.\n\n### Reliability handling\n - Sequence numbers are byte offsets\n - TCP uses cumulative ACKs (next expected byte: the sequence number of the next packet is the same as the last ack)\n - Sliding window that allows up to $W$ contiguous bytes to be in flight at the same time\n - Retransmissions are triggered both by timeouts and duplicate acks\n - Single timer is used for the 1st byte of the window\n - Timeouts computed from RTT measurements\n\n\n## TCP States\n![[/cs168/img/Pasted image 20221017040812.png]]\n\n## Congestion Control Implementation\n\nFor an intro to congestion control, see [[congestion control]].\n\nTCP uses a **loss-based, host-based, dynamic adjustment** congestion control scheme.\n\n### Terms\n - **Loss-based:** window determined by packet loss\n - **Host-based:** routers do not participate; window size is implicitly determined by hosts only\n - **AIMD:** Additive Increase Multiplicative Decrease\n - **RWND:** Advertised window/Receiver window: maintained by receiver and directly communicated to sender for flow control (max bandwidth the receiver can handle before buffer overflow)\n - **CWND:** Congestion Window: computed by sender using concurrency control algorithm (how many bytes can be sent without overloading links)\n - **Sender-side window:** min of RNWD and CWND. Typically, assume that RWND \u003e\u003e CWND.\n - **MSS:** Maximum Segment Size: max number of bytes of data that one TCP packet can carry in payload\n - **Sender Transmission Rate:** CWND/RTT (bits per second)\n\t - Changing CWND \u003c==\u003e changing transmission rate\n - **SSTHRESH:** slow start threshold (last safe rate). equal to CWND/2 on first loss\n\n\n### Window Mechanics\nRecall that the sender maintains a sliding window of $W$ contiguous bytes, where $W$ is the window size (typically CWND). On receiving an ACK for new data $j$ where $j\u003ei$, then the window slides to start at $j$.\n\nThe sender maintains a single timer for the smallest value $i$ in the window. On a timeout, the sender retransmits the packet that starts at byte $i$.\n\nSince the receiver sends cumulative ACKs, full information isn't provided so the sender will count the number of duplicate acks received (dupACK). When dupACK == 3, the sender will retransmit (**fast retransmit**).\n\n\n### Changing CWND\n**Main idea:** Change CWND based on ACK arrivals (**ack clocking**)\n - The spacing between acks is representative of the bandwidth. Longer spacing = lower bandwidth\n - Optimal solution = full utilization of minimum link bandwidth\n\n### Slow Start\n1. Initialize CWND equal to MSS. (initial sending rate is one MSS per RTT)\n2. Double CWND every RTT until first loss occurs. (On every ACK, add 1x MSS to CWND)\n3. When first loss occurs, set SSTHRESH=CWND/2\n\n### AIMD/Congestion Avoidance\n - No loss -\u003e increase CWND by 1 MSS every RTT\n\t - Implementation: successful ACK received -\u003e$CWND = CWND + MSS \\times MSS/CWND$ \n - 3 dupACK -\u003e divide CWND in half\n\t - Implementation: save dupACKcount in memory, and increment if duplicate detected\n - Timeout -\u003e set CWND to MSS, and restart Slow Start\n\t - switch back to AIMD when SSTHRESH is hit\n\n\n### Fast Recovery\nFast Recovery is an optimization to congestion avoidance. The main idea is to keep packets in flight by allowing senders to keep sending even when a dupACK is received.\n\nIf dupACKcount is 3:\n - set SSTHRESH to $\\lfloor CWND/2 \\rfloor$\n - set CWND to SSTHRESH + 3xMSS\n\nWhile in fast recovery:\n - CWND = CWND + MSS for every additional dupACK\n - Set CWND = SSTHRESH upon receiving first new ACK\n\n\n### State Machine\n![[/cs168/img/Pasted image 20221025184701.png]]\n\nTCP Sawtooth\n![[/cs168/img/Pasted image 20221024112005.png]]\n\n\n## TCP Throughput\n\nGiven RTT and the loss rate $p$, we can derive the throughput of TCP.\n\nAssume:\n - loss occurs whenever CWND reaches $W_{max}$\n - loss is detected by duplicate ACKS (no timeouts)\n - ignore slow start throughput\n\nSince we go between half of $W_{max}$ and full, the average window size per RTT is equal to $\\frac{3}{4}W_{max}$. Therefore, the average throughput is $\\frac{3}{4}W_{max} \\times \\frac{MSS}{RTT}$.\n![[/cs168/img/Pasted image 20221031211322.png]]\nOn average, our loss rate is $p=1/A$ (where A Is the area under the curve in one of the periods). Using this, we can see that the area $A$ is equal to $\\frac{3}{8}W_{max}^2$.\n\nSolving for $W_{max}$ and plugging it into the average throughput equation yields this formula for average throughput:\n$$\\sqrt{\\frac{3}{2}} \\frac{MSS}{RTT \\sqrt{p}}$$\n### Implications of throughput equation\n\n - Flows get throughput inversely proportional to RTT. So lower RTT = higher throughput, which can be unfair for further connections.\n - Scaling a single flow to high throughput is very slow with additive increase, and ramping up to very fast bandwidth (hundreds of gbps) could take hours.\n\t - solution: HighSpeed TCP (RFC 3649): past a certain threshold speed, increase CWND faster.\n - TCP throughput is choppy due to repeated swings: some apps (streaming) may prefer sending at a steady rate\n\t - solution: equation-based congestion control (measure RTT and drop percentage $p$ and directly apply equation)\n - TCP confuses corruption with congestion: throughput is proportional to 1/sqrt(p) even for non-congestion losses\n - Due to 50% of flows being \u003c1500B, many flows never leave slow starts, and there are too few packets to trigger dupACKs\n\t - solution: use higher initial CWND\n - since TCP fills up queues before detecting loss, delays can be large for everyone in a bottleneck link\n\t - solution: Google BBR algorithm (sender learns minimum RTT, and decreases rate when observed RTT exceeds minimum RTT)\n - congestion control is intertwined with reliability: CWND is adjusted based on acks and timeouts. we can't easily get congestion control without reliability.\n\n## Fairness\n\n**General approach:**\n - A router classifies incoming packets into flows.\n - Each flow has its own queue in the router.\n - The router picks a queue in a fair order and transmits packets from the front of that queue.\n\n### Max-Min Fairness\n**Main idea:** if a flow doesn't get its full demand, then no other flow will get more than that amount.\n\nIf the total available bandwidth is $C$ and each flow $i$ has a bandwidth demand $r_i$, then the fair allocation of bandwidth $a_i$ to each flow is calculated as\n$$a_i = min(f, r_i)$$ where $f$ is the flow's fair share, calculated by the following:\n - Get the average $C/N$ (where $N$ is the number of flows).\n - Subtract all of the $r_i$ from $C$ where $r_i \u003c N$. For each flow that this is done for, subtract one from $N$.\n - For all of the remaining flows, set $f = C/N$.\n\n### Fair Queueing (RCP)\nFQ addresses the issue where packets may not all be the same size.\n - For each packet, compute the time where the last bit would have left the router if flows are served bit by bit (deadlines)\n - Serve packets in increasing order of their deadlines.\n\nAdvantages of FQ:\n - Isolation of flows (cheating flows don't benefit)\n - bandwidth share does not depend on RTT\n - flows can pick any rate adjustment scheme\n\nDisadvantages:\n - more complex than FIFO\n - only helps, but does not solve, congestion control\n - too complex to implement at high speeds\n - unfair for applications with different numbers of flows \n\n### Explicit Congestion Notification (ECN)\n - Single bit in packet header set by congested routers in ACK\n - Host treats acks with set ECN bit as a dropped packet\n - Doesn't confuse corruption with congestion\n - Early indicator of congestion can be used to avoid delays\n - lightweight to implement",
    "lastmodified": "2023-01-12T00:47:51.11975984Z",
    "tags": null
  },
  "/cs168/addressing-ip": {
    "title": "Addressing",
    "content": "\nHow do we scale the ideas of routing and forwarding to the scale of the entire internet? \n\nThis is mainly resolved with the domain of **addressing.**\n\n## Early Addressing Schemes\nIn the early internet, each network had its own identifier, and each host within a network had its own identifier. Naturally, any host could be addressed using two numbers in the form `networkID.hostID`.\n\nAs a result of this hierarchical addressing scheme, each *internal router* only needs to store information about the hosts within the same network, as well as a gateway address to a *border router* connected to external networks.\n\n## IPv4\nIn the modern internet, addresses are assigned using the IPv4 scheme, which is typically represented in the **dotted quad** format (XXX.XXX.XXX.XXX). \n\nIPv4 addresses are 32-bit, and \n\n### Classful Addressing\nIn the early internet, there were three main classes of networks:\n![img](\u003c/cs168/img/Pasted image 20220918211936.png\u003e)\nHowever, this classful structure created several issues, the biggest of which was that the majority of organizations needed Class B networks, despite there only being ~16,000 of them.\n\n\n### CIDR\nAs a solution to classful addressing, CIDR (**classless inter-domain routing**) was invented. CIDR introduces a new hierarchy for address assignment:\n - First, ICANN (Internet Corporation for Assigned Names and Numbers) acquired the remaining Class C networks.\n - Next, ICANN gives out a chunk to **RIRs** (Regional Internet Registries), like ARIN.\n - Then, larger organizations (mostly ISPs) acquire chunks from their responsible RIR.\n - Finally, smaller organizations and individuals acquire individual IP addresses from ISPs.\n\nAt each step, the assigner adds a certain number of bits to reduce the number of available addresses for the next step.\n\n\n### IPv4 Header\n![img](\u003c/cs168/img/Pasted image 20221003153110.png\u003e)\n\n* Version (4b): equal to 4 for IPv4 and 6 for IPv6\n* Header Length (4b): typically set to 20 bytes if options are not used\n* Type of Service (8b): used to specify how the packet should be treated\n* Datagram length (16b): number of bytes in the packet (maximum $2^{16} - 1$, or 65535)\n* Identifier (16b): used for uniquely identifying groups of fragments of a single IP datagram (all fragments in the same group will have the same ID)\n* Flags (3b):\n\t* first bit is always 0\n\t* second bit is 1 if packet can be fragmented, 0 otherwise\n\t* third bit is 1 if packet isn't the last fragment, 0 otherwise\n* Fragmentation Offset (13b): offset (divided by 8-bit units) from original payload\n* TTL (8b): discard packet if TTL=0\n* Upper-layer protocol: next layer protocol to use (6 for TCP, 17 for UDP)\n* Header checksum: used to verify header integrity (recomputed at each hop)\n* Source IP (32b): where packet came from\n* Destination IP (32b): where packet is sent to\n\n\n## Prefix Matching\nGiven a routing table, how do we actually match a requested destination IP with its host?\n\nThe naive solution would be to just iterate through all of the table entries until a match is found, but this is very slow. \nAn improvement would be to create a **prefix tree** to take advantage of the binary tree structure enabled by bitstrings.\n![img](\u003c/cs168/img/Pasted image 20221008151948.png\u003e)\n\n\nRealistically, due to the hierarchy of addressing multiple prefixes are often assigned to the same port (such as towards your ISP). Suppose in the illustration above that 0**, 101, and 11* all pointed towards Port 1. Then, the prefix tree can be compacted as such:\n\n![img](\u003c/cs168/img/Pasted image 20221008152108.png\u003e)\n\n\n\n\n\n## IP Fragmentation\n\nMaximum Transmission Unit (MTU)\n\n### Example\nSuppose we have an MTU of 500 bytes, and a 600-byte packet. Then, the packet will be split into two packets:\n - the first one will have 500 byte total length (480bytes data + 20 byte header). \n\t - Flag will be set to 001.\n\t - Offset will be 0.\n - the second one will have 120 byte total length (100 bytes data + 20 byte header).\n\t - Flag will be set to 000.\n\t - Offset is 480/8 = 60.\n\n\n## IPv6\nThe creation of IPv6 was motivated by the fact that one day we would run out of IPv4 addresses (32-bit, so 4,294,967,296 total). At this point we actually have already run out of IPv4 addresses, but you can buy some unused ones [here](https://auctions.ipv4.global/) for about $10,000-30,000 per /24 block. \n\nAs of today (Oct 2022), about 40% of internet users support IPv6 (https://www.google.com/intl/en/ipv6/statistics.html), but it will take a very long time before we can completely deprecate IPv4.\n\n### Philosophy\n - Don't make the network deal with problems: leave it to the end hosts\n - Simplify while still allowing extensibility\n\n### Differences from IPv4\nIPv6 is a more elegant, but unambitious protocol that mostly builds onto IPv4 with some minor improvements.\n\nHere are the IPv4 and IPv6 headers side by side:\n![img](\u003c/cs168/img/Pasted image 20221010105745.png\u003e)\n\n - **More addresses:** $2^{128}$ addresses, which is far more than we will probably ever need. The source and destination address fields are now 4x larger (128 bits instead of 32).\n - **Removed checksum:** since the network is best-effort anyways, it's excessive to make each router compute the checksum. Instead, we can just verify it at the end host.\n - **Removed length field:** All IPv6 headers are the same length (40 bytes).\n - **Better options:** Rather than the ambiguous \"options\" field, IPv4 uses the \"next header\" field to point to the next layer's header.\n\t - Each next header field has an ID corresponding to the protocol of the next header. For example, if Next Header = 6, the router will know to look for a TCP header.\n\t - Next Headers can be chained/nested through multiple layers.\n - **Eliminated packet fragementation:** Instead of fragmentation, use **MTU Discovery**, where hosts can send small exploration packets to determine the MTU of routers in the path and decide how big to make the packets. If a packet larger than the MTU is sent to a router, an error message will be sent back to the host.\n - **Added flow label:** explicit mechanism to denote related packet streams: allow for multiple sessions and grouping of related packets\n\n\n## Security\n\nIf an attacker can choose whatever they want to put in an IPv4 packet, they can exploit several vulnerabilities:\n - change source and destination addresses to whatever you want: can claim to be a source you're not\n\t - choose different source address for every packet to avoid filtering\n\t - cause destination to block a particular host\n - set Type of Service to cause hosts to treat attack traffic as high priority\n\t - most ISPs mitigate this by not allowing end hosts to set TOS\n - send packets larger than MTU to create resource exhaustion\n - traceroute: discover topology via TTL",
    "lastmodified": "2023-01-12T00:21:54.515711833Z",
    "tags": null
  },
  "/cs168/cli": {
    "title": "Networking Command Line Tools",
    "content": "\n## nslookup\nResolves a hostname to an IP address (or the reverse).\n\nBasic usage: `nslookup \u003chostname\u003e \u003cDNS server\u003e`\n - Example:\n```\n❯ nslookup cs168.io\nServer:         127.0.0.53\nAddress:        127.0.0.53#53\n\nNon-authoritative answer:\nName:   cs168.io\nAddress: 185.199.109.153\nName:   cs168.io\nAddress: 185.199.110.153\nName:   cs168.io\nAddress: 185.199.111.153\nName:   cs168.io\nAddress: 185.199.108.153\n```\n\nReverse lookup: `nslookup \u003cip\u003e`\n```\n❯ nslookup 185.199.110.153\n153.110.199.185.in-addr.arpa    name = cdn-185-199-110-153.github.com.\n```\n\n\n\n## host\nUsed for DNS lookup (converting between IP addresses and domain names).\n\n`host -t ns \u003cHOSTNAME\u003e`\n\n```\n❯ host -t ns google.com\ngoogle.com name server ns2.google.com.\ngoogle.com name server ns4.google.com.\ngoogle.com name server ns3.google.com.\ngoogle.com name server ns1.google.com.\n```\n\n\n## ping\nMeasures RTT (round trip time) between host and remote server by sending ICMP (internet control message protocol) packets\n\n\n## traceroute\nTraces the route that packets take from computer to destination.\n - Shows router IP addresses and hop times\n - Asterisks = packet lost when being sent to router\n - Uses TTL (time to live) field in IP header; gets decremented by 1 at each router\n - packets are discarded when TTL=0 to avoid loops\n\n```\n❯ traceroute google.com\ntraceroute to google.com (142.251.214.142), 30 hops max, 60 byte packets\n 1  Docsis-Gateway.hsd1.ca.comcast.net (10.0.0.1)  1.275 ms  1.326 ms  1.346 ms\n 2  96.120.89.97 (96.120.89.97)  15.764 ms  18.875 ms  18.963 ms\n 3  96.110.176.209 (96.110.176.209)  19.056 ms  19.095 ms  19.135 ms\n 4  162.151.78.129 (162.151.78.129)  19.219 ms  19.160 ms  19.243 ms\n 5  be-232-rar01.santaclara.ca.sfba.comcast.net (162.151.78.253)  15.767 ms  17.192 ms  18.799 ms\n 6  96.108.99.249 (96.108.99.249)  26.164 ms  21.468 ms  19.513 ms\n 7  be-299-ar01.santaclara.ca.sfba.comcast.net (68.86.143.93)  21.295 ms  16.004 ms  15.695 ms\n 8  96.97.98.246 (96.97.98.246)  12.520 ms 69.241.75.46 (69.241.75.46)  22.875 ms 96.112.146.26 (96.112.146.26)  22.982 ms\n 9  * * *\n10  142.251.224.30 (142.251.224.30)  22.203 ms 209.85.252.250 (209.85.252.250)  23.538 ms sfo03s32-in-f14.1e100.net (142.251.214.142)  21.774 ms\n```\n\n",
    "lastmodified": "2023-01-12T00:01:25.884604208Z",
    "tags": null
  },
  "/cs168/congestion-control": {
    "title": "",
    "content": "If the capacity of the output link is less than the capacity of the incoming links, then it is possible for too many packets to arrive at once, overloading the link.\n\nHere's a graph of the packet delay as a function of load, assuming that we use a simple queue:\n\n![img](\u003c/cs168/img/Pasted image 20221024085656.png\u003e)\n\nFundamentally, congestion control is a resource allocation problem. However, it is very complex because changing one link can have a global impact, and these impacts need to be accounted for by every router on every flow change.\n\n## History (Karels and Jacobson)\nIn the 1980s, the early internet experienced congestion collapse when the network was overloaded. As a solution, Van Jacobson and Michael Karels created an algorithm to adjust window size based on observed packet loss. \nThis algorithm was quickly adopted because it required no router or application updates, only a small patch to BSD's TCP implementation.\n - 1986 congestion collapse: packets getting stuck in queues --\u003e packets get dropped -\u003e packets are resent -\u003e more packets in network -\u003e overload\n\n## Goals\n - Low packet delay and loss\n - High link utilization\n - Fair sharing across flows\n\nThese three goals are not always compatible, so we aim to strike a reasonable balance between them.\n\n\n## Possible Approaches\n - **Reservations:** use a system for flows to reserve bandwidth (see [[resource sharing (packet and circuit switching)]]). However, this comes with all of the issues of reservations, which was not used for general internet architecture.\n- **Pricing Model:** treat bandwidth as a scarce commodity, and raise the costs of links in high demand so new flows go elsewhere. In many cases, this model is optimal but requires a payment framework (which doesn't exist outside of datacenters).\n- **Dynamic Adjustment:** hosts dynamically learn the current level of congestion and azdjust sending rate accordingly. This is a highly general solution that doesn't assume anything about the business model or application requirements. However, it assumes that clients are honest about their calculations, and that there are few malicious actors.\n\t- Host-based congestion control: no support from routers; hosts individually adjust rate based on implicit feedback (packet delay, acks, dropped packets)\n\t- Router-assisted congestion control: routers signal congestion back to hosts, and hosts pick rate based on explicit feedback\n\n## Detecting Congestion\n\n**Packet loss:** if packets are dropped, congestion probably occurred so send less\n - Pro: Fail-safe signal since TCP already implements reliability\n - Con: doesn't account for non-congestive loss like checksum errors; can be confused with packet reordering due to TCP using cumulative ACKs\n\n**Increase in packet delay:** congestion may be correlated with packet delay\n - Historically not used due to complications in measuring delay\n - Used by Google's BBR protocol\n\n## Implementation\n\n### Discovering an Initial Rate\n**Goal:** Estimate available bandwidth in a safe and efficient manner.\n**Solution:** Slow Start\n - Start at a very small rate\n - Increase exponentially until first loss (double rate)\n - First safe rate is half of the rate where first loss was experienced\n - double CWND every RTT\n\n### Rate Adjustment\nAfter the initial rate is determined using Slow Start, TCP needs to dynamically adjust the rate to adapt to changes in available bandwidth.\n\nThere is a tradeoff between efficiency (utilization of total available bandwidth) and fairness (how similar the allocations are for different flows). We can model this tradeoff using this graph:\n![img](\u003c/cs168/img/Pasted image 20221025113828.png\u003e)\n - The goal is to get as close to the center as possible (both on the efficiency and fairness lines).\n\nThere are 4 methods of changing the rate. A = additive, M = multiplicative, I = increase, D = decrease.\n - **AIAD**:  can become more efficient, but will never converge to fairness since the slope of the line never changes\n\t - ![[/cs168/img/Pasted image 20221025114116.png|300]]\n - **MIMD:** similarly to AIAD, can be more efficient but doesn't converge to fairness. \n\t - ![[/cs168/img/Pasted image 20221025114302.png|300]]\n\t - Slope of the line is always $x_2/x_1$ \n - **MIAD:** maximially unfair; will allocate all of the capacity to one flow (converge to either X or Y axis)\n - **AIMD:** both efficient and fair\n\t - ![[/cs168/img/Pasted image 20221025114502.png|300]]\n\n\n",
    "lastmodified": "2023-01-12T00:23:16.174899275Z",
    "tags": null
  },
  "/cs168/dns": {
    "title": "",
    "content": "\nDNS (domain name system) was created as a solution to make IP addresses human-readable for users. \n\nIn the early days, DNS took the form of a standardized address book called hosts.txt maintained by Elizabeth Feinler at the Network Information Center. This included an IP address, user-friendly name, and properties such as supported protocols. Whenever someone wanted to look up a name, they would query for hosts.txt. However, this got troublesome due to increased burden on the NIC team, high bandwidth usage as the number of hosts increased, and having a single point of failure.\n\n\n## Hierarchy\n**Names are hierarchical:** Domains get more specific from right to left\n\n**Authority is hierarchical:** Each level has a responsible party (.edu, berkeley.edu, etc)\n - The DNS root is controlled by ICANN\n - Top Level Domains (TLDs) are controlled by over 1500 authorities, such as Educause for edu domains and Verisign for .net/.com domains.\n - A **zone** corresponds to an administrative authority responsible for a contiguous portion of the authority. An example of a zone is `*.berkeley.edu` which controls all domains ending in berkeley.edu.\n\n**Infrastructure is hierarchical:** the DNS system is composed of many name servers which each are responsible for one part of the hierarchy.\n\n\n## Name Lookup\n1. A client looks up a domain by querying their **resolving name server** (usually run by ISP)\n2. The resolving name server runs a **recursive query** (actually iterative) by repeatedly doing the following:\n\t1. Get a request from the current server (starting at the root)\n\t2. If the server knows the answer, return the answer.\n\t3. Otherwise, move onto the next server and return the result of that query.\n\nThere are several main classes of name servers:\n - Root server knows all the TLD servers\n - TLD server knows about a particular TLD (such as .edu)\n - Authoritative servers know information about their zone (such as \\*.berkeley.edu) and map domain names to IPs.\n - \n\n\n## The DNS Protocol\n\nC / python socket API:\n`result = gethostbyname(\"hostname.com\")`: deprecated but still common, limited to IPv4\n`error = getaddrinfo(\"hostname.com\", NULL, NULL, \u0026result)`: more modern, not limited to IPv4\n\nStandard DNS server: BIND (berkeley internet name domain server)\n - basically a daemon/server process\n - listens on port 53 (UDP)\n\nMessages may be either a query or response (QR bit in header 0 or 1 respectively). \n\nData is stored in **resource records** (RRs) that are a tuple of (type, name, value, ttl, class).\n - type is A, NS, etc.\n - name is the domain name\n - value is the IP address\n - ttl is how long the record is valid for \n - class is used for other network types (not really used in practice)\n\n### Step by step\n1. Client queries resolving name server\n2. Resolving name server queries root server, requesting an A record\n3. Response: list of NS records corresponding to TLD/authoritative servers, as well as an additional A record (IP for name server we should ask next)\n4. Repeat until the desired authoritative server is contacted, and an A record is returned\n\n### Registering a domain\n - Companies can purchase/request IP blocks from ISP\n - Register domain with a registrar\n - Run 2 authoritative name servers for the domain (often handled by registrar/external service)\n - Registrar will insert pairs of NS and A records into the TLD name servers\n\n### Reverse lookups\nUsing the PTR record, we can convert an IP address to a hostname.\n - name = dot-quad IP address listed backwards (138.110.1.200 -\u003e 200.1.110.138)\n - name is followed by `.in-addr.arpa`\n\n\n### Record Types\n**A:** \"address record\" - maps hostname to IP address\n**AAAA:** Same as A, but for ipv6\n**NS:** \"nameserver\" - maps domain to DNS server\n**CNAME:** \"canonical name\" - way for aliasing from one hostname to another hostname\n**DNAME:** maps an entire subtree to another subtree\n**MX:** \"mail exchanger\": redirects to another mail server\n**TXT:** human-readable information, often used to prove ownership of domain\n**SRV:** used for arbitrary services (servicename.transportprotocol.hostname)\n\n## Availability, Scalability, Performance\n**DNS should be:**\n - Highly available: accessible at all times (otherwise the internet breaks down)\n - Highly scalable: most devices on the internet will use DNS\n - Highly performant: lookups should be fast and take little bandwidth\n\n**How do we do this?** Just add more servers.\n - Domains have at least two name servers each\n - Have multiple servers per domain such that if one domain goes down, others are still available\n - Have multiple root servers (currently, there are 13), and make each of these root servers a network of physical servers around the world. (For example, the E root has over 300 servers with the same IP address using anycast)\n - Caching: Increases performance by reducing the number of requests/iterative queries being made. Caches can be introduced at any layer, including the host. \n\n## Example\n\nLet's say our local host wants to access the domain `ischool.berkeley.edu`.\n1. Our host will send a recursive query to the resolving name server (`cdns01.comcast.net`), asking for the A record for `ischool.b.e`.\n2. The resolving nameserver will check the cache, and if present, return the result.\n3. If cache entry not present, the resolving name server queries the root server requesting the A record for `ischool.b.e`.\n4. The root server sends back the DNS tuples `(NS, edu, k.edu-servers.net)`, and `(A, k.edu-servers.net, aaa.aaa.aaa.aaa)`.\n5. The resolving nameserver queries `k.edu-servers.net` requesting the A record for `ischool.b.e`.\n6. The TLD server sends back NS and A records for `berkeley.edu`.\n7. The resolving nameserver queries `adns1.berkeley.edu`.\n8. Berkeley's DNS server sends back the desired A record, along with a TTL.",
    "lastmodified": "2023-01-12T00:05:06.194215045Z",
    "tags": null
  },
  "/cs168/end-to-end-operation": {
    "title": "",
    "content": "\nSuppose we have the following scenario:\n - Host H1 boots up\n - Fetches small file from H5\n - Goes idle\n - Fetches two small files from H2\n![[/cs168/img/Pasted image 20221210190305.png]]\n\n\nHere's what will happen:\n1. DHCP to get configuration\n\t1. UDP Discover =\u003e broadcast \n\t2. UDP Offer from H4 \u003c- H1\n\t3. UDP Request =\u003e broadcast\n\t4. UDP ack \u003c- H1\n2. ARP for DNS server\n\t1. ARP request for H3 =\u003e broadcast\n\t2. H3 ARP response \u003c- unicast to H1\n3. Resolve H5\n\t1. UDP DNS request for H5.com =\u003e H3\n\t2. UDP DNS response \u003c- H1\n4. ARP for R1\n\t1. ARP request for R1 =\u003e broadcast\n\t2. ARP response from R1 \u003c- H1\n5. TCP connection to H5\n\t1. TCP SYN =\u003e H5\n\t2. TCP SYNACK \u003c- H1\n\t3.  TCP ACK =\u003e H5\n6. HTTP request to H5\n\t1. TCP HTTP GET =\u003e H5\n\t2. TCP ACK \u003c- H1\n\t3. HTTP response \u003c- H1\n\t4. ACK =\u003e H5\n\t5. (after download completes and connection becomes idle for a while) FIN =\u003e H5\n7. TCP disconnect from H5\n\t1. ACK \u003c- H1\n\t2. FIN \u003c- H1\n\t3. ACK =\u003e H5\nThe rest of the steps are extremely similar to the above.\n9. Resolve H2\n10. ARP for H2\n11. TCP to H2\n12. HTTP to H2\n13. HTTP to H2 (2)\n14. TCP disconnect from H\\2",
    "lastmodified": "2023-01-12T00:23:28.746773684Z",
    "tags": null
  },
  "/cs168/ethernet": {
    "title": "",
    "content": "\n## Shared Media\nIn a radio network, nodes use a shared medium (the electromagnetic spectrum). As such, transmissions from different nodes might collide with one another, so we need a **multiple access protocol** to allocate the medium between users.\n\nSome common approaches for doing this include:\n - Frequency Division Multiplexing: divide medium by frequency. This can be wasteful since frequencies are likely to be idle often.\n - Time Division Multiplexing: divide medium by time. Each sender gets a fixed time slot to send data. This has similar drawbacks to FDM.\n - Polling protocols: a turn-taking scheme where a coordinator gets to decide who gets to send data when (how Bluetooth works)\n - Token-passing: a turn-taking scheme where a virtual token is passed around, and only the holder can transmit\n - Random access: see [[#Pure ALOHA random access]]\n\n## ALOHAnet\nAdditive Links Online Hawaii Area: a first attempt at wireless connections across the Hawaiian islands (1968, Norman Abramson)\n\nIn ALOHAnet, a hub node transmitted its own frequency, and all remote nodes transmitted on the same frequency using a random access scheme.\n\n### Pure ALOHA random access\n1. If a remote has a packet, just send it.\n2. When the hub gets a packet, it sends an ack.\n\t- If two remote sites transmitted at the same time, a collision will occur and the hub will not send an ack\n3. If the remote doesn't get the expected ack, wait a random amount of time and resend.\n\n## Ethernet\nIn 1972, Bob Metcalfe was trying to connect hundreds of Xerox computers in the same building. It needed to be fast, maximially distributed, and cheap. \n\nThe main idea was to connect all of the machines onto the same cable, and use it as a shared medium.\n\n### Carrier Sense Multiple Access (CSMA)\nCSMA is an improvement over ALOHA: instead of nodes sending data first, CSMA nodes listen to the network first and start transmitting when it's quieter.\n\nBy itself, this doesn't completely avoid collisions due to propagation delay.\n\n### CSMA/CD\nMain idea: listen while you talk. If a node detects another packet being sent at the same time, stop sending since the packet has already collided. This is **collision detection** (CD).\n\nIn addition, use a randomized **binary exponential backoff**: if retransmit after collision also collides, wait twice as long; continue doubling for every collision.\n\n### Addresses and Service Types\nOn the ethernet shared medium, everyone will receive transmitted data. As such, ethernet has **flat addresses:** no routing or aggregation is required.\n\nAddresses are 48 bits (6 bytes) shown as six 2-digit hex numbers with colons. The general structure is:\n - 2 bits of flags\n - 22 bits identifying manufacturer (company/org)\n - 24 bits identifying device\nAddresses are typically permanently stored in network interface hardware, and are mostly unique (there are more devices than there are addresses). \n\nThe **broadcast address** is all ones (FF:FF:FF:FF:FF:FF). Data sent to this address are received by everyone. This allows trivial implementation of broadcast.\n\nMulticast (sending to all members within a group) is also trivially implemented by setting the first bit to 1.\n\nHowever, classic ethernet does not support anycast (single address being shared by multiple devices).\n\n\n### Switched Ethernet\nIn modern ethernet implementations, shared media is rarely used. Instead, switches exist between nodes that remove the possibility of collision. \n\nThe main idea of switched ethernet is to flood all packets, such that everyone gets it just like in classic ethernet.\n\n\n### Summary: MAC (L2) vs IP (L3)\n\nMAC addresses:\n - hard coded by device manufacturers\n - not aggregation friendly (\"flat\" addresses with no hierarchy)\n - topology independent: same even when host moves\n - main purpose: packet transfer within the same L2 network\n - require no network configuration\n\nIP addresses:\n - dynamically configured and assigned by network operators + DHCP\n - have hierarchical structure\n - topology dependent: depends on where host is attached\n - main purpose: packet transfer to destination subnet\n\nThe IP/MAC split solves the **bootstrap problem**, in which the fixed behavior of MAC makes a convenient first assignment that IP can build off of for assigning the first hop. \n\n## ARP\n**Address Resolution Protocol:** converts IP addresses to corresponding ethernet addresses.\n\nARP runs directly on top of **L2** (between L2 and L3, which is IP). In general, the host broadcasts a query asking who has a particular IP address. The desired host then responds via unicast with its ethernet address. \n\nHosts typically cache results in an ARP table (Neighbor table), which is refreshed occasionally.\n\n\n### Example\nSuppose we have the following network topology:\n![[/cs168/img/Pasted image 20221213130109.png|300]]\n\nIf H1 wants to send a packet to the IP address `10.0.0.2`:\n1. Check the prefix to see if it's on the same subnet. (it is)\n2. H1 broadcasts an ARP request to all hosts on the subnet.\n3. H2 answers H1's request with its MAC address (using unicast)\n4. H1 receives the answer, sends the packet, and caches the entry in its ARP table.\n\nIf H1 wants to send a packet to `10.1.0.3`:\n1. Check the prefix and see that the subnet is different. \n2. Since the subnet is different, broadcast an ARP request for the router (`10.0.0.254`) instead.\n3. R1 answers H1's request with its MAC address.\n4. H1 receives the answer, and sends the packet with destination IP `10.1.0.3`, but destination MAC of R1.\n\n\n\n## DHCP\nAlthough ethernet addresses are hard-coded into the hardware, IP addresses are adaptable depending on the context. Typically, the routers know what IP addresses to assign to hosts, but how do hosts know this?\n\nOne method is to manually assign static addresses to each host. However, portable devices like phones or laptops may move around multiple times a day, and needing to reassign them every time we move is very annoying!\n\nThe solution is **DHCP (Dynamic Host Configuration Protocol)**, which provides a way for hosts to query the network for local configuration information (IP address, netmask, default gateway, local DNS resolver).\n\nDHCP servers are added to the network, either as standalone or as a part of a router, which listen to UDP port 67.\n\nThe DHCP server leases IP addresses to hosts. If the lease is not renewed, the IP address will be returned to the pool and can be assigned to another host.\n\n### DHCP handshake\n![[/cs168/img/Pasted image 20221210183624.png]]\n\nNotes:\n - Discovery and request packets are **broadcast** by hosts, and have source IP 0.0.0.0, destination IP 255.255.255.255. This is because DHCP is built on IP, but no IP addresses are initially known.\n- The source MAC is the address of the router, and the destination MAC is the address of the next hop's router.\n\n\n",
    "lastmodified": "2023-01-12T00:23:36.198699179Z",
    "tags": null
  },
  "/cs168/final-review": {
    "title": "",
    "content": "\n## Part 1\n\nOriginal questions: [final review part 1](https://notes.bencuan.me/cs168/cs168_final_review_fa22.pdf)\n\n### 1.1\n**less aggressive** than normal TCP. \n\nAggressiveness is determined by the throughput. Higher throughput = more aggressive.\n\nThroughput can be calcuated by dividing the number of bytes over time (or, packets per RTT).\n\nIn a normal TCP implementation, the multiplier $M$ is $0.5$.\n\nAt full throughput (highest possible window size $W$ before loss occurs), the throughput is $W/RTT$. At minimum throughput during congestion avoidance (right after loss is detected), the throughput is $1/2 \\times W/RTT$Q. Therefore, the average throughput for typical TCP is $3/4 \\times W/RTT$.\n\nIn the modified case, $M=0.25$ so the average is $(0.25+1)/2 \\times W/RTT = 5/8\\times W/RTT$. Since the throughput is less than TCP, it's less aggressive.\n\nNote that the increase to the additive constant $A=2$ doesn't change average throughput, it only makes the frequency of the AIMD sawtooth cycle twice as fast.\n\n\n### 1.2\nSending an ACK once every two packets is **both reliable and TCP-compatible**, because of the in-order property of TCP. If the ACK sequence number is greater than that of the two previous packets, it will provide enough information to the recipient to consider both those packets as sent.\n\n### 2\nHere's the sketch of a TCP connection between your computer (H) and the Gradescope server (S):\n1. SYN from H -\u003e S\n2. SYN+ACK \u003c-\n3. ACK + HTTP request -\u003e\n4.  ACK + HTTP response \u003c-\n5. ACK + FIN -\u003e\n6. FIN + ACK \u003c-\n7. ACK -\u003e\n\n\n### 3\nStart with CWND=1 and SSTHRESH=50. All constants are in terms of numbers of MSS.\n![[/cs168/img/Pasted image 20221213144250.png]]\n\n1. 9 ACKs are receieved: CWND += 9, so it becomes 10. (slow start)\n2. 8 ACKs are received: CWND += 8, so it becomes 18. (slow start)\n3. A timeout occurs: SSTHRESH = CWND/2 = 9, and CWND gets reset to 1.\n4. 45 ACKS are received:\n\t1. Fast recovery until CWND = 10. (first 9 ACKs)\n\t2. Congestion avoidance:\n\t\t1. Next 10 ACKs increase CWND to 11\n\t\t2. Next 11 ACKs increase CWND to 12\n\t\t3. Next 12 ACKs increase CWND to 13\n\t\t4. Final 3 ACKs increase CWND to 13 3/13\n5. 10 ACKs are received: CWND = 14 (congestion avoidance)\n6. 9 dupACKs are recieved:\n\t1. Fast recovery after 3 dupACKs --\u003e CWND = $\\lfloor 14/2 \\rfloor + 3 = 10$, SSTHRESH = $\\lfloor$CWND$/2 \\rfloor = 7$ \n\t2. Remaining 6 dupACKs during fast recovery: CWND += 6 = 16\n7. 35 ACKs are received:\n\t1. Congestion avoidance begins at CWND=7\n\t2. Next 7 ACKS increase CWND to 8\n\t3. Next 8 ACKs increase CWND to 9\n\t4. Next 9 ACKs increase CWND to 10\n\t5. Final 10 ACKs increase CWND to 11\n8. Timeout occurs:\n\t1. CWND is reset to 1, SSTHRESH = floor(11/2) = 5\n9. 8 ACKs received:\n\t1. First 5 = fast recovery, increase CWND to 6\n\t2. Next 3 increase to 3/6 =\u003e CWND = 6 1/2\n10. 2 dupACKs received:\n\t1. nothing happens (3 required)\n11. 4 ACKs are received: \n\t1. Congestion avoidance: First 3 increase CWND to 7\n\t2. Final ACK increases CWND to 7 1/7\n\n\n### 4\nRecall that if the total available bandwidth is $C$ and each flow $i$ has a bandwidth demand $r_i$, then the fair allocation of bandwidth $a_i$ to each flow is calculated as$$a_i = min(f, r_i)$$ where $f$ is the flow's fair share, calculated by the following:\n - Get the average $C/N$ (where $N$ is the number of flows).\n - Subtract all of the $r_i$ from $C$ where $r_i \u003c N$. For each flow that this is done for, subtract one from $N$.\n - For all of the remaining flows, set $f = C/N$.\n\n#### 4.1\n1. Find $C/N = 15/4$.\n2. See that $r_A = 3$, which is less than $C/N$. So $a_A = 3$ and the new average is $12/3 = 4$.\n3. See that $r_B = 4 = C/N$, so $a_B = 4$ and the new average is $8/2 = 4$.\n4. See that $r_C = 5 \u003e C/N$, so give it $a_C = C/N = 4$ and the new average is $4/1 = 1$.\n5. Give the remaining 4Mbps to the last flow, so $a_D = 4$.\n\n#### 4.2\nThe process is equivalent to the one above. If the initial $C=17$, then $C/N = 5$ for flows C and D, so they each get 5Mbps instead of 4.\n\n#### 4.3\nBasically, we want to simulate fair queuing by dropping packets to match the desired bandwidth from 4.2.\n\nSince $a_i = r_i$ for A, B, and C, we want to use the same bandwidth so $p_i = 0$. \n\nFor flow D, we want $a_D \\times (1-p_D) = r_D$. Solve for $p_D$:\n$6 \\times (1-p_D) = 5$\n$1 - p_D = 5/6$ so $p_D = 1/6$ \n\n### 5\n![[/cs168/img/Pasted image 20221213145743.png]]\n\n#### 5.1\nIf $A_1$ wants to message $A_3$, it will need to broadcast an ARP request to all hosts in A-Net. So $A_2, A_3, R_A$ will all see the request.\n\n#### 5.2\nWhen $A_3$ responds, it is a unicast so only $A_1$ will know its MAC address.\n\n#### 5.3\nIf $B_1$ wants to message $A_3$, it will need to go through $R_B$ so it first needs to request $R_B$'s MAC address.\n\n#### 5.4\n$R_A$ will need to make an ARP request for $A_3$, since it doesn't know $A_3$'s MAC address yet.\n\n#### 5.5\nIf $A_3$ wants to message $B_2$, it will need $R_A$'s MAC address. However, since an ARP request was made from $R_A$ to $A_3$ already, the MAC is cached and does not need to be re-requested.\n\n#### 5.6\nAfter $B_2$ receives the packet, $R_B$ will have the MACs of $B_1$ and $B_2$ from the requests made in 5.3 and 5.5.\n\n#### 5.7\n$R_A$ will have $A_1$ cached from its broadcast from 5.1, and $A_3$ cached from the request made in 5.3.\n\n### 6\nRecall that DHCP has 4 parts:\n![[/cs168/img/Pasted image 20221210183624.png|300]]\n1. Discovery is broadcast (source 0.0.0.0 since no IP is known yet, and destination is 255.255.255.255 since DHCP server also is unknown)\n\t1. Client MAC is sent as source, with destination as FF:FF:FF:FF\n2. Offer is broadcast with source IP of the DHCP server, and destination IP 255.255.255.255 (since server doesn't know who requested it)\n3. Request is broadcast with source 0.0.0.0 and 255.255.255.255 to accept the offer\n\t1. Client MAC is sent as source, with destination of FF:FF:FF:FF (need to broadcast to all DHCP servers, to tell those not selected to reclaim the offered address)\n4. Acknowledge message is sent with DHCP server as source, and destination 255.255.255.255\n\t1. Contains IP address, subnet mask, default gateway IP, dns server IP, and lease time\n\t2. \n\n\n#### 6.1\nDiscovery and request packets have source 0.0.0.0 and destination 255.255.255.255, so the number of packets is $2H$.\n\n#### 6.2 and 6.3\nAll DHCP packets are broadcast, so none are unicast.\n\n#### 6.4\nOffers and Acks have a defined source IP, and destination 255.255.255.255.\n\nAssuming we have $D$ DHCP servers and $H$ hosts, each server will give an offer to each host (making $D \\times H$ offer packets), and each host will receive one ACK (making $H$ acks). So $DH + H$ total.\n\n#### 6.5\nAll discover and request packets contain their own source MAC, and have a destination of FF:FF:FF:FF. So $2H$ total.\n\n#### 6.6\nDHCP makes all broadcasts on the IP layer, so no ARP requests need to be sent.\n\n#### 6.7\nAll servers on the same L2 network will all receive the same number of DHCP packets, since all packets are broadcast. The numbers are as follows:\n - $H$ hosts each make 1 discovery packet\n - Each of $D$ servers responds to the hosts, making $HD$ offers\n - Each host sends a request, making $H$ requests total\n - Each host receives an ack, making $H$ acks total\n\n### 7\n![[/cs168/img/Pasted image 20221213151815.png]]\nAlice and Bob both want to access \"www.tumblr.com\".\n\n#### 7.1\nThe end goal is to receive an A or AAAA record that translates the domain name into an IP address.\n\n#### 7.2\nRoot servers will return both an NS record and A record, corresponding to the TLD server for .com.\n\n#### 7.3\nThe iterative process is as follows: (with edge weights for Alice)\n1. DNS client queries DNS server (1)\n2. Server queries root (3)\n3. Root returns records (3)\n4. Server queries TLD (2)\n5. TLD returns records (2)\n6. Server queries nameserver (1)\n7. Nameserver returns an A record (1)\n8. Server returns A record to client (1)\nSo 1+3+3+2+2+1+1+1 = 14 total.\n\nBob follows exactly the same process, but with different edge weights.\n\n#### 7.4\nIf Alice is in the US and Bob is in China, the Tumblr server is probably in the US because Bob's latency is higher than Alice's.\n\n#### 7.5\nAuthoritative DNS servers can use IP geolocation to redirect users to closer content servers, decreasing latency.\n\n\n\n## Part 2\n\n[final review part 2](https://notes.bencuan.me/cs168/cs168_final_review2_fa22.pdf)\n\n### True False\n1. F, telephone networks use circuit switching and the modern internet uses packet switching.\n2. F, transport layer is layer 4.\n3. F, the outermost header is the application headers (HTTP etc).\n4. T, the only increase/decrease mode that is fair is AIMD.\n5. F, UDP does provide checksums.\n6. F, HTTP runs over TCP, not UDP.\n7. T, DNS runs over UDP since it needs to be responsive.\n8. T, DHCP runs over UDP since it's broadcast.\n9. F, ARP runs on L2 so no UDP is used.\n10. T, ARP requests are broadcast.\n11. F, ARP responses are unicast.\n12. F, ACK packets can be combined with HTTP requests (which are payloads).\n13. F, MX is a mail record that redirects a domain to another domain's mail server.\n14. F, removing timers means TCP wouldn't be reliable in the case of timeouts.\n15. T, SDN allows additional control of networking within cloud providers; traditional networking relies on vendor code within hardware devices.\n16. T, OpenFlow gives access to the forwarding plane.\n17.  F, cellular networks store user state on the data plane to route packets to the correct carrier.\n18. F, Google's global WAN consists of many different interconnected regions and zones.\n\n\n### Short Answer\n1. Sending 1TB over a 1Gbps link would take 8000 seconds, or about 133 minutes. Driving 45 miles at 25mph would take 108 minutes, so it would be faster.\n2. Only TCP provides points 1, 2, and 4. Both provide multiplexing/demux capabilities.\n3. ECN is a protocol where routers notify hosts of congestion.\n4. HTTP is stateless so it uses cookies to store information across TCP sessions.\n5. OpenFlow, see the [[#SDN]] section.\n6. Initial DNS requests from hosts are sent to the local DNS server, which begins the iterative query process.\n7. DHCP is used to request the laptop's IP address. In the process, the laptop also learns the router's IP address. DNS is used to convert the domain to an IP. ARP is used to find the MAC address of the first router.\n8. Throughput for TCP is proportional to $\\frac{MSS}{RTT \\sqrt{p}}$. This proportion for Connection A is $\\frac{1000}{100 \\times 0.1} = 100$, and for B it is $\\frac{2000}{500 \\times .2} = 20$. So Connection A's throughput is 5 times that of Connection B.\n   \n\n### HTTP and TCP\n\n#### 3a.\n1. SYN sent\n2. SYN+ACK received, CWND=2\n3. ACK sent with HTTP GET\n4. HTTP response received\n\n2 RTT.\n\n\n#### 3b.\nNonpersistent connections require a new connection for every request, so one is needed for each of the 3 images.\n\nPersistent connections don't need any new connections.\n\n#### 3c.\nFrom 3a, it takes 2 RTT to download the index page.\nAfter the index page is downloaded:\n\nWe have three concurrent connections, one for each image. So we only need to consider the time to download one image.\n-   The first RTT will correspond to the SYN and SYN-ACK exchange\n-   In the second RTT, the client sends the request for the image to the server. The image size is 2 MSS but the server's congestion window is 1. So the server can only send one MSS over.\n-   In the third RTT, the client sends an ACK (for the first MSS) back to the server and only now can the server send the second MSS in the image. (Note that receiving the ACK also increases the server's CWND to 2 MSS -- which doesn't matter for this scenario but will if there was more data to send as in the case with the persistent connection)\n\nThe pipelined case is the same, but minus the first RTT for the exchange. \n\n### Detailed Sequence of Packets\n1.    ⇉ DHCP discover\n2.  ⇇ DHCP offer\n3.  ⇉ DHCP request\n4.  ⇇ DHCP ack\n5.  ⇉ ARP request for DNS IP (to ask about B and C IPs)\n6.  **← ARP response from DNS (3rd received)**\n7.  → DNS request for B IP\n8.  ← DNS response with B IP\n9.  ⇉ ARP request for B (in the same subnet, doesn't need to go to router)\n10.  ← ARP response from B\n11.  → TCP SYN to B\n12.  ← TCP SYN+ACK from B\n13.  → TCP ACK to B\n14.  **→ HTTP request to B (8th sent)**\n15.  ← ACK from B (to the request from A)\n16.  ← HTTP response from B\n17.  → ACK to B (for the HTTP response)\n18.  → TCP FIN to B\n19.  ← TCP ACK from B (to the FIN)\n20.  ← TCP FIN from B\n21.  → TCP ACK to B (to the FIN)\n22.  → DNS request for C IP\n23.  **← DNS response for C IP (11th received)**\n24.  ⇉ ARP for Router (since C is in another subnet, need routers MAC)\n25.  ← ARP response from Router\n26.  → TCP SYN to C\n27.  ← TCP SYN+ACK from C\n28.  **→ TCP ACK to C (15th sent)**\n29.  → HTTP request to C\n30.  ← TCP ACK from C (to the request from A)\n31.  ← HTTP response from C\n32.  → TCP ACK to C\n33.  → TCP FIN to C\n34.  ← TCP ACK from C\n35.  ← TCP FIN from C\n36.  → TCP ACK to C\n\n### SDN\nIn a Software-Defined Network, the **control program** expresses the operator’s intentions for network control by configuring the switches in the **abstract network view** , which is part of the API provided by the **virtualization layer** that is based on the **global network view** it receives from the **network operating system** , which in turn uses the **switch interface (OpenFlow)** to control the physical switches.\n\n![[/cs168/img/Pasted image 20221213172913.png|300]]",
    "lastmodified": "2023-01-12T00:49:27.458759904Z",
    "tags": null
  },
  "/cs168/interdomain-routing-bgp": {
    "title": "Interdomain Routing (BGP)",
    "content": "\nIn [[intradomain routing]], we primarily focused on processes for intradomain routing- where switches discover paths within their own networks.\n\nNow, we'll discuss **interdomain routing** between many autonomous systems.\n\n## Autonomous Systems (AS)\nAs a review, an autonomous system is a domain that represents a network under a single administrative control. Every AS is assigned a unique ASN by ICANN.\n\nA **stub AS** only sends and receives packets on behalf of its directly connected hosts. Some examples include companies and universities.\n\nOn the other hand, a **Transit AS** carries packets on behalf of other ASes. These can vary greatly in scale from global to regional, and may be organized hierarchically.\n\nThere are three basic kinds of relationships between ASes: customer (pays for usage), provider (is paid by others for usage), and peers (don't pay each other and are assumed to exchange roughly equal traffic).\n\n![[/cs168/img/Pasted image 20220928162353.png|300]]\n\nTier 1 ASes are at the top of the hierarchy:\n - typically span multiple continents\n - do not have providers\n - are peered with most other tier 1 ASes\n - examples: AT\u0026T, Verizon...\n\n## Goals for Interdomain Routing\nSimilarly to intradomain routing, we still want to be able to find valid routes (with no loops or dead ends), and optimize for least cost paths.\n\nIn addition, there are two main goals:\n - Scalability: must be feasible for use in the entire internet\n - Policy compliance: routes must reflect business goals of ASes\n\n\n### Scaling\nThe key to scaling is host [[addressing (ip)]]. Since IP addresses have hierarchical subnet support, instead of enumerating every single IP address, we can simply say something like \"all x.y.00/16 addresses are owned by Comcast\" and redirect all traffic within that subnet to Comcast.\n\nAdditionally, the hierarchical addressing structure allows for a further optimization of pointing to higher tier ASes, since each of them will know how to reach lower tier ASes.\n\nOne possible downside to hierarchical addressing is that we are not able to aggregate 'multi-homed' networks with more than one provider. \n\n### Policy\nSome ASes will have preferences on where to route their traffic, even if they may not be objectively optimal in terms of least cost.\n\nThere are two main principles for typical policies:\n1. ASes don't accept traffic unless they're getting paid: only carry traffic to customers, and only use peering links to send traffic between customers.\n2. Either make money or send money when sending traffc: only send to provider if no peers or customers are available. \n\nAlso, ASes want autonomy and privacy: the ability to choose their own policies, and to not explicitly announce their policy choices to others.\n\nPolicy controls how routes are imported and exported.\n - **Import (selection)**: choosing which path to use\n\t - controls how traffic leaves the network\n - **Export:** which path to advertise\n\t - controls how traffic enters the network (what traffic this AS carries)\n\n\n\n\n# BGP\n![[07 Networking#BGP]]\n\nEssentially, BGP is very similar to Distance-Vector with some key differences:\n - BGP aggregates destinations using hierarchical addressing.\n - BGP does not pick the shortest path routes. Instead, it chooses the route based on policy.\n - Rather than doing distance-vector routing, BGP is **path-routing**: rather than advertising distance, advertise the entire path.\n\t - This allows for easier loop detection: if an advertised path includes the current AS, it will discard it.\n - Sometimes, for policy reasons, an AS may choose not to advertise a route to a destination.\n\n\n### BGP Sessions\nThere are several gateway protocol session types:\n - **eBGP** (external) sessions are between border routers in **different ASes**. Routers learn about external routes, and exchange routes to different destination prefixes.\n\t - Only border routers need to speak eBGP.\n - **iBGP** (internal) sessions are within the **same AS**. Routers learn which border routers to use, and distribute externally learned routes internally.\n\t - Commonly in practice, route reflectors are run for iBGP: essentially they are dedicated machines for each domain that handle all iBGP connections between them. So rather than having all routers map to each other, they just point to the route reflector.\n - IGP for intradomain routing (see [[intradomain routing]])\n\nEach router has two routing tables: nextHops for internal destinations (IGP), and egress routers for external destinations (iBGP).\n\n\n### BGP Messages\n**Basic BGP messages:**\n - Open: establish BGP session\n - Notification: report unusual conditions\n - Update: informs neighbors of new routes (announcements) or inactive routes (withdrawal)\n\t - Basic format: maps IP to route attributes (parameters used during route selection)\n\t - Local attributes: kept private\n\t - Public attributes: shared with other routers\n\n**Attributes:**\n - ASPATH: path vector that lists all ASes a route advertisement has traversed in reverse order. Carried in route advertisements\n - LOCAL_PREF: used to choose between different AS paths\n\t - only carried in iBGP messages since ASes don't want to publicize their preferences\n - MED: Multi-Exit Discriminator\n\t - used when ASes have multiple links between one another\n\t - lower MED = better\n\t - set by announcing AS\n - IGP Cost: \"hot potato\" routing- minimize cost of traversing internal network to border router\n\t - may conflict with MED\n\nRoute selection in priority order\n1. Pick highest LOCAL_PREF\n2. Pick shortest ASPATH\n3. Pick lowest IGP cost to next hop\n4. Pick lowest MED (other router preferences)\n5. Tie break by router ID\n\n\n\n### Issues with BGP\n - Security: no guarantee that AS owns advertised prefixes, or that it will follow the advertised path (prefix hijacking)\n - Performance: policy-based, not cost-based (so advertised path length can be misleading)\n - Configuration: BGP misconfiguration is a major source of internet outages\n - Reachability and convergence not guaranteed if Gao-Rexford not followed\n\n## Gao-Rexford Rules\nGao-Rexford rules describe common practice in import/export policies:\n - When importing (selecting) a route to a destination, customer \u003e peer \u003e provider.\n\t - ASes may use additional rules for tiebreaking\n - When exporting routes:\n\t - if route advertised by customer, export route to everyone.\n\t\t - paths go in any direction in tree\n\t - if route advertised by peers or providers, only export route to customers.\n\t\t - paths point downward in tree\n\nIf all ASes follow G-R rules, the following guarantees are made in the steady state:\n - routes are \"valley free\": TODO\n - reachability: any two ASes can communicate\n - convergence: all routers agree on paths\n\nAssume that:\n - customer-provider relationships are acyclic\n - tier 1 ASes are at the top and all peer with one another\n\n### Policy Oscillation\nIf we don't follow Gao-Rexford rules, ",
    "lastmodified": "2023-01-12T00:47:36.927907108Z",
    "tags": null
  },
  "/cs168/internet-organization-and-layers": {
    "title": "Internet Organization",
    "content": "\n\nCurrently, five internet layers exist:\n - Application (L7), where code interfaces with the internet as an abstraction,\n - Transport (L4), which can guarantee either reliable or unreliable data delivery,\n - Network (L3), which delivers best-effort global packet delivery,\n - Datalink (L2), which delivers best-effort local packet delivery,\n - Physical (L1), which physically moves bits between locations.\n\nHIstorically, L5 (Session layer) and L6 (Presentation layer) existed, but have since been combined with L7 and L4.\n\n\n### Local vs. Global Packet Delivery\nThere are many different types of links (ethernet, fiber, wifi...) that connect switches together. \nHowever, each type of link only knows how to manage its own network; ethernet packets can't get transferred into wifi on their own.\n\nThis is the main difference between local (single network) and global (multi network) delivery, which is managed between L2 and L3.\n\n\n## What is a protocol?\nCommunication throughout the internet is standardized into **protocols**, which are agreements between parties on how to communicate.\n\nProtocols include both the syntax (how the data is formatted) and the semantics (how the data corresponds to states). They exist at many levels:\n![[/cs168/img/Pasted image 20220907173818.png]]\n\nThe primary benefit of having so many layers is abstraction- each layer only needs to deal with its specific assignment, and assume that all lower layers carry out their assignments.\n\nAll layers need to be implemented on the end-host, in order to convert bits into application data. \n![[/cs168/img/Pasted image 20220907174540.png|500]]\n\nHowever, only L3 and below are supported by the network because the network does not support reliable delivery.\n - More specifically, switches implemented L1 and L2, and routers implemented L1, L2, and L3.\n\nBelow is an example of a protocol diagram:\n![[/cs168/img/Pasted image 20220907182007.png]]\nNotice that the datalink layers (ethernet, OTN) never communicate directly between each other; they send their information up to the IP network layer to be translated.\n\n## End to End Principle\nA guiding principle for modern internet architecture is the **end to end principle**, which states that the end-hosts should be responsible for guaranteeing security and reliability without needing to rely on anything within the network.\n\nThis is because the network cannot be guaranteed to be 100% reliable (equipment breaks down, etc), and end-to-end checks for reliability are required anyways so might as well make them robust.",
    "lastmodified": "2023-01-12T00:24:05.946401323Z",
    "tags": null
  },
  "/cs168/intradomain-routing": {
    "title": "Introduction to Routing",
    "content": "\n## Addressing and Naming\n\nIn the real world, people have names and are located at addresses. When we move around, our name stays the same, but our address changes.\n\nThe internet works in a very similar manner. Hosts have a **network name** (which describes which host it is) and a **network address** (where the host is currently located).\n\n## Conceptual Intro to Routing\n - First, we'll run a distributed routing algorithm between switches and routers. This algorithm will help us gather information about the network, and compute paths between its topology.\n- Within each router, the algorithm will store forwarding information to send packets to different links based on their destination. This is known as the **forwarding table**.\n\nThe distinction between *creating* the forwarding table and *using* the forwarding table is captured in the **control plane** and **data plane**.\n* There is also a third plane, the **management plane**, which allows the router to interact with humans and external systems to configure and monitor the device.\n\nThe control plane is the mechanism using to compute the forwarding table.\n - Inherently global (must know topology)\n - Contains routing algorithm\n - Relatively infrequent time scale (per network event)\n - Primary challenge: compute routes at scale while accounting for network failure and the autonomy of ISPs\n\nThe data plane uses the table to forward packets.\n - Inherently local (only depends on arriving packet and local table)\n - Contains forwarding algorithm\n - Relatively frequent time scale (per packet arrival)\n - Primary challenge: perform routing operations at a nanosecond time scale\n\n\n### Forwarding vs Routing: Summary\n**Forwarding** is the process of looking up a packet's destination in a routing table and sending the packet to the correct neighbor. Forwarding is inherently *local* and operates on the *data plane*.\n\n**Routing** is the process of routers communicating with other routers to determine how to populate forwarding tables. Routing is inherently *global* and operates on the *control plane*.\n\n\n# Destination-Based Forwarding\n\n## Forwarding Tables\n\nFor the data plane work, each router needs to store information about how to reach a destination.\n\nA simple way of doing this is **destination-based forwarding:** the decision of where to route packets to depends only on its destination.\n\n## Routing Graph Representation\nWe can graph paths that a packet will take to one particular destination within the network.\n - Each routing table contributes directed connections from its host router to the next hop in the table.\n - Each node/router should have exactly one arrow to another node.\n - Once two paths join at a router, they will never split again.\n - The set of all paths creates a **directed delivery tree** that covers every node that is able to reach the destination. This is a type of oriented spanning tree where the root is the destination node.\n\n## Routing State Validity\nThe minimum requirement for a \"good\" routing state should be that the destination is reachable.\n\nA global routing state is *valid* if it produces forwarding decision that always deliver packets to their destinations. \n\n**Validity is achieved if and only if for each destination, there are no dead ends or cycles.** \n\nThe goal of routing procols is to compute a valid state. \n\n### Validation\nNow that we have a condition for validity, how do we actually check that it's true?\n - First, select a single destination.\n - For each router, mark the outgoing edge with an arrow. There should only be one per router if using destination-based routing.\n - Eliminate all links that were not marked.\n - The state is now valid if and only if the remaining graph is a directed delivery tree (acyclic, with every arrow pointing towards the destination).\n - Repeat this process for every destination.\n\n\n## Types of Routers\nThe internet is a network of networks, and not all of these networks may use the same protocol. This is primarily because each network has a different use case, which have different requirements (size, number of hosts, bandwidth, cost...)\n\n**Intradomain Routing::** also known as Autonomous System: routing within a single network\n - Usually use IGPs (Interior Gateway Protocols)\n - Each network can choose their own protocol\n \n**Interdomain Routing:** routing between different networks (autonomous systems)\n - EGPs (Exterior Gateway Protocols)\n - All AS's agree on a protocol\n - Internet has used BGP for a long time\n\n# Intradomain Routing (L2/L3)\n## Least-Cost Routing\nHow do we quantify how \"good\" a route is exactly?\n\n1. Route needs to work: destination needs to be reachable (no loops or dead ends)\n2. Minimize cost: number of hops, price, progagation delay, distance, reliability\n\t1. Cost can be abstracted into some general value/weight for each edge\n\nCosts are usually configured/determined based on routers and their links. \n\nLeast-costs:\n - avoid loops (since loop = infinite cost)\n - are destination-based (all costs depend on destination only)\n - form a spanning tree\n\n### Trivial Routes\nRoutes that are unimportant and can be ignored:\n - Route from router to itself (loopback)\n - Route away from router with only one neighbor (default route)\n\t - Default routes sometimes exist when there's multiple routes, but one is always preferred (wifi vs cellular)\n\n### Static Routes\n - Manually entered in by an operator\n - Typically used when operator has specific need (hosts don't usually participate in routing procols) \n\n\n## Distance-Vector Routing Protocols\n\nD-V routing protocols are very similar to the Bellman-Ford shortest path algorithm.\n[[/cs70/discrete-math/graphs#Bellman Ford Shortest Paths with Negative Edge Lengths|CS70 Notes on Graphs]]\n\nHowever, Distance-Vector routing is asynchronous and has incomplete state, since each router can collect information simultaneously but only knows about its own local state. This differs from the traditional version of Bellman-Ford, which is serial (only one calculation at one time, and the entire state is known).\n\nThe basic table update algorithm for D-V is as follows:\n - Neighbors advertise a route with a particular distance/cost to a particular destination\n\t - *do not* advertise to neighbor whos entry is in the nextHop table (avoid split horizon problem)\n - Router adds 1 to advertised distance and saves it in the nextHop table, along with the address of the neighbor that advertised it\n - If a neighbor gives a lower number than the current nextHop, it replaces the previous entry\n\t - Exception: any cost given by current best neighbor will overwrite the entry, even if it's larger\n\t - Exception to exception: stop counting at some maximum value to avoid counting to infinity when a loop exists\n - Direct routes need to be manually populated to initialize cost\n\n\n### Failures in D-V\n\n**What happens when the network is unreliable?** \nSometimes, packets get dropped. An easy solution is to continuously advertise to all neighbors at a certain interval. (This differs from triggered updates- only sending on change. Choosing between the two is a tradeoff of reliability vs efficiency.)\n - Can also combine this with triggers to be most responsive: when table changes, when link becomes available, when link fails\n\nThe order in which packets arrive can also be nondeterministic.\n\n**What happens when a link between two routers fail completely?**\nWe can add a new field to the routing table, **Time To Live (TTL).** Table entries will only be valid until that TTL expires. Then, when a link goes down, the time will run out and the entry will be deleted, so it can then be  replaced by the next best neighbor.\n - Most effective: set TTL to some multiple of the advertisement interval to guarantee that routes have at least a few tries before timing out\n - If a route does go down and the TTL expires, we can **poison** that route by setting its cost to $\\infty$. So instead of not advertising a route, we actively advertise that the router doesn't have a route. This makes the information propagate faster than waiting for timeouts.\n\n**How can we deal with the split horizon problem?**\n - Recall that the split horizon problem occurs when the optimal route expires/dies, and an unrelated route advertises a path away from the actual destination \n - Solution: **Poison reverse**: if a router advertises a loop, set that value to $\\infty$ so the next advertisement is immediately accepted  \n\n\n## Link-State Routing\n - Very common IGP\n - Major examples include IS-IS (intermediate system to intermediate system) and OSPF (open shortest path first)\n - Main principle: if a router had a global view of the network, it could easily compute the path to any destination.\n\t - Every router builds a full graph of the network and finds paths from itself to every destination on the graph \n\t\t - Can use traditional shortest paths algorithms like Dijkstras\n\t - Populate forwarding table with next hop: only works if all other routers agree on what the best path is\n\n\n### How does this compare to distance-vector?\nD-V is distributed globally (all nodes do it), but using local data.\nLink-State is computed **locally using global data**.\n - Global data includes the state of every link in the network (if it exists, if it's up, and how much it costs)\n\n### Sharing info globally\nThe hardest part of link-state is getting the global state itself. \nTo do this, every router needs to:\n - find out who its neighbors are (exchanges hello messages)\n - tell everyone about neighbors (use **flooding**: when local information changes upon receiving info from a neighbor, send to all other neighbors)\n - Tell everyone about adjacent destinations\n\n\n\n### Link State Flooding\nSome issues with the brute-force flooding idea:\n - Doesn't scale well with huge networks\n - Since packets are duplicated, the number of packets sent grows exponentially if the branching factor is greater than 1\n  - Packets can be dropped on unreliable networks\n  - Can't guarantee that individual routers will agree on best paths (see convergence section)\n\nSome solutions:\n - Each router stores a sequence number, and puts it into their packets. If the info packet has a lower sequence number than the current revision, it's already been seen and is ignored. If it's greater, remember the sequence number and send the flood update to neighbors. \n - Periodically resend floods to guarantee reliability\n\n\n### Link State Convergence\nSome calculations in link-state management take time, and in that time the state can change, causing divergence between routers.\n\nFailure not detected: packets are sent to a dead link\nFailure detected but not recomputed: can create dead ends\nFailure detected but not globally notified: can create loops\nState changes: packets in transit can get stuck if their destination link goes down\n\n\n## Spanning Tree Protocol\n\n### Learning Switches\n  - Unlike Distance-Vector and Link-State protocols, which have static local table states, tables are filled in opportunistically using data packets.\n\t  - This means that instead of dropping packets to unknown destinations, send the packet to all possible destinations (i.e. flood it). \n\t\t  - Also flood when the recorded nextHop is the same as the message's sender (avoid loops).\n\t  - Static routes also need to be learned, so on the initial send typically all of the routers will need to be pinged.\n\t  - Eventually, one of the packets will reach the destination, and information can then be sent backwards so that all routers in the path can learn about the host.\n - Doesn't work when network has loops\n\n### From Learning Switches to Spanning Tree\nIn order to address the issue that learning switches don't work when the network has cycles, we can use the **spanning tree protocol:** the main idea being that we disable routes until we create a spanning tree of the entire network.\n\nSTP is only used in local (layer 2) networks, where bandwidth is generally not a concern and the number of nodes is relatively small, allowing for packet flooding.\n\nSince flooding can find hosts, no static routes are needed anymore.\n\n**Step 1: find least cost paths from every switch to the root**\n\nIntroduction:\n - This is basically the Distance-Vector protocol with a single table entry where that entry is the destination, or the switch at the root of the tree.\n - Every switch has a unique orderable ID.\n - Our goal is to first find the root (lowest ID), then find the best path to the root (lowest cost).\nAlgorithm:\n - All switches begin by thinking they are the root.\n - On receiving a route message from a neighbor:\n\t - If the the advertised root is smaller, use it instead.\n\t - If it's larger, ignore it.\n\t - If it is the same as stored, use normal D-V update rules to minimize the distance, breaking ties by preferring the next hop with the smallest ID.\n - Only the root and switches that think they are the root will generate periodic advertisements. All other switches will forward advertisements when received.\n\n**Step 2: disable data delivery on every link not on a shortest path to root**\n - Each switch:\n\t - Enables the link along the best path to root\n\t - Enable all links to hosts (anything that is not a switch, i.e. have not sent any advertisements)\n\t - Disables every other link\n\n**Step 3:** when a link on the tree fails, start over\n - If a route expires, routers think they are the root again",
    "lastmodified": "2023-01-12T00:38:16.293713458Z",
    "tags": null
  },
  "/cs168/intro-to-the-internet": {
    "title": "",
    "content": "\n## About this Class\n\nThere are two meanings of internet:\n - the infrastructure that connects computing devices,\n - or the ecosystem of applications built on that infrastructure.\n\nWhen the average person says \"internet\" they usually refer to the second definition. This class, on the other hand, explores the first.\n\n**Why study the internet?** It's one of the most impactful and life-changing inventions in human history. In addition, it's too large and complex for theoretical models and requires an **entirely new design paradigm** of:\n - Decentralized control\n - best-effort service model (no guarantee or notification of data delivery)\n - route around trouble\n - dumb infrastructure, smart endpoints\n - end-to-end design\n - layering\n\n\n## About the Internet: a high-level overview\nAt a very high level, the Internet is composed of three main types of components:\n - **End hosts**, like phones, computers, and IoT devices, send and receive packets as a first or last destination.\n - **Switches**, which are often routers, manage the connections between end hosts and forward packets arriving on one link to another link.\n - **Links** connect switches and end hosts together. These could be one of many technologies like fiber cables, WiFi, or phone lines.\n\n\n### Some more definitions\n**ISPs** (internet service providers) operate independently from one another and each manage a small portion of the available internet. Oftentimes, the infrastructure within an ISP is abstracted away from the public, and can be treated as a singular component.\n\nSince ISPs are often competing and may not cooperate to create the optimal route for end users, network engineers must account for real-world and business considerations for any design.\n\n**Autonomous Systems** (AS) are groups of routers under the same control. ISPs consist of one or more AS.\n\n**Packets** are segments of bytes. Packets typically include:\n - A header (info for network to make decisions). Packet headers *must* contain the destination address.\n - A body (payload, and/or headers for other layers)\n - The header is meaningful to both the network and endpoint, whereas the body is only useful to the endpoint.\n\n**Flow** refers to a stream of packets exchanged between two endpoints.\n\n**Hostnames** are human-readable identifiers (like a domain, google.com).\n - Hostnames don't provide information about the location of a host. However, they can correspond to IP addresses that do.\n![[/cs168/img/Pasted image 20220826114154.png]]\n\n\n**The main job of the Internet is to transfer data between end hosts.** This is more difficult than it seems because there are many considerations:\n - What path do we take between hosts and switches?\n - Do the available paths have adequate bandwidth?\n - What protocols do we use? Can it handle every possible communication case?\n\n\n## Internet Problems to Solve\nIn order to keep the internet running, we need to answer the following questions:\n - How do we create a robust naming scheme for billions of end-hosts? (IP)\n - How do we address endhosts? (DNS)\n - How do we map names to addresses?\n - How do we compute forwarding tables? (routing control plane)\n - How do we forward packets? (routing data plane)\n\n",
    "lastmodified": "2023-01-12T00:24:16.938291093Z",
    "tags": null
  },
  "/cs168/measuring-link-performance": {
    "title": "",
    "content": "\n## Some values\nThe **Bandwidth** of a link is the number of bits sent/received per unit time (measured in bps, bits per second).\n\nThe **Propagation delay** of a link is the time it takes a bit to travel along the link (measured in seconds). It is analogous to the 'length' of the link.\n\n**Bandwidth-delay product (BDP)** is the product of bandwidth and propagation delay, measured in bits. It is analogous to the total capacity of a link (how many bits can be in the link at the same time).\n\n**Transmission delay** is equal to Packet Size / Link Bandwidth. It describes how long it will take before the entire packet has entered the link.\n\n**Queueing delay** describes the amount of time a packet exists in a router's queue when transient overload occurs.\n\n**Packet Delay** is equal to the sum of transmission delay, propagation delay, and queueing delay.\n\n**Router Capacity** is equal to the number of external ports multiplied by the speed of each port. \n * Example: a router with 4 100Mbps ports and 1 1Gbps port will have a total capacity of 0.4 + 1 = 1.4Gbps.\n![[/cs168/img/Pasted image 20220831185459.png]]",
    "lastmodified": "2023-01-12T00:24:19.642263964Z",
    "tags": null
  },
  "/cs168/reliability": {
    "title": "",
    "content": "\nIn general, the network is best-effort, meaning that packets are not guaranteed to be delivered successfully. How do we build reliability on top of an unreliable network?\n\n## Semantics of correct delivery\n\n1. At the network layer (L3 and below), delivery is **best-effort**. No guarantees can be made.\n2. At the transport layer (L4), delivery is **at-least-once**. Packets should reach the end host, but may be duplicated.\n3. At the application layer (L7), delivery is **exactly-once.** \n\nThe reliability goals of the transport and application layer are not guaranteed (since the underlying network can still fail)! However, reliability protocols must announce failures to the application, and never falsely claim a successful delivery.\n\n\n### Sending and receiving\n![[/cs168/img/Pasted image 20221017030035.png|500]]\n**One way delay** is the amount of time it takes for a packet to reach the reciever from the sender; **Round trip time** is the amount of time it takes for a packet to go both to and from the receiver.\n\nPackets can be duplicated in this example, where the acknowledgement message was lost and so the sender retransmitted the data:\n![[/cs168/img/Pasted image 20221017030246.png]]\n\nAn **ack** represents an acknowledgement of a successful receipt of a packet; a **nack** (negative ack) represents a failure message saying that the packet was corrupted.\n\n\n\n### Goals for reliable transfer\n\n**Correctness:** the destination receives every packet, uncorrupted, at least once\n**Timeliness:** data is transferred in a short period of time\n**Efficiency:** minimize use of bandwidth; avoid sending packets unnecessarily\n\nIn addition, we need to address all of the things that can happen to packets:\n - Lost packets -\u003e resend\n - Corrupted packets -\u003e send nack\n - Delayed packets -\u003e no issue due to at-least-once reliability\n - Duplicated packets -\u003e no issue due to at-least-once\n - Reordered packets -\u003e sequence numbers\n\n\n## Single packet case\n\n### Algorithm\nSender:\n - send packet\n - set timer (to some multiple of RTT)\n - if no ACK is received when the timer goes off, resend the packet and reset timer\n\n### Building Blocks\n - Checksums are used to detect corruption\n - Feedback is received in the form of acks/nacks\n - Retransmissions address lost packets\n - Timeouts let senders know when to resend packets\n\n## Multiple packet case\n\n### Stop and wait protocol\nUse the single packet solution repeatedly, and wait until the ack for packet $i$ is received before sending packet $i+1$.\n\nWhile this is correct, it is very slow and inefficient, with a max throughput of 1 packet per RTT. It is sometimes used when the RTT is very slow, such as internal communications between components in the same machine.\n\n### Flow Control\nBasic idea: the receiver tells the sender how much space it has left in an **advertised window** which is carried in the ACK. The sender will then adjust its window accordingly.\n\n### Window-based algorithms\nAllow multiple packets to be sent at the same time, and keep a window of packets in-flight with a maximum size of $W$. When an ack is received, remove that packet from the window, and allow the next one to be sent.\n\nThis achieves correctness and efficiency to some degree.\n\nThe value of $W$ should be picked to avoid overloading links (congestion control) and the receiver (flow control), while still taking advantage of the network capacity. In the ideal case where our network capacities our infinite, we should set $W$ to allow the sender to transmit packets for the entire RTT.\n - Let $B$ be the minimum link bandwidth, and $P$ be the packet size.\n - We want the sender to send at rate $B$ for the duration of the RTT to maximize efficiency.\n\t - In reality we don't usually want to use 100% of $B$ since the link is shared with other flows; the transport layer at the sender generally implements a congestion control algorithm to compute the desired bandwidth to use (congestion window). \n - Therefore, set $W$ such that $W \\times P \\sim RTT \\times B$.\n - To address congestion control and flow control, set $W$ to be the minimum of the above, the congestion control window, and the advertised window.\n\n### Full Information ACKs\nRather than sending one ack corresponding to each individual packet, full information ACKs send two things:\n - the highest number $n$ such that all packets with sequence number up to $n$ were delivered, and\n - any additional packets (could have skipped some numbers after $n$).\n\nFull information ACKs can get very long, so as a compromise we can just send a **cumulative ACK** with only the first of the two parts of the full information ACK. Cumulative acks tell senders how many packets to send, but not which ones to resend because they don't tell the sender exactly which packets were received. For example, if the ACK \"n \u003c= 4\" was sent 3 times, we know that a packet must have been lost, but it could have been any number greater than 4.\n\n![[/cs168/img/Pasted image 20221017032837.png]]\n\n\n### Go Back N\nUse window algorithm, but if an ack is not received, resend all $W$ packets in the window starting from the one that was lost.",
    "lastmodified": "2023-01-12T00:24:26.362196518Z",
    "tags": null
  },
  "/cs168/resource-sharing-packet-and-circuit-switching": {
    "title": "Resource Sharing",
    "content": "\n## Statistical Multiplexing\n\nOn the internet, millions of packets going to different destinations must share the same routers and paths. \n\nOne way to handle this demand is **statistical multiplexing**- the concept of combining demands to share resources efficiently, rather than statically partitioning resources.\n\nSome examples of statistical multiplexing:\n - processes sharing CPU cores (vs each process using 1 core)\n - Cloud computing (vs each user has their own datacenter)\n - public transit (vs each person drives a car)\n\n**The peak of aggregate demand is far less than the aggregate of peak demands.**\n - Don't design for the absolute worst case, since not every user will have peak usage at exactly the same time.\n\n## Two approaches to sharing\nThere are two main approaches to resource sharing, both of which enable statistical multiplexing.\n\n**Reservations:** end-hosts explicitly reserve bandwidth when needed.\n - Implemented via **circuit switching**:\n\t - 1. source sends reservation request to destination\n\t - 2. switches establish a circuit\n\t - 3. source sends data through circuit\n\t - 4. source sends a teardown message\n \n**Best effort:** just send packets and hope they reach the end destination\n - Implemented via **packet switching**\n\t - Each packet makes an independent decision about how to handle the packet\n\t - Switches add incoming packets to queue to handle **transient overload** (when incoming demand exceeds outgoing link bandwidth)\n\t\t - Eventually if the link is saturated for a long time, **persistent overload** will occur as the queue overflows and drops packets\n\n### Which method is better?\nCircuit switching is better for:\n - workloads with predictable/understandable behaviors and smooth, constant-rate demand\n - providing an intuitive abstraction for business models\n\nPacket switching is better for:\n - optimizing efficiency for amount of bandwidth used, especially for bursty workloads where peak load is reserved but rarely utilized fully\n - implementing a finer granularity of statistical multiplexing\n - Error recovery\n - Simpler implementation (no need for endhosts to manage each flow and keep track of requests)\n\n\n### Handling failures\n**Packet switching failure:**\n - Network must detect failure and recalculate routes on the routing control plane\n - Endhosts and individual flows may experience temporary loss of service, but no action is required on their part\n**Circuit switching failure:**\n - In addition to all steps for handling packet switching failure, endhosts must tear down old reservations and send a new reservation request for every impacted flow\n",
    "lastmodified": "2023-01-12T00:02:31.307891781Z",
    "tags": null
  },
  "/cs168/sockets-and-ports": {
    "title": "",
    "content": "\n## Network Ports\nSwitches and routers have **physical ports** where links connect to switches.\nThe OS supports **logical ports** where applications connect to the operating system's network stack.\n\n## Sockets\nA **socket** is an OS mechanism that creates and manages logical ports. When an app wants access to the network, a socket is opened and associated with a **port number**. All incoming packets to that port number are then sent to the socket it's associated with.\n\nSockets are an abstraction layer that allow processes in the OS to communicate over the network.\n - Includes `connect`, `listen`, `accept`, `send`, `recv` API calls\n - Clients initiate new connections to servers; servers listen, accept, and dispatch connections to many clients at once\n - Connections pipe data bidirectionally between a process on a client and a process on a host\n - Sockets are uniquely identified by IP:port combination; client port is usually randomly assigned, whereas server port is fixed and already known by the client.\n\nLogical ports are a part of the socket abstraction. Port numbers are included in the L3 packet header.",
    "lastmodified": "2023-01-12T00:03:01.871559878Z",
    "tags": null
  },
  "/cs168/web": {
    "title": "",
    "content": "\n## Origins\nIn 1989, Tim Berners-Lee set out to solve a problem: there was a lot of information being stored digitally, and no way to find or access much of it. He created \"Information Management: A Proposal\" in which the concept of the \"web\" was first established.\n\nThis proposal had several key parts:\n - not based on a hierarchy\n - allows remote access across networks\n - heterogeneity: different systems can access the same data\n - non-centralization: ability for existing systems to be linked together without a central control\n - access to existing data: ability to get data from existing databases to reduce overhead of adapting new system\n\n**Why was this so successful?**\n - Very flexible; didn't force any changes on existing data, systems, or networks\n - Many systems were built for networks in the first place\n - Integrated interface for scattered information\n - Practical solution to a specific problem\n - Early form of open-source software (free for anyone to use)\n - No over-specification: websites can be structured in many ways\n - No central authority or single underlying system: anyone can add their own systems easily\n - Ability to quickly navigate between different sources\n\n## Basics\n\n**What do we need to create the Web?**\n - A way to represent content with links: HTML\n - A client program to access content: web browsers\n - A way to reference content: URLs\n - A way to host content: servers\n - A protocol to transfer content between servers and clients: HTTP\n\n### URL Syntax\n\n**scheme://host:port/path/resource?query#fragment**\n - Scheme: protocol (https, ftp, smtp...)\n - Host: DNS hostname or IP address\n - Port: 80 for http, 443 for https\n - Path: traditional filesystem hierarchy\n - Resource: desired resource\n - Query: search terms\n - Fragment: subpart of a resource\n\n## HTTP\n*Note:* The following information refers to the HTTP 1.0 standard. HTTP 2 is also commonly supported(about 44% adoption), and HTTP 3 is upcoming (5%, mostly Google/Facebook), but they are significant departures in terms of implementation.\n\n**Main idea:**\n - Client-server architecture\n - Client connects to server via TCP on port 80\n - Stateless protocol\n\n### HTTP Request\n - Plaintext, separated with CRLF (CR = Carriage Return, ASCII 13, LF = Line Feed, ASCII 10)\n - Request Line: **Method Resource Protocol**\n\t - Method: GET, HEAD, POST...\n\t - Resource: what needs to be fetched\n\t - Protocol version: HTTP/1.1 or HTTP/1.0\n - Request Headers: provide additional information\n - Body: separated with a blank line; used for submitting data\n\n\n### HTTP Status\n - Status Line: **Protocol Status Reason**\n\t - Protocol: HTTP/1.1 or HTTP/1.0\n\t - Status: status code (200, etc)\n\t - Reason: human-readable message\n\n### HTTP Methods\n - GET: request to download (body on response only)\n - POST: send data from client to server (body often present in both request and response)\n - HEAD: same as GET except no body is needed in the response (used to check for existence)\n\n### Status Codes\n - 1xx: informational (not defined)\n - 2xx: successful\n\t - 200: OK\n - 3xx: redirection\n\t - 301: moved permanently\n\t - 304: not modified\n- 4xx: client error\n\t- 400: bad request\n\t- 401: unauthorized\n\t- 404: not found\n- 5xx: server error\n\t- 500: internal server error\n\n\n### Caching\nWeb caching takes advantage of temporal locality: if something is accessed, it'll probably be accessed soon. This is true because the most popular content is accessed far more frequently than non-popular content.\n\nCaching is implemented via two headers:\n - Cache-Control: max-age=(seconds) - 1.1\n - Expires: (absolute time of expiry) - 1.0\n\nWe can also specify the following to force skip caches:\n - Cache-Control: no-cache - 1.1\n - Pragma: no-cache - 1.0\n\nAdditional settings:\n - If-Modified-Since: (date)\n\t - If a resource has changed since date, respond with latest version. Otherwise, respond with 304 (not modified)\n\n![[/cs168/img/Pasted image 20221108140614.png]]\n\n\n**Proxy servers** make requests on behalf of clients. This creates an extra layer of caching that can server multiple clients more quickly.\n - Reverse proxies are caches close to the servers.\n - Forward proxies are caches close to the clients. (typically done by ISPs)\n\n### CDNs\nContent Delivery Networks provide caching and replication as a service.\nCDNs are large-scale distributed storage infrastructure that create new domain names for customers. The content provider then rewrites content to reference the new domains instead of the original ones.\n - typically aliased using CNAMEs to make domain names still human-readable\n**Pull:**\n - CDN acts like a cache\n - content provider gives CDN an origin URL\n - when a client requests it from CDN:\n\t - if cached, serve\n\t - if not cached, pull from origin\n - easier to implement (less work for content provider)\n\n**Push:**\n - Content provider uploads content to CDN, who serves it like a normal server\n - provides more control over content\n\n### HTTP Performance\nThe primary bottleneck is RTT, not transmission delay. Using standard TCP, downloading many small objects takes 2 RTTs per object, which adds up to a lot of time.\n\nSome optimizations can be made:\n - **Concurrent requests:** make many requests in parallel\n\t - need to share bandwidth between all concurrent requests\n - **Persistent connections:** maintain TCP connection across multiple requests\n\t - can be combined with concurrent requests\n\t - default for HTTP 1.1\n - **Pipelined connections:** send multiple requests all at once\n\t - can combine small requests into one large request\n\t - not used in practice, due to bugs and head-of-line blocking (remaining connections all need to wait for a slow connection in the middle)",
    "lastmodified": "2023-01-12T00:24:49.765961376Z",
    "tags": null
  },
  "/cs186/": {
    "title": "Welcome to CS186!",
    "content": "\n# Welcome to my CS186 Guide!\n\nThis is a **non-comprehensive** guide to databases written with an intention to supplement learning and reviewing of Berkeley's [CS186](https://cs186berkeley.net) material. Main topics include:\n\n* [SQL syntax](\u003ccs186/00 SQL Basics\u003e)\n* [How to improve popular sorting and hashing algorithms to work well with limited memory](\u003ccs186/04 Sorting and Hashing\u003e)\n* [B+ trees](\u003ccs186/02 B+ Trees\u003e) and other advanced indexing structures\n* [Join algorithms](\u003ccs186/05 Iterators and Joins\u003e)\n* [Query optimization](\u003ccs186/07 Query Optimization\u003e)\n* [Parallel query processing](\u003ccs186/09 Parallel Query Processing\u003e)\n* [Crash Recovery (AERIES)](\u003ccs186/10 Recovery\u003e)\n* [Database transactions and Concurrency](\u003ccs186/08 Transactions\u003e)\n* [Entity-Relationship Diagrams](\u003ccs186/12 ER Diagrams\u003e)\n\nI recognize that the course notes for 186 can be *very* dense sometimes, and don't cover 100% of the information you need to do well on projects and exams. While this also doesn't covery everything, I try to focus on content that the notes don't.\n\n**This isn't a replacement for lectures and other course content.** You probably need to look at those first, and come here if something isn't sticking!\n\n\u003e [!important] Please read this first!\n\u003e \n\u003e [What is an I/O and why should I care?](io)\n\n## Disclaimer\n\nAlthough I am a 186 TA, these notes are not official course content. They have not been reviewed or approved by an instructor, and there may be inaccurate or missing information. Please don't bother the other course staff with questions about the content here- contact me instead (email or office hours).\n\n## Concept Maps\n\n### Database Implementation\n![implementation](concept-implementation.png)\n\n### Database Design\n![design](concept-design.png)\n\n### ACID\n![acid](concept-acid.png)\n\n## Prerequisites\n\nCS 186 projects are done in Java. Knowledge of [CS61B](/cs61b) concepts are assumed. Specifically, you should understand:\n - OOP fundamentals such as classes, inheritance, and objects and implement them in Java\n - Binary trees, their runtime proprties, and implementation of efficient search and insert algorithms\n - Basic hashing and sorting algorithms\n - Use an IDE (preferably IntelliJ or VSCode) and its debugger to step through code and create breakpoints\n\nIn addition, knowledge from the last part of [CS61C](https://cs61c.org) is assumed and will be very useful for the first part of 186. This includes:\n - Knowing how computers store memory, the different types of memory (disk, RAM, cache), and why we have them\n - How data is stored on disk (files, pages, records)\n\nUnsure about prerequisite content? You can review my [CS61B notes](/cs61b) if needed. I'll cover the main points from 61C at the start of [Disks, Buffers, Files](cs186/01%20Disks,%20Buffers,%20Files.md).\n\n## How to contribute\n\nSee the [contributing guide](/contributing) for more details!\n\nTwo particular additions that need to be made are entries for Functional Dependencies and NoSQL. I don't have notes written for this since these topics were not covered when I took the course.\n\n\n\n",
    "lastmodified": "2023-01-12T23:23:07.911559093Z",
    "tags": null
  },
  "/cs186/00-SQL-Basics": {
    "title": "SQL Basics",
    "content": "## Relevant Materials\n - [Note 1](https://notes.bencuan.me/cs186/coursenotes/n01-SQLPart1.pdf)\n - [Note 2](https://notes.bencuan.me/cs186/coursenotes/n02-SQLPart2.pdf)\n - [Discussion 1](https://docs.google.com/presentation/d/1PZ7R8iKSm3gHUapi9l-WAlv_TWKQ-1VvAF98ZnEHW-o/edit)\n\n## What is SQL?\n\n**S**tructured **Q**uery **L**anguage (/ˈsiːkwəl/) is a highly standardized syntax for performing operations on a **database**.\n\n### Terminology\nSQL databases are a set of named **relations**, or tables, that describe the relationship between **attributes**. You can think of attributes as the columns of the table, and each record (also known as a **tuple**) being one row in the table.\n\nRelations are composed of:\n - A **schema**, which is the description of the table. Schemas are fixed, with unique attribute names and atomic types (integer, text, etc.).\n - The **instance**, which is the set of data that satisfy the schema. Instances can frequently change (whenever a row is added or updated), as long as any additions are consistent with the schema.\n\nAs an example for using this terminology: if we add a column to the table, we can say that \"we updated the schema of the relation to include an additional attribute\".\n\n### A note on looking up SQL things online\nThe SQL syntax and features we cover in this course are known as \"standard SQL\", whose specifications can be found [here](https://blog.ansi.org/2018/10/sql-standard-iso-iec-9075-2016-ansi-x3-135/). \n\nIn the wild, there are many implementations of SQL (like SQLite, MySQL, MariaDB), which may have an extended feature set or slightly different syntax. We will generally stay away from these extended features, and you do not need to know them for now.\n\nIf you're struggling to find relevant information, I would recommend prepending \"sqlite\" to the front of your search query (e.g. \"sqlite how to create a table\"). We use SQLite in Project 1, and for most things it's safe to assume that the syntax will be what we're looking for. Read more about SQL vs SQLite [here](https://cs186.gitbook.io/project/assignments/proj1/sql-vs-sqlite).\n\n### Running SQL queries\nYou will install sqlite3 in [Project 1](https://cs186.gitbook.io/project/assignments/proj1/getting-started). Once you've installed it, you can run `sqlite3` in your terminal to start an interactive session, or run `sqlite3 database.db` to read from a file named `database.db`.  Once in the session, you can also run `.read file.sql` to run queries written in the file `file.sql`, or run `.schema` to get schema information for the current database.\n\nIn a pinch, the [CS61A online interpreter](https://code.cs61a.org/) also works great, and has a built-in visualizer that's especially useful for exploring aggregation.\n\n### Pedagogy note\nDon't get too hung up on the syntax, or remembering how to use every small feature of SQL. The language itself is only a small part of this course- for most of our time, we'll discuss how to actually *implement* the features you use here.\n\nIf you anticipate needing SQL in future work, [here's a nice reference](https://www.w3schools.com/sql/sql_ref_keywords.asp) for common keywords and how to use them.\n\n## Keys                                                                                                \n\nWhen defining schemas, it's often important to be able to guarantee that rows are unique so that we can catch duplicate information. For example, if the school had a database of all enrolled students, we wouldn't want two students to have the same SID!\n\n### Primary Keys\n\nPrimary keys are unique, non-null, and can be used to identify an entry. Many times, adding `PRIMARY KEY (id)` during [table creation](#Create%20Table) is good enough.\n\nIn other cases, like the boat reservation tracking example in lecture, we would need more than one attribute (`PRIMARY KEY (sid, bid, day)`) to guarantee uniqueness, since a boat can be reserved many different times.\n\n### Foreign Keys\n\nForeign keys reference other tables' primary keys. Building onto the boat example, the boat ID would be the same as the ID’s in a table of boats, so we could add `FOREIGN KEY (bid) REFERENCES Boats` to the reserves table instead of copying everything over.\n\nThe main purpose of foreign keys is to maintain the uniqueness and non-null constraint of an attribute, since it *has* to match the primary key of another table.\n\nBelow is a screenshot from lecture that puts some code to the example.\n![lecture screenshot](SQL%20Basics/Untitled.png)\n\n## Writing Queries\n\nEnough with the long complicated words, let's write some SQL!\n\n### Create Table\nFirst, let's create a table:\n```sql\nCREATE TABLE clubs(\n\tname TEXT,\n\talias TEXT,\n\tmembers INTEGER,\n\tPRIMARY KEY (name)\n) AS\nSELECT \"Computer Science Mentors\", \"CSM\", 500 UNION\nSELECT \"Open Computing Facility\", \"OCF\", 50;\n```\n\n[Here's a good list of common data types that you can use.](https://www.digitalocean.com/community/tutorials/sql-data-types) For the purposes of this class we will mostly focus on INT, BOOLEAN, TEXT, CHAR(n), VARCHAR(n), and BYTE. More about what these do in the [next section](01%20Disks,%20Buffers,%20Files.md).\n\n### Insert Values\nThere's more clubs to add! Let's add one after the table has already been created:\n```sql\nINSERT INTO clubs VALUES\n\t(\"Eta Kappa Nu\", \"HKN\", 100),\n\t(\"Computer Science Association\", \"CSUA\", 200);\n```\n\n\n### Basic Querying\nBelow is the basic structure of a query:\n```sql\nSELECT name AS clubname\nFROM clubs\nWHERE members \u003e= 100 AND members \u003c= 300 \nORDER BY clubname\nLIMIT 3;\n```\nHere, we:\n - SELECT the column `name` FROM the table `clubs`, and rename it to `clubname`;\n - Keep only the clubs WHERE the number of members is between 100 and 300;\n - Sort the entries by name (ascending by default),\n - and keep only the top 3 entries (by alphabetical order).\n\n### Aggregation\nAggregation can seem tricky, but the core idea is simple: **crunch similar rows into one row, and keep one particularly interersting value.**\n\nThere are three parts to this:\n1. **GROUP BY:** Specify the column containing the similar values. All rows with the same value in this column will be combined into one row. \n2. **HAVING:** Specify how you want to filter (this is optional.) The syntax is basically the same as `WHERE`, except instead of a column name, we use an aggregate on a column name (such as `MAX(members)` or `COUNT(*)`).\n3. Modifications to **SELECT:** Ensure that all of the selected columns (except the one(s) passed into GROUP BY) are aggregates (MAX, MIN, COUNT, SUM...). \n\nIt's possible to GROUP BY multiple columns. This will group together every combination of values in those two columns. For example, if we did `GROUP BY name, alias`, and two clubs `Open Computing Facility` and `Original Cat Friends` had the same alias `OCF`, they would represent two separate groups.\n\n{{\u003c tabs \"qc\" \u003e}}\n{{\u003c tab \"Quick Check\" \u003e}}\nWhat is the difference between `WHERE` and `HAVING`? \n{{\u003c /tab \u003e}}\n{{\u003c tab \"Answer\" \u003e}}\nIn short, `WHERE` operates on individual rows, and `HAVING` operates on groups. \n\nWhenever you want to do something that requires the `GROUP BY` to have been done first, like filter by `MAX(members) \u003e 100`, it needs to be in the `HAVING` clause.\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n### Practice Problems\n\nStill unsure about querying and aggregation? [Here are some of my old 61A discussion slides](\u003chttps://notes.bencuan.me/cs186/coursenotes/61A%20Discussion%2012.pdf\u003e) that have some practice problems (back when we still taught SQL). All of the tables referenced are already preloaded for you in [code.cs61a.org](https://code.cs61a.org).\n\n\n## Logical Processing Order\n\nSQL Queries are typically processed in a different order than they're written. Here's the order- try to develop an intuition as to why this order would make more sense to a machine than how queries are usually written:\n\n1. `FROM` (find the table that is being referenced, join if needed)\n2. `WHERE` (filters out rows)\n3. `GROUP BY` (aggregate)\n4. `HAVING` (filters out groups)\n5. `SELECT` (choose columns)\n6. `ORDER BY` (sort)\n7. `LIMIT` (cut off the output)\n\nWhen writing queries, I often like to follow this order as well since each step builds on the previous one.\n\n### A note on aliasing\nOne consequence of Logical Processing Order is that **we cannot use aliases in WHERE, GROUP BY, or HAVING** because they are processed before any alias is defined in SELECT!\n\nFor example, `SELECT name as clubname WHERE clubname = 'Open Computing Facility'` is NOT a valid query in standard SQL.\n\nHowever, since ORDER BY and LIMIT come afterwards, we are allowed to use aliases there.\n\n\n## Joins\n![Untitled](SQL%20Basics/Untitled%201.png)\nIf we have two tables and need to access information from both in a query, we will need to join the two tables together!\n\nFor this section, we will use the following tables as examples:\n![](SQL%20Basics/Pasted%20image%2020230107122706.png)\n\n### Cartesian Product\nBy default, if a join (`SELECT ... FROM a, b...`) is done in SQL without specifying a type, a **cross product** (Cartesian product) is calculated. Every row in table `a` (the left table) is combined with every row in table `b` to create $R_a * R_b$ rows ($R_a$ = number of rows in table `a`). \n\nIn the example below, since `clubs` had $2$ rows and `members` had $4$ rows, we should expect the result to have $3 \\times 4 = 12$ rows. Note that most of these rows are pretty useless, since there is no correlation between the member and the club they were joined with.\n![|500](SQL%20Basics/Pasted%20image%2020230107122726.png)\n\n### Inner Join\n\nAn inner join takes only the rows in which a particular attribute (or list of attributes) can be found in both the left and right tables. \n\n- For example, an inner join on the `sid` attribute could be written out as `SELECT ... FROM a, b WHERE a.sid = b.sid`.\n- Inner join is the **default behavior** for the JOIN operation, which looks like this:\n    \n    ```sql\n    SELECT ...\n    FROM a INNER JOIN b\n    ON a.sid = b.sid\n    ...\n    ```\n\nIn the example below, we only keep the clubs CSM and OCF, and only keep the members that are in those two clubs:\n![](SQL%20Basics/Pasted%20image%2020230107122849.png)\n\n### Natural Join\n\nA `NATURAL JOIN` automatically inner joins tables on whichever attributes share the same name between the two tables.\n\nIf the columns `alias` and `club` were both named the same thing, then `SELECT ... FROM a NATURAL JOIN b ...` is completely equivalent to the example in the inner join section above. Otherwise, the NATURAL JOIN will return an empty table if no column names are shared (even if the contents are the same).\n\n### Outer Join\n\nLeft outer joins return all matched rows (as in an inner join), AND additionally preserves all unmatched rows from the left table. Any non-matching fields will be filled in with null values.\n![](SQL%20Basics/Pasted%20image%2020230107123046.png)\n\nA right outer join is the same as the left outer join, except it preserves unmatched rows from the right table instead. Flipping the table order on a left outer join creates an equivalent right outer join:\n![](SQL%20Basics/Pasted%20image%2020230107123142.png)\n\nA full outer join returns all rows, matched or unmatched, from the tables on both sides of the join clause. \n\n\n## Advanced Mechanics\n\n### String Comparisons\n\nUsing the `LIKE` operator, we can do the following:\n\n- Match any single character: `_`\n- Match zero, one. or multiple characters: `%`\n- Example: `WHERE name LIKE 'B_%'` will match all rows with a name starting with a B and are at least 2 characters long\n\n### Unions and Intersections\n\nThe `UNION` operator combines two queries (like an OR statement).\n\nThe `INTERSECT` operator combines two queries, and discards rows that do not appear in both (like an AND statement).\n\nThe `EXCEPT` operator subtracts one query’s results from another.\n\nUNION, INTERSECT, and EXCEPT operate using **set semantics** (distinct elements) and will keep only one of each unique element in the result.\n\nUsing UNION ALL, INTERSECT ALL, and EXCEPT ALL will manage **cardinalities** and will add or subtract the number of identical elements accordingly.\n\n- UNION ALL = sum of cardinalities\n- INTERSECT ALL = minimum of cardinalities\n- EXCEPT ALL = difference of cardinalities\n\n### Nested Queries\n\nThe  `IN` operator allows subqueries to be made. For example, we can `SELECT ... FROM ... WHERE id IN (SELECT .....)`\n\n- The `EXISTS` keyword can be used in place of `IN` to make **correlated subqueries** where the table in the subquery interacts with the outer query.\n- `ANY` and `ALL` can be used as well: `SELECT * FROM a WHERE a.value \u003e ANY (subquery...)` would only keep rows in `a` that are bigger than the smallest value in the subquery.\n- `ALL` can be used to compute an argmax: for example, if we want a sailor with the highest rating, we can `SELECT * FROM s WHERE s.rating \u003e= ALL(SELECT s2.rating FROM s s2)`\n\n### Views\n\nA view is a **named query.** It can be thought of as a temporary table that can be accessed in future queries to make development simpler.  Unlike tables, it is not computed immediately, and results are cached when they are needed.\n\n```sql\nCREATE VIEW name\nAS SELECT ...\n```\n\nA “view on the fly” can also be created using the `WITH` keyword:\n\n```sql\nWITH name(col1, col2) AS\n(SELECT ...), \nname2(col1, col2) AS (SELECT ...),\nSELECT ...\n```\n\n",
    "lastmodified": "2023-01-10T22:27:55.483147113Z",
    "tags": null
  },
  "/cs186/01-Disks-Buffers-Files": {
    "title": "Disks, Buffers, and Files",
    "content": "\n## Relevant Materials\n\n - [Note 3](https://notes.bencuan.me/cs186/coursenotes/n03-DisksFiles.pdf)\n - [Discussion 2](https://docs.google.com/presentation/d/10pKMJVZAA44ABJkIJXw9JhGd1nSQvvrf1qzEO770Ap8/edit#slide=id.g11049acc126_0_4)\n\n## Introduction\n\nNow that we've taken a look at how humans can interface with databases using [SQL](\u003c/cs186/00 SQL Basics\u003e), let's jump all the way down to the bottom and lay the foundations for how we can go from individual bytes to a fully functional database!\n\nBefore reading this section, review the page [What is an I/O and why should I care?](/cs186/io) To reiterate the most important points from this section,\n - An I/O occurs when a page is transferred between disk and memory (either read or written).\n - Pages are always fetched in whole: it is impossible to read/write half of a page to memory.\n - For the purposes of this class, a \"block\" and a \"page\" on disk are considered the same thing.\n\n\u003e [!summary] Summary\n\u003e \n\u003e  **Disks** are physical devices good at storing a huge amount of data.\u003cbr\u003e\n\u003e **Files** are stored on the disk and represent one table.\u003cbr\u003e\n\u003e **Databases** are collections of one or more tables.\u003cbr\u003e\n\u003e **Pages** are the basic building block of files. A file is generally made up of many pages.\u003cbr\u003e\n\u003e **Records** represent single rows in the table. Many records can be stored on the same page.\n\u003e \n\u003e When records from a database need to be accessed, they are copied from the disk to the **buffer** in memory one page at a time.\n\n## Devices\n\nHere's the hierarchy of physical memory devices that modern computers use. The main tradeoff is **price to speed:** the devices higher up on the chart (like the cache) allow for far faster accesses, but are much more expensive to produce per unit of data compared to slow devices (like hard drives).\n\n![Untitled](Disks,%20Buffers,%20Files/Untitled.png)\n\n\n### (Optional Context) The anatomy of a hard drive\n\n\u003e This section is taken from 61C. It's not required knowledge for 186, but it helps develop an intuition for what types of access patterns are faster than others on the disk. The main takeaway: disks are really slow.\n\nHard drives are magnetic disks that contain tracks of data around a cylinder. \nHDD's are generally good for sequential reading, but bad for random reads.\n\n![Untitled|400](Disks,%20Buffers,%20Files/Untitled%201.png)\n\n**Disk Latency = Queueing Time + Controller Time + Seek Time + Rotation Time + Transfer Time**\n- Queuing Time: amount of time it takes for the job to be taken off the OS queue\n- Controller Time: amount of time it takes for information to be sent to disk controller\n- Seek Time: amount of time it takes for the arm to position itself over the correct track\n- Rotation Time (rotational latency): amount of time it takes for the arm to rotate under the head (average is 1/2 a rotation)\n\n**Disk space management:**\n- provides an API to read and write pages to device\n- Organizes bytes on disk into pages\n- Provides locality for the ‘next’ sequential page\n- Abstracts filesystem and device details\n\n## Files\n\nA **Database file (DB FILE)** is a collection of pages, which each contain a colection of records. Databases can span multiple machines and files in the filesystem (we'll explore this idea more in [Distributed Transactions](\u003ccs186/11 Distributed Transactions.md\u003e).\n\nThere are two main types of files: **heap files**, which are **unordered**, and **sorted files**, in which records are sorted on a key. As you could imagine, sorted files add a significant amount of complexity in exchange for possibly faster runtimes. In general, **range selections and lookups are faster in sorted files, while insertions, deletions, and updates are faster in heap files.**\n\n### File Cost Analysis\n\nIn order to make efficient queries, we need a measure of how good or fast a query is. Knowing that queries operate on records, which are stored on pages in a file on disk, we can use the following cost model for analysis:\n- $B$ = number of data blocks (pages) in file\n- $R$ = number of records per page\n- $D$ = average time to read or write disk page (i.e. cost of one I/O)\n\nFor analysis, we will use the following assumptions:\n- We are mostly concerned about the **average** case.\n- The workload is **uniform random.**\n- Inserts and deletes operate on **single records.**\n- Equality selections will have **exactly one match.**\n- Heap files always **insert to the end of the file.**\n- Sorted files are always sorted according to search key.\n- Packed files are compacted after deletions.\n\nAs an exercise, think about what might happen to the runtime if we try to remove each of these assumptions.\n\n| Operation | Heap File | Sorted File | Explanation |\n| --- | --- | --- | --- |\n| Scan all records | $B*D$ | $B*D$ | Full scan = need to access every page in the file |\n| Equality Search | $B/2$ (average) | $\\log_2(B) * D$* | **Heap:** on average, need to go through half the file \u003cbr\u003e **Sorted**: Binary search runtime |\n| Range Search | $B*D$ | $(\\log_2B + P)*D$ | **Heap:** no guarantee on location of elements in desired range \u003cbr\u003e **Sorted:** binary search to find start of range; range is $P$ pages long |\n| Insertion | $2D$ | $(\\log_2B + B) * D$ | **Heap:** read last page, then write page \u003cbr\u003e **Sorted:** find location (binary search), then insert and shift rest of file |\n| Deletion | $(B/2 + 1) * D$ | $(\\log_2 B + B) * D$ | **Heap:** need to find page first, then write it back (hence the +1) \u003cbr\u003e **Sorted:** find location (binary search), then delete and shift rest of file  |\n\n### Heap File Implementation\nThere are two approaches to actually implementing heap files.\n\n#### Linked List\nThe first is the **linked list implementation**, where we have two linked lists: one of full data pages, and one of pages that still have free space. To insert a value into the file, we can ignore all of the full pages and just traverse the free pages, stopping at the first page that has enough free space to support the insertion.\n\n![ll](Disks,%20Buffers,%20Files/Pasted%20image%2020230107153137.png)\n\nYou can find a common problem relating to heap files in the [[#practice-problems|Practice Problems section]].\n\n\n#### Page Directory\nThe second type of heap file is a **page directory implementation.** Here, instead of a linked list of data pages, we'll store a linked list of header pages:\n![](Disks,%20Buffers,%20Files/Pasted%20image%2020230107153729.png)\nEach header page then contains a list of pointers to data pages, as well as a pointer to the next header page.\n\n\n\n### Sorted File Implementation\nDon't worry too much about this. We'll explore a better way of maintaining sorted order when we discuss index files in [B+ Trees](cs186/02%20B+%20Trees.md).\n\n## Records\n\n### Fixed vs. Variable Records\n**Fixed length records** have a constant, known length. An example is integers, which always have 4 bytes.\n- Field types are the same for all records, so just store the type information in memory. Variables can be accessed in the same location every time.\n\n**Variable length records** may change in size depending on the data that is stored. An example is text, which could be 0 or more characters long. Here's how we implement them:\n- Move all variable length fields to the end of the record:\n    ![Untitled](Disks,%20Buffers,%20Files/Untitled%204.png)\n- Create a header in the beginning to point to the end of variable length fields (compute beginning based on presence of other variables).\n\n### Data File Implementations\nSo, how do we actually store the records inside data pages?\n\nFirst, every data page needs a **page header**. This header includes metadata like free space, number of records, pointers, bitmaps, and a slot table for which parts of the file are empty.\n\nIf records are fixed length, we can pack them densely, which maximizes the amount of data we can store on each page.   \n    ![packed|300](Disks,%20Buffers,%20Files/Untitled%202.png)\n - We can easily append new records, but to delete, we would need to rearrange the records that come after the deleted record, which can get expensive.\n\nWe can also have **unpacked** fixed length records:\n\n![unpacked|300](Disks,%20Buffers,%20Files/Untitled%203.png)\n- To do this, we will:\n    - Keep a **bitmap** of free and empty slots in the header (one bit for each slot, rounded up to the nearest byte).\n    - To add, find an empty slot in the bitmap and mark it as filled.\n    - To delete, just flip the bitmap reference to 0. Don't worry about modifying the data itself, since it'll be overwritten eventually.\n\n For variable length records, we use **slotted page records**:\n-  Relocate the page header into the footer. (This will allow for the slot directory to be extended.)\n- In the footer, store pointers to free space containing the length and pointer to the next record.\n- This can be prone to fragmentation (will need to be addressed somehow).\n- This can also be used for fixed length records to handle null records\n\n### Calculating Record Size\n\nRecords consist of atomic values like ints and chars. Typically, records also include pointers (depending on implementation) as well as variable length records.\n\n![Untitled](Disks,%20Buffers,%20Files/Untitled%205.png)\n\nFor a standard record in a linked list, the following is required:\n- $N$ bytes for each variable, where $N$ is its size in the chart above\n- One 4-byte pointer in the header for every variable length record\n- If nullable, each **non-primary key** takes 1 bit in the bitmap. Make sure to round up to the nearest byte.\n- If using a slotted page implementation for variable length records, we’ll need 8 additional bytes in the header (free pointer, slot count) and 8 additional bytes in every record (record length, record pointer).\n\n**The maximum number of records that can be stored in a page is equal to the page size divided by the minimum record size, rounded down to the nearest integer.**\n\n- For slotted page, it would be the floor of (page size - 8 bytes) / (min record size + 8 bytes) due to the additional metadata needed.\n\nThe slot directory in a slotted page implementation has the following items:\n- slot count (4 bytes)\n- free space pointer (4 bytes)\n- (record pointer + record size) tuple for every record (8N bytes)\n\n## Practice Problems\n\n{{\u003c tabs \"q1\" \u003e}}\n{{\u003c tab \"Question 1\" \u003e}}\n\n![ll](Disks,%20Buffers,%20Files/Pasted%20image%2020230107153137.png)\n\nSuppose you have a linked list implementation illustrated in the image above (3 full pages, and 3 pages with free space). In the worst case, how many I/Os will it take to insert a record into a free page? Assume there is enough space in an existing page in the file.\n{{\u003c /tab \u003e}}\n{{\u003c tab \"Q1 Answer\" \u003e}}\n**5 I/Os.** Here's the walkthrough- each step incurs one I/O:\n1. Read the header page to find the pointer to the first free page.\n2. Read the first free page, and realize that it doesn't have enough space! Luckily, it has the pointer to the second free page in it.\n3. Read the second free page. The same thing occurs.\n4. Read the third free page. Due to the problem statement we can assume that our data will fit here! So we will update the third page to insert the new data.\n5. Write the updated page back to disk.\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n{{\u003c tabs \"q2\" \u003e}}\n{{\u003c tab \"Question 2\" \u003e}}\nSuppose you have 5 header pages, and each header page can store pointers to 30 data pages. What's the worst case I/O cost for inserting a record? *Do not* assume that an existing data page can hold the new data, but *do* assume that not all of the header pages are full.\n{{\u003c /tab \u003e}}\n{{\u003c tab \"Q2 Answer\" \u003e}}\n**7 I/Os.** In the worst case, all data pages are full, and all header pages are also full except for the very last one. So, the following must happen:\n - Incur 5 I/Os reading each of the 5 header pages. Since the page directory implementation stores metadata about whether data pages are full or not, we don't have to actually read in the data pages.\n - Create a new data page, and write it to disk, incurring 1 I/O.\n - Update the last header page with a pointer to the new page, incurring 1 I/O.\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n{{\u003c tabs \"q3\" \u003e}}\n{{\u003c tab \"Question 3\" \u003e}}\nSuppose we have the clubs table from the previous section:\n```sql\nCREATE TABLE clubs(\n\tname TEXT PRIMARY KEY,\n\talias TEXT,\n\tmembers INTEGER\n);\n```\n\nWhat is the maximum number of records that can fit on a 1 KiB (1024 byte) page, assuming all fields are not null?\n{{\u003c /tab \u003e}}\n{{\u003c tab \"Q3 Answer\" \u003e}}\n**50 records.**\n\nThe maximum number of records is achieved when each record is as small as possible. This occurs when both of the text variables have a length of 0. So the smallest record contains:\n - 4 byte pointer to `name`,\n - 4 byte pointer to `alias`,\n - 4 byte integer `members`.\n\nIn total, each minimum-size record is 12 bytes long. However, each record also requires a pointer and a record length value to be stored in the footer (4 bytes each), meaning each record effectively takes 20 bytes in the page.\n\nThe slot directory always contains the slot count and free space pointer (4+4 = 8 bytes), so let's subtract 8 bytes from 1024 to get 1016 bytes remaining for use for records.\n\nFinally, let's divide 1016 by 20 to get the number of records that can fit:\n$$\\lfloor 1016/20 \\rfloor = 50$$\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}",
    "lastmodified": "2023-01-10T22:32:25.580574957Z",
    "tags": null
  },
  "/cs186/02-B+-Trees": {
    "title": "B+ Trees",
    "content": "\n## Relevant Materials\n - [Note 4](https://notes.bencuan.me/cs186/coursenotes/n04-B+Trees.pdf)\n - [Discussion 3](https://docs.google.com/presentation/d/1sOlfZVFGWWl4xFW4X22L8uESvvb7SJYER8PEfRy1Wcg/edit): view this for B+ tree algorithm walkthroughs!\n\n## Introduction\nB+ Trees are one type of **index**: a data structure that allows for quick lookups based on a particular key. They are very similar to binary trees, but can have more than two pointers and come with a variety of improvements.\n\n### What is an index exactly?\nWe can index a collection on any **ordered** subset of columns.\n\nIn an ordered index (such as a B+ Tree), the keys are ordered **lexicographically** by the search key columns:\n- First, order by the 1st column.\n- If there are rows with identical values in the 1st column, sort them by the 2nd column.\n- Continue until all columns are processed.\n\n#### Composite Search Keys (optional context)\n\nUsing a **composite search key** is one way to create an index on multiple columns. The composite search key on a set of columns $(k_1, \\cdots, k_n)$ matches a query if:\n- the query is a conjunction of zero or more **equality clauses:**\n    - `k1 = v1 AND k2 = v2 .. k_m = v_m`\n- and at most 1 **range clause:**\n    - either $k_{m+1} \u003c v_{m+1}$ or $k_{m+1} \u003e v_{m+1}$\n\nIntuitively, a composite search key matches a continuous range of rows in the lexicographically sorted table.\n\n## The Representation\n\n![Untitled](B+%20Trees/Untitled.png)\n\nThere are two types of nodes in a B+ Tree.\n - **Inner nodes** make up all but the last layer of the tree, and store Key-Pointer pairs that reference more nodes.\n - **Leaf nodes** make up only the last layer of the tree, and store either records themselves or references to the records.\n\nYou can think about each node being data that is stored on one page. So, when we want to access data in a B+ tree, we'll have to incur one I/O for each node that we read or write. We can assume that the fan-out is small enough such that this will always be true.\n\nThe **height** of a tree $h$ is defined as the number of pointers it takes to get from the root node to a leaf node. For example, it would take 3 I/Os to access a leaf node for a height $2$ tree (read root node, read inner node, read leaf node).\n\nAll entries within each node are sorted. All B+ trees must follow the two invariants below to guarantee nice properties:\n\n### Key Invariant\nFor any value $x$ in an inner node, the subtree that its pointer references must only have values greater than or equal to $x$.\n\n### Occupancy Invariant\nThe **order** of the tree, $d$, is defined such that each interior node is at least partially full:\n$$d \\le E \\le 2d$$\nwhere $E$ is the number of entries in a node. In other words, every node must have at least $d$ entries and at most $2d$ entries.\n\nThe **fan-out** is equal to $2d+1$. (This is the max number of pointers in each node.) The amount of data a B+ tree can store grows exponentially based on the fan-out factor: $f^h$ where $f$ is the fanout and $h$ is the height of the tree.\n\nAt typical capacities (fan-out of 2144), at a height of 2 the tree can already store $2144^3 = 9855401984$ records!\n\n\n## Operations\n\n### Insertion\n\nB+ Tree insertion is guaranteed to maintain the occupancy invariant.\n\nFor the following steps, we will use the example of trying to insert the value $21$ into the tree below:\n\n![Untitled](B+%20Trees/Untitled%201.png)\n\n1. Find the leaf node where the value should go (using binary search):\n    \n    ![Untitled](B+%20Trees/Untitled%202.png)\n    \n2. If the leaf node now has more than $2d$ entries:\n    1. Split the leaf node into two leaf nodes $L_1$ and $L_2$ with $d$ and $d+1$ entries, respectively.\n    \n    ![Untitled](B+%20Trees/Untitled%203.png)\n    \n    b. **Copy** the first value of $L_2$ into the parent node and adjust pointers to include $L_1$ and $L_2$.\n    \n    ![Untitled](B+%20Trees/Untitled%204.png)\n    \n3. If the parent is now overflowed, then recurse and do the algorithm again. But this time, instead of copying the first value, we will **move** it instead (doesn’t stay in the original node).\n\n### Deletion\nIn practice, the occupancy invariant is often not strictly enforced. This is because rearranging the tree is less efficient than having a good-enough approximation. \n\nTherefore, for B+ Tree deletion, just identify the leaf node that contains the desired value to delete, and simply remove it. Nothing else needs to be done.\n\nThis is acceptable in practice because it is usually far more common to insert values into a B+ tree than it is to delete them, and insertions will restore the occupancy invariant quickly.\n\n## The Three Alternatives\nThere are three ways to implement B+ trees that we'll explore in this class. Note that in Project 2, we will create an Alternative 2 B+ tree implementation.\n\n### Alternative 1\nThe first alternative is to store records directly in the leaf nodes. This allows faster access to the data, but is very inflexible in the case that we want to build an index on another column (we'd have to copy over all the data to another B+ tree).\n\n### Alternative 2\nThe second alternative is to store pointers to data pages in the leaf nodes, which then store the records. This solves the inflexibility issue of Alt. 1, but will need to incur an additional I/O \n\n### Alternative 3\nThe third alternative stores a *list* of pointers to matching record locations in the leaf nodes. This allows us to use less data if storing many duplicate entries, but comes at the cost of additional complexity.\n\n### Clustered Indexes\n\n![Untitled](B+%20Trees/Untitled%205.png)\n\nIn a clustered index, data on disk is roughly sorted (clustered) with respect to an index. This benefits accesses using that index, but may hurt performance for other indices.\n- Clustering can only be done with Alt. 2 or 3 B+ trees. We'll often talk about a \"Alt. 2 unclustered B+ tree\" or something similar.\n- Clustered indexes are more expensive to maintain (since we need to periodically update the order of files and reorganize).\n- Clustered indexes also work best when heap files have extra unfilled space to accommodate inserts, resulting in a larger number of pages.\n\n\u003e [!important] I/O Rule for Clustered Indexes\n\u003e \n\u003e In unclustered indexes, it takes about **1 I/O per record** accessed from the B+ tree, since each record is assumed to be in a different page. In clustered indexes, it takes about **1 I/O per page of records**, since neighboring records are assumed to be on the same page.\n\n\n## Optimizations and Improvements\n\n### Bulk Loading\n\nB+ Tree operations are rather inefficient in that we currently always need to start searches from the root. In addition, there is poor cache utilization due to large amounts of random access.\n\nBulkloading a B+ tree creates a slightly different structure, but has some nice guarantees that allow it to be used when constructing new trees from scratch.\n\nIn bulk loading:\n1. Sort the data by a key.\n2. Fill leaf pages up to size $f$ (the **fill factor**).\n3. If the leaf page overflows, then use the insertion split algorithm from a normal B+ tree.\n4. Adjust pointers to reflect new nodes if needed.\n\n### Sibling Pointers\n\nTo aid in tree traversal, we can add previous and next pointers between the child nodes. When stored in sequential order, data nodes can be visited from other data nodes more quickly.\n\n## Practice Problems\n\n{{\u003c tabs \"q1\" \u003e}}\n{{\u003c tab \"Question 1\" \u003e}}\nWhat is the maximum number of data entries an Alternative 1 B+ tree with height $h$ and degree $d$ can hold?\n{{\u003c /tab \u003e}}\n{{\u003c tab \"Q1 Answer\" \u003e}}\n$$(2d) \\times (2d+1)^h$$\nA height $0$ tree would just have a single leaf node. We know that the leaf node can hold up to $2d$ entries, so this gives us a good starting point.\n\nNow, a height $1$ tree would have one root node pointing to $2d + 1$ leaf nodes (due to the fan-out property). Since each leaf node can still hold $2d$ entries, in total therer should be $(2d) \\times (2d + 1)$ entries.\n\nWe can see that this pattern continues- for every additional layer, we add $2d+1$ inner nodes, which each point to $2d+1$ lower nodes. So we need to keep multiplying the result by $2d+1$, yielding the formula above.\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n{{\u003c tabs \"q2\" \u003e}}\n{{\u003c tab \"Question 2a\" \u003e}}\nSuppose we have a Alternative 2 clustered index built on `members` with a height of 5.\nHow many I/Os on average would it take to run the query `SELECT * FROM clubs WHERE members \u003e 60`? Assume the following:\n - 20 leaf pages satisfy this predicate.\n - 100 records satisfy this predicate.\n - $d=4$.\n - Each leaf page has pointers to the previous and next leaf pages.\n - Each data page fits 25 records.\n{{\u003c /tab \u003e}}\n{{\u003c tab \"Q2a Answer\" \u003e}}\n**26 I/Os.**\n\nFirst, we need to find the leaf node corresponding to `members = 60`. It will take $2$ I/Os to find the leaf page, since the height is 2.\n\nOnce we find the first leaf page, we can continue reading the sibling pointers until we reach the end, so no further inner nodes need to be accessed. In total, we will incur $20$ I/Os reading leaf pages.\n\nSince the index is clustered, we can assume that on average, each page of records incurs 1 I/O. There are 100 records that satisfy the predicate, and each page fits 25 records, so it takes $4$ I/Os to read the data.\n\nIn total, $2 + 20 + 4 = 26$  I/Os.\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n{{\u003c tabs \"q2b\" \u003e}}\n{{\u003c tab \"Question 2b\" \u003e}}\nSuppose everything is the same as the previous problem, except that the index is now *unclustered*. How many I/Os will the query incur now?\n{{\u003c /tab \u003e}}\n{{\u003c tab \"Q2b Answer\" \u003e}}\n**122 I/Os.**\n\nIt will take the same number of I/Os to read the inner and leaf pages: 2 and 20 respectively.\n\nHowever, we now need to incur an average of 1 I/O *per record*, rather than per page of records, so it will take about 100 I/Os to read all of the records.\n\nIn total, $2 + 20 + 100 = 122$ I/Os.\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n",
    "lastmodified": "2023-01-10T22:29:52.594031959Z",
    "tags": null
  },
  "/cs186/03-Buffer-Management": {
    "title": "Buffer Management",
    "content": "\n## Introduction\nSo far, we've established the fact that the disk is slow, and memory is fast- and that one of the biggest challenges in database implementation is in minimizing the number of times we need to incur I/Os by transferring data in between disk and memory.\n\nSince memory is limited, we need to figure out a clever way to re-use information once it's read into memory, while still allowing new information to come in when needed. This way, we can minimize the number of times we need to read the disk in order to find something.\n\nThe system that does this is the **buffer manager.** It employs a **page replacement policy** to decide which pages to evict when the buffer is full and a new page is read from disk.\n\n## Relevant Materials\n - [Note 5](https://notes.bencuan.me/cs186/coursenotes/n05-BufferMgmt.pdf)\n - [Discussion 3](https://docs.google.com/presentation/d/1ZZxV_EziQJd47w3MNo72X4z8c7upX4KGiMqvuEI-vnM/edit#slide=id.g157c8825e69_0_0): view this for buffer management walkthroughs!\n\n## Page Replacement Policies\n\n### LRU\n**L**east **R**ecently **U**sed policy: evict the page that was least recently accessed. This makes intuitive sense because if a page hasn't been used in a long time, then it's likely we don't need it anymore!\n\n### Clock\nAlthough LRU seems pretty good, it can get quite inefficient since we need to keep track of the latest access time for every page in the buffer, and quickly find the oldest time (probably using some sort of heap).\n\nThankfully, we can approximate LRU with the Clock policy! Rather than strictly using the latest access time, we'll instead add a **reference bit** to each frame.\n\nSee [Discussion 4](https://docs.google.com/presentation/d/1ZZxV_EziQJd47w3MNo72X4z8c7upX4KGiMqvuEI-vnM/edit#slide=id.g157c8825e69_0_58) for a walkthrough, or if you prefer to read the algorithm, go to the next section.\n\n### Detailed Clock Algorithm\n\n**On initialization:** Set the clock hand to point to the 0th entry, and set all reference bits to 0.\n  \n**When trying to access a page from memory:**\n1.  Iterate through the entire cache looking for the page. If found, set the reference bit of the page to 1 and return the page. *DO NOT* move the clock hand!\n2. If not found, go back to the clock hand's location and do the following:\n\t1. Skip all pinned pages. (A page is pinned if it's currently in use, meaning we cannot evict it from the cache.)\n\t2. If the current entry has a reference bit of 0, then set the reference bit to 1, evict that entry, replace it with the desired entry from disk, and return it.\n\t3. Otherwise, set the reference bit to 0, advance the clock hand, and repeat the previous 2 steps.\n\n### MRU\nAnother major issue with LRU (and Clock, to some extent) is that it struggles with repeated patterns that are longer than the number of buffer frames available.\n\nFor example, the access policy ABCDEABCDEABCDEABCDE would result in $0$ hits if we had $4$ or fewer buffer frames, since $E$ would always evict $A$, $A$ would then evict $B$ which would evict $C$, and so on. This problem is known as **sequential flooding.**\n\nThe solution to sequential flooding is to use **M**ost **R**ecently **U**sed policy, replacing the page that was used the earliest. If we fed the ABCDE example into a MRU policy, it would result in far more hits (since only two replacements would be needed per cycle, rather than 5).\n\n## Exam Tips\nA very common exam question would look something like this:\n\n\u003e Given the access pattern ABCDEDEFG and a buffer manager with 4 frames, what is the hit rate of \u003cLRU/MRU/Clock\u003e? Express your answer as \"X/Y\", where X is the number of hits and Y is the total number of requests.\n\nIn my opinion, the best way to tackle these problems is to draw a grid that looks something like this:\n\n| Frame | A     | B   | C   | D   | E   | D   | E   | F   | G   |\n| ----- | ----- | --- | --- | --- | --- | --- | --- | --- | --- |\n| 1     |  |     |     |     |     |     |     |     |     |\n| 2     |   |     |     |     |     |     |     |     |     |\n| 3     |   |     |     |     |     |     |     |     |     |\n| 4     |   |     |     |     |     |     |     |     |     |\n\nThen, for each access, list which pages are in the buffer at that point in time, marking the hits. Below is an example for LRU, which would have a hit rate of $2/9$:\n\n| Frame | A     | B   | C   | D   | E   | D   | E   | F   | G   |\n| ----- | ----- | --- | --- | --- | --- | --- | --- | --- | --- |\n| 1     | A |  A   |  A   |  A   |  E   |     |  HIT   |  E   |  E   |\n| 2     |   |  B   |  B   |  B   |  B   |     |     |   F  |   F  |\n| 3     |   |     |   C  |  C   |  C   |     |     |  C   |   G  |\n| 4     |   |     |     |  D   |   D  |  HIT   |     |  D   |  D   |\n\nClock is a bit harder to do, but still managable. I prefer still using the grid method, rather than drawing out the clock face and having to keep erasing the clock hand to advance it. I usually do this by keeping track of the hand position and reference bits. In the example below, the `+`  represents the clock hand, and the reference bit is the number after each page letter:\n\n| Frame | A     | B   | C   | D   | E   | D   | E   | F   | G   |\n| ----- | ----- | --- | --- | --- | --- | --- | --- | --- | --- |\n| 1     | +A1 |  +A1   |  +A1   |  +A1   |  +E1   |   +E1  |  +E1 (HIT)   |  E0   |  E0   |\n| 2     |     |  B1   |  B1   |  B1   |  B0   |  B0   |  B0   |   +F1  |   F0  |\n| 3     |     |       |   C1  |  C1   |  C0   |   C0  |   C0  |  C0   |   +G1  |\n| 4     |     |       |       |  D1   |   D0  |  D1 (HIT)   |  D1   |  D1   |  D1   |\n\n\n",
    "lastmodified": "2023-01-10T23:10:42.585361784Z",
    "tags": null
  },
  "/cs186/04-Sorting-and-Hashing": {
    "title": "Sorting and Hashing",
    "content": "\n## Introduction\nWhen dealing with disk operations, traditional sorting algorithms tend to create lots of random accesses and can be quite slow. We’ll explore a few strategies for creating optimized algorithms for sorting databases that work around our limited memory and buffer management abilities.\n\n## Relevant Materials\n - [Note 6: Sorting](https://notes.bencuan.me/cs186/coursenotes/n06-Sorting.pdf)\n - [Note 7: Hashing](https://notes.bencuan.me/cs186/coursenotes/n07-Hashing.pdf)\n - [Discussion 4: Sorting](https://docs.google.com/presentation/d/1ZZxV_EziQJd47w3MNo72X4z8c7upX4KGiMqvuEI-vnM/edit#slide=id.g157c8825e69_0_1744)\n - [Discussion 5: Hashing](https://docs.google.com/presentation/d/1vsnH3HhD5SlBZpfnLkeUAoYLeoD9jOQ_0ADcS5A7hR0/edit#slide=id.g4fe834b467_0_0)\n\n## Single-Pass Streaming\n\nSingle-pass streaming is an approach for mapping inputs to their desired outputs while minimizing memory and disk usage. We will see this principle being used for many algorithms in this course.\n\n**Main idea:** There are two buffers (input and output). Continuously read from the input buffer and convert them into outputs to place in the output buffer. Only write to disk when the output buffer fills.\n\n![Untitled](Sorting%20and%20Hashing/Untitled.png)\n\n**Optimization: double buffering**\n- The main thread runs the function that converts inputs into outputs.\n- A second I/O thread runs simultaneously to handle the filling and draining of input and output buffers.\n- If the main thread is ready for a new buffer to compute, swap buffers between the two threads.\n\n## Two-Way External Merge Sort\n\nTwo-Way External Merge Sort is a building block to generalized merge sort.\n\n**Main idea:** As input buffers are streaming in, sort each input buffer, then merge two input buffers together into one output buffer using merge sort. Repeat until all pages are merged.\n\n![Untitled](Sorting%20and%20Hashing/Untitled%201.png)\n\nFor larger input sets that span multiple pages, several passes are required. In each pass, pages are merged together and double in size.\n\n**I/O Cost Analysis**\n- Suppose we have $N$ pages.\n- In every pass, we read and write each page in file, causing $2N$ IO’s.\n- The number of passes is logarithmic in nature: $\\lceil \\log_2 N \\rceil + 1$\n- Multiplying the number of passes by the cost per pass gives a total cost of $2N \\cdot (\\lceil log_2 N \\rceil + 1)$.\n\n## General External Merge Sort\n\nIn a typical system, we have more than 3 buffer pages available to us at a time. So, we can merge more than two pages at a time. Let's walk through how this might look like (with the example from Discussion 4):\n\n![ms](\u003cSorting and Hashing/Pasted image 20230108224822.png\u003e)\n\n### Pass 0\nIn the example above, we have 8 data pages of 2 records each. Since we can only fit 4 pages in the buffer at once, we will need multiple passes.\n\nFor pass 0, the goal is to create the largest sorted runs possible by filling the buffer with records. Since our buffer can fit 4 pages at once, we'll end up creating 2 sorted runs of 4 pages each. **Pass 0 does not need to use an output buffer, since we're not streaming anything!** Every set of 4 pages is self-contained.\n\nEventually, we'll create the two runs below by grouping 4 pages together and sorting them in memory:\n```\n[0, 1, 6, 9, 10, 17, 20, 25] (pages 0-3)\n[2, 3, 4, 7, 8, 11, 12, 15] (pages 4-7)\n```\n\nThis process takes $2N$ I/Os, where $N$ is the total number of pages, because we need to first read all the pages then write them all back out once they're sorted into runs.\n\n### Pass 1\nFor the next pass, we *do* need an output buffer, since we must persist data in between runs to combine them. This is what it might look like in memory:\n![p1](\u003cSorting and Hashing/Pasted image 20230108225437.png\u003e)\nNow that we're using general external merge sort, you can see that we can merge up to 3 sorted runs at the same time ($N-1$). But since only 2 were created, the final input buffer will be left empty. \n\nThe process of sorting in-memory is as follows:\n1. Read in all of the input pages.\n2. Find the minimum value out of all of the input pages.\n3. Write that value to the output buffer, and delete it from its source input buffer.\n4. If the output buffer is full, write it to disk and empty it.\n5. If all input buffers are full, flush the rest of the output buffer to disk and we're done!\n\n### Calculating the Number of Passes\nThe number of passes required to sort $N$ pages when we have $B$ buffers is given by the equation below:\n$$1 + \\lceil \\log_{B-1} \\lceil N / B \\rceil \\rceil$$\nThe $1$ at the front is for Pass 0. This creates $N/B$ runs of length $B$. \n\nThen, in every pass, we combine $B-1$ runs into a single run. The algorithm completes when the number of runs left is $1$, so we need to figure out how many times to divide the initial number of runs $N/B$ by $B-1$ before it becomes $1$, which can be done using the $\\log$ term. \n\nOne implication of this equation is that the number of required passes decreases exponentially with respect to the number of buffer pages!\n\n### Calculating the I/O Cost of External Sort\nThe I/O cost calculation is actually pretty simple once we know the number of passes. In each pass, we read every page in and write every page out once, so we can just multiply the number of passes by $2N$:\n$$2N(1 + \\lceil \\log_{B-1} \\lceil N / B \\rceil \\rceil)$$\n\n\n## External Hashing\n\nHashing is best for when we don’t care about the absolute order of elements, but only to group similar elements together. This is useful for GROUP BY operations.\n\nIn 61B, we learned how to create hash tables using an array of linked lists. However, this method only works if we have enough memory to store the entire collection of data at the same time, so we'll need to modify this a bit!\n\n\n### Divide and Conquer\nThe main idea of external hashing is use a two-step process:\n1. Break down the problem into smaller parts until each subpart can fit entirely into memory.\n2. Combine the partitions back together to create one big hash table. \n![Untitled](Sorting%20and%20Hashing/Untitled%202.png)\n\nEssentially, by partitioning the values, we are splitting a large file into many smaller files, each one with at most $B$ pages.\n\nSince these smaller files can each fit into the buffer, we can then use our normal methods to create an in-memory hash table, which will group everything together.\n\n### How is this different from sorting?\nThere are a few important differences:\n1. Rather than creating a smaller number of longer runs for each pass, we're creating a larger number of smaller runs.\n2. In the real world, no hash function can always uniformly partition data. So, we will probably end up having some groups being larger than others.\n3. We might end up only filling a part of a page in some partitions, even though we started with completely full pages. This means that the number of writes per pass might be greater than the number of reads. (Example: If we had $N=35$ and created $10$ uniform partitions, each partition would be $4$ pages long (3.5 rounded up). So we'd have 35 reads, and 40 writes.)\n\n### Use unique hash functions!\nIf we used the same hash function to create partitions in every pass, then our partitions would never get smaller! So, for every pass of external hashing, we must use a different hash function.\n\nAnother related issue is when we have a very large number of identical values, since they won't ever be broken down. When implementing hashing, we should add in a check for this case and stop recursively partitioning if it occurs.\n\n### Calculating I/O Cost of Hashing\nAs a consequence of the above, we can't write a clean formula for calculating the I/O cost of hashing. Luckily, there is a straightforward process we can use instead.\n\nFor this part, let's suppose that $B=10$ and we have $N=100$ pages to hash. Our first hash function creates one partition of size $50$, one partition of size $29$, and seven partitions of size $3$. All future hash functions are uniform (i.e. they create $B-1$ partitions of equal size).\n\n#### Pass 1\nFirst, let's calculate the I/O cost of the first pass:\n* We read in all $N=100$ pages, which takes $100$ I/Os.\n* We write $50 + 29 + 7*3$ pages, which takes $100$ I/Os\n* In total, Pass 1 takes $200$ I/Os.\n\n#### Pass 2\nFor the next pass, we only advance the partitions which don't fit in memory ($n \\le B$). In this case, only the two large partitions (50 and 20) satisfy this, so they are recursively partitioned.\n - It takes $50 + 29 = 79$ I/Os to read in the data for this pass.\n - The partition of size $50$ gets broken down into $B-1=9$ equal partitions of size $\\lceil 50/9 \\rceil = 6$. This incurs $9*6=54$ I/Os to write the grouped partition back to disk.\n - The partition of size $29$ gets broken down into $9$ equal partitions of size $\\lceil 29/9 \\rceil = 4$. This incurs $9*4=36$ I/S to write.\n - In total, this pass incurs $79 + 54 + 36 = 169$ I/Os.\n\n#### Conquer\nNow, all of our partitions fit into disk so we can run the conquer phase to group them back together! To do so, we need to read in every partition we have into memory, and write the grouped version back.\n\nTo regroup, this is what our recursively partitioned data looks like right now:\n - $7$ partitions of size $3$, from the first pass\n - $9$ partitions of size $6$, from recursively partitioning the $50$ page partition\n - $9$ partitions of size $4$, from recursively partitioning the $29$ page partition\n\nSo, to read and write all of this will take $2 \\times (8*2 + 9*6 + 9*4) = 212$ I/Os\n\n#### Total\nThe I/O cost of hashing in this example is $200 + 169 + 212 = 581$ I/Os.\n![diagram](\u003cSorting%20and%20Hashing/Pasted%20image%2020230109000909.png\u003e)\n",
    "lastmodified": "2023-01-10T23:12:17.004253129Z",
    "tags": null
  },
  "/cs186/05-Iterators-and-Joins": {
    "title": "Iterators and Joins",
    "content": "## Introduction\n\nAs you may have seen already, some SQL queries involve joining lots of tables together to get the data we need. However, that joining comes at a cost- every join multiplies the number of rows in the output by the number of rows in the table! \n\nFor this reason, it's very important that we try to optimize the join operation as much as possible, such that we can minimize the amount of data to process. In this section, we'll explore a methods of doing this, and compare their runtimes.\n\n\u003e [!hint] Tip\n\u003e \n\u003e I would recommend playing around with the [Loop Join Animations](https://cs186berkeley.net/resources/join-animations/) visualizer I made- it will help provide some intuition for the first few joins since staring at an algorithm isn't for everyone!\n\u003e \n\u003e The [discussion slides](https://docs.google.com/presentation/d/1qMc6ihzx2xA0wUhn5Ahgb53MXsT6A6P6igzcftze1y8/edit#slide=id.g116533ba7b8_0_1198) also have a full walkthrough of the more involved joins (SMJ, GHJ).\n\n\n## Relevant Materials\n\n - [Loop Join Animations](https://cs186berkeley.net/resources/join-animations/)\n - [Discussion 6](https://docs.google.com/presentation/d/1qMc6ihzx2xA0wUhn5Ahgb53MXsT6A6P6igzcftze1y8/edit#slide=id.g116533ba7b8_0_1198)\n - [Note 8](https://notes.bencuan.me/cs186/coursenotes/n08-Joins.pdf)\n\n\n## Cost Notation\n\nMake sure you keep this section around (whether it's in your head, or bookmarked)! It'll be extremely useful for this section.\n\nSuppose $R$ is a table.\n - $[R]$ is the number of pages needed to store $R$.\n - $p_R$ is the number of records per page of $R$.\n - $|R|$ is the number of records in $R$, also known as the **cardinality** of $R$.\n\t- $|R| = p_R \\times [R]$.\n\n## Simple Nested Loop Join\n\nIntuitively, joining two tables is essentially a double for loop over the records in each table:\n\n```python\nfor record r in R:\n\tfor record s in S:\n\t\tif join_condition(r, s):\n\t\t\tadd \u003cr, s\u003e to result buffer\n```\n\nwhere `join_condition` is an optional function, also known as $\\theta$, that returns a boolean (true if record should be added to result).\n\nThe cost of a simple join is the cost of scanning $R$ once, added to the cost of scanning $S$ once per tuple in $R$:\n$$[R] + |R|[S]$$\n\n## Page Nested Loop Join\n\nSimple join is inefficient because it requires an I/O for every individual record for both tables.\n\nWe can improve this by operating on the page level rather than the record level: before moving onto the next page, process all of the joins for the records on the current page.\n\n```python\nfor rpage in R:\n\tfor spage in S:\n\t\t\tfor rtuple in rpage:\n\t\t\t\t\tfor stuple in spage:\n\t\t\t\t\t\tif join_condition(rtuple, stuple):\n\t\t\t\t\t\t\tadd \u003cr, s\u003e to result buffer\n```\n\nNow, the cost becomes the cost of scanning $R$ once, then scanning $S$ once per *page* of $R$:\n$$[R] + ([R] \\times [S])$$\n\n## Block Nested Loop Join\n\nTo improve upon loop join even further, let’s take advantage of the fact that we can have $B$ pages in our buffer.\n\nRather than having to load in one page at a time, we can instead load in:\n- $1$ page of $S$\n- $1$ output buffer\n- $B-2$ pages of $R$\n\nand then load in each page of $S$ one by one to join to all $B-2$ pages of $R$ before loading in a new set of $B-2$ pages.\n\n```python\nfor rblock of B-2 pages in R:\n\tfor spage in S:\n\t\tfor rtuple in rblock:\n\t\t\tfor stuple in sblock:\n\t\t\t\tadd \u003crtuple, stuple\u003e to result buffer\n```\n\nThe cost now becomes the cost of scanning $R$ once, plus scanning $S$ once per number of blocks:\n$$[R] + \\lceil [R] / (B-2) \\rceil \\times [S]$$ \n\n## Index Nested Loop Join\n\nIn previous version of nested loop join, we’d need to loop through all of the elements in order to join them. \n\nHowever, with the power of B+ trees, we can quickly look up tuples that are equivalent in the two tables when computing an equijoin.\n\n```python\nfor rtuple in R:\n\tadd \u003crtuple, S_index.find(joinval)\u003e\n```\n\nCost: $[R] + |R| \\times t_S$ where $t_S$ is the cost of finding all matching $S$ tuples\n- Alternative 1 B+Tree: cost to traverse root to leave and read all leaves with matching utples\n- Alternative 2/3 B+Tree: cost of retrieving RIDs + cost to fetch actual records\n    - If clustered, 1 IO per page. If not clustered, 1 IO per tuple.\n- If no index, then $t_S = |S|$ which devolves INLJ into SNLJ.\n\n## Sort-Merge Join\n\n**Main idea:** When joining on a comparison (like equality or $\u003c$), sort on the desired indices first, then for every range (group of values with identical indices) check for matches and yield all matches.\n\n![Untitled](Iterators%20and%20Joins/Untitled.png)\n\nThe cost of sort-merge join is the sum of:\n- The cost of sorting $R$\n- The cost of sorting $S$\n- The cost of iterating through R once, $[R]$\n- The cost of iterating through S once, $[S]$\n\nOne optimization we can make is to stream both relations directly into the merge part when in the last pass of sorting! This will reduce the I/O cost by removing the need to write and re-read $[R] + [S]$. This subtracts $2 \\times ([R] + [S])$ I/Os from the final cost.\n\n\n## Grace Hash Join\nIf we have an equality predicate, we can use the power of hashing to match identical indices quickly.\n\nNaively, if we load all records in table $R$ into a hash table, we can scan $S$ once and probe the hash table for matches- but this requires $R$ to be less than $(B-2) \\times H$ where $H$ is the hash fill factor.\n\nIf the memory requirement of $R \u003c (B-2) * H$ is not satisfied, we will have to partition out $R$ and process each group separately.\n\nEssentially, Grace Hash Join is very similar to the divide-and-conquer approach for hashing in the first place:\n\n![Untitled](Iterators%20and%20Joins/Untitled%201.png)\n\n- In the dividing phase, matching tuples between $R$ and $S$ get put into the same partition.\n- In the conquering phase, build a separate small hash table for each partition in memory, and if it matches, stream the partition into the output buffer.\n\nFull process:\n\n1. **Partitioning step:**\n\t1.  make $B-1$ partitions.\n\t2. If any partitions are larger than $B-2$ pages, then recursively partition until they reach the desired size.\n2. **Build and probe:** \n    1. Build an in-memory hash table of one table $R$, and stream in tuples of $S$.\n    2. For all matching tuples of $R$ and $S$, stream them to the output buffer.\n\n\n### Calculating the I/O Cost of GHJ\nThe process of calculating the GHJ cost is extremely similar to that of standard external hashing. The main difference is that we are now loading in two tables at the same time.\n\nLet's look at the example from Discussion 6:\n - Table $R$ has 100 pages and 20 tuples per page.\n - Table $S$ has 50 pages and 50 tuples per page.\n - Assume all hash functions partition uniformly.\n - Do not include the final writes in the calculation.\n - If $B=8$, what is the I/O cost for Grace Hash Join?\n\n#### Number of Passes\nLike hashing, our goal is to make the partitions small enough to fit in the buffer. But now that we have two tables, **we only need one of them to fit**! This is because we can put the smaller table into memory, then stream the larger table in one page at a time using one buffer frame.\n\n![np](\u003cSorting and Hashing/Pasted image 20230109172013.png|300\u003e)\nAs you can see in the image above, as long as one of the tables fits in $B-2$ pages, we're all set for the Build and Probe stage.\n\nIn each stage, of the Partitioning step, we create $B-1$ partitions, so we solve for the number of recursive passes $x$ in the following manner:\n$$\\lceil \\frac{\\min([R], [S])}{(B-1)^x} \\rceil \\le B-2$$\nIn this case, $[S]$ is smaller, so we can plug in $\\lceil 50/(8^2) \\rceil = 1 \\le 8$ to confirm that we need $2$ passes of partitioning before we can Build and Probe.\n\n#### Partition Cost\nThe partition cost calculation is the same as for hashing. However, we must partition *both* tables separately using $B-1$ partitions each at each step.\n\n**Pass 1:**\n1. The first read takes $100+50 = 150$ I/Os.\n2. Partition $R$ into $7$ equal partitions of $15$ and write it back to disk = $15*7=105$ I/Os.\n3. Partition $S$ into $7$ equal partitions of $8$ and write it = $8*7=56$ I/Os.\n\n**Pass 2:**\n1. We read in the results from pass 1: $105 + 56 = 161$ I/Os.\n2. Partition each of the 7 partitions of 15 into 7 more partitions of $\\lceil 15/7 \\rceil = 3$, making $49$ partitions of size $3$ in total. Writing these back takes $49*3 = 147$ I/Os.\n3. Do the same thing for the 7 partitions of 8 to get $49$ partitions of size $2$, taking $49*2 = 98$ I/Os to write back.\n\n**Build and Probe:** Building and probing requires reading all of the partitions created in pass 2. This takes $(3*49) + (2*49) = 245$ I/Os. Remember that we don't count the final writes!\n\n**Total:**\n$(150 + 105 + 56) + (161 + 147 + 98) + 245 = 962$ I/Os to run GHJ. ",
    "lastmodified": "2023-01-10T23:20:39.192554488Z",
    "tags": null
  },
  "/cs186/06-Relational-Algebra": {
    "title": "Relational Algebra",
    "content": "\n## Introduction\n\n**Relational algebra** is a language that represents a logical query plan for translating SQL queries into underlying actions. This is useful because SQL queries don't save information for the *order* in which operations are carried out. As you'll see, several different ways of processing the same query could lead to the same result.\n\nIt represents *how* we perform operations on sets to achieve the desired result. In contrast, [relational calculus](https://en.wikipedia.org/wiki/Relational_calculus) represents the result (the *what* of a calculation). We won't cover relational calculus in this class, since everything that can be represented with relational calculus can be equivalently represented in relational algebra.\n\n## Relevant Materials\n - [Note 9](https://notes.bencuan.me/cs186/coursenotes/n09-RelAlg.pdf)\n - [Discussion 6](https://docs.google.com/presentation/d/1qMc6ihzx2xA0wUhn5Ahgb53MXsT6A6P6igzcftze1y8/edit)\n\n## Operators\n\n### Unary Operators\n\nUnary operators work on a **single relation.** \n\n- **Projection**: $\\pi$ (pi)\n    - Retains only desired columns (vertical)\n    - Example: `SELECT name FROM R` becomes $\\pi_{name}(R)$\n- **Selection**: $\\sigma$ (sigma)\n    - Retains only a subset of rows (horizontal)\n    - Example: `SELECT * FROM R WHERE id = 100` becomes $\\sigma_{id=100}(R)$\n- **Renaming**: $\\rho$ (rho)\n    - rename attributes and relations\n    - Example: $\\rho((1 \\to sid1, 4 \\to sid2), S)$ renames the 1st and 4th columns to `sid1` and `sid2` respectively\n\n### Binary Operators\n\nBinary operators work on **pairs of relations.** \n\n- Union: $\\cup$\n    - Or operator: either in r1 or r2\n    - Equivalent to `UNION` in SQL (doesn’t keep duplicates: `UNION ALL` does)\n- Set difference:  $-$\n    - Tuples in r1, but not in r2\n    - Equivalent to `EXCEPT` in SQL\n- Cross product: $\\times$\n    - Joins r1 with all r2\n    - Equivalent to `FROM r1, r2...` in SQL\n\nThe schemas for both relations must be identical for union and set difference.\n\n### Compound Operators\n\nCompound operators are macros (shorthand) for several unary or binary operators together.\n\n- Intersection: $\\cap$\n    - And operator: both in r1 and r2\n- Joins: $\\bowtie$, $\\Join_\\theta$\n    - Combine relations that satisfy predicates (combination of cross product, selection)\n    - Theta join ($\\Join_{\\theta}$): join on any logical expression $\\theta$\n    - Natural join ($\\Join$): equi-join on all matching column names\n        - $R \\Join S = \\pi_{unique cols} \\sigma_{matching cols equal}(R \\times S)$\n\n### Extended Relational Algebra\n\n- Group by: $\\gamma$\n    - Usage: $\\gamma_{age, AVG(rating),COUNT(*)\u003e2}(S)$ = `GROUP BY age, AVG(rating) HAVING COUNT(*)\u003e2`\n\n## Converting SQL to Relational Algebra\n\nHere's my process for converting between SQL queries and Relational Algebra!\n\nFirst, recall the SQL Logical Processing Order:\n1. `FROM` (find the table that is being referenced, join if needed)\n2. `WHERE` (filters out rows)\n3. `GROUP BY` (aggregate)\n4. `HAVING` (filters out groups)\n5. `SELECT` (choose columns)\n6. `ORDER BY` (sort)\n7. `LIMIT` (cut off the output)\n\nThe key is to go through the query in this order, and build a relational algebra statement inside out.\n\nHere's a nonsensical example query:\n```sql\nSELECT a.name, b.capital\nFROM countries AS a, countries AS b\nWHERE a.name = b.capital\nGROUP BY continent\n```\n\nThe logical processing order for this would be:\n1. Join the `countries` table with itself\n2. Filter for rows where `a.name = b.capital`\n3. Group by continent\n4. Filter for columns `name` and `capital`\n\nBuilding it would look like this:\n1. $\\rho_a countries \\times \\rho_b countries$ (FROM)\n2. $\\sigma_{a.name = b.capital}(\\rho_a countries \\times \\rho_b countries)$ (WHERE)\n3. $\\gamma_{continent}(\\sigma_{a.name = b.capital}(\\rho_a countries \\times \\rho_b countries))$ (GROUP BY)\n4. $\\pi_{a.name, b.capital}(\\gamma_{continent}(\\sigma_{a.name = b.capital}(\\rho_a countries \\times \\rho_b countries)))$ (SELECT)\n\n\n\n",
    "lastmodified": "2023-01-10T23:13:37.531311813Z",
    "tags": null
  },
  "/cs186/07-Query-Optimization": {
    "title": "Query Optimization",
    "content": "\n## Introduction\n\n**Query optimization** is the bridge between a declarative language (like SQL, where you describe “what” you want) and an imperative language (like Java, which describes how the answer is actually computed). Here, we built the translator that converts SQL into logic that a computer can understand.\n\nIf you think about it, this can be really complicated- there's lots of ways to execute a query (i.e. many equivalent relational algebra statements), and we have to somehow figure out which one is the best *without* executing any of them!\n\n## Relevant Materials\n - [Note 10](https://notes.bencuan.me/cs186/coursenotes/n10-QueryOpt.pdf)\n - [Discussion 7](https://docs.google.com/presentation/d/1rvAz_Ms1uxLiyQqGmv-R_xU9NqOjNVzYEWekrtHNuDc/edit)\n\n## System R Optimizers\nThe System R query optimizer framework was conceptualized in the 1970s, and lays the framework for most modern query optimizers today. This is what we will be studying in this class.\n\n![Untitled](Query%20Optimization/Untitled.png)\n\nIn System R, the query parser first checks for correctness and authorization (user permissions to access the table). It then generates a parse tree out of the query. This step is usually fairly straightforward, since it's just breaking up the query into chunks that our programming language can understand, without having to make any decisions.\n\nNext, the query rewriter converts queries into even smaller query blocks (like a single WHERE clause), and flattens the views.\n\nOnce the query is rewritten, it gets passed into the query optimizer. The primary goal of a query optimizer is to translate a simple query plan into a better query plan. A cost-based query optimizer processes one query block at a time (e.g. select, project, join, group by, order by). \n\n- For each block, consider:\n    - all relevant access methods\n    - All left-deep join trees: right branches are always simple FROM clauses. Observe the illustration below for examples of left-deep and not-left-deep trees:\n    \n    ![Untitled](Query%20Optimization/Untitled%201.png)\n    \n\nTypically, we don’t care about exact performance; the main purpose of query optimization is to prune out extremely inefficient options. As long as the final result is good enough, we're happy!\n\n## The Components of a Query Optimizer\n\nThere are three main problems:\n\n1. **Plan space:** for a given query,  what plans are considered?\n    1. Two query plans are **physically equivalent** if they result in the same content and the same physical properties (primarily sort order and hash grouping).\n2. **Cost estimation:** how do we estimate how much a plan will cost?\n    1. In System R, cost is represented as a single number: `I/Os + CPU-factor*#tuples` (where CPU factor is the proportion of time the system spends actually computing the query). For the purposes of this class, we'll only focus on the I/O cost.\n    2. For each term, determine its **selectivity** $S$ (size of output / size of input).  Lower selectivity value is better (filters more items).\n        1. Result cardinality is equal to the max number of tuples multiplied by the product of all selectivities.\n        2. If searching for `col = value`,  $S = 1/N(l)$ where $N(l)$ is the number of unique values in the table.\n        3. If searching for `col1 = col2`, then $S = 1/max(N(l_1), N(l_2))$.\n        4. If searching for `col \u003e value`, then $S = (max(l) - value) / max(l) - min(l) + 1).$\n        5. If we are missing the needed stats to compute any of the above, assume that $S = 1/10$. \n        6. If searching for a disjunction (or) $Q_1 \\lor Q_2$, $S = S_1 + S_2 - (S_1 \\times S_2)$.\n        7. If searching for a conjunction (and) $Q_1 \\land Q2$, $S = S_1 \\times S_2$.\n        8. If searching for a negation (not), $\\lnot Q_1$, $S = 1 - S_1$.\n        9. For joins, simply apply the selectivity query to the cross product of the two tables that are being joined.\n    3. For clustered indexes, the approximate number of IOs is $(P(L) + P(R)) \\times S$ where $P$ is the number of pages and $S$ is selectivity.\n    4. For unclustered indexes, the approximate cost is $(P(L) + T(R))\\times S$ where $T$ is the number of tuples.\n    5. A sequential scan of a file takes $N(R)$ cost.\n3. **Search strategy:** how do we search the plan space?\n\n\n## Selectivity Estimation\nSince the number of rows in our output depends heavily on the data and what selections we make out of it, we need a way to estimate the size of outputs after each operation. This is known as **selectivity estimation.**\n\nLike evaluating query cost, selectivity estimation is very rough and generally prioritizes speed over accuracy- so much so that **if we don't have enough information, we just assign an operation the arbitrary selectivity value of** $1/10$ (meaning that the the output has 1/10 of the number of rows as the input).\n\nBelow are some charts from discussion of some common cases you might run into, and how to calculate their selectivity. Assume the following:\n - `|c|` corresponds to the number of *distinct values* in column c.\n - If we have an index on the column, we should also know `|c|`, and the max/min values.\n\n![se1](\u003cSorting and Hashing/Pasted image 20230109180143.png\u003e)\n![se2](\u003cSorting and Hashing/Pasted image 20230109180153.png\u003e)\n![se3](\u003cSorting and Hashing/Pasted image 20230109180200.png\u003e)\n![se4](\u003cSorting and Hashing/Pasted image 20230109180209.png\u003e)\n\nTo get the number of records in the output, we take the **floor** of the result of multiplying the selectivity estimate with the number of records in the input.\n\n### Selectivity Estimation Practice\n\nSuppose $R(a,b,c)$ has 1000 tuples and $S(a)$ has 500 tuples. We have the following indexes:\n\n- R.a: 50 unique integers uniformly distributed in $[1, 50]$\n- R.b: 100 unique float values uniformly distributed in $[1, 100]$\n- S.a: 25 unique integers uniformly distributed in $[1, 25]$\n\nWhat is the estimated number of tuples in the output after running the following queries?\n\n{{\u003c tabs \"q1\" \u003e}}\n{{\u003c tab \"Q1\" \u003e}}\n`SELECT * FROM R;`\n{{\u003c /tab \u003e}}\n{{\u003c tab \"Q1 Answer\" \u003e}}\nFull scan requires iterating through every tuple in $R$, so 1000 tuples are outputted.\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n{{\u003c tabs \"q2\" \u003e}}\n{{\u003c tab \"Q2\" \u003e}}\n`SELECT * FROM R WHERE a = 42;`\n{{\u003c /tab \u003e}}\n{{\u003c tab \"Q2 Answer\" \u003e}}\nThe selectivity is $1/50$ since there are 50 unique values in $a$ and exactly one of them is desired.\nThis results in $1000 \\times 1/50 = 20$ tuples.\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n\n{{\u003c tabs \"q3\" \u003e}}\n{{\u003c tab \"Q3\" \u003e}}\n`SELECT * FROM R WHERE c = 42;`\n{{\u003c /tab \u003e}}\n{{\u003c tab \"Q3 Answer\" \u003e}}\nWe have no information, so by default $S=1/10.$ $1000 \\times 1/10 = 100$ tuples.\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n\n{{\u003c tabs \"q4\" \u003e}}\n{{\u003c tab \"Q4\" \u003e}}\n`SELECT * FROM R WHERE a \u003c= 25;`\n{{\u003c /tab \u003e}}\n{{\u003c tab \"Q4 Answer\" \u003e}}\nExactly 1/2 of all possible values of `a` are less than 25 (exact formula listed above). So $1000 \\times 1/2 = 500$ tuples.\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n{{\u003c tabs \"q5\" \u003e}}\n{{\u003c tab \"Q5\" \u003e}}\n`SELECT * FROM R WHERE b \u003c= 25;`\n{{\u003c /tab \u003e}}\n{{\u003c tab \"Q5 Answer\" \u003e}}\nUsing the equation for selectivity of inequalities, (value - low) / (high - low) = (25-1)/(100-1) = 24/99. $\\lfloor 1000 \\times 24/99 \\rfloor = 242$ tuples.\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n## Common Heuristics\n\n**Selection and projection cascade and pushdown:** apply selections ($\\sigma$) and projections ($\\pi$) as soon as you have the relevant tables. i.e. push them as far to the right as possible\n\n**Avoid Cartesian products:** given a choice, do theta-joins rather than cross products.\n\n**Put the more effective selection onto the outer loop before a join:** reorder joins such that we are joining a smaller table in the outer loop with a larger table in the inner loop, especially if this allows us to filter out more rows in the outer loop\n\n**Materialize inner tables before joins:** rather than calculating selections on the fly, create a temporary filtered table before passing it into a join\n\n- Not effective 100% of the time since it costs IO’s to write and re-read the table\n\n**Use left-deep trees only** (explained in an earlier section).\n\n\n## Selinger Query Optimization\n\nThe Selinger query optimization algorithm uses dynamic programming over $n$ passes (where $n$ is the number of relations).\n\nIn each of the passes, we use the fact that left-deep plans can differ in the order of relations, access method for leaf operators, and join methods for join operators to enumerate all of the plans.\n\nMore specifically:\n\n- In the 1st pass, find the best single relation plan for each relation. (what’s the best way to scan a table?)\n    - This includes full scans (# IOs = # pages in table) and index scans (# IOs depends on type of index and any applicable selects, since selections are pushed down)\n- In each $i$ith pass, find the best way to join the result of an $i-1$ relation plan to the $i$th relation. (The $i-1$ plan will always be the outer relation due to the left-deep property.)\n- For each subset of relations, retain only:\n    - Cheapest plan overall for each combination of tables,\n    - Cheapest plan for each interesting order of tuples\n\n**The principle of optimality:** the best overall plan is composed of the best decisions on the subplans. This means that if we find the cheapest way to join a subset of tables, we can add on more tables one by one by finding the cheapest cost for that single join operation.\n\n\n### Choosing Join Algorithms\n\n**Table access with selections and projections:**\n- Heap scan\n- Index scan if available\n\n**Equijoins:**\n- Block nested loop join when simple algorithm needed\n- Index nested loop join if one relation is small and the other one is indexed\n- Sort-merge join if equal-size tables, small memory\n- Grace hash join if 1 table is small\n\n**Non equijoins:**\n- Block nested loop join\n\n\n### Interesting Orders\nIf a GROUP BY or ORDER BY clause will be processed later on, or a future join might benefit from the structure of the current join, it may be useful to take a temporary hit in IO cost in order to avoid needing to resort or regroup the table in a future step.\n\nOnly Sort Merge Join, Grace Hash Join, and index scans can produce interesting orders.\n\n\n\n### Full Sellinger Walkthrough\n\nThis problem is taken from [Fall 2020 Midterm 2](https://drive.google.com/file/d/1tTZSpPvhWM6z4VgqNn5AGksCjRjU7Mq9/view?usp=sharing).\n\nSuppose we have the following query:\n```sql\nSELECT R.a, S.b, T.c\nFROM R INNER JOIN S ON R.a = S.a\nINNER JOIN T ON R.b = T.b\nWHERE R.b \u003c= 10 AND T.c \u003c= 20\nGROUP BY S.b;\n```\n\n#### Pass 1\nWe're given the following possible single table access plans for Pass 1:\n![sp1](\u003cSorting and Hashing/Pasted image 20230109182021.png\u003e)\n\n\n(In reality, we'd need to do selectivity estimation to find those numbers, but since you already did some [[#Selectivity Estimation Practice|practice]]) we'll skip it for now.)\n\nThe first step is to identify the minimum cost accesses for each of the tables:\n - Option (b) is the best way to access $R$, so we'll keep it.\n - Option (d) is the best way to access $S$, so we'll keep it.\n - Option (f) is the best way to access $T$, so we'll keep it.\n\nNext, we can identify any interesting orders:\n - The only interesting order is (e), since we `GROUP BY s.b`, and (e) is an index scan on the same column.\n\nIn summary, four plans would advance: b, d, e, f.\n\n#### Pass i\n\nNow for the 2nd pass, we will consider some ways to join two tables together:\n![sp1](\u003cSorting and Hashing/Pasted image 20230109182429.png\u003e)\n\nLet's start again by identifying the best way to join each combination of tables together:\n - (b) is the best way to join $R$ with $S$.\n - (d) is the best way to join $S$ with $T$.\n - (e) is the best way to join $R$ with $T$.\n\nHowever, we can see that the original query does not actually join S with T! So we can safely discard (d), since we'll never end up using it.\n\nSince there are no interesting orders here besides (b), the final result is that only (b) and (e) advance to Pass 3.\n",
    "lastmodified": "2023-01-10T23:22:45.683644684Z",
    "tags": null
  },
  "/cs186/08-Transactions": {
    "title": "Transactions and ACID",
    "content": "\n## What is a transaction?\n\nTransactions are collections of operations that can be treated like a single unit. The primary reason why we need transactions is to obey the **ACID** properties:\n- **Atomicity:** either all operations happen, or none of them\n- **Consistency:** database remains in a consistent state with its constraints (for example, primary keys will never be null)\n- **Isolation:** it should appear as if we only run 1 transaction at a time (even if they’re actually run concurrently)\n- **Durability:** once a transaction commits, it persists\n\nTransactions support two main operations:\n- COMMIT: indicates a successful transaction, changes should be saved\n- ABORT: indicates an unsuccessful transaction, changes should be reverted\n\n## Relevant Materials\n - [Note 11](https://notes.bencuan.me/cs186/coursenotes/n11-Xact1.pdf)\n - [Note 12](https://notes.bencuan.me/cs186/coursenotes/n12-Xact2.pdf)\n - [Discussion 8](https://docs.google.com/presentation/d/1nbqCBb3H-UZSKJLm3INSS3-rhTNw8vWJti9wlcXL2uI/edit)\n\n## Serializability\nAs previously mentioned, transactions must be treated like a single unit, even if they are actually made up of many smaller operations. However, it's often inefficient to only run one transaction at a time-- whenever a transaction tries to read something from the disk, we can start running another transaction while waiting for the data to be retrieved.\n\nWe can create a **schedule** to determine the order in which we execute operations in a set of transactions. A **serial schedule** is a schedule in which every transaction completes without interleaving (finish all parts of one transaction from start to finish before moving to the next) - ideally, we would want all schedules to approximate a serial schedule.\n\nFormally, **Two schedules are equivalent if:**\n- They involve the same transactions\n- The final state after all transactions is the same\n- Each transaction’s operations are completed in the same order\n  \n  In order to check serializability, we will check if they are **conflict serializable:**\n    - Two operations are in a schedule conflict if\n        - at least one operation is a write\n        - the operations are on different transactions\n        - the operations work on the same resource\n    - Two operations are conflict equivalent if every conflict is ordered in the same way.\n    - A schedule is conflict serializable if it is conflict equivalent to a serial schedule.\n- **View serializability** refers to conflict serializability in which blind writes (intermediate writes that are overwritten without a read in between) are ignored. Checking view serializability is an NP complete problem.\n\nIn summary:\n![Untitled](Transactions/Untitled.png)\n\n### Conflict Dependency Graphs\n\nTo draw a conflict dependency graph for a schedule, represent each transaction as a node. Then, draw an arrow from an earlier operation to a later operation if **the two operations are done in different transactions, and at least one of the operations was a write.**\n\nTo find equivalent schedules, run topological sort on all involved graphs. **All conflict serializable schedules have an acyclic dependency graph.** So if a graph has a cycle, it is not conflict serializable.\n\n## Locking\n\nIf two transactions need to access the same data, we need a way to guarantee isolation! The solution is for a transaction to **lock** a resource if it needs access to it. Then, other transactions should wait until the lock is released before accessing the same resource.\n\nA transaction may lock a resource in two primary ways:\n- **S lock** (shared): allows a transaction to read a resource\n    - Multiple transactions can hold S lock on the same resource at the same time\n- **X lock** (exclusive): allows a transaction write a resource\n    - No other transaction can have any type of lock on the same resource as a transaction with an X lock on it\n\n\nHere's the **lock compatibility matrix** for S and X locks:\n    ![Untitled](Transactions/Untitled%202.png)\n\n### Two Phase Locking (2PL)\n\n2PL is one method of enforcing conflict serializability.\n\nThere are two phases:\n1. From start until a lock is released, the transaction is only acquiring locks (acquiring step)\n2. From after a lock is released to the end of the transaction, the transaction is only releasing locks (release phase)\n\nTransactions cannot acquire any lock after it has released a lock.\n\n**Strict 2PL** only allows releasing of locks at the end of the transaction. This avoids cascading aborts (when unrelated transactions are aborted due to lock release schedule).\n\n\n## Deadlock\n\nDeadlock occurs when there is a cycle of transactions all waiting for each other to release their locks.\n\n### Deadlock Avoidance\n\nDeadlock avoidance is the process of catching deadlocks before they occur. There are two main ways we can avoid deadlock:\n- **Wait-die:** if $T_i$ wants a lock but $T_j$ holds a conflicting lock:\n    - If $T_i$ higher priority, wait for $T_j$ to release\n    - If $T_i$ lower priority, abort (die)\n- **Wound-wait:**\n    - If $T_i$ is higher priority, $T_j$ aborts\n    - If $T_i$ is lower priority, it waits for $T_j$ to finish\n- If no explicitly defined priority, we can assign priority by age (current time - start time).\n\n### Deadlock Detection\nDeadlock detection refers to the process of detecting and resolving deadlocks when they occur.\n\nTo perform deadlock detection, we can draw a **waits-for graph**:\n- One node per transaction\n- If $T_i$ holds a lock that conflicts with the lock that $T_j$ wants (i.e. $T_j$ waits for $T_i$), add an edge from $T_j$ to $T_i$. (Check the lock compatibility matrix to see what lock types conflict).\n- Deadlock occurs if there is a cycle in the graph\n\nWaits-for graphs are very similar to conflict dependency graphs, except that **rather than older operations pointing to newer ones, newer operations point to older ones.** This is because the later operation \"waits for\" the older one to complete.\n\n\n\n## Multigranularity Locking\n\n\n\n- Tuple-level locking: one lock per tuple (high locking overhead due to a scan requiring many locks)\n- Table-level locking: one lock per table (low concurrency since any update locks the entire table)\n- **Multigranularity Locking:** based on operation, allow for different types of locks\n    - Scans = lock entire table = lower overhead\n    - Update tuple = lock only the affected tuple = higher concurrency\n    - For each lock, transactions must hold **intent locks (IX, IS)** at all higher levels of granularity\n        - Indicate a future requirement to lock at a higher level\n        - Example: If S lock on tuples is requested, we need intent locks on database, table, and page\n        - IX = intent to acquire exclusive lock on lower level\n        - IS = intent to acquire shared lock on lower level\n        - SIX = shared + intent to acquire exclusive lock at lower level. (equivalent to having both S and IX locks - can read entire table and acquire X locks when needed)\n        - In order to acquire S, a transaction must also have the IS lock (same for X)\n\n![Untitled](Transactions/Untitled%203.png)\n\n\n\n## Practice Problems\n\n{{\u003c tabs \"q1\" \u003e}}\n{{\u003c tab \"Question 1\" \u003e}}\n(Fall 2022 MT2) Draw the conflict dependency graph for the following schedule. Is this schedule conflict serializable?\n![tp1](\u003cTransactions/Pasted image 20230109222952.png\u003e)\n{{\u003c /tab \u003e}}\n{{\u003c tab \"Answer\" \u003e}}\nTo draw the conflict dependency graph, remember the rule of drawing an arrow from an earlier operation to a later operation if the two operations are in different transactions and at least one of them was a write:\n![tp1a](\u003cTransactions/Pasted image 20230109223439.png\u003e)\n\nThen, we compress all of the arrows into their corresponding transactions, resulting in the following graph:\n![tp1b](\u003cTransactions/Pasted image 20230109223458.png\u003e)\n\nSince there is a cycle from T2 to T5, this schedule is **not conflict serializable**.\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n\n{{\u003c tabs \"q2\" \u003e}}\n{{\u003c tab \"Question 2\" \u003e}}\n(Spring 2022 MT2) Suppose we wanted to read the entire Page 1. What locks should we hold on each layer after granting the lock?\n\nHere is the original state:\n![tp3](\u003cTransactions/Pasted image 20230109225009.png\u003e)\n{{\u003c /tab \u003e}}\n{{\u003c tab \"Answer\" \u003e}}\n\nRight now, we can't read Page 1 since we don't have an S lock on it. Therefore, we need to promote the IX lock on Page 1 into an SIX lock.\n\nSince an S lock exists on Page 1 now, Tuple 1 can release its S lock (no S in S descendants).\n\nEverything else remains the same, so the following locks will be held:\n - Tuple 1: NL\n - Tuple 2: X\n - Page 1: SIX\n - Table: IX\n - Page 2: X\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}",
    "lastmodified": "2023-01-10T23:24:37.654761971Z",
    "tags": null
  },
  "/cs186/09-Parallel-Query-Processing": {
    "title": "Parallel Query Processing",
    "content": "\n## Relevant Materials\n - [Note 15](https://notes.bencuan.me/cs186/coursenotes/n15-PQP.pdf)\n - [Discussion 11](https://docs.google.com/presentation/d/1QhHHveYGIzGynJdRyli5XnyXkNt2c_FX9AWtn5t1fQE/edit#slide=id.g12051cee1a3_0_2249)\n\n## Parallelism\n\nParallelism helps us break down a big problem into small, independent chunks. The idea is that a lot of machines all working on the same problem at the same time will finish the problem more quickly.\n\nThere are two main metrics we want:\n- **Speed-up:** if we add more hardware, the same workload should be completed more quickly.\n- **Scale-up:** if the workload increases, we should be able to add a corresponding amount of hardware to make the problem be processed with the same amount of time as before.\n\nThere are two main types of parallelism:\n- **Pipelining:** each machine does one component of the calculation, then passes the result on to another machine\n- **Partitioning:** each machine runs the same computations on a different set of data.\n\nNow for types of query parallelism:\n- **Inter-query parallelism:** each query runs on a different processor. Requires parallel-aware concurrency control.\n- **Intra-query, inter-operator parallelism:** each operator in one query is done by a differerent machine.\n    - **Pipeline parallelism:** every query operation depends on the previous query’s output\n    - **Bushy tree parallelism:** do two operators at the same time if they don’t depend on each other\n- **Intra-query, intra-operator parallelism:** for joins, each machine scans and processes a chunk of the table, and all results are eventually combined.\n    - **Partition parallelism:** partition the data, and operate on each partition simultaneously since they don’t depend on each other\n\n## Data Partitioning\n\nSo, if we’re going to do intra-operator parallelism, how do we split up the data in the first place?\n\n![Untitled](Parallel%20Query%20Processing/Untitled.png)\n\nRange and hash partitioning are prone to key-skew. Round-robin ensures that all machines receive roughly equal amounts of work regardless of the data distribution.\n\nHowever, with range and hash partitioning, searching is more efficient since we only need to query a subset of machines.\n\n## Parallel Query Operators\n\n### Parallel Hashing\n\n![Untitled](Parallel%20Query%20Processing/Untitled%201.png)\n\nAdd a new partitioning phase to separate data into machines before running the algorithm individually for each machine.\n\n### Parallel Hash Joins\n\n![Untitled](Parallel%20Query%20Processing/Untitled%202.png)\n\nUse hash partitioning on both relations, then perform a normal hash join on each machine independently.\n\n### Symmetric Hash Joins\n\nSymmetric hash joins are a type of **streaming hash join algorithm**: it does not require all tuples to be available when it runs.\n\n**Basic idea:** build two hash tables ($R$ and $S$) at the same time\n- When a tuple from $R$ arrives, probe hash table for $S$ and add the tuple into hash table for $R$.\n    - If there are matching tuples in $S$, then add all joined tuples to the output by iterating over the hash table bucket.\n- Do the same for $S$ and $R$.\n\n### Parallel Sorting\nPartition the data over machines using **range partitioning.** Then, perform sort-merge join independently on each machine. Since each range is independent, we can join all of them at the end for the final output.\n\n### Parallel Hashing\nParallel hashing uses the same idea as parallel sorting, except that since we don't care about sort order we use **hash partitioning** instead.\n\n### Parallel Aggregation\n\nSUM, COUNT, AVERaGE, etc.\n\n- Use hierarchical aggregation: first, local function calculates sum and count for both machines. Then, a global function combines the results from all of the machines.\n\n### Asymmetric Shuffles\n\nSometimes, data is already partitioned the way we want. This would make it redundant to repartition or send data. \n\nFor example, if we wanted to run sort-merge join on R and S, but R is already range partitioned, then we can leave R alone and range-partition S using the same ranges before performing the merge.\n\n### Broadcast Joins\n\nSometimes, one table is tiny and another one is huge. It can be very expensive to partition the huge table, so we can instead send the entire tiny table to each machine containing the huge table and perform the operation locally.\n\nHere are some examples of parallel operations:\n- Lookup by key: easy for range/hash, need to broadcast to all machines for RR\n- Insert: need specific machine for range/hash, can go to any machine for RR\n- Unique key: easy for range/hash, need to broadcast request for RR. If response received, overwrite in correct machine. Otherwise, insert anywhere\n\n## Measuring Parallelism (Problem solving strategies)\n\n**Network cost:** amount of data we need to send over the network to perform an operation\n- Measured in bytes/KB/GB etc.\n- Unlike I/Os, we can send one tuple at a time rather than entire pages\n- Network cost is incurred whenever a tuple needs to be moved to another machine (e.g. due to partitioning). Typically all data originates on 1 of the machines and needs to be distributed.\n\n**Measuring partitioning costs:**\n- Given $N$ pages on one machine, we want to partition the data onto $M$ machines. How much data would be transferred if each page is $S$ KB large?\n    - If all data is uniform and hash functions are uniformly distributed, all partition schemes (hash, range, RR) would put $N/M$ pages on each machine. $M-1$ machines need to be written to, so $\\frac{N}{M} \\times (M-1) \\times S$ KB would be written.\n    - In the best case, range and hash partitioning would not need to write anything at all (since everything is on the first machine). So the cost is $0$ KB. Round Robin best case is the same as the above calculation.\n    - In the worst case, range and hash partitioning would need to write all $M$ pages to other machines, so $M \\times S$ KB would be written. Round Robin is guaranteed to always uniformly distribute data so its worst case and best case are the same.",
    "lastmodified": "2023-01-10T23:18:16.049440528Z",
    "tags": null
  },
  "/cs186/10-Recovery": {
    "title": "Recovery",
    "content": "\n## Introduction\n\n**Recovery** is the process of making databases resilient to failure. Specifically, recovery enforces **durability** (a committed transaction remains persistent) and **atomicity** (either all of the operations in a transaction complete, or none of them).\n\n**Assumptions:**\n- We use strict two-phase locking for concurrency control.\n- Updates happen in-place: transactions that modify data overwrite entries in the database.\n\n## Relevant Materials\n - [Note 13](https://notes.bencuan.me/cs186/coursenotes/n13-Recovery.pdf)\n - [Discussion 9](https://docs.google.com/presentation/d/1K9BNas4NYQbRSB8q_EswPepjwVj-cijxQOsZEIYTNsY/edit?usp=sharing)\n\n## Steal/No Force\n\n### No Steal Policy\n\nDon’t allow buffer pool frames with uncommitted updates to be replaced or flushed to disk.\n- Achieves atomicity\n- Can cause poor performance due to pinned pages limiting buffer replacement\n\n### Force Policy\n\nBefore commit, ensure that every update is forced onto the disk.\n- Achieves durability\n- Can cause poor performance due to high random IO\n\nA simplistic attempt at recovery (that doesn’t actually work) would be to combine no-steal and force. This doesn’t work because it doesn’t guarantee atomicity if the DB crashes while writing dirty pages.\n\n### Steal No-Force Policy\n\nSteal No-Force is the most efficient approach, but also complicated:\n- No Force: flush dirty pages as little as possible, and only when convenient, before commits. Allow for redoing modifications. (Can complicate durability)\n- Steal: allow buffer pool frames to be replaced whenever convenient. (Can complicate atomicity)\n\n## Logging\n\n![Untitled](Recovery/Untitled.png)\n\n**Main idea:** for every update, record info to allow undoing and redoing.\n\nA log is an ordered list of records.\n\n- Each record contains:\n    - Transaction ID\n    - Page ID\n    - Offset\n    - Length\n    - Old Data\n    - New Data\n    - Additional control info\n- A log also contains a write buffer (tail) in RAM.\n- Each log record has a unique, increasing log sequence number (LSN).\n- The log tracks `flushedLSN` that tells us the most recently flushed log record.\n- Each data page in the database contains a `pageLSN`, a pointer to the most recent log record for an update to that page.\n\n**Write Ahead logging protocol (WAL):**\n\n- Log record must be written for an update before the corresponding data page is written to disk (allows atomicity with UNDO info)\n- All log records must be stored for a transaction before commit (allows durability with REDO info)\n- **Invariant:** before page `i` is flushed to the DB, `pageLSN \u003c= flushedLSN`. i.e. all log records for the page need to be flushed before the page itself can be flushed.\n\n### ARIES Log Records\n\n![Untitled](Recovery/Untitled%201.png)\n\nARIES  (Algorithms for Recovery and Isolation Exploiting Semantics) is a logging algorithm. Some details:\n\n- Every log record contains `prevLSN`, which is the previous log record written by this transaction. This helps us undo a chain of operations.\n- Log records can be several types:\n    - Update, commit, abort\n    - Checkpoint (for log maintinence)\n    - Compensation Log Records (CLRs) for undo actions\n    - End (of commit or abort)\n- Two in-memory tables are created:\n    - Transaction table contains one entry per active transaction. When a transaction commits or aborts, it is removed.\n        - Contains transaction ID, status (running, committing, aborting) and lastLSN columns.\n    - Dirty page table contains one entry per dirty page in the buffer pool.\n        - Contains page ID and recLSN (log record that first caused the page to be dirty).\n        - recLSN stands for “recovery LSN”: the first timestamp in which the page is dirty.\n\n### ARIES Checkpoints\n\n**Main idea:** save the state of the database periodically so we don’t need to process the entire log during recovery.\n\nA checkpoint consists of the following:\n\n- Stop accepting any new transactions\n- Wait until all current transactions complete (commit or abort)\n- Flush log to disk\n- Flush all dirty pages to disk\n- Write a CKPT log record\n- Flush log again\n- (At this point, all commits are written, and all aborts have been rolled back)\n- Resume processing transactions\n\nThis is very slow because the database freezes during checkpoint creation. **Fuzzy checkpointing** attempts to resolve this issue by saving the state of all transactions and page statuses, but does not stop any transactions or flush dirty pages.\n\n- Keep track of transaction states (transaction table) and dirty page table\n- Save the above to disk\n- When recovering, recreate the above from the log, recreate running transactions and dirty pages in memory, then replay the rest of the log.\n\nSpecifically, the following happens:\n\n- Write a BEGIN CKPT to log\n- Flush log to disk\n- Continue normal operation\n- When DPT and transaction tables are written to disk, write END CKPT to log\n\n### ARIES Normal Operation\n\n**Start Transaction:**``\n- Write START to log\n- Update transactions table with new transaction\n- Set the following values\n    - `prevLSN = lastLSN` in log\n    - `pageLSN = LSN` in buffer pool\n    - `lastLSN = LSN` in transaction table\n    - If `recLSN` is null, then set it to `LSN` (i.e. first time this page is dirty)\n\n**Flush Page:**\n- Flush log up to and including `pageLSN`\n- Remove page from DPT and buffer pool\n\n**Fetch page:** \n- Create new entry in DPT and buffer pool\n\n**Commit:**\n- Write commit record to log\n- Flush log up to entry\n- Update transaction table status to commit\n\n**Abort:**\n- Write abort record to log\n- Find first action to undo from `lastLSN`\n- Start to undo changes\n- Write compensation record (CLR) to log, and set is `undoNextLSN` to the next record to undo\n- Follow `prevLSN` like a linked list pointer to find next value(s) to undo\n- When the last action has been undone, change the transaction status to Abort\n\n## Crash Recovery\n\n### Summary\n- Start from a checkpoint from the master record\n- Analysis phase: figure out which transactions committed and which ones failed\n- REDO phase: repeat the history of the log and reconstruct the state of the database before the crash.\n- UNDO phase: undo effects of failed transactions.\n\n### Analysis Phase\n\n- Re-establish knowledge of state at checkpoint via transaction table and dirty page table stored in the checkpoint.\n- Scan log forward from the checkpoint.\n    - End record: remove transaction from transaction table\n    - Update record: if page is not in DPT, add it to the DPT and set its `recLSN` to `LSN` (current log record being scanned).\n    - Else: add transaction to transaction table, set `lastLSN` to `LSN`, then change the transaction status on commit or abort.\n- After analysis ends:\n    - For every transaction in the committing state, write a corresponding END record and remove it from the transaction table.\n    - The transaction table now displays which transactions were active at the time of crash. Set all of these to aborting status and write abort records.\n    - The DPT now shows which dirty pages might not have made it to disk.\n    \n\n### REDO Phase\n\n- Scan forward from the log record containing the smallest `recLSN` in the dirty page table.\n    - Checkpoints don’t actually save data, so we have to replay all of the actions that didn’t necessarily make it onto disk. `recLSN` tells us when the log and disk diverges.\n- Cases where we don’t want to redo:\n    - **Main idea:** The point of REDO is to replay transactions. If an operation has already made it to disk, we don’t need to redo it.\n    - Affected page is not in DPT (page was flushed and removed before checkpoint)\n    - Affected page is in DPT, but `recLSN \u003e LSN` (page was flushed and removed from DPT, then referenced again and reinserted into DPT later on)\n    - `pageLSN \u003e= LSN` (page was updated again and flushed after the log record)\n- If we do want to redo:\n    - Reapply the logged action.\n    - Set pageLSN to LSN with no additional logging.\n\n### UNDO Phase\n\n- The transaction in the transaction table after analysis should abort.\n- Do one backwards pass of the entire log, and undo sequentially.\n\n![Untitled](Recovery/Untitled%202.png)\n\n### What happens if DB crashes during crash recovery?\nNothing! Crash recovery is inherently durable, because it still follows the same rules as write-ahead logging in that log records are always written before any changes are made. If recovery doesn't complete, then we can simply start over from the beginning of recovery and try again.",
    "lastmodified": "2023-01-10T23:17:45.789604174Z",
    "tags": null
  },
  "/cs186/11-Distributed-Transactions": {
    "title": "Distributed Transactions",
    "content": "\n## Introduction\nIn some situations (like in datacenters), the computation needed for transactions gets to be too great for a single computer to handle.\n\nOne solution for this is to build *wide*- connect a whole bunch of computers together, and have them all work on the same thing! However, this comes with its challenges.\n\nOne such challenge is how we can still preserve ACID properties of transactions when each computer is working independently. What happens if one computer crashes?\n\n## Relevant Materials\n - [Note 16](https://notes.bencuan.me/cs186/coursenotes/n16-DistXact.pdf)\n - [Discussion 12](https://docs.google.com/presentation/d/1G1A93sgcPWIDSZklHyqya62VFqMbsFnSnKap9vi8AG0/edit)\n\n\n## Two Phase Commit\nTwo Phase Commit (which has no relation to Two Phase Locking, except by name) is a method of establishing consensus between distributed nodes running the same transaction. The main idea is to guarantee that either all nodes complete successfully, or none will commit.\n\n![Untitled](Distributed%20Transactions/Untitled.png)\n\n**Phase 1: voting**\n- Coordinator asks participants to vote by sending a PREPARE message to all participants.\n- Participants send VOTE YES or VOTE NO to coordinator.\n- Participants log and flush either a PREPARE or ABORT record to the log, keeping track of the coordinator ID.\n- After the coordinator receives a message from all participants, the coordinator logs and flushes either a COMMIT or ABORT record to log\n\n**Phase 2: results**\n- Coordinator tells participants to COMMIT or ABORT.\n- Participants log and flush COMMIT or ABORT to log.\n- Participants send ACK to coordinator.\n- Coordinator logs (but does not need to flush) an END record to the log, to remove it from the transaction table.\n\nAll results must be unanimous in order to COMMIT. Any one node that can’t commit should cause the entire transaction to ABORT.\n\n### Recovery\n- If we have a COMMIT or ABORT log record, we know what to do. (The coordinator should send commit or abort messages periodically until all ACKs are received.)\n- If we have a PREPARE log record, but no commit/abort, then we’re at a participant node that should send a message to the coordinator inquiring about the status of the transaction.\n- If we have no prepare, commit, or abort, then something crashed.\n    - If at a participant node, abort the transaction (did not send YES)\n    - If at a coordinator node, respond to all future votes with ABORT.\n- It is never possible to COMMIT if either the coordinator or participants have written an ABORT.\n- It is never possible to ABORT if any one participant has written COMMIT.\n\n### Optimization\n\n**Presumed abort:** a transaction should abort if we have no log records locally.\n\nWhen a transaction aborts:\n- Coordinator cleans up locally- remove transaction from table if it doesn’t have ACKs\n- If participant receives ABORT, do not send ACKs\n- If transaction not in coordinator’s transaction table when participant inquires, ABORT\n- Don’t store participant IDs in abort records\n- Abort records do not need to be flushed\n\n### Blocking\n\nIf a node crashes during the voting (first) phase, any participant that voted yes keeps locks and waits for commit or abort\n\nIf a participant doesn’t recover, coordinator respawns new participant using log records; destroy old participant.\n\nIf the coordinator doesn’t recover, 2PC doesn’t work (use 3PC, etc).\n\n### Distributed Deadlock\n\nSuppose multiple machines have running transactions, and each machine has its own waits-for graph.\n\nTo evaluate deadlock, union all of the waits-for graphs and check for cycles.\n\n## 2PC Timing (Problem solving strategies)\n\n**Problem: Find the best case time for a transaction to complete using 2PC:**\n\nPhase 1:\n- Coordinator sends a prepare message (coordinator send time)\n- Participants flush to log (flush time)\n- Participants send Yes message (max of participant send times)\n- Coordinator flushes a commit log (flush time)\n\nPhase 2:\n- Coordinator sends commit message (coord send time)\n- Participants flush commit record (flush time)\n- Participants send ACK (max of participant send times)\n- Coordinator flushes END record (flush time)\n\n**Problem: Find the minimum time it takes for 2PC to abort.**\n\nPhase 1:\n- Coordinator sends prepare message\n- Committing participants flush prepare, aborting participants add abort record\n    - max (times for aborts to send, times for commits to send + flush time)\n\nPhase 2:\n- Coordinator sends abort message\n- Under abort optimization, no ACK is required.",
    "lastmodified": "2023-01-10T23:18:06.545492904Z",
    "tags": null
  },
  "/cs186/12-ER-Diagrams": {
    "title": "E-R Diagrams",
    "content": "\n## Introduction\n\nProduction databases have a lot of tables with complicated relationships. **Entity Relationship (ER) Diagrams** help us organize databases in a visual manner.\n\n### Steps in Database Design\n\nDatabase design is a bit different from the rest of the content we've covered so far. In previous sections, we mostly learned how to use databases and write the algorithms that make it work efficiently-- but now, we need to ensure that the data itself is structured in a meaningful manner to take advantage of all those optimizations!\n\nHere are some parts of database design:\n- Requirement Analysis: what do users need the database to do?\n- Conceptual Design: highly level description of DB schemas\n- Logical Design: translate conceptual model into DBMS data model\n- Schema Refinement: consistency, normalization\n- Physical Design: indices, disk layout\n- Security Design: who accesses what, and how\n\nER Diagrams help us with *conceptual design.*\n\n## Relevant Materials \n - [Note 13](https://notes.bencuan.me/cs186/coursenotes/n13-DBDesign.pdf)\n - [Discussion 10](https://docs.google.com/presentation/d/1qRrHbZ2zTLDUjrUJ5cn3jaAU1On0apKizWqfTKVGMwg/edit#slide=id.g5202e50430_0_0)\n\n## Data Models\n\nA data model is a collection of concepts for describing data.\n\nA schema is a description of a particular collection of data using a given data model. \n\nAbstraction:\n- Users see views (eg app on smartphone)\n- Logical structure defined by conceptual schema\n- Physical structure stores conceptual schema using files and indices\n\n**Logical Data Independence:** maintain views when logical structure changes\n\n**Physical data independence:** maintain logical structure when physical structure changes\n\n## Entities\n\nEntities are real-world objects that are described with attributes.\n\nAn entity set is a collection of the same type of entities (same attributes).\n- Entity sets are described by a key (rectangle) and attributes (ellipses):\n    \n    ![Untitled](ER%20Diagrams/Untitled.png)\n    \n- Primary keys are underlined.\n\n## Constraints\n\nA relationship is an association between multiple entities or entity sets.\n\nA relationship set is a collection of the same type of relationships (diamond).\n\n![Untitled](ER%20Diagrams/Untitled%201.png)\n\n## Weak Entities\n\nWeak entities can be defined uniquely only with the key of another entity.\n- The partial key (dashed underline) is the key in the other entity that must be combined with the owner entity’s key.\n- Must exist in a many-to-one relationship (1 owner entity, many weak entities) with total participation\n- Weak entities and their relationship set are bolded",
    "lastmodified": "2023-01-10T23:18:25.07738996Z",
    "tags": null
  },
  "/cs186/io": {
    "title": "What is an I/O and why should I care?",
    "content": "If you're taking 186, you've probably heard or experienced some variation of the following:\n - This class has a lot of I/O counting on exams\n - I/Os are weird, sometimes you can read like 5 things at the same time but it's still one I/O for some reason\n - I/O counting is tedious and boring and I will never do it after this class, so why do I need to do it??????\n\nWhile I can't guarantee that you'll ever count I/Os after this class, my hope for this article is to justify why it's necessary for understanding key database design concepts, and how the principles can be applied to real-world issues in query optimization. It's like learning how to multiply numbers by hand when we have calculators: although functionally obsolete, we still need to understand the mechanics before we can start taking the shortcut.\n\n\n## The Problem\n\nThe biggest issue that most database solutions solve is that **disks are slow and memory is fast, but we don't have enough memory to store everything we need.**\n\nThink about trying to process hundreds of gigabytes of data on your computer (very common for applications like machine learning), even though you only have something like 16GB of RAM.\n\nIf we want our operations to complete in a reasonable amount of time, we'll want to do as much as possible within RAM. Most of the algorithms you've likely encountered in 61B assume that we have an *infinite* amount of fast memory, and that all operations took the same amount of time, since we only cared about asymptotic runtimes.\n\nHowever, in the real world, reading something from memory could be hundreds of thousands of times faster than reading something from disk. As such, when evaluating the runtime of an algorithm we only care about how long it takes to transfer something from disk into memory so that we can access it. This basic unit of time is what we call the Input-Output cost, or \"an I/O\" for short.\n\n\n## Definition of an I/O\n\n\u003e [!abstract] Summary\n\u003e \n\u003e **An I/O is a single read or write event where one page of data is transferred between memory and disk.**\n\nA **page** is the basic (\"atomic\") unit of information on disk: since it's more efficient than reading one byte at a time, nearly all modern hard drives and SSDs have some hard-coded block size in their firmware, such that any data accessed from them will always be delivered one block at a time. These blocks are then converted into pages, which also have a fixed size, in the operating system.\n\nFor the purposes of this class, **\"block\" and \"page\" can be used interchangably.** In most contexts we will refer to it as a page. However, in general, [there is a difference.](https://stackoverflow.com/questions/22137555/whats-the-difference-between-page-and-block-in-operating-system)\n\nA very important thing to note down is that **there is no such thing as a fractional I/O.** If we need to read 4.1 pages' worth of data, it will really take 5 I/Os since the last page needs to be read in its entirety.\n\n## Applications\n\nThe primary application for evaluating I/O cost is for [query optimization](\u003ccs186/07 Query Optimization\u003e), where we need to decide which operation is the most efficient out of several possibilities. \n\n**Why can't we just use asymptotic runtime?**\n - We're dealing with known, finite input sizes: We may decide to use a different algorithm for a 1000-row table versus a 10000000-row table, even if the algorithm for the former has poorer asymptotic properties.\n - The difference between a $O(n)$ algorithm and an $O(2n)$ algorithm can get extremely noticable when we have millions (or billions) of rows in a table.\n - The runtime depends on the data that we put in. For instance, certain types of joins (like Sort-Merge Join) perform poorly when we have large amounts of duplicate data. Since we already know (or can approximate) what data we have, we can use this knowledge to estimate how much of the data will need to be accessed to complete the operation, which may be dramatically better or worse than its average runtime.\n\n## Practice\n\nHere are some basic I/O problems to test your understanding, before moving onto applying it to more involved algorithms. **For all of the below problems, assume that one page can store 5 (five) integers, and that all available space on a page will be used before a new page is created.**\n\n{{\u003c tabs \"q1\" \u003e}}\n{{\u003c tab \"Q1\" \u003e}}\nAlice has an array `[1, 2, 3, 4, 5]` stored on disk. She changes the `3` into a `6`, then writes the updated array back to disk. How many I/Os did this operation incur? \n{{\u003c /tab \u003e}}\n{{\u003c tab \"Q1 Solution\" \u003e}}\n**2 I/Os**. One to read the entire array (since it's on the same page), and one to write the entire array back.\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n{{\u003c tabs \"q2\" \u003e}}\n{{\u003c tab \"Q2\" \u003e}}\nBob has an array `[10, 7, 9, 8, 6]` stored on disk. He performs an in-place Insertion Sort and reads the result, but does not save it. How many I/Os did this operation incur? \n{{\u003c /tab \u003e}}\n{{\u003c tab \"Q2 Solution\" \u003e}}\n**1 I/O**, which is incurred when Bob reads the entire array from disk. No I/Os are incurred for actually performing the sort, since all of the swapping operations are done in memory which do not count.\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n{{\u003c tabs \"q3\" \u003e}}\n{{\u003c tab \"Q3\" \u003e}}\n**Challenge:** How many I/Os does it take to insert a page at the end of a linked list of $N$ pages? Assume the pointer to the next page is stored within each page (so no additional data is needed).\n{{\u003c /tab \u003e}}\n{{\u003c tab \"Q3 Solution\" \u003e}}\n**N + 2 I/Os.** To find the end of the linked list, we first need to read all $N$ pages. Then, we need to perform 2 writes- one to update the next pointer of the now second-to-last page, and one to write the new page.\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}",
    "lastmodified": "2023-01-07T08:16:30.719337983Z",
    "tags": null
  },
  "/cs61a/": {
    "title": "CS 61A: Computer Programs",
    "content": "\n## Introduction\n\n![Concept map](conceptmap.jpg)\n\nBeing the largest course at Berkeley, CS 61A has a *lot* of existing resources- not to mention John DeNero's recorded lectures are everything you could ever hope for in a lecture. I just don't see how I could contribute any meaningful content note that hasn't been done extremely well multiple times already.\n\nInstead, I want to make a space where you can more easily find all of those resources, share some thoughts about my time TAing for 61A, and provide some dialogue about critical skills not taught in 61A but are necessary for succeeding in the CS major and software engineering.\n\n## The important bits of 61A\n\nCS61A is not really an intro CS class in that it moves *way* too quickly for someone who has never seen any of the concepts covered. This is, by design, a difficult truth of the matter: if you're not prepared for 61A (where it's assumed you've already seen much of the content), you're probably also not prepared for future CS classes that have an even larger amount of more conceptually difficult content.\n\nEven as someone with prior experience, it's easy to get swept up and overwhelmed by the pace. If you're experiencing this, my advice is this:\n\n**Don't get hung up on every detail- you don't need to understand everything perfectly, just the most important concepts.** I didn't feel comfortable with 61A content until teaching it for the 3rd or 4th time, and you probably only have one go at it!\n\nHere's a list of things I think is worth paying attention to, and why you should pay attention to them:\n - **ABSTRACTION:** If there's one word that should be burned into your memory after 61A, it's this. Abstraction is a concept that we take entirely for granted as computer scientists and software engineers- hopefully 61A helps you appreciate why we can't live without it.\n - **Recursion:** Recursion's really weird when you first learn about it- how can you make something call itself and somehow do a useful thing? Yet, recursion is found everywhere, from the lowest levels of computer architecture (61C) to the latest theory (CS70, CS170, etc).\n - **Learning new programming languages quickly:** 61A takes you between two or more languages in a fraction of time most people learn a single one. In future courses, learning new languages is a skill you're assumed to have built up from this experience: for example, 61B makes you learn Java in a week, and CS161 plops an entire project on you in Golang without formal instruction on how to use it. Pay attention to what skills you can carry over from Python, and figure out what helps you pick up new syntax faster (make make a cheat sheet).\n - **Environment diagram intuition:** You will probably never use an environment diagram after 61A/B, but the hope is that getting really good at making them will help you think more like a computer and understand which structures/algorithms are more efficient. Being able to reason through each step of an environment diagram (and maybe deriving the rules without memorizing them) are skills that will carry over to many aspects of computer science.\n\n\n## Taking advantage of resources\n\n\u003e [!summary] Resources Page\n\u003e \n\u003e Go [here](/cs61a/resources) for a list of resources!\n\nDue to the large size of the class, it might be hard to navigate the massive but often limited network of resources available (long OH queues, lots of people asking questions at lecture, etc.). \n\nHere's some tips that helped myself as well as many of my past students who needed extra support:\n - **Ask your TA for help!** TA's are available by email, during OH, or often right before/after discussion. You're welcome to ask them conceptual questions as well as consult them on your particular situation in the class. (Please be considerate of their time though- we're often not paid for the time we spend answering student questions outside of office hours, though we're almost always happy to help when we can!)\n - **Sign up for CSM sections!** CSM is an incredible resource that gives you free access to a tutor. Sections can range anywhere from 1 to 6 people in size, so you're usually able to find the size that works for you.\n - **Go to lab sections!** There's a lot of support in lab sections, and if it's not too busy, you're usually welcome to ask non-lab questions (such as for homework, practice exams, or content). It's a nice space to get work done and have shorter queue times compared to general office hours.\n - **Take good notes!** Taking notes during lecture, lab, and discussion will help you pay closer attention to the content, and have something to look back at when creating your cheat sheet for exams. As an added bonus, maybe you can put them online afterwards and help others :)\n\n## Exam Tips\n\nUnfortunately, only attending class and completing assignments is still not quite enough to guarantee success on exams. Make sure you're getting additional practice!\n\n\u003e [!summary] Exam Tips Page\n\u003e \n\u003e Go [here](/cs61a/midterm-tips) for my test-taking tips!\n\n## How and why you should teach 61A\n\nBeing a student at Berkeley gives you the pretty unique opportunity to teach (and maybe even run) an official course for thousands of students while still being an undergrad.\n\nWhile teaching is definitely not for everyone, it can be an excellent motivator while you're still taking the course to do well-- striving to understand the content well enough to teach it will get you really good with the concepts at hand.\n\nCSM and the AI program both do a great job of lowering the bar of entry for those interested in teaching. If you're sufficiently motivated and have a good grasp of the material, you have an excellent shot at trying it out.\n\n### What's the process for becoming a TA?\n\nThe path to becoming a TA is different for everyone, but this is probably the most common path:\n1. Take the class you want to teach, and do well in it. (Don't worry if you don't- there will be plenty more classes to ace!)\n2. In the semester after, apply to be an AI or a CSM Junior Mentor (applications will be announced at the beginning of the semester in the class forum as well as EECS 101). It might take a semester or two to get accepted due to the demand, but be patient and seek out opportunities in other courses as well!\n3. Either before, during, or after AI/CSM, you can also take CS 370 to improve your pedagogical skills, get more experience with teaching, and stand out among other candidates for teaching positions.\n4. Apply for tutor or reader positions for any classes you'd like to teach (applications will be announced on EECS101 as well, typically due in October/November for Spring, Feb/March for Summer, March/April for Fall). Applying for summer sessions is generally the least competitive, since many existing TA's will probably be interning or doing something else over the summer.\n5. Once you're on course staff, it's generally a matter of time and interest before you become a TA (or head TA).",
    "lastmodified": "2023-01-12T02:36:53.343863941Z",
    "tags": null
  },
  "/cs61a/midterm-tips": {
    "title": "",
    "content": "## Introduction\n\nI get asked a lot about whether I have any advice for doing well on 61A exams, so I thought it would be nice to type some of it out. The following is my opinion/experience only, so feel free to ignore some or all of it if something else is more effective for you!\n\nFor a more complete guide, please visit [https://cs61a.org/articles/studying/](https://cs61a.org/articles/studying/)!\n\n## General Info\n\n- Midterm 1 is *very early* in the semester. The purpose of this is to allow you the option of using the midterm as feedback in case you are considering switching to CS10, CS88, etc.\n- Exams emphasize material covered more recently, but due to the highly cumulative nature of the course you should expect anything you’ve seen so far to appear.\n- Exams generally have three parts:\n    - **What Would Python Do (WWPD)-** similar to WWPD in labs, where you’re given some code and asked about the output/behavior of the code.\n    - **Environment Diagram-** typically 1 per exam. These are very similar to the ED’s we do in lecture and discussion, but may be more difficult.\n    - **Code-writing-** typically ~2-3 per midterm, slightly more for the final. Nearly all exam-type coding problems are fill in the blank, either with multiple choice or short answer.\n- Midterm 1 is worth 40 points, midterm 2 is worth 50, and the final is worth 75. This means that it’s totally ok if you don’t do as well as you’d like early in the semester!\n- The average score for exams is usually somewhere around 55-65% of full score. 61A exams are not curved.\n\n## Topics\n\n### Midterm 1\n\n- Control statements (if, while)\n    - Digit chopping (`%` and `//` to process large integers using `while`)\n- Booleans and conditional statements (and, or, not; short circuiting)\n- Environment diagrams\n- Higher order functions (passing in or receiving another function as a parameter)\n- Lambda functions\n\n### Midterm 2\n\n- Recursion and tree recursion\n    - Partition problems (count coins)\n- Iterators and Generators (yield, yield from)\n- Lists and mutability\n    - Append vs extend, pop vs remove\n    - List slicing\n- Trees\n- Object Oriented Programming\n- Linked Lists\n- Less emphasized: efficiency, string representation (str, repr)\n\n### Final\n\n- Everything from MT1 and MT2\n- Interpreters\n    - REPL\n    - Scheme project design\n    - Eval/apply\n- Scheme\n- Regex\n- BNF\n\n## Suggested Timeline\n\nHere's how I study for 61A exams, and CS exams in general. This might not work for you though, so don't be afraid to experiment and come up with your own list of priorities!\n\n**3-5 days before exam:** \n\n1. Make sure you've watched all of the lectures and caught up on homeworks, labs, etc. I think a lot of students underestimate how important it is to attempt all of the problems: they're given for a reason, and many exam problems will feel very familiar if you understand the homework problems (for example, the pattern of splitting large numbers with `%` and `//` will almost certainly show up on the exam).\n2. Even if it's not required, make a **written** cheat sheet to summarize the most important topics on the exam. I find that typing out notes isn't quite enough for it to sink in, and leaves room for a lot of detrimental shortcuts (copy pasting, linking to existing resources, etc.) It's actually a good sign if you end up not using your cheat sheet at all during the exam, since that means you've internalized everything on it already!\n\n**After the above steps are completed:**\n\n1. Attempt a past semester's exam untimed and with external help (friends, your cheat sheet, Google...). This will give you a taste of the exam's content without making you feel overwhelmed or discouraged at being unable to complete problems on your own just yet.\n2. Carefully review the solutions to the exam after you're done, and make a note of all the problems and topics you need to work on. If needed, add more items to your cheat sheet or re-watch past lectures to gain a better understanding of the topic.\n3. If you still have time, you can repeat steps 1-2 a couple more times until you feel confident in your ability to solve problems on the exam!\n4. Try at least one exam in a more formal setting (timed, no distractions, using only the resources allowed on the actual exam).\n\n## Mental Health\n\nI would argue that especially for CS exams that involve complex problem-solving, feeling your best during the exam is more important than studying after a few hours of practice. Here are some things I always try my best to do:\n\n- **Talk to someone and bounce ideas around before the exam.** This could be a friend, lab partner, TA during office hours, or even a [rubber duck](https://medium.com/@katiebrouwers/why-rubber-ducking-is-one-of-your-greatest-resources-as-a-developer-99ac0ee5b70a#:~:text=By%20definition%2C%20rubber%20ducking%20is,a%20method%20of%20debugging%20code.\u0026text=Very%20often%2C%20by%20rubber%20ducking,to%20do%20any%20Googling%20whatsoever.)! Being able to communicate your strengths, weaknesses, and concerns helps greatly in identifying a battle plan for upcoming studying sessions.\n- **Get 8-9 hours of sleep before the exam.** Even if you're still in the middle of studying, just drop everything and go sleep! I've found that it improves performance far more than that extra hour or two of studying would ever do.\n- **Take a break immediately before the exam.** If you study right up until exam time, you will risk burning out. Take a walk, grab some boba, play some games, read a book, do some push ups- doesn't matter, as long as you're not thinking about 61A or coding in any way.\n- **Expect the worst, hope for the best!** Do whatever you need to in order to stay as relaxed as possible during the exam. Set a low bar for yourself (e.g. you'll try to complete 1 problem at least), and feel good about doing more than that! If you ever blank out, you'll have your cheat sheet to get you un-stuck :)\n- **If you're feeling unwell, don't take the exam!!** We will likely excuse you from this midterm, and your score will be replaced by some function of your MT2 and final scores. You are also welcome to request to take the exam remotely if you are experiencing symptoms but otherwise feel ok.\n\nAnd last of all, remember that the exam is far more inconsequential than you might think, so as long as you show up, do your best, and have fun (honestly, 61A tests are kinda fun without all the stress), everything will be ok!\n\n- For intended-CS stressed about that 3.3 GPA: students consistently get higher grades in 61B than 61A, so you can likely declare even if you don't do as well as you'd like in 61A.\n- For those who just want to pass: exams aren't worth a whole lot, and there are plenty of opportunities for extra credit / recovery, so as long as you turn in *something* and be diligent in completing homeworks/labs/projects you will pass!\n\n## During the Exam\n\n- **Remember your data types!!!!** The one trick that almost singlehandedly got me through 61A exams: before filling out a problem of any kind, read through the code and label any variables, fill-in-the-blank lines, parameters, and return values with what type of object you think they should be (e.g. number, function, string, list...). This will make it much easier to figure out what is happening, especially for reverse ED's and skeleton code problems, since you have now severely restricted the possible answers to each blank.\n    - This also applies for homeworks/labs/projects. Data type mismatches are by far the most common issues that I see when helping out during office hours.\n- **Try to attempt every problem first, before going back to fix your answers.** A blank box is instantly worth 0 points- and oftentimes your split-second intuition can really come in handy for coming up with solutions that are *almost* correct in very little time.\n- **Don't panic!** The midterm's not really that important (as explained above). If something does go wrong during or before the exam that prevents you from doing your best work, you can also contact us (61A staff) to discuss further arrangements.\n\n## FAQ\n\n(Will be populated as more questions arise)\n\n**Q:** How many practice exams should I do?\n\n**A:** As many or few as feels most comfortable for you, but remember that quality \u003e quantity for practice. It's better to do fewer and really understand them, rather than rushing through like 10. I typically do 2-3 for CS courses.\n\n**Q:** This midterm was easier/harder than expected, will the next exam be harder/easier as a result?\n\n**A:** Due to phenomenon of [regression to the mean](https://fs.blog/regression-to-the-mean/), it’s actually more likely than not that this will occur, but not by any intentional acts of malice. Basically, if you took an unusually difficult exam, the next one will probably be more average in difficulty, and thus feel easier than the last one.\n\n**Q:** Will ____ be emphasized on the midterm?\n\n**A:** Not sure; I don’t write the exam. If it was emphasized on previous exams, OR it was specifically mentioned by Pamela that it would be on the exam, then the likelihood that it will be on this exam is high.\n\n**GLHF!** 🥰",
    "lastmodified": "2023-01-12T00:53:15.951812286Z",
    "tags": null
  },
  "/cs61a/resources": {
    "title": "",
    "content": "\nHere are some resources!\n\n\n## My Resources\n\n### Scheme Cheat Sheet\n\nThis cheat sheet was created in Fall 2021 and includes Scheme syntax bits, and correspondences to Python.\n\n[61A Scheme Cheat Sheet](https://docs.google.com/document/d/1Fehiia8fSdXD2XUJpNvVbxG8EDtOmGrnKtSMz09Wmds/edit)\n\n### Discussion and Lab Slides\nThese slides were created by me and presented during the Spring 2022 offering of CS61A.\n\n| Link | Content |\n|------|------|\n| [Discussion 1](\u003chttps://notes.bencuan.me/cs61a/slides/61A Discussion 1.pdf\u003e) | Expressions, values, statements, control, environment diagrams  |\n| [Discussion 2](\u003chttps://notes.bencuan.me/cs61a/slides/61A Discussion 2.pdf\u003e) | Higher order functions |\n| [Discussion 3](\u003chttps://notes.bencuan.me/cs61a/slides/61A Discussion 3.pdf\u003e) | Recursion |\n| [Discussion 4](\u003chttps://notes.bencuan.me/cs61a/slides/61A Discussion 4.pdf\u003e) | Tree recursion, lists |\n| [Discussion 5](\u003chttps://notes.bencuan.me/cs61a/slides/61A Discussion 5.pdf\u003e) | Sequences, mutability, OOP |\n| [Discussion 6](\u003chttps://notes.bencuan.me/cs61a/slides/61A Discussion 6.pdf\u003e) | String representation, trees |\n| [Discussion 7](\u003chttps://notes.bencuan.me/cs61a/slides/61A Discussion 7.pdf\u003e) | Linked lists, iterators, generators |\n| [Discussion 10](\u003chttps://notes.bencuan.me/cs61a/slides/61A Discussion 10.pdf\u003e) | Scheme |\n| [Discussion 11](\u003chttps://notes.bencuan.me/cs61a/slides/61A Discussion 11.pdf\u003e) | Tail Recursion |\n| [Discussion 12](\u003chttps://notes.bencuan.me/cs61a/slides/61A Discussion 12.pdf\u003e) | Programs as Data |\n| [Discussion 13](\u003chttps://notes.bencuan.me/cs61a/slides/61A Discussion 13.pdf\u003e) | Regex, BNF |\n| [Discussion 14](\u003chttps://notes.bencuan.me/cs61a/slides/61A Discussion 14.pdf\u003e) | Some advice |\n| [Lab 1](\u003chttps://notes.bencuan.me/cs61a/slides/61A Lab 1.pdf\u003e) | Python Syntax |\n| [Lab 2](\u003chttps://notes.bencuan.me/cs61a/slides/61A Lab 2.pdf\u003e) | Higher order functions, lambdas |\n| [Lab 4](\u003chttps://notes.bencuan.me/cs61a/slides/61A Lab 4.pdf\u003e) | Recursion, tree recursion |\n| [Lab 5](\u003chttps://notes.bencuan.me/cs61a/slides/61A Lab 5.pdf\u003e) | List comprehensions, mutation |\n| [Lab 6](\u003chttps://notes.bencuan.me/cs61a/slides/61A Lab 6.pdf\u003e) | OOP, inheritance |\n| [Lab 7](\u003chttps://notes.bencuan.me/cs61a/slides/61A Lab 7.pdf\u003e) | Trees, linked lists |\n| [Lab 8](\u003chttps://notes.bencuan.me/cs61a/slides/61A Lab 8.pdf\u003e) | Efficiency |\n| [Lab 10](\u003chttps://notes.bencuan.me/cs61a/slides/61A Lab 10.pdf\u003e) | Scheme |\n| [Lab 11](\u003chttps://notes.bencuan.me/cs61a/slides/61A Lab 11.pdf\u003e) | Interpreters |\n| [Lab 12](\u003chttps://notes.bencuan.me/cs61a/slides/61A Lab 12.pdf\u003e) | Data Abstraction |\n| [Lab 13](\u003chttps://notes.bencuan.me/cs61a/slides/61A Lab 13.pdf\u003e) | Regex |\n| [Lab 14](\u003chttps://notes.bencuan.me/cs61a/slides/61A Lab 14.pdf\u003e) | Final review + tips |\n\n## Other Resources\n\nThese resources were created by other 61A TA's throughout the years.\n\n| Link | Content |\n| -----| ------- |\n| [Official 61A Resource Page](http://cs61a.org/resources) | Go here first!! |\n| [Albert Wu's Notes](http://albertwu.org/cs61a/) | Lots of good practice problems, as well as notes on important, often overlooked topics like debugging, style, vim, and git. |\n| [Jade's 61A Guide](https://jadesingh.org/cs-61a) | Comprehensive 61A notes with practice problems and solutions |\n| [Sequoia's Textbook](https://sequoiatree.github.io/) | A lot of information in textbook format with interactive environment diagrams |",
    "lastmodified": "2023-01-12T01:26:28.175938735Z",
    "tags": null
  },
  "/cs61b/": {
    "title": "Welcome to CS61B!",
    "content": "\n# Welcome to my CS61B Guide!\n\nThis is a **non-comprehensive** guide to data structures written with an intention to supplement learning and reviewing of Berkeley's [CS61B](https://inst.eecs.berkeley.edu/\\~cs61b) material. Main topics include:\n\n* Object oriented programming basics\n* Abstract data types\n* Asymptotics and runtime analysis\n* Sorting algorithms\n* Search algorithms\n* And some more miscellaneous topics thrown in!\n\nThis guide is written to be as easy to follow and digestible as possible😀I've included lots of diagrams, practice problems, and more intuitive explanations instead of the more straightforward approach most textbooks use. **This isn't a replacement for lectures and other course content.** You probably need to look at those first, and come here if something isn't sticking!\n\n### The 61B Concept Map\n\n![](\u003cimg/assets/image (6).png\u003e)\n\n\n\n## Who is this for?\n\nMostly me; making unnecessarily detailed guides is my goto method of making sure I understand everything😁 But you are welcome to use it as well for reviewing for 61B exams, touching up on data structures knowledge, or whatever you want!\n\n**Basic programming knowledge gained from** [**CS61A**](https://cs61a.org/) **or equivalent is assumed.** [[/cs61a|Click here]] for my notes for that!\n\n## How to use this guide\n\nAgain, I will emphasize that this **isn't a textbook.** While I try to be as comprehensive as possible, I'm sure I missed plenty of important concepts or assume you know others. Please [open an issue](https://github.com/64bitpandas/notes/issues) if you think something's wrong!\n\nThis content was ported from my original [61B Notes](https://cs61b.bencuan.me), so you may see some strange formatting here and there. Again, please create an issue if you spot anything overly egregious.\n\n\u003e [!note] Content Note\n\u003e\n\u003e For more difficult topics, I'll put a warning like this at the top of the page with links to prerequisites or supporting topics!\n\n\nThere are also plenty of practice problems to try out! Here's an non-exhaustive list of pages with those if you are mostly interested in them and not the conceptual content.\n\n* [Access Control](/cs61b/oop/access-control.md#practice)\n* [Dynamic Method Selection](/cs61b/oop/dynamic-method-selection.md)\n* [Generic Types](/cs61b/oop/generics.md#generic-subtypes)\n* [Asymptotics Practice](/cs61b/asymptotics/asymptotics-practice.md)\n\n\n\n## How to contribute\n\nSee the [contributing guide](/contributing) for more details!\n\nThe pages that could be most improved (in no particular order) are [Union Find (Disjoint Sets)](/cs61b/abstract-data-types/union-find-disjoint-sets), [Stacks and Queues](/cs61b/abstract-data-types/collections/stacks-and-queues), [Linked Lists](/cs61b/abstract-data-types/collections/linked-lists), [Sets](/cs61b/abstract-data-types/collections/sets), [Sorting](algorithms/sorting), [Searching](/cs61b/algorithms/searching), [Binary Search](/cs61b/algorithms/searching/binary-search), [Shortest Paths](/cs61b/algorithms/shortest-paths/), and [Exceptions](/cs61b/misc-topics/exceptions). Feel free to add whatever content you like (explanations, examples, practice problems, memes...) to these!\n\nAdditionally, there are plenty of topics (Regex, Testing, Files/Scanners, Ranges, GUI just to name a few) that aren't currently covered in this guide. If you want to add one of these topics, please create an issue first but it will almost certainly be approved.\n\n### Credits\n\n* [Ben Cuan](https://github.com/64bitpandas)\n* [Arin Chang](https://github.com/arinchang)\n",
    "lastmodified": "2023-01-12T02:22:25.769212536Z",
    "tags": null
  },
  "/cs61b/abstract-data-types/": {
    "title": "",
    "content": "",
    "lastmodified": "2023-01-06T09:29:04.786658104Z",
    "tags": null
  },
  "/cs61b/abstract-data-types/binary-trees/": {
    "title": "",
    "content": "\n\u003e [!quote] \u0026nbsp;\n\u003e\n\u003e \"The most important concept in computer science\" - Josh Hug\n\n## Humble Origins\n\nLinked lists are great, but we can do better! Let's try **rearranging the pointers** in an interesting way.\n\nInstead of starting at one end of the list, let's set our first pointer at the **middle** of the list!\n\n![](\u003c../../img/assets/image (69).png\u003e)\n\nNow, let's make new pointers going to the **center** of each **sublist** on the left and right of the center.\n\n![](\u003c../../img/assets/image (70).png\u003e)\n\nLet's do it again!\n\n![](\u003c../../img/assets/image (71).png\u003e)\n\nWould ya look at that, we've got a **tree**! 🌲\n\n![🌲🌲🌲🌲🌲](\u003c../../img/assets/image (73).png\u003e)\n\n## Types of Trees\n\nRight now, we can determine some properties that all trees have.\n\n* All trees have a **root node**.\n* All nodes can point to **child nodes.** Or, if they don't have any children, they are **leaves.**\n\nWe can add more and more constraints to our tree to make them more useful!\n\nFirst, let's add the constraint that **node can only have 2 or fewer children** to create a **binary tree.**\n\nThen, let's **ensure our tree is sorted** to create a **binary search tree.** A tree is sorted if it has these properties:\n\n* Every value in the **left subtree** of a node is **less than** the node's value.\n* Every value in the **right subtree** of a node is **greater than** the node's value.\n* Values are **transitive** - there are **no duplicate values**.\n* The tree is **complete** - it is possible to **compare any two values** in the tree and say that one is **either less than or greater than the other.**\n* The tree is **antisymmetric** - If `p \u003c q` is true and `q \u003c r` is also true, then it must follow that `p \u003c r`.\n\n## Tree Operations\n\nThere are **three important operations** that trees should support: **find, insert, and delete.**\n\n### **Find**\n\nFinding a value in a tree uses the [Binary Search](../../algorithms/searching/binary-search.md) algorithm. \n\n\n### Insert\n\nThe insert algorithm is **very similar to binary search.** Here are the steps to take:\n\n* Search for the item. **If it's found, then do nothing** since the value is already in the tree.\n* If it's not found (search would return null in this case), then create a node and put it where it should be found. If using recursion, this last step is already done- all we need to do is return a new node!\n\nHere's the algorithm:\n\n```java\npublic BST insert(BST T, Key sk) {\n    if (T == null) {\n        // Create new leaf with given key. Different from search\n        return new BST(sk, null, null); \n    }\n    if (sk.equals(T.key)) {\n        return T;\n    } else if (sk \u003c T.key) {\n        T.left = find(T.left, sk); // Different from search\n    } else {\n        T.right = find(T.right, sk); // Different from search\n    }\n}\n```\n\n### Delete\n\nThis one's a bit trickier because we need to make sure that the new tree still **preserves the binary search tree structure.** That means that we might have to shuffle around nodes after the deletion. There are **three cases:**\n\nA) The node to delete is a **leaf**. This is an easy case- just remove that node and you're done!\n\n![Deleting a leaf.](\u003c../../img/assets/image (64).png\u003e)\n\nB) The node to delete has **one child.** In this case, **swap** the node with its child, then **delete the node.**\n\n![Deleting a node with one child.](\u003c../../img/assets/image (65).png\u003e)\n\nC) The node to delete has **two children.** This one's trickier, because we still need to preserve the tree structure! In this case, we have to **traverse the node's children** to find the **next biggest value** and swap that up to replace the old node.\n\n![Deleting a node with two children.](\u003c../../img/assets/image (66).png\u003e)\n\n## Asymptotic Analysis\n\nA binary tree can be **bushy** or **spindly.** These two cases have dramatically different performances!\n\n**Bushy** trees are the **best case.** A tree is bushy if **every parent has exactly 2 children.**\n\nA bushy tree is guaranteed to have a height of $\\Theta(\\log(n))$ which means that the runtimes for adding and searching will also be $\\Theta(\\log(n))$ .\n\n**Spindly** trees are the **worst case.** A tree is spindly if **every parent has exactly 1 child.** This makes the tree essentially just a linked list!\n\nA spindly tree has a height of  $\\Theta(n)$ which means that the runtimes for adding and searching will also be $\\Theta(n)$ .\n\n![](\u003c../../img/assets/image (67).png\u003e)\n\nIn [Balanced BSTs](balanced-search-structures.md), we will explore ways of guaranteeing that a tree is bushy!\n\n## Limits of Trees\n\nWhile trees are extremely versatile and fantastic for a variety of applications, trees have some limitations that make it difficult to use in some situations.\n\n* **All items in a tree need to be comparable.** We can't construct a binary tree out of categorical data, like models of cars, for example.\n* **The data must be hierarchical.** If data can be traversed through in multiple ways, or forms loops, [Graphs](../graphs.md) are probably better.\n* **The best case runtime is** $\\Theta(\\log(n))$ . This might seem good, but other data structures like [Tries](tries.md) and [Hash Tables](../hashing.md) can be as good as **** $\\Theta(1)$ !\n\n## Tree Traversals\n\nCheck out these pages for information on how to go through each element of a tree!\n\n[Depth First Search](../../algorithms/searching/depth-first-search-dfs.md)\n\n[Breadth First Search](../../algorithms/searching/breadth-first-search-bfs.md)\n\n",
    "lastmodified": "2023-01-06T10:09:43.531029438Z",
    "tags": null
  },
  "/cs61b/abstract-data-types/binary-trees/balanced-search-structures": {
    "title": "",
    "content": "\n\u003e [!info] Content Note\n\u003e\n\u003e Please read [Binary Trees](/cs61b/binary-trees) before continuing!\n\n\n**Balanced Binary Search Trees** are an even more specific subcategory of binary trees that have an important property: **they are always bushy.**\n\n## B Trees (2-4 Trees)\n\n**The basic idea:** Nodes can hold multiple values now! When nodes have too many values, we will split it.\n\nA **2-4 tree** is named such because each parent can have **2 to 4 children.** Another constraint we will put on is a **limit on the** **number of items allowed in a single node**, so that we can guarantee that searching a single node will always be $\\Theta(n).$\n\n### **Adding Values to a B-Tree**\n\nAdding values to a B Tree can be a bit tricky because we need to make sure all the properties are still followed. Here are some example scenarios:\n\nIf a node already has 2 or more children, place the new value in one of its existing children.\n\n![](\u003c../../img/assets/image (81).png\u003e)\n\nIf a node is full (reaches the limit), we must **split the node** by **moving one value up to the parent** and **creating another child node**. Here, we'll use a limit of **3**.\n\n![](\u003c../../img/assets/image (82).png\u003e)\n\n### Properties of B Trees\n\n* Searching in a single node is **constant runtime** since the limit is a constant.\n* All leaves must be the **same distance** from the root.\n* A non-leaf node with **k** items must have **k+1** children.\n* The height of a B tree is guaranteed to be $\\Theta(\\log(n))$ because it is bushy.\n\n## Red-Black Trees and Tree Rotation\n\n**The basic idea:** Let's try to represent B trees in a **binary tree format.** That means that every parent can only have 2 children! In order to do this, we'll **add an extra color property** to each node.\n\n**Black nodes** are just like any normal binary tree node, but **Red nodes** represent the nodes in B Trees that have **more than one value.** For example, let's convert the B Tree we were working with before into a RB Tree.\n\n![](\u003c../../img/assets/image (83).png\u003e)\n\nIn order to make our lives easier, we'll restrict our Red Black trees into **left leaning red black trees** which can **only have red nodes on the left.**\n\n### **Tree Rotation**\n\nIn order to ensure that adding new nodes won't break the Red Black Tree structure, we will use a concept called **tree rotation** which swaps around nodes. There are two rotations, a **left rotation** and a **right rotation,** which move a child node up to replace its parent. For example, a **left rotation** moves the **right node up and left** to replace the parent.\n\nA \"left rotation on 7\" looks like this:\n\n![](\u003c../../img/assets/image (84).png\u003e)\n\nNotice that the **8** gets moved to be a **right child** of **7** after the rotation! This is necessary to preserve the binary tree structure.\n\nA \"right rotation on 7\" looks like this:\n\n![](\u003c../../img/assets/image (85).png\u003e)\n\nHere, the **6** gets moved to be a **left child** of **7.**\n\nIf you want to see how these rotations can be implemented into the `insert` algorithm, [try the homework](https://inst.eecs.berkeley.edu/\\~cs61b/sp20/materials/hw/hw8/index.html) on implementing a LLRB Tree! Below is a brief outline on how insert works:\n\n* **Always add values to a leaf node as a red node first.** Follow normal sorted binary tree rules.\n* If the link is leaning right, rotate the tree to make it left leaning.\n* If a node already has a red link to the left, temporarily add it to the right also as a red link.\n  * Then, flip the color of all links connected to the node (if previously black, turn red; if previously red, turn black)\n  * Might need to fix right-leaning red nodes that are created as a result\n* If a node has red links to both parent and child, rotate it such that it becomes the above case, and then handle that case like you did before.\n\n### Properties of Red Black Trees\n\nLike B Trees, Red Black Trees have some important properties that allow them to be easily distinguishable.\n\n* Red Black trees have a **one-to-one correspondence** with B trees. That means for every Red Black tree, there is exactly one B Tree that represents the same connections. This also means that a Red Black Tree will have the same runtimes as their corresponding B Trees. (Take a linear algebra course to learn more about isomorphisms 🙂 )\n* **Every node must have the same number of black nodes in between itself and the root.** This might be a bit surprising at first, but remember that their corresponding B Tree is always bushy, and red links mean a multi-value node in a B Tree.\n",
    "lastmodified": "2023-01-10T21:41:21.612906286Z",
    "tags": null
  },
  "/cs61b/abstract-data-types/binary-trees/heaps": {
    "title": "",
    "content": "## What are Heaps?\n\nA heap is a **specific order of storing data,** often in a list. Heaps are very similar to binary trees, but have some differences:\n\n* Unlike trees, heaps **only care about the root node.** Usually, the root node is either the **largest** or **smallest** value in the heap (corresponding with max-heaps and min-heaps), and we don't care too much about the rest.\n* Every element in the heap must be **larger than all its children** (in a max-heap) or **smaller than all its children** (in a min-heap). This is known as the **heap property.**\n\nWhen stored in a list, there is an **important rule** to figure out how to identify parent nodes and their children: **a node's parent has an index equal to half of that node's index.** More specifically, `parentIndex = nodeIndex / 2` where `/` has floor-division properties.\n\n![Converting a heapified list into a min-heap diagram.](\u003c../../img/assets/image (60).png\u003e)\n\n## The Heapify Algorithm\n\nThe most important heap algorithm is **heapify**, which converts any non-heap list into a heap. This algorithm is vital to most heap functions like insert or remove, since these functions often break the heap structure before fixing it with heapify.\n\n**Here's how it works:**\\\n****(This example is an excerpt from my [Sorting Guide](https://docs.google.com/document/d/1dUfzdh5V3okrwFbB9o0PgtEBaLHyCqJFwpQWyQ53IeU/edit). The example provided is a max-heap \\[5,6,2,4,1].)\n\nStart with the element in the middle of the array (which is the root of the heap).\n\n![](\u003c../../img/assets/image (61).png\u003e)\n\nIf the root is smaller than either of its children (larger for a min-heap), swap it with its largest child (smallest for a max-heap).\n\n![](\u003c../../img/assets/image (62).png\u003e)\n\n\n\nIf the root was swapped, recursively call heapify on the new position. Otherwise, stop recursion.\n\nAfter heapify is complete, it should look like this:\n\n![](\u003c../../img/assets/image (63).png\u003e)\n\n## Practical Applications\n\n[Lab 9](https://inst.eecs.berkeley.edu/\\~cs61b/sp20/materials/lab/lab9/index.html) is a fantastic resource for practicing heap implementations and working with the algorithms that are needed to work with heaps (like heapify, insert, remove). Since this lab goes into plenty of detail about how each of these algorithms work, I won't explain them too much here.\n\nHeap sort relies on the heap structure to provide consistent nlogn sorting! I have more information about this on page 11 in my [sorting guide](https://docs.google.com/document/d/1dUfzdh5V3okrwFbB9o0PgtEBaLHyCqJFwpQWyQ53IeU/edit).\n",
    "lastmodified": "2023-01-06T10:09:52.386930974Z",
    "tags": null
  },
  "/cs61b/abstract-data-types/binary-trees/tries": {
    "title": "",
    "content": "## Main Ideas\n\nA **trie** is a specific implementation of a set and is short for **retrieval tree.**\n\nIt only works on sets with a **finite alphabet**, like digits or ASCII characters, for example. The idea is that each node can act like an **array containing all characters in the alphabet** and we can just access the branches super fast by indexing into them!\n\nTries are fantastic for searching to see if a word is contained in a set. Here's an example:\n\n![This trie contains the words 'batcat', 'batman', and 'banana'.](\u003c../../img/assets/image (74).png\u003e)\n\nThis is great because it makes the `add()` and `contains()` functions run in $\\Theta(1)$ time! Additionally, it makes special string operations like prefix matching or autocomplete very efficient.\n\nWe can improve this data structure a lot- for instance, we can condense the leaves to reduce the number of nodes like this:\n\n![](\u003c../../img/assets/image (75).png\u003e)\n\nI won't go into too much detail on how to optimize it further, or how to implement the actual functions efficiently, but hopefully you'll have a good sense of how to do it yourself after learning about concepts like [Hashing and Hash Tables](/cs61b/abstract-data-types/hashing.md) or [Sets](/cs61b/abstract-data-types/collections/sets.md) etc.\n",
    "lastmodified": "2023-01-10T21:53:10.982797011Z",
    "tags": null
  },
  "/cs61b/abstract-data-types/collections/": {
    "title": "",
    "content": "\n![An overview of all the Collections in Java.](\u003c../../img/assets/image (3).png\u003e)\n\n**Collection** is a Java interface for common abstract data types that store multiple items in them.\n\n## Sub-Interfaces\n\n* **Lists** are indexed sequences with duplication. The two most common types are [**ArrayLists**](/cs61b/abstract-data-types/collections/arrays.md#array-lists)  and [**Linked Lists**](linked-lists.md).\n* [**Sets**](/cs61b/abstract-data-types/collections/sets.md)  are non-indexed sequences with no duplication. (That is, every value in a set is unique.)\n* **Maps** are key-value pairs. See [Hashing and Hash Tables](/cs61b/abstract-data-types/hashing.md) for a description on one common map implementation, the HashMap. All keys in a map must be unique, but values can be duplicated.\n* [**Stacks and Queues**](/cs61b/abstract-data-types/collections/stacks-and-queues.md)  are two ordered collections that have two core behaviors:\n  * push(T x): puts x on the top.\n  * pop(): Removes the first item. (See the stacks and queues page for more information.)\n\n## Common Functions\n\n* **Membership tests** `contains()` and `containsAll()` that can determine whether or not an element is in the collection.\n* `size()` to get the number of items in the collection.\n* `isEmpty()` returns true if there is nothing in the collection.\n* `iterator()` returns an Iterator object to go through all the values in the collection.\n* `toArray()` converts the collection to a standard Java array.\n* **Optional** functions that aren't implemented in the interface: `add, addAll, clear, remove, removeAll, retainAll (intersection)`\n  * Throws `UnsupportedOperationException` if not implemented.\n",
    "lastmodified": "2023-01-10T21:46:31.25034943Z",
    "tags": null
  },
  "/cs61b/abstract-data-types/collections/arrays": {
    "title": "",
    "content": "\n\u003e [!info] Content Note\n\u003e\n\u003e This page assumes prior knowledge of Python lists from CS61A or equivalent.\n\nArrays are a very popular data structure that stores an indexed list of data. \n\n\n![An artistic interpretation of a new int\\[5\\] {6, 1, 2, 3, 99};](\u003c../../img/assets/image (37).png\u003e)\n\n## Properties\n\n* **Fixed length:** after instantiation, the length of an array cannot be changed.\n* Every value in array is the **same type** and holds the **same amount of bits** in memory.\n* **Zero-indexed.** That means `arr[0]` returns the first value, and `arr[arr.length]` is out of bounds.\n* **No methods.** Helper methods from other libraries (like `System.arraycopy`) need to be used to manipulate arrays.\n* **Retrieval is independent of size** and takes constant time regardless of how big arrays are.\n\n## Using Arrays in Java\n\n**Instantiation:**\n\n* `int[] a = {1, 2, 3, 4, 5};` assigns values.\n* `int b = new int[3];` creates array of provided length populated with default values.\n\n**Copying**\n\n* Simply assigning `int[] c = b` will copy the **pointer** to array b! Not the values! See [Java Objects](/cs61b/oop/objects.md) for a discussion on why this is significant.\n* Use `System.arraycopy(source, start, target, startTarget, amountToCopy)` to **shallow copy** the values (or pointers) in the array. That is, if an array is holding **reference types,** only the pointers will be copied and not the actual values of the reference objects being held.\n* `System.arraycopy(b, 0, x, 3, 2)` is equivalent to `x[3:5] = b[0:2]` in Python.\n\n**Multidimensional Arrays**\n\n* `int[][] 2d = new int[4][4];`or `int[][] 2d = new int[][] {{1}, {2, 3}, {4, 5, 6}};`will create **arrays inside of an array.** This is useful for storing matrices, coordinate maps, or any other multidimensional data!\n\n**Generic Arrays**\n\n* Arrays of generic objects are NOT allowed! Use ArrayLists instead.\n* Or, this workaround can be used:`Type[] items = (Type[]) new Object[length]`\n\n## Array Lists\n\nJava has another built-in type that uses an array under the hood, which is the `ArrayList`. Here's how ArrayLists are different from normal arrays:\n\n* ArrayLists can resize arbitrarily. (They use something similar to the array case study in the [Amortization](/cs61b/asymptotics/amortization.md#what-if-we-doubled-the-size-instead-of-adding-one) page.\n* ArrayLists use [Generic Types](/cs61b/oop/generics) and therefore do not support primitive types like `int`.\n* ArrayLists have all behaviors expected from the [Collections](/cs61b/collections) interface.\n",
    "lastmodified": "2023-01-10T21:48:05.345532301Z",
    "tags": null
  },
  "/cs61b/abstract-data-types/collections/linked-lists": {
    "title": "",
    "content": "\n\u003e [!info] Content Note\n\u003e\n\u003e This page assumes prior knowledge of linked lists from CS61A or equivalent. I'll assume you have already worked with basic singly linked lists before.\n\n\nThe linked list is an extremely common recursive data structure that allows storage and access of an arbitrary amount of data.\n\n## Feature List of an Effective Linked List\n\n1. **Rebranding**- represents Node as an individual object rather than having one monolithic List type.\n2. **Bureacracy:** Create an abstraction barrier so that users do not need to know how methods or Nodes work, only how to call them.\n3. **Access Control:** Data cannot be accessed directly to prevent dangerous behavior; only the provided methods are used.\n4. **Nested Class:** Nodes are nested within the List object since other classes do not need it.\n5. **Caching:** The size of the list is incremented every time a node is added, so running size() is O(1) and traversal is not needed.\n6. **Generalizing:** A **sentinel node** represents an empty list and remains the first node of the list. When getFirst() is called, the second node is actually returned (since the first node is always the sentinel).\n7. **Doubly Linked:** Nodes have both first and last pointers for even faster traversal.\n8. **Circular list:** Sentinel last pointer points to the last value in the node, allowing for fast removeLast().\n\n![An illustration of an effective linked list.](\u003c../../img/assets/image (36).png\u003e)\n\n## Method List\n\n| Method                                                               | Description                                      | Optimal Runtime |\n| -------------------------------------------------------------------- | ------------------------------------------------ | --------------- |\n| \u003cp\u003e\u003ccode\u003eaddFirst(T x)\u003c/code\u003e\u003c/p\u003e\u003cp\u003e\u003ccode\u003eaddLast(T x)\u003c/code\u003e\u003c/p\u003e    | Adds a node to the front/back of the list.       | $\\Theta(1)$   |\n| \u003cp\u003e\u003ccode\u003egetFirst()\u003c/code\u003e\u003c/p\u003e\u003cp\u003e\u003ccode\u003egetLast()\u003c/code\u003e\u003c/p\u003e          | Gets the node at the front/back of the list.     | $\\Theta(1)$   |\n| \u003cp\u003e\u003ccode\u003eremoveFirst()\u003c/code\u003e\u003c/p\u003e\u003cp\u003e\u003ccode\u003eremoveLast()\u003c/code\u003e\u003c/p\u003e    | Removes the node at the front/back of the list.  | $\\Theta(1)$   |\n| `size()`                                                             | Returns the number of nodes in the list.         | $\\Theta(1)$   |\n| `contains(T x)`                                                      | Returns true if the list contains element `x`.   | $\\Theta(n)$   |\n| \u003cp\u003e\u003ccode\u003eadd(T x, int pos)\u003c/code\u003e\u003c/p\u003e\u003cp\u003e\u003ccode\u003eremove(T x)\u003c/code\u003e\u003c/p\u003e | Adds/remove an element at an arbitrary location. | $\\Theta(n)$   |\n\n## Limitation: Arbitrary Retrieval\n\nYou may have noticed in the chart above that it takes $\\Theta(n)$  time to retrieve arbitrary values from the list. This will get really slow if the list is large! If arbitrary values need to be accessed frequently, [Arrays](arrays.md) are much better.\n\n## The Java List Interface\n\nJava has a built-in `LinkedList` class so you don't have to implement it yourself! Read up on the [official docs](https://docs.oracle.com/javase/8/docs/api/java/util/LinkedList.html/) to learn more about the specific methods and behaviors provided.\n\n",
    "lastmodified": "2023-01-06T10:10:13.090700981Z",
    "tags": null
  },
  "/cs61b/abstract-data-types/collections/sets": {
    "title": "",
    "content": "\n\u003e [!warning] Warning\n\u003e\n\u003e This page is incomplete. [help make it better!](/contributing.md)\n\n## Basics\n\nA Set stores a collection of values with **no duplicates.** Sets have no inherent order, so you can't rely on expecting any value to come before any other value when iterating through them.\n\nSome set functions include:\n\n* `add(T x)`\n* `contains(T x)`\n* `size()`\n\n## ArraySet\n\nAn ArraySet is an array-based solution to a set implementation.\n\n* Objects get added to an array that gets [resized](../../asymptotics/amortization.md) when it's too full.\n* In order to allow for iteration, we can use one of two methods:\n  *   One method is to use **iterators** which work very similarly to Python iterators:\n\n      ```java\n      Iterator\u003cInteger\u003e seer = set.iterator();\n      while (seer.hasNext()) {\n        System.out.println(seer.next());\n      }\n      ```\n  * Another method is to implement the `Iterator` and `Iterable` interface.\n    * Iterator must implement `hasNext()` and `next()` methods\n    * Requires generic type\n    * Iterable must implement `iterator()` method which returns the Iterable object\n    * Allows usage of for/foreach loops\n",
    "lastmodified": "2023-01-10T21:52:13.415319794Z",
    "tags": null
  },
  "/cs61b/abstract-data-types/collections/stacks-and-queues": {
    "title": "",
    "content": "\nStacks and queues are two very common data structures used for a variety of applications from [CPU processes](https://www.tutorialspoint.com/operating\\_system/os\\_processes.htm) to [finding shortest paths using Dijkstra's Algorithm](/cs61b/algorithms/shortest-paths/dijkstras-algorithm.md). Fundamentally, they are very similar in structure and **only differ by the order in which items are popped from them**.\n\n## Pushing and Popping\n\n### Pushing\n\nAdding an item to a stack or queue is called **pushing**. This will either put the item on the **top** of a stack or in the **back** of a queue.\n\nYou can think of a stack like a pile of pizza boxes- the one on the top is the first one you have to take off if you need one!\n\n![](\u003c../../img/assets/image (52).png\u003e)\n\nOn the other hand, you can think of a queue like lining up for a ride at Disneyland. The first person who gets in line will get to go first, and the last person who gets in will go last. (Of course, we all know people cut and stuff- see [Priority Queues](/cs61b/collections/stacks-and-queues.md#priority-queues) to see how this is better handled.)\n\n![those lines tho](\u003c../../img/assets/image (54).png\u003e)\n\n### Popping\n\nTaking an item out of a stack or queue is called **popping.**\n\nStacks are **last in, first out (LIFO).** That means the last item that you put in will be the first item that gets popped.\n\nQueues are **first in, first out (FIFO).** That means that the first item that you put in will be the first item that gets popped.\n\n## Priority Queues\n\nLet's say you bought a VIP pass and get to cut to the front of the line for your favorite Disneyland ride! Well, a normal Queue won't be able to model this behavior since it puts everything in the back by default.\n\nA priority queue will solve this design need by introducing a new **priority** **tracking system** for each item in the queue! **If an item has a lower priority number, it will get to go first.**\n\n![gotta grab those fastpasses yEEt 🎟](\u003c../../img/assets/image (53).png\u003e)\n",
    "lastmodified": "2023-01-10T21:52:04.855397269Z",
    "tags": null
  },
  "/cs61b/abstract-data-types/comparables-and-comparators": {
    "title": "",
    "content": "\n## What is it?\n\nA **Comparable** is a **generic type** that allows standardized comparisons between objects.\n\nIn other words, anything that has a `compareTo()` method can be a Comparable!\n\nMany Java libraries already use Comparable without you knowing! Some of the more well-known ones are `Collection` and `String`.\n\n### CompareTo can't return anything you want!\n\nThere are some very specific properties CompareTo needs to have! Usually, we take them for granted but might forget about them when making our own.\n\n* If `x` and `y` are the **same object**, `y.compareTo(x)` must return **0.**\n* `x.compareTo(y)` must return the **negative** of `y.compareTo(x)`. (if one throws an error, the other must too!)\n* If `x` and `y` are the **same object**, `x.compareTo(z)` must **equal** `y.compareTo(z)` **for all z.**\n\n### Defining a Comparable subclass\n\n```java\npublic class MyComparable implements Comparable\u003cMyComparable\u003e {\n    public int foo;\n    ...\n\n    /** Instance method that has nothing to do with comparable */\n    public void doSomething() {\n        ...\n    }\n\n    /** Comparable method used to compare objects of this type */\n    public int compareTo(Object o) {\n        MyComparable mc = (MyComparable) o;\n        return ...\n    }\n}\n```\n\n## **Comparators**\n\nComparators are used instead of higher order functions in order to provide a **callback** function to methods. One example of where it is used commonly is `Collections.sort`. You can pass in a comparator here to change how items are sorted- for example, you could sort `Person` objects by their `height` variable.\n\n**The interface is as follows:**\n\n```java\npublic interface Comparable\u003cT\u003e {\n int compare(T o1, T o2);\n}\n```\n\n### How is it different from Comparables???\n\nComparable is used to compare **itself** to **other objects**; a Comparator compares **two other objects but not itself.**\n\n",
    "lastmodified": "2023-01-06T09:29:31.142313179Z",
    "tags": null
  },
  "/cs61b/abstract-data-types/graphs": {
    "title": "",
    "content": "\n## Introduction\n\nGraphs are simply a collection of **vertices** connected by **edges.** They're very similar to trees, but are much more versatile and don't require hierarchical relationships like trees do.\n\n![A very simple graph.](\u003c../img/assets/image (55).png\u003e)\n\nFor most purposes, we will be working with **simple graphs** that follow two rules:\n\n* There are **no loops** (a connection of a node to itself).\n* There are **no parallel edges** (two edges that connect the same two vertices).\n\n![Don't make these graphs pls. Keep life simple!](\u003c../img/assets/image (56).png\u003e)\n\n## Graph Properties\n\nGraphs can be described by some properties that they could have. Here are the important ones:\n\nA graph can be **directed** if edges are arrows and have a direction, or **undirected** if you can cross edges in any direction.\n\nA graph is **cyclic** if the edges form a loop, or **acyclic** if there are no loops (like in a tree).\n\n![Direction vs. Cycles](\u003c../img/assets/image (57).png\u003e)\n\nGraphs can have **edge labels** if edges are numbered (great for distances). They can also have **vertex weights** if vertices are numbered (great for priorities or costs).\n\n![Edge labels vs. Weights](\u003c../img/assets/image (58).png\u003e)\n\nGraphs are **connected** if all of the vertices are connected with edges, such that you can freely move from one vertex to any other vertex.\n\n![](\u003c../img/assets/image (59).png\u003e)\n\n## Graph Queries\n\nHere are some cool things you can do with graphs:\n\n* Is there a path between two vertices? (s-t path)\n* What is the shortest route between two vertices? (shortest s-t path)\n* Are there cycles? (cycle detection)\n* Can you visit each vertex/edge exactly once? (Euler tour / Hamilton tour)\n* Is a graph connected? (connectivity problem)\n* Is a vertex that disconnects the graph when removed? (single point of failure / biconnectivity)\n* Are two graphs isomorphic?\n* Can a graph be drawn with no crossing edges? (planarity)\n\n## More on Graphs\n\n[Depth First Search (DFS)](/cs61b/algorithms/searching/depth-first-search-dfs.md), [Breadth First Search (BFS)](/cs61b/algorithms/searching/breadth-first-search-bfs.md), [Minimum Spanning Trees](/cs61b/algorithms/minimum-spanning-trees/), [Shortest Paths](/cs61b/algorithms/shortest-paths/), [Dijkstra's Algorithm](/cs61b/algorithms/shortest-paths/dijkstras-algorithm.md), [A\\* Search](/cs61b/algorithms/shortest-paths/a-search.md), [Prim's Algorithm](/cs61b/algorithms/minimum-spanning-trees/prims-algorithm.md), and [Kruskal's Algorithm](/cs61b/algorithms/minimum-spanning-trees/kruskals-algorithm.md) all rely on graphs. Graphs are a super useful concept!!!\n",
    "lastmodified": "2023-01-10T21:51:37.783641831Z",
    "tags": null
  },
  "/cs61b/abstract-data-types/hashing": {
    "title": "Hashing and Hash Tables",
    "content": "\n## Data Indexed Sets: Introduction\n\nSo far, we've explored a whole bunch of ways we can store items, but they aren't really optimized for general searching. What if we could get searching in $\\Theta(1)$ time??? Wouldn't that be nice!\n\nLet's try something: **putting all of our data in a massive array.** Let's say that we know all our data falls into the range from 0 to 10,000 and make an array of 10,000 length to hold stuff.\n\n![](\u003c../img/assets/image (86).png\u003e)\n\nHere, it doesn't matter what index each item is stored in- if we want to get \"eecs\" which is stored at key 3, it will be as instantly accessible as \"haas\" which is all the way in 9998.\n\nOf course, this has a **major design flaw** that you can probably see right away. **It takes way too much memory!**\n\n## Hash Codes\n\nLet's figure out a way to get around the issue of space, but still not lose our awesome constant-time property. One way we can do this is to represent each item with a **hash code** and store them into the index with that hash code.\n\nFor instance, let's use the **first letter of a word** as the hash code. We have just turned a nearly infinite space of possibilities into something that can be stored in just **26** **buckets.**\n\n![](\u003c../img/assets/image (87).png\u003e)\n\nWhile this solution is great, it still has another **major drawback**, which can be illustrated with this example:\n\n![](\u003c../img/assets/image (88).png\u003e)\n\nIn the worst case, this just turns back into a **linked list!** That means the runtime just went from O(1) to O(n), and that's no good.\n\n## Good Hash Codes\n\nIf we can somehow create a \"good\" hash code, we can prevent things like the example above from happening because there shouldn't be a clear pattern in what buckets different objects go to. More specifically, a good hash code:\n\n* Ensures that two objects that are **equal** have the **same hash code.**\n* Ensures that **no distinguishable pattern** can be made out of hash codes from different objects.\n* Returns a **wide variety** of hash codes (not just putting everything into a single bucket, for example).\n\nLuckily, Java already handles hash code generation for us using the `hashCode()` function in the Object class. This function returns an **integer** that can be used to create good hash tables.\n\n## Dynamic Resizing\n\nLet's add another feature to our hash table: **dynamic resizing.** This means that the number of buckets will increase proportionally to the number of items in the set.\n\nOne fairly simple way to do this with a numerical hash code is to mod the hash code by the number of buckets to get which bucket an item is stored in. For example, if a item has hash code `129382981` and we have `10` buckets, then we put it in bucket `1`, or `129382981 % 10`.\n\nIn order to do this, we'll choose a **load ratio** at which to resize. This load ratio is calculated as `N/M`, where N is the number of items and M is the number of buckets. For example, a load ratio of 2 will mean the table resizes when, on average, each bucket has 2 items in it.\n\nWhen resizing, we must **recompute all the hash codes** so that we can balance out all of the buckets again.\n\nThis has some cool runtime implications that are closely related to [Amortization](/cs61b/asymptotics/amortization.md). Like what happened in the dynamically resizing array, resizing hash tables like this is also a $\\Theta(1)$ operation. Nice!\n\n## Java Hash Tables\n\nIn Java, hash tables are used in the data structures `HashSet` and `HashMap` which are the most popular implementation of sets and maps.\n\nThese two implementations provide **fantastic performance** and **don't require values to be comparable** like trees do.\n\nHowever, they have a drawback that must be considered: **objects cannot be modified after they are put into the hash table.** This is because mutating an object will change its hash code, which means that the object will be lost forever since its bucket doesn't match the current hash code!\n\nIf the built-in hash code generator isn't what is needed (like you want two objects to be equal if they have the same size, for instance), you can override the `hashCode()` method. **Be careful when doing this** because `hashCode()` relies on `equals()` to find which bucket objects are in! So, if hashCode is overridden, it is highly recommended to override equals as well to ensure that they are compatible.\n",
    "lastmodified": "2023-01-10T21:50:16.540371253Z",
    "tags": null
  },
  "/cs61b/abstract-data-types/union-find-disjoint-sets": {
    "title": "Union Find (Disjoint Sets)",
    "content": "\n# Union Find (Disjoint Sets)\n\n\u003e [!info] Content Note\n\u003e\n\u003e This is not a complete entry, because I feel like existing course materials already cover this in an extremely intuitive manner. See[ lab 14](https://inst.eecs.berkeley.edu/~cs61b/sp20/materials/lab/lab14/index.html) for an guide on how to implement your own Union Find structure!\n\nThe Union Find data structure is a way of representing a bunch of nodes that are connected to each other in subsets. It's used in [Kruskal's Algorithm](/cs61b/algorithms/minimum-spanning-trees/kruskals-algorithm.md) among other things.\n\nUnion Find is named as such because it supports two functions, **find** (which returns the group that a value is contained in), and **union** (which connects two values to form a single group).\n\nUnion Find tracks each set with an ID, typically **the value of the root of each set.** In the sections below, we'll discuss how to add an item to a set, as well as figure out which set an existing item is in.\n\n## Union\n\nIn order to **join two values together,** we need to use the **union** function. Let's see what it does visually:\n\n![Calling union(1,2).](\u003c../img/assets/image (78).png\u003e)\n\nThere are lots of ways to represent this behavior. One possible method is to keep an **array of parent values** corresponding to each actual value. In the example above, for instance, we can choose 1 as our parent and make 2 fall under that. Let's see how this might work:\n\n![Parents list.](\u003c../img/assets/image (79).png\u003e)\n\nNow, let's say we call `union(3,2)`. We can just set the parent of 3 to 2, as to create a structure like this:\n\n![union(1,2) followed by union(3,2)](\u003c../img/assets/image (80).png\u003e)\n\nThis looks a lot like a tree!\n\nYou might have noticed that this looks like a **spindly tree** though, which is bad for runtime! Perhaps we can convert it to the equivalent of a bushy tree- the union function can be made much more efficient using tricks such as WeightedQuickUnion and Path Compression. Watch [this playlist](https://www.youtube.com/watch?v=JNa8BRRs8L4\\\u0026list=PL8FaHk7qbOD59HbdZE3x52KOhJJS54BlT\\\u0026index=1) for more information!\n\n## Find\n\nFirst, let's explore how to implement an efficient way to **find which set a value is in.** Using the union function from above, we can do this pretty easily with this simple algorithm:\n\n* If the parent is 0, simply return the value.\n* If the parent is not 0, return the result of calling the function on the parent value.\n\nIf we follow this algorithm on the example in the Union section, we can see that calling `find(3)` will go to `2`, then finally to `1` and return `1`.\n",
    "lastmodified": "2023-01-10T21:50:23.61630801Z",
    "tags": null
  },
  "/cs61b/algorithms/": {
    "title": "",
    "content": "",
    "lastmodified": "2023-01-06T09:07:49.820042527Z",
    "tags": null
  },
  "/cs61b/algorithms/minimax": {
    "title": "Minimax Algorithm",
    "content": "\n## Game Trees\n\nThe Minimax algorithm is often used for making AI's for turn-based games. It relies on the use of a type of **game tree,** which maps out all of the possible moves that players can make.\n\nIn the tree, there are two types of nodes: **maximizing nodes** and **minimizing nodes.** The max-nodes represent **you**- you want to make your position as advantageous as possible (maximizing your score). The min-nodes represent **your opponent-** they want to make you do as poorly as possible (minimizing your score).\n\nThe scores themselves are generated using a **heuristic function** that assesses the current game state and returns a number based on which player has an advantage, and to what extent. **This heuristic is totally up to you to figure out and has very few constraints.** There are a couple rules, however:\n\n* Heuristic functions must return **positive values** if you're doing better than your opponent, and **negative values** if your opponent is doing better.\n* Heuristic functions must return the **maximum value** for a state in which you won, and the **minimum value** for a state in which your opponent won.\n\nIn most games, you and your opponent will take turns, so each layer will alternate node type, like this:\n\n![](\u003c../img/assets/image (99).png\u003e)\n\nIn most games, this tree will spiral out of control because there are far too many nodes to possibly analyze (maybe even an infinite number)! Therefore, we need to set a **depth** to stop searching and compute a heuristic. For example, if the depth is **3**, it'll look something like this:\n\n![](\u003c../img/assets/image (100).png\u003e)\n\nNow that the tree has bottomed out at the heuristic layer, we can start going back up to figure out which move we should make! The rules are simple: **min-nodes take the smallest of the values** while **max-nodes take the largest of the values.** Here's the first layer, for example:\n\n![](\u003c../img/assets/image (101).png\u003e)\n\nHere's the entire tree filled out:\n\n![](\u003c../img/assets/image (102).png\u003e)\n\nAnd here's the minimax algorithm in pseudocode format:\n\n```python\ndef minimax_value(s: MinimaxNode):\n    if is_terminal(s):\n        return s.value\n    elif s.player == Maximizing:\n        return max(minimax_value(c) for c in s.children)\n    elif s.player == Minimizing:\n        return min(minimax_value(c) for c in s.children)\n```\n\n## **Alpha-Beta Pruning**\n\nWe can make our tree **even more efficient** by simply ignoring all of the branches that will lead to results that will **never be chosen.** Here, we'll assume that **both players play optimally** (choose the best move for their particular node).\n\nIn the example above, we can see that the 7 on the right will **never need to be visited** because we **already know that 5 will be chosen.**\n\nIn order to do this, we'll introduce two additional parameters, **alpha** and **beta.** Here are the rules:\n\n* **Alpha** starts out as **negative infinity** and is set by **max nodes** to their current value.\n* **Beta** starts out as **positive infinity** and is set by **min nodes** to their current value.\n* A node **passes its alpha and beta values** onto its children.\n* If **alpha is greater than beta (**$\\alpha \\ge \\beta$**),** the branch will be **pruned** (no longer visited).\n\nHere are the step-by-step instructions on how to process a node:\n\n1. Copy the alpha and beta values from the parent node. (If no parent node exists, then initialize alpha to negative infinity and beta to positive infinity.\n2. For every branch:\n   1. Recursively process the branch.\n   2. Update the current alpha/beta value depending on the value of the branch after processing. (MaxNodes can only update alpha, and MinNodes can only update beta.)\n   3. If $\\alpha \\ge \\beta$**,** then prune the rest of the branches (stop this loop).\n3. Set the value of this node to the biggest (MaxNode) or smallest (MinNode) value seen.\n\nThis is a pretty tough concept to grasp, and that's why I've illustrated how it works below. Read on!\n\n## A Story of Minimax Nodes: An Intuitive Understanding\n\nMinimax is quite difficult to understand just by studying its rules. In order to really know what's going on, we need to know why we have all of these rules and what everything represents. Here's how I think about it:\n\n![](\u003c../img/assets/image (24).png\u003e)\n\n![](\u003c../img/assets/image (25).png\u003e)\n\n![](\u003c../img/assets/image (27).png\u003e)\n\n![](\u003c../img/assets/image (28).png\u003e)\n\n![](\u003c../img/assets/image (29).png\u003e)\n\n![](\u003c../img/assets/image (30).png\u003e)\n\n![](\u003c../img/assets/image (31).png\u003e)\n\n![](\u003c../img/assets/image (33).png\u003e)\n\n_NOTE: The 5's in the above image should all be 7's. This will be corrected soon (tm)._\n\n\n\n## Practice Problems\n\n{{\u003c tabs \"minimax-q1\" \u003e}}\n{{\u003c tab \"Question 1\" \u003e}}\nHere's a tree. Figure out:\n\n* What values each of the nodes report\n* Which branches are pruned\n* The alpha and beta values at each visited node\n\n![](\u003c../img/assets/image (34).png\u003e)\n{{\u003c /tab \u003e}}\n\n{{\u003c tab \"Q1 Answer\" \u003e}}\nHere's my answer! The green arrows denote the order in which the nodes are visited. Note that the branches are pruned every time **alpha is greater than beta.**\n\n![](\u003c../img/assets/image (35).png\u003e)\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\nThis was just an ordinary problem and **might not be enough to ensure that you fully understand minimax trees**! Here are some checks you can do to ensure that your understanding is strong:\n\n* Figure out what the tree returns and prunes intuitively _without_ finding any alpha or beta values.\n* Make your own minimax tree problem like the one above and solve it. Are you confident in your answer (since no answer key exists)?\n* Make a minimax tree that's missing some values, and try to find all possible values that fit in there such that the branch will become pruned.\n* Implement the minimax algorithm in Java.\n",
    "lastmodified": "2023-01-10T22:21:22.194890388Z",
    "tags": null
  },
  "/cs61b/algorithms/minimum-spanning-trees/": {
    "title": "",
    "content": "\n## Spanning Tree Definition\n\nA **spanning tree** $T$ is a subgraph of a graph $G$ where $T$:\n\n* Is connected (there's a path to every vertex)\n* Is acyclic (no cycles)\n* Includes every vertex (spanning property)\n\n**Notice:** the first two properties defines a tree structure, and the last property makes the tree spanning.\n\nA **minimum spanning tree** is a spanning tree with minimum total edge weight.\n\nExample: I want to connect an entire town with wiring and would like to find the optimal wiring connection that connects everyone but uses the least wire.\n\n## MST vs. Shortest Path Tree\n\nIn contrast to a shortest path tree, which is essentially the solution tree to running Dijkstra’s with root node = source vertex, a MST has no source. However, it is possible for the MST to be the same as the SPT.\n\nWe can think of the MST as a global property for the entire graph, as opposed to SPT which depends on which node is the source node.\n\nIf the edges of the graph are not unique, there’s a chance that the MST is not unique.\n\n## Cuts Property\n\n* A **cut** is defined as assigning the nodes in a graph into two sets.\n* A **crossing edge** is an edge that connects two nodes that are in different sets\n* The smallest crossing edge is the crossing edge with smallest weight\n\nThe **Cut Property** states that the smallest crossing edge is always going to be in the MST, no matter how the cut is made.\n\n![](\u003c../../img/assets/image (109).png\u003e)",
    "lastmodified": "2023-01-06T09:31:56.808460682Z",
    "tags": null
  },
  "/cs61b/algorithms/minimum-spanning-trees/kruskals-algorithm": {
    "title": "Kruskal's Algorithm",
    "content": "\n\u003e [!info] Content Note\n\u003e\n\u003e Before reading, review [Minimum Spanning Trees](./) and [Union Find (Disjoint Sets)](../../abstract-data-types/union-find-disjoint-sets.md) as they both make Kruskal's algorithm possible!\n\n\n## Conceptual Overview\n\nKruskal's algorithm is another optimal way to construct a **minimum spanning tree**. It's benefits are that it is conceptually very simple, and easy to implement. The idea is that first we sort all the edges of the graph in order of increasing weight. Then, add the smallest edge to the MST we are constructing unless this creates a cycle in the MST. Repeat until V - 1 edges total.\n\n## Detailed Breakdown\n\nIn order to optimally check if adding an edge to our MST creates a cycle, we will use a **WeightedQuickUnion** object. (See [Union Find (Disjoint Sets)](../../abstract-data-types/union-find-disjoint-sets.md) for a recap on what this is.) This is used because checking if a cycle exists using a WeightedUnionFind object boils down to one `isConnected()` call, which we know takes $\\Theta(\\log(N))$.\n\nTo run the algorithm, we start by adding all the edges into a [PriorityQueue](../../abstract-data-types/collections/stacks-and-queues.md). This gives us our edges in sorted order. Now, we iterate through the PriorityQueue by removing the edge with highest priority, checking if adding it forms a cycle, and adding it to our MST if it doesn't form a cycle.\n\nLet's see an example of Kruskal's Algorithm in action!\n\nHere, we start with a simple graph and have sorted all of its edges into a priority queue.\n\n![](\u003c../../img/assets/image (103).png\u003e)\n\nSince the edge **DE** is the shortest, we'll add that to our UnionFind first. In the process, we'll **remove DE from the priority queue.**\n\n![](\u003c../../img/assets/image (104).png\u003e)\n\nWe'll do the same thing with the next shortest path, **DC.**\n\n![](\u003c../../img/assets/image (105).png\u003e)\n\nNow, let's move on to **AB.** Notice that this time, connecting A and B creates another **disjoint set!** Unlike Prim's Algorithm, Kruskal's Algorithm does not guarantee that a solution will form a tree structure until the very end.\n\n![](\u003c../../img/assets/image (106).png\u003e)\n\nNow, let's connect **BC.**\n\n![](\u003c../../img/assets/image (107).png\u003e)\n\nSince **CE** and **BD** would both form cycles if connected, **we are done 😄** Here's the final tree:\n\n![](\u003c../../img/assets/image (108).png\u003e)\n\n## PseudoCode\n\n```java\npublic class Kruskals() {\n\n    public Kruskals() {\n        PQ edges = new PriorityQueue\u003c\u003e();\n        ArrayList\u003cEdge\u003e mst = new ArrayList\u003c\u003e();\n    }\n\n    public void doKruskals(Graph G) {\n        for (e : G.edges()) {\n            PQ.add(e);\n        }\n        WeightedQU uf = new WeightedQU(G.V());\n        Edge e = PQ.removeSmallest();\n        int v = e.from();\n        int w = e.to();\n        if (!uf.isConnected(v, w)) {\n            uf.union(v, w);\n            mst.add(e);\n        }\n\n    }\n}\n```\n\n## Runtime Analysis\n\nLeft as an exercise to the reader 😉\n\n(The answer is $\\Theta(E\\log(E))$by the way. Try to convince yourself why!)\n",
    "lastmodified": "2023-01-10T22:03:03.829296446Z",
    "tags": null
  },
  "/cs61b/algorithms/minimum-spanning-trees/prims-algorithm": {
    "title": "Prim's Algorithm",
    "content": "\n\u003e [!info] Content Note\n\u003e\n\u003e Before reading, review [Minimum Spanning Trees](./), as that is the foundation of Prim's algorithm!\n\n## Conceptual Overview\n\nPrim's algorithm is an optimal way to construct a **minimum spanning tree**. It basically starts from an arbitrary vertex, then considers all its immediate neighbors and picks the edge with smallest weight to be part of the MST. **Note:** this creates a cut in the graph, where the two nodes in the MST being constructed are in one set, and every other vertex of the graph is in another set.\n\nNow, the edges taken into consideration include all immediate neighbors of every node in the MST. Add the edge that has the smallest weight to the MST. Repeat until every vertex has been visited. The result is an MST for the graph.\n\n## Detailed Breakdown\n\nThe way Prim's algorithm is usually implemented is via [PriorityQueue](../../abstract-data-types/collections/stacks-and-queues.md), `edgeTo` array, and` distTo` array. You will soon see its similarities to [Dijkstra's](../shortest-paths/dijkstras-algorithm.md).\n\nFirst, insert all vertices into the PriorityQueue, storing vertices in order of **distance from MST**. Then, remove vertex with highest priority in the PriorityQueue and relax its edges. In each of these iterations, the distTo and edgeTo arrays will be updated for each vertex v if the **weight of the edge is smaller than the current value in distTo\\[v]**. In other words, only update if the distance from the MST to the vertex is the best seen so far. This is a very important point, and is one of the subtleties that makes Prim's algorithm fundamentally different from Dijkstra's.\n\n## Useful Properties/Invariants\n\nThe MST under construction is **always connected.**\n\n## Pseudocode\n\n```java\npublic class Prims() {\n\n    public Prims() {\n        PQ = new PriorityQueue\u003c\u003e();\n        edgeTo = new Edge[numVertices];\n        distTo = new Dist[numVertices];\n        marked = new boolean[numVertices];\n    }\n\n    public void doPrims() {\n        PQ.add(sourceVertex, 0);\n        for(v : allOtherVertices) {\n            PQ.add(v, INFINITY);\n        }\n        while (!PQ.isEmpty()) {\n            Vertex p = PQ.removeSmallest();\n            marked[p] = true;\n            relax(p);\n        }\n    }\n\n    public void relax(Vertex p) {\n        for (q : p.neighbors()) {\n            if (marked[q]) { continue; }\n            if (q.edgeWeight \u003c distTo[q]) {\n                distTo[q] = q.edgeWeigth;\n                edgeTo[q] = p;\n                PQ.changePriority(q, distTo[q]);\n            }\n        }\n    }\n}\n```\n\nLooking at this pseudocode, the resemblance to Dijkstra's makes them seem nearly identical. But hopefully you've read the conceptual overviews first, and you understand the remarkable subtlety that leads to two very fundamentally different algorithms.\n\n## Runtime Analysis\n\nThis is the same as for Dijkstra's Algorithm.\n\n**Unsimplified:**\n\n$\n\\theta(V * log(V) + V * log(V) + E * log(V))\n$\n\n**Simplified:**\n\n$\n\\theta(E * log(V))\n$\n\n**Explanation:**\n\n* each add operation to PQ takes log(V), and perform this V times\n* each removeFirst operation to PQ takes log(V) and perform this V times\n* each change priority operation to PQ takes log(V), perform this at most as many times as there are edges\n* everything else = O(1)\n* usually, there are more or equal edges compared to the number of vertices.\n\n## Demo\n\n[https://docs.google.com/presentation/d/1GPizbySYMsUhnXSXKvbqV4UhPCvrt750MiqPPgU-eCY/edit#slide=id.g9a60b2f52\\_0\\_0](https://docs.google.com/presentation/d/1GPizbySYMsUhnXSXKvbqV4UhPCvrt750MiqPPgU-eCY/edit#slide=id.g9a60b2f52\\_0\\_0)\n",
    "lastmodified": "2023-01-06T09:48:10.809306589Z",
    "tags": null
  },
  "/cs61b/algorithms/searching/": {
    "title": "",
    "content": "\nThis section will cover some ways to find values in a set.\n\n{{\u003c section \u003e}}",
    "lastmodified": "2023-01-06T09:12:35.041206788Z",
    "tags": null
  },
  "/cs61b/algorithms/searching/binary-search": {
    "title": "",
    "content": "# Binary Search\n\nBinary search is a way of finding a specific node in a tree. It only works on [binary trees](../../abstract-data-types/binary-trees/) due to its helpful sorted property. It simply traverses the tree, moving left if the current node is too large or right if it is too small.\n\nBinary search runs in $\\Theta(\\log(n))$ time for bushy trees, which is also the number of layers in a tree.\n\n## The Algorithm\n\n```java\npublic BST find(BST T, Key sk) {\n    if (T == null) {\n        return null;\n    }\n    if (sk.equals(T.key)) {\n        return T;\n    } else if (sk \u003c T.key) {\n        return find(T.left, sk);\n    } else {\n        return find(T.right, sk);\n    }\n}\n```\n",
    "lastmodified": "2023-01-06T02:00:56.863239833Z",
    "tags": null
  },
  "/cs61b/algorithms/searching/breadth-first-search-bfs": {
    "title": "Breadth First Search (DFS)",
    "content": "\nBreadth First Search (BFS), like [Depth First Search (DFS)](depth-first-search-dfs.md), is a method of **traversing a graph.** BFS simply traverses in a different order, but otherwise is very similar to DFS.\n\nThe main difference is that BFS **visits all children before any subgraphs.** In a tree, we call this **level order.**\n\n![](\u003c../../img/assets/image (110).png\u003e)\n\nFor the example tree above, a level order traversal would go in this order: **D B F A C E G.**\n\n## Step by Step\n\n**Let's see how we might implement BFS.**\n\nSome data structures we will need are:\n\n* A graph to traverse.\n* A queue **Q** to keep track of which nodes need to be processed next.\n* A list of booleans **marked** to keep track of which nodes were already visited.\n* (Optional) **edgeTo** and **distTo** to keep track of information that might be useful for other applications (like [Dijkstra's Algorithm](../shortest-paths/dijkstras-algorithm.md)).\n\nFirst, let's start with a vertex in the graph by marking it and adding it to the queue.\n\n![](\u003c../../img/assets/image (111).png\u003e)\n\nThe next step is to **remove A from the queue** and **add its children** (B and C) **to the queue.** Also, we need to **mark all of the children.**\n\n![](\u003c../../img/assets/image (112).png\u003e)\n\nNext, we'll move onto the **next item on the queue** (B). We'll do the same thing that we did with A: remove B, mark all its children, and add its children to the queue. **Since C is already marked, we do not add it to the queue again.**\n\n![](\u003c../../img/assets/image (113).png\u003e)\n\nNow, we'll move on to the next item on the queue, C, and do the same thing. Again, we won't add C or A because they are both marked.\n\n![](\u003c../../img/assets/image (114).png\u003e)\n\nFinally, we'll visit the two remaining nodes in the queue, D and E. Since all of the nodes are marked now, there aren't any other nodes to visit.\n\n",
    "lastmodified": "2023-01-06T09:26:40.532610939Z",
    "tags": null
  },
  "/cs61b/algorithms/searching/depth-first-search-dfs": {
    "title": "Depth First Search (DFS)",
    "content": "\n## Depth First Traversal\n\nBefore we move on to searching, let's talk about **traversing. Traversal** is the act of **visiting nodes in a specific order.** This can be done either in trees or in graphs.\n\nFor trees in particular, there are **three main ways** to traverse.\n\n![The example tree we will use for traversal illustrations.](\u003c../../img/assets/image (89).png\u003e)\n\nThe first way is **inorder** traversal, which visits **all left children**, then **the node itself,** then **all right children.** The end result should be that the nodes were visited in **sorted order.**\n\nThe second way is **preorder** traversal, which visits **the node itself first,** then **all left children,** then **all right children.** This method is useful for applications such as printing a directory tree structure.\n\nThe third way is **postorder** traversal, which visits **all left children,** then **all right children,** then **finally the node itself.** This method is useful for when operations need to be done on all children before the result can be read in the node, for instance getting the sizes of all items in the folder.\n\nHere are some pseudocodey algorithms for tree traversals.\n\n```java\n// INORDER will print A B C D E F G\nvoid inOrder(Node x) {\n    if (x == null) return;\n    inOrder(x.left);\n    print(x);\n    inOrder(x.right);\n}\n\n// PREORDER will print D B A C F E G\nvoid preOrder(Node x) {\n    if (x == null) return;\n    print(x);\n    preOrder(x.left);\n    preOrder(x.right);\n}\n\n// PREORDER will print A C B E G F D\nvoid postOrder(Node x) {\n    if (x == null) return;\n    preOrder(x.left);\n    preOrder(x.right);\n    print(x);\n}\n```\n\n## Depth First Search in Graphs\n\nGraphs are a little more complicated to traverse due to the fact that they could have **cycles** in them, unlike trees. This means that we need to **keep track of all the nodes already visited** and add to that list whenever we encounter a new node.\n\nDepth First Search is great for determining if everything in a graph is connected.\n\nHere's an outline of how this might go:\n\n* Keep an array of 'marks' (true if node has been visited) and, optionally, an edgeTo array that will automatically keep track of how to get to each connected node from a source node\n* When each vertex is visited:\n  * Mark the vertex\n  * For each adjacent unmarked vertex:\n    * Set edgeTo of that vertex equal to this current vertex\n    * Call the recursive method on that vertex\n\nLike trees, DFS can be done **inorder, preorder, or postorder.** It's nearly identical behavior to trees, with the addition of the marks array.\n",
    "lastmodified": "2023-01-06T09:26:14.672906997Z",
    "tags": null
  },
  "/cs61b/algorithms/shortest-paths/": {
    "title": "",
    "content": "\nWe've seen that Breadth-First Search can help us find the shortest path in an unweighted graph, where the shortest path was just defined to be the fewest number of edges traveled along a path. In the following shortest-paths algorithms, we will discover how we can generalize the breadth-first traversal to find the path with the lowest total cost, where the cost is determined by different weights on the edges.",
    "lastmodified": "2023-01-06T09:31:51.212530335Z",
    "tags": null
  },
  "/cs61b/algorithms/shortest-paths/a-search": {
    "title": "A* Search",
    "content": "\n\u003e [!info] Content Note\n\u003e\n\u003e In order to understand A\\*, you'll need to be comfortable [Dijkstra's Algorithm](dijkstras-algorithm.md) first!\n\n\n## A\\* Algorithm\n\nThe A\\* Search Algorithm is **incredibly similar to Dijkstra's Algorithm** with one addition: a **heuristic function.**\n\nThis heuristic function calculates weights of a path **from a vertex to a goal vertex.** This way, we can help bias our algorithm in the right direction so that it doesn’t make a bunch of bad moves.\n\nThis has an important implication: **not all vertices get visited.** The algorithm only cares about finding the best path to the goal, and not any other vertex (assuming we design our heuristic well).\n\nThe **order** that the vertices get visited is lowest **distance + heuristic**. This is basically the same as Dijkstra's, just with that added heuristic term.\n\n## What's a good heuristic?\n\nHeuristic functions can be really tricky to design, since there isn't much to go off of.\n\n**A good heuristic has these two properties:**\n\n* **Admissible** - heuristic of each vertex returns a cost that is \u003c= the true cost/distance i.e. h(A) \u003c= cost(A, goal)\n* **Consistent** - difference between heuristics of two vertices \u003c= true cost between them i.e. h(A) - h(B) \u003c= cost(A, B)\n\n## **Want more?**\n\n[Here's a cool demo!](https://docs.google.com/presentation/d/177bRUTdCa60fjExdr9eO04NHm0MRfPtCzvEup1iMccM/edit#slide=id.g369665031c\\_0\\_350)\n\n",
    "lastmodified": "2023-01-06T09:48:47.056911102Z",
    "tags": null
  },
  "/cs61b/algorithms/shortest-paths/dijkstras-algorithm": {
    "title": "Dijkstra's Algorithm",
    "content": "\n\u003e [!info] Content Note\n\u003e\n\u003e Before continuing, make sure you're comfortable with [Graphs](../../abstract-data-types/graphs.md), [Stacks and Queues](../../abstract-data-types/collections/stacks-and-queues.md), and [Shortest Paths](./).\n\n\n## One sentence overview\n\nVisit vertices in order of best-known distance from source; on visit, relax every edge from the visited vertex.\n\n## Detailed Breakdown\n\nDjikstras uses a **PriorityQueue** to maintain the path with lowest cost from the starting node to every other node, an **edgeTo** array to keep track of the best known predecessor for each vertex, and a **distTo** array to keep track of the best known distance from the source vertex to every other vertex.\n\n**Relaxing** the edges of a vertex v just refers to the process of updating edgeTo\\[n] for each neighbor n to v.\n\nYou'll see in the pseudocode and diagrams below that succesful relaxation only occurs when the edge connecting the vertex being visited to one of its neighbors yields a smaller total distance than the current shortest path to that neighboring vertex that the algorithm has seen.\n\nNow, here's a demonstration on how it works! Let's start out with this graph:\n\n![](\u003c../../img/assets/image (92).png\u003e)\n\nWe'll start at node A and try to figure out the shortest path from A to each node. Since we have no idea how far each node is, we'll take the conservative guess that everything is infinitely far away ♾😎\n\nThe first thing we have to do is update A's adjacent nodes, which are **B** and **D**. Since there's only one known path to each, it shouldn't be too hard to see why we need to update the values below. One thing to note is that the priority queue **sorts the vertices by the distance it takes to get there.**\n\n![](\u003c../../img/assets/image (93).png\u003e)\n\nNow, we have a choice to move on to either **B** or **D**. Since B has a **shorter distance,** we'll move on to that first. When we move on, we have to **remove that value from the priority queue** and **update all of its neighbors.** Here, we see that going from **B to D** is **shorter** than **A to D**, so we have to **update distTo AND edgeTo of D** to reflect this new, shorter path. **This process** (updating each adjacent node) **is called relaxing the edges of a node.**\n\n![](\u003c../../img/assets/image (94).png\u003e)\n\nNow, let's move onto **D** since it has the next shortest path. Again, we **remove D from the priority queue** and **relax C** since we found a shorter path.\n\n![](\u003c../../img/assets/image (95).png\u003e)\n\nFinally, we'll move onto **C** as that has the next shortest path in the priority queue. This will reveal our final node, **E**.\n\n![](\u003c../../img/assets/image (96).png\u003e)\n\nSince **the priority queue is now empty,** our search is done! 😄 Here's what the final solution looks like **in a tree form**:\n\n![Dijkstra's Algorithm ALWAYS produces a solution in a tree format.](\u003c../../img/assets/image (98).png\u003e)\n\nIt's a very spindly tree indeed, but hopefully it demonstrates that the result is **acyclic**.\n\n## Properties of Dijkstra's Algorithm\n\n**Dijkstra's Algorithm has some invariants (things that must always be true):**\n\n1. edgeTo\\[v] always contains best known predecessor for v\n2. distTo\\[v] contains best known distance from source to v\n3. PQ contains all unvisited vertices in order of distTo\n\n**Additionally, there are some properties that are good to know:**\n\n* always visits vertices **in order of total distance from source**\n* relaxation always **fails on edges to visited vertices**\n* guarantees to work optimally **as long as** **edges are all non-negative**\n* solution always creates a **tree form.**\n* can think of as **union of shortest paths to all vertices**\n* **edges in solution tree always has V-1 edges**, where V = the number of vertices. This is because every vertex in the tree except the root should have **exactly one input.**\n\n## Pseudocode\n\n```java\npublic Class Djikstra() {\n\n    public Djikstra() {\n        PQ = new PriorityQueue\u003c\u003e();\n        distTo = new Distance[numVertices];\n        edgeTo = new Edge[numVertices];\n    }\n\n    public void doDijkstras(Vertex sourceVertex) {\n        PQ.add(sourceVertex, 0);\n        for(v : allOtherVertices) {\n            PQ.add(v, INFINITY);\n        }\n        while (!PQ.isEmpty()) {\n            Vertex p = PQ.removeSmallest();\n            relax(p);\n        }\n    }\n    // Relaxes all edges of p\n    void relax(Vertex p) {\n        for (q : p.neighbors()) {\n            if (distTo[p] + q.edgeWeight \u003c distTo[q]) {\n                distTo[q] = distTo[p] + q.edgeWeight;\n                edgeTo[q] = p;\n                PQ.changePriority(q, distTo[q]);\n            }\n        }\n    }\n}\n```\n\n## Runtime Analysis\n\n**Unsimplified:**\n\n$\n\\theta(V * log(V) + V * log(V) + E * log(V))\n$\n\n**Simplified:**\n\n$\n\\theta(E * log(V))\n$\n\n**Explanation:**\n\n* each add operation to PQ takes log(V), and perform this V times\n* each removeFirst operation to PQ takes log(V) and perform this V times\n* each change priority operation to PQ takes log(V), perform this at most as many times as there are edges\n* everything else = O(1)\n* usually, there are more or equal edges compared to the number of vertices.\n",
    "lastmodified": "2023-01-06T09:48:59.340777202Z",
    "tags": null
  },
  "/cs61b/algorithms/sorting": {
    "title": "Sorting",
    "content": "\n\u003e [!important] Sorting Guide\n\u003e\n\u003e For more information about specific sorting algorithms covered in 61B, see my [guide on sorting](https://docs.google.com/document/d/1dUfzdh5V3okrwFbB9o0PgtEBaLHyCqJFwpQWyQ53IeU/edit) that covers all of the sorts in far greater detail 🙂\n\n## Why sort?\n\n* It makes searching for a specific value much faster (e.g. binary search). Typically, searching through an unsorted list requires a full scan ($\\Theta(N)$​ runtime).\n* It's easy to see if two items in list are equal: just compare to see if any neighboring values are the same.\n\n## Properties of a Sorting Algorithm\n\nA sorting algorithm changes a sequence based on a **total order.** A total order is:\n\n* **Total:** All items can be compared with one another\n* **Reflexive:** An item can be compared to itself\n* **Antisymmetric:** x \u003c= y AND y \u003c= x IFF y == x\n* **Transitive:** If x \u003c= y and y \u003c= z, then x must be \u003c= z\n\nA sorting algorithm could be **stable** if it does not change relative order of equivalent entries. For example, if Bob and I both owned Toyota Corollas, and the list of cars were sorted by model, if Bob's car came before mine originally it must also come before mine in the sorted list after a stable sort.\n\n\n\n## Sorting Algorithm Classifications\n\n* **Internal sort:** Keeps all data in primary memory\n* vs. **External sort:** Processes data in batches, then merges them together at the end\n* **Comparison-based sort:** The only thing we know about keys are their relative orders\n* **Radix sort:** Uses information other than keys\n* **Insertion sort:** Insert items at their appropriate positions one at a time\n* **Selection sort:** Chooses items and places them in order\n\n## Sorting in Java\n\nJava automatically chooses the best sorting algorithm for a given list if you call the `Arrays.sort` method.\n\n```java\nString[] x = new String[] {\"Vat\", \"Bat\", \"Cat\"};\n\nArrays.sort(x); // mutates x into Bat, Cat, Vat\nArrays.sort(x, Collections.reverseOrder()); // mutates x into Vat, Cat, Bat\nArrays.sort(x, 0, 2) // sorts the first two elements, leaving the rest unchanged (Cat, Vat, Bat)\n```\n\n## Inversions\n\nInversions are used as a measure for how sorted a list is. For every two elements that are swapped compared to a sorted list, we add one inversion.\n\n* As an example, if `1 2 3 4 5` is a sorted list, `1 4 3 2 5` would have one inversion (`4` and `2` are swapped).\n* 0 inversions mean a list is perfectly sorted.\n* In the worst case, a reversed list will have $(N \\cdot (N-1))/2$ inversions.\n\n## The Guide to Sorting Algorithms\n\n[A comprehensive guide to sorting algorithms, now with memes!](https://docs.google.com/document/d/1dUfzdh5V3okrwFbB9o0PgtEBaLHyCqJFwpQWyQ53IeU/edit)\n",
    "lastmodified": "2023-01-06T10:09:27.451208362Z",
    "tags": null
  },
  "/cs61b/asymptotics/": {
    "title": "",
    "content": "",
    "lastmodified": "2023-01-06T09:23:45.034430993Z",
    "tags": null
  },
  "/cs61b/asymptotics/amortization": {
    "title": "",
    "content": "# Amortization\n\n\u003e [!info] Content Note\n\u003e\n\u003e Please read [Asymptotic Analysis Basics](asymptotics.md) first. If you don't, none of this will make any sense!\n\n**Amortization** means **spreading out.**\n\nSometimes, an operation takes different amounts of time for different values of $n$. Rather than having to report runtimes for each different case, we can instead average all of them out and report the **amortized runtime.**\n\nThis is especially good for functions where most actions have a low cost, but a few have a high cost. We'll see an example of this further down the page!\n\n## A Case Study: Resizing Arrays\n\nAs you probably know, normal Java arrays don't resize. If we create a `new int[5]` then that array will always have a length of 5.\n\nBut what if we wanted to make an array resize itself every time it reaches capacity? (Like a `List`!) Let's see what happens when we **add one to the array size:**\n\nFirst, we have to make a new array with a new size:\n\n![](\u003c../img/assets/image (16).png\u003e)\n\nThen, we have to copy over all of the old elements over:\n\n![](\u003c../img/assets/image (17).png\u003e)\n\nFinally, we can add in the new element!\n\n![](\u003c../img/assets/image (19).png\u003e)\n\n**Let's analyze the runtime of this operation.**\n\n* A single resizing will take $\\Theta(n)$ time.\n* Adding a single element will take $\\Theta(1)$ time.\n* Together, a single operation will take $\\Theta(n+1)$ time, which simplifies into  $\\Theta(n)$ .\n* Since we're doing a n-operation n times, **the end result is a resizing function that is**$\\Theta(n^2)$. **We can do better with the power of amortization!**\n\n### **What if we doubled the size instead of adding one?**\n\n* A single resizing will take $\\Theta(2n)$ time \\_\\*\\*\\_which simplifies into $\\Theta(n)$ time.\n  * We do this every time the array hits a power of 2 (2, 4, 8, 16, 32 ...).\n* Adding a single element will take $\\Theta(1)$ time.\n  * We do this every time we add a new element, so in all we add n elements. Therefore, this is an\n    * $\\Theta(n)$operation.\n\n**Therefore, the unsimplified function is:** $\\Theta(n + (2 + 4 + 8 ... +2^i))$ where $2^i$ is the largest power of two less than n. This might not seem clear on its own, so let's rewrite it:\n\n$\n\\theta(n + (\\frac{n}{2} + \\frac{n}{4} + ... + 8 + 4 + 2))\n$\n\nIntuitively, this looks like this:\n\n![](\u003c../img/assets/image (39).png\u003e)\n\nMathematically, it looks like this:\n\n$\nn + n\\sum_{n=1}^{n}(\\frac{1}{2})^n\n$\n\nWhich simplifies to $2n$if you recall your power series properties . **Therefore, this approach is** $\\Theta(n)$ **!!**\n\n![](\u003c../img/assets/image (116).png\u003e)\n\n\n\n\n\n",
    "lastmodified": "2023-01-06T09:50:40.071681788Z",
    "tags": null
  },
  "/cs61b/asymptotics/asymptotics": {
    "title": "Asymptotic Analysis Basics",
    "content": "\n\u003e [!info] Content Note\n\u003e\n\u003e This concept is a big reason why a strong math background is helpful for computer science, even when it's not obvious that there are connections! Make sure you're comfortable with Calculus concepts up to [power series](http://tutorial.math.lamar.edu/Classes/CalcII/PowerSeries.aspx).\n\n\n## An Abstract Introduction to Asymptotic Analysis\n\nThe term **asymptotics,** or **asymptotic analysis,** refers to the idea of **analyzing functions when their inputs get really big.** This is like the **asymptotes** you might remember learning in math classes, where functions approach a value when they get very large inputs.\n\n![](\u003c../img/assets/image (13).png\u003e)\n\nHere, we can see that $y= \\dfrac{x^3}{x^2 + 1}$ looks basically identical to $y = x$ when x gets really big. Asymptotics is all about reducing functions to their eventual behaviors exactly like this!\n\n## That's cool, but how is it useful?\n\nGraphs and functions are great and all, but at this point it's still a mystery as to how we can use these concepts for more practical uses. Now, we'll see how we can **represent programs as mathematical functions** so that we can do cool things like:\n\n* **Figure out how much time or space a program will use**\n* **Objectively tell how one program is better than another program**\n* **Choose the optimal data structures for a specific purpose**\n\nAs you can see, this concept is **absolutely fundamental** to ensuring that you write **efficient algorithms** and choose the **correct data structures.** With the power of asymptotics, you can figure out if a program will take 100 seconds or 100 years to run without actually running it!\n\n## How to Measure Programs\n\nIn order to convert your `public static void Main(String[] args)` or whatever into `y = log(x)`, we need to figure out what `x` and `y` even represent!\n\n**TLDR:** It depends, but the three most common measurements are **time, space,** and **complexity**.\n\n**Time** is almost always useful to minimize because it could mean the difference between a program being able to run on a smartphone and needing a supercomputer. Time usually increases with the **number of operations** being run. Loops and recursion will increase this metric substantially. On Linux, the `time` command can be used for measuring this.\n\n**Space** is also often nice to reduce, but has become a smaller concern now that we can get terabytes (or even petabytes) of storage pretty easily! Usually, the things that take up lots of space are **big lists** and **a very large number of individual objects.** Reducing the size of lists to hold only what you need will be very helpful for this metric!\n\nThere is another common metric, which is known as **complexity** or **computational cost.** This is a less concrete concept compared to time or space, and cannot be measured easily; however, it is highly generalized and usually easier to think about. For complexity, we can simply assign basic operations (like println, adding, absolute value) a complexity of **1** and add up how many basic operation calls there are in a program.\n\n## Simplifying Functions\n\nSince we **only care about the general shape of the function,** we can keep things as simple as possible! Here are the main rules:\n\n* **Only keep the** **fastest growing term.** For example,  $log(n) + n$ can be simplified to just $n$since $n$ grows faster out of the two terms.\n* **Remove all constants.** For example,  $5log(3n)$ can just be simplified to $log(n)$since constants don't change the overall shape of a function.\n* **Remove all other variables.** If a function is really $log(n + m)$ but we only care about n, then we can simply it into  $log(n)$.\n\nThere are two cases where we can't remove other variables and constants though, and they are:\n\n* A polynomial term $n^c$(because $n^2$grows slower than $n^3$, for example), and\n* An exponential term $c^n$(because $2^n$grows slower than $3^n$, for example).\n\n## The Big Bounds\n\nThere are **three** important types of runtime bounds that can be used to describe functions. These bounds put restrictions on how slow or fast we can expect that function to grow!\n\n**Big O** is an **upper bound** for a function growth rate. That means that **the function grows slower or the same rate as the Big O function.** For example, a valid Big O bound for $log(n) + n$ is $O(n^2)$ since $n^2$ grows at a faster rate.\n\n**Big Omega** is a **lower bound** for a function growth rate. That means that **the function grows faster or the same rate as the Big Omega function.** For example, a valid Big Omega bound for  $log(n) + n$ is $\\Omega(1)$ since $1$ (a constant) grows at a slower rate.\n\n**Big Theta** is a **middle ground** that describes the function that grows at the **same rate** as the actual function. **Big Theta only exists if there is a valid Big O that is equal to a valid Big Omega.** For example, a valid Big Theta bound for  $log(n) + n$ is $\\Theta(n)$ since $n$ grows at the same rate (log n is much slower so it adds an insignificant amount).\n\n\n\n![A comparison of the three bounds.](\u003c../img/assets/image (15).png\u003e)\n\n## Orders of Growth\n\nThere are some **common functions** that many runtimes will simply into. Here they are, from fastest to slowest:\n\n| Function              | Name        | Examples                                               |\n| --------------------- | ----------- | ------------------------------------------------------ |\n| $\\Theta(1)$         | Constant    | System.out.println, +, array accessing                 |\n| $\\Theta(\\log(n))$   | Log         | Binary search                                          |\n| $\\Theta(n)$         | Linear      | Iterating through each element of a list               |\n| $\\Theta(n\\log(n))$  | nlogn 😅    | Quicksort, merge sort                                  |\n| $\\Theta(n^2)$       | Quadratic   | Bubble sort, nested for loops                          |\n| $\\Theta(2^n)$       | Exponential | Finding all possible subsets of a list, tree recursion |\n| $\\Theta(n!)$        | Factorial   | Bogo sort, getting all permutations of a list          |\n| $\\Theta(n^n)$       | n^n 😅😅    | [Tetration](https://en.wikipedia.org/wiki/Tetration)   |\n\nDon't worry about the examples you aren't familiar with- I will go into much more detail on their respective pages.\n\n![Source: bigocheatsheat.com. Check it out, it's great!](\u003c../img/assets/image (14).png\u003e)\n\n## Asymptotic Analysis: Step by Step\n\n1. Identify the function that needs to be analyzed.\n2. Identify the parameter to use as $n$.\n3. Identify the measurement that needs to be taken. (Time, space, etc.)\n4. Generate a function that represents the complexity. If you need help with this step, [try some problems!](asymptotics-practice.md)\n5. [Simplify](asymptotics.md#simplifying-functions) the function (remove constants, smaller terms, and other variables).\n6. Select the correct bounds (O, Omega, Theta) for particular cases (best, worst, overall).\n",
    "lastmodified": "2023-01-06T09:50:01.304102855Z",
    "tags": null
  },
  "/cs61b/asymptotics/asymptotics-practice": {
    "title": "",
    "content": "# Asymptotics Practice\n\n\u003e [!info] Content Note\n\u003e\n\u003e Make sure to review [Asymptotic Analysis Basics](asymptotics.md) before proceeding with these problems.\n\n## Introduction\n\nAsymptotics is a very intuition-based concept that often doesn't have a set algorithm for computing. The best way to get good at analyzing programs is to practice!\n\nWith that said, here are some problems of increasing difficulty for you to enjoy 😊\n\n\u003e [!hint] Read before you do the problems!\n\u003e\n\u003e For all of the below problems, assume that all undefined functions have a constant O(1) complexity.\n\n## Loops\n\n{{\u003c tabs \"q1\" \u003e}}\n{{\u003c tab \"Question 1\" \u003e}}\nWhat runtime does this function have?\n\n```java\nvoid throwHalfOfMyItems(int n) {\n    for (int i = 0; i \u003c n; i += 1) {\n        if (i % 2 == 0)\n            throwItem(n);\n    }\n}\n```\n{{\u003c /tab \u003e}}\n\n{{\u003c tab \"Q1 Answer\" \u003e}}\n$\n\\Theta(n)\n$\n\n**Explanation:** The method `throwItem()` runs `n/2` times. Using the simplification rules, we can extract the constant `1/2` to simply get `n`.\n\n![Keep the change, ya filthy animal.](\u003c../img/assets/image (40).png\u003e)\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n{{\u003c tabs \"q2a\" \u003e}}\n{{\u003c tab \"Question 2a\" \u003e}}\nWhat runtime does this function have?\n\n```java\nvoid lootShulkerBoxes(int n) {\n    for (int box = n; box \u003e 0; box -= 1) {\n        for (int stack = 0; stack \u003c n; stack += 1) {\n            for (int i = 0; i \u003c 64; i += 1) {\n                lootItem(i * stack * box);\n            }\n        }\n    }       \n}\n```\n{{\u003c /tab \u003e}}\n\n{{\u003c tab \"Q2a Answer\" \u003e}}\n$\n\\Theta(n^2)\n$\n\n**Explanation:** There are **three** nested loops in this problem. Whenever there are nested loops whose runtimes are independent of each other, we need to **multiply** the runtimes in each loop.\\\nSo, we get: $\\Theta(n * n * 64)$ which simplifies into `n^2`\n\n![That's a lot of items to loot...](\u003c../img/assets/image (41).png\u003e)\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n{{\u003c tabs \"q2b\" \u003e}}\n{{\u003c tab \"Question 2b\" \u003e}}\nI've tweaked the previous problem a little 😁 Try to spot the difference and see if it changes the runtime at all!\n\n```java\nvoid lootShulkerBoxes(int n, int stacksToLoot) {\n    for (int box = n; box \u003e 0; box -= 1) {\n        for (int stack = stacksToLoot; stack \u003e 0; stack -= 1) {\n            for (int i = 0; i \u003c 64; i += 1) {\n                lootItem(i * stack * box);\n            }\n        }\n    }       \n}\n```\n{{\u003c /tab \u003e}}\n\n{{\u003c tab \"Q2b Answer\" \u003e}}\n$\n\\Theta(n)\n$\n\n**Explanation:** Even though `stacksToLoot` is a user input, we're only concerned about finding the runtime for `n` so `stacksToLoot` can be treated like a constant! Therefore, we now have $\\Theta(n * s* 64)$ where `s = stacksToLoot` which simplifies into `n`.\n\n![ok now this is getting a bit overboard](\u003c../img/assets/image (42).png\u003e)\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n## Recursion\n\nThe following two problems are inspired by [this worksheet](https://inst.eecs.berkeley.edu/\\~cs61b/sp20/materials/disc/discussion8.pdf).\n\n{{\u003c tabs \"q3\" \u003e}}\n{{\u003c tab \"Question 3\" \u003e}}\nTREEEEEEEEE recursion 🌳🌲🌴\n\n```java\nvoid plantJungleSaplings(int n) {\n    if (n \u003e 0) {\n        for (int i = 0; i \u003c 4; i += 1) {\n            plantJungleSaplings(n - 1);\n        }\n    }\n}\n```\n{{\u003c /tab \u003e}}\n\n{{\u003c tab \"Q3 Answer\" \u003e}}\n$\n\\Theta(4^n)\n$\n\n**Explanation:** This tree recursion creates a tree with `n` layers. Each layer you go down, the number of calls multiplies by 4!\n\n![Tree diagram for method calls.](\u003c../img/assets/image (48).png\u003e)\n\nThis means that the number of calls in total will look like this:\n\n$\n\\sum_{i=1}^{n}4^i\n$\n\nAnd if you remember your power series, you'll know that this sum is equal to $4^{n+1}-1$ which simplifies into the final answer.\n\n![an image that makes you long for TreeCapacitator](\u003c../img/assets/image (49).png\u003e)\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n{{\u003c tabs \"q4\" \u003e}}\n{{\u003c tab \"Question 4\" \u003e}}\nLet's replace the 4 in the previous problem with **n** and see what insanity ensues.\n\n```java\nvoid plantCrazySaplings(int n) {\n    if (n \u003e 0) {\n        for (int i = 0; i \u003c n; i += 1) { // This line changed\n            plantCrazySaplings(n - 1);\n        }\n    }\n}\n```\n{{\u003c /tab \u003e}}\n\n{{\u003c tab \"Q4 Answer\" \u003e}}\n$\n\\Theta(n!)\n$\n\n**Explanation:** This tree recursion creates a tree with `n` layers. Each layer you go down, the number of calls multiplies by `n-1`...\n\n![What a mess (!)](\u003c../img/assets/image (51).png\u003e)\n\nThis means that the number of calls in total will look like this:\n\n$\n\\sum_{i=1}^{n} \\frac{n!}{i!}\n$\n\nSince `n!` is not dependent on `i` it can be factored out of the sum to produce this:\n\n$\nn!\\sum_{i=1}^{n} \\frac{1}{i!}\n$\n\nHey, that looks a lot like the Taylor series for $e$! Since `e` is a constant, it simply reduces to `n!`.\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n## Best and Worst Case Runtimes\n\n{{\u003c tabs \"q5\" \u003e}}\n{{\u003c tab \"Question 5\" \u003e}}\nHere's a case where the best case and worst case runtimes are different. Can you figure out what they are? (Let `n = items.length`).\n\n```java\nItem[] hopperSort(Item[] items) {\n    int n = arr.length; \n    for (int i = 1; i \u003c n; ++i) { \n        int key = items[i]; \n        int j = i - 1; \n        while (j \u003e= 0 \u0026\u0026 items[j].compareTo(key) \u003e 0) { \n            items[j + 1] = items[j]; \n            j = j - 1; \n        } \n        items[j + 1] = key; \n    } \n}\n```\n{{\u003c /tab \u003e}}\n\n{{\u003c tab \"Q5 Answer\" \u003e}}\n**Best Case:** $\\Theta(n)$ if the array is nearly sorted except for a couple values. In this case, the `while` loop will only run a small number of times, so the only loop left is the for loop.\n\n**Worst Case:** $\\Theta(n^2)$if the array is totally reversed. This will cause the `while` loop to run on the order of `O(n)` times, resulting in a nested loop.\n\n**Note:** HopperSort is literally just Insertion Sort 😎🤣\n\n![hoppers rate 64/64](\u003c../img/assets/image (45).png\u003e)\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n{{\u003c tabs \"q6\" \u003e}}\n{{\u003c tab \"Question 6\" \u003e}}\nHere's a mutual recursion problem! What are the best and worst cases for `explodeTNT(n)`? What are their runtimes?\n\n```java\nvoid explodeTNT(int n) {\n    if (n % 2 == 0) {\n        digDirts(n - 1, true);\n        digDirts(n - 2, false);\n    } else {\n        digDirts(n / 2, true);\n    }\n}\n\nvoid digDirts(int n, boolean isTNT) {\n    if (isTNT) {\n        explodeTNT(n / 2);\n    }\n    removeDirt(); // not implemented, assume O(1) runtime\n}\n```\n{{\u003c /tab \u003e}}\n\n{{\u003c tab \"Q6 Answer\" \u003e}}\n**Best Case:** $\\Theta(\\log(n))$ if n is even. This will result in n being halved every function call.\n\n**Worst Case:** $\\Theta(n)$if n is odd. See the tree below for an illustration of what happens in this case- hopefully the diagram will make it clearer as to why it's O(n).\n\n![A diagram of what happens in the worst and best cases.](\u003c../img/assets/image (46).png\u003e)\n\n![don't play with tnt, kids](\u003c../img/assets/image (47).png\u003e)\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n## Challenge Problems\n\nThese problems are quite difficult. Don't be concerned if you don't feel confident in solving them (I certainly don't).\n\n{{\u003c tabs \"q7\" \u003e}}\n{{\u003c tab \"Question 7\" \u003e}}\nA huge disaster :ooo\n\n```java\n//initially start is 0, end is arr.length.\npublic int PNH(char[] arr, int start, int end) {\n    if (end \u003c= start) {\n        return 1;\n    }\n    int counter = 0; \n    int result = 0;\n    for (int i = start; i \u003c end; i += 1) {\n        if (arr[i] == 'a') {\n            counter += 1;\n        }\n    }\n    for (int i = 0; i \u003c counter; i += 1) {\n        result += PNH(arr, start + 1, end);\n    }\n    int mid = start + (end - start) / 2;\n    return PNH(arr, start, mid) + PNH(arr, mid + 1, end);\n}\n```\n{{\u003c /tab \u003e}}\n\n{{\u003c tab \"Q7 Answer\" \u003e}}\n**Best Case:** $\\Theta(n\\log(n))$ If none of the characters in char\\[] is 'a', then each call to PNH does $\\Theta(n)$ work. Total work per layer is always N, with logN layers total.\n\n**Worst Case:** $\\Theta(n!)$ All of characters in char\\[] is 'a'. In this case, the for loop recursive calls will dominate the runtime, because it'll be the main part of the recursive tree. The interval start to end is decreased by one in the for loop recursive calls, while that interval is halved in the return statement recursive calls. This means the return statement recursive calls will reach the base case in logn levels, while the recursive calls in the for loop will take n levels. Thus, we can proceed with the same analysis as question 4.\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n{{\u003c tabs \"q8\" \u003e}}\n{{\u003c tab \"Question 8\" \u003e}}\nCongrats for making it this far! By now you should be an expert in asymptotic analysis :P Here's one last problem:\n\n```java\n//initially start is 0, end is arr.length.\npublic int lastOne(char[] arr, int start, int end) {\n    if (end \u003c= start) {\n        return 1;\n    }\n    else if (arr[start] \u003c= arr[end]) {\n        return lastOne(arr, start + 1, end - 1);\n    } else {\n        int temp = arr[start];\n        arr[start] = arr[end];\n        arr[end] = temp;\n\n        return lastOne(arr, start + 1, end) \n        + lastOne(arr, start, end - 1) \n        + lastOne(arr, start + 1, end - 1);\n    }\n}\n```\n{{\u003c /tab \u003e}}\n\n{{\u003c tab \"Q8 Answer\" \u003e}}\n**Best Case:** $\\Theta(n)$ if the else if case is always true. This will produce a tree with height n/2, where each height does constant work.\n\n**Worst Case:** $\\Theta(3^n)$ if else if case is never true. Sorry no diagram yet :((\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n",
    "lastmodified": "2023-01-06T09:54:01.017507801Z",
    "tags": null
  },
  "/cs61b/misc-topics/": {
    "title": "",
    "content": "",
    "lastmodified": "2023-01-06T09:06:13.732985614Z",
    "tags": null
  },
  "/cs61b/misc-topics/exceptions": {
    "title": "",
    "content": "# Exceptions\n\n## Basics\n\nAn **exception** occurs when something unintended occurs and the interpreter must exit.\n\nWhile this might sound like a bad thing, we can often throw our own exceptions to handle known errors or edge cases more gracefully.\n\n### Exceptions in Java\n\nIn Java, there are two types of exceptions: **checked** and **unchecked.**\n\n**Checked** exceptions are handled during compile time, and are included in the method declaration. As an example:\n\n```java\npublic void openFile() throws IOException {\n    ...\n}\n```\n\n* All children that override this method must also throw the same exceptions.\n\n**Unchecked** exceptions are not handled during compile time, and thus are thrown during runtime. All `Error` or `RuntimeException` types are unchecked; all other exceptions are checked. Some examples of unchecked exceptions are dividing by zero (`ArithmeticException`), or accessing an index that doesn't exist (`IndexOutOfBoundsException`).\n\n![Some of the more common Exception types in Java.](\u003c../img/assets/image (4).png\u003e)\n\n## Creating Custom Exceptions\n\nWe can use the `throw` keyword to create exceptions with custom error messages as follows:\n\n```java\npublic void divide(int a, int b) {\n    if (b == 0) {\n        throw new Exception(\"Error Message\");\n    } else {\n        return a / b;\n    }\n}\n```\n\nThis is often used within a `try catch` block, as such:\n\n```java\npublic void divide2() {\n    int a = 0;\n    try {\n        return 10 / 0;\n    } catch(Exception e) {\n        System.out.println(\"oops!\");\n    }\n }\n```\n\nAn alternate to custom exceptions is to simply handle exception cases. For example, we can add a check to make sure a number is not zero before running a division operation.\n\n## Try/Catch/Finally Example\n\nLet's check your understanding of exception handling!\n\n```java\nstatic String tryCatchFinally() {\n        try {\n            System.out.println(\"trying\");\n            throw new Exception();\n        } catch (Exception e) {\n            System.out.println(\"catching\");\n            return \"done catch\";\n        } finally {\n            System.out.println(\"finally\");\n        }\n    }\n```\n\n{{\u003c tabs \"q1\" \u003e}}\n{{\u003c tab \"Q1\" \u003e}}\nWhat will be printed (and in what order) when `tryCatchFinally()` is run?\n{{\u003c /tab \u003e}}\n\n{{\u003c tab \"Q1 Answer\" \u003e}}\nFirst, `trying` will be printed.\n\nSince an Exception is thrown, the catch block will run next, so `catching` is printed next.\n\nSince finally blocks _always_ run regardless of result, `finally` is printed last.\n{{\u003c /tab \u003e}}\n{{ \u003c /tabs \"q2\" \u003e}}\n\n{{\u003c tabs \u003e}}\n{{\u003c tab \"Q2\" \u003e}}\nSuppose the same code were run, but without the `catch` block. What would this code do?\n\n```java\nstatic String tryFinally() {\n        try {\n            System.out.println(\"trying\");\n            throw new Exception();\n        } finally {\n            System.out.println(\"finally\");\n        }\n}\n```\n{{\u003c /tab \u003e}}\n\n{{\u003c tab \"Q2 Answer\" \u003e}}\nIf the try block throws an uncaught Exception (i.e. if catch block does not exist or catch block does not handle the type of Exception that is thrown in the try block), Java halts execution of the try block, **executes the finally block**, then raises a runtime error.\\\n\\\nSo, the following sequence would occur:\\\n1\\. `trying` is printed.\\\n2\\. `finally` is printed.\\\n3\\. The program exits with a `RuntimeException`.\n{{\u003c /tab \u003e}}\n{{ \u003c /tabs \u003e}}\n",
    "lastmodified": "2023-01-10T22:24:00.749381718Z",
    "tags": null
  },
  "/cs61b/misc-topics/modular-arithmetic": {
    "title": "",
    "content": "# Modular Arithmetic and Bit Manipulation\n\n\u003e [!warning] Content Note\n\u003e\n\u003e Make sure you're comfortable working with binary numbers (adding, subtracting, converting to decimal) before continuing.\n\n## Integer Types\n\nThis is an excerpt from the chart in [Java Objects](/cs61b/oop/objects.md). Go there to review primitive types first!\n\n| Type  | Bits | Signed | Literals                      |\n| ----- | ---- | ------ | ----------------------------- |\n| byte  | 8    | yes    | 3, (int)17                    |\n| short | 16   | yes    | None - must cast from int     |\n| char  | 16   | no     | 'a', '\\n'                     |\n| int   | 32   | yes    | 123, 0100 (octal), 0xff (hex) |\n| long  | 64   | yes    | 123L, 0100L, 0xffL            |\n\n## Signed Numbers\n\nA type is **signed** if it can be **positive** **or** **negative.** Unsigned types can _only_ be positive.\n\nIn signed types, the **first bit** is reserved for determining the sign of the number (0 is positive, 1 is negative). This means that there is one fewer bit for the actual number. For example, ints only have **31** bits for the number.\n\n### Reading negative numbers\n\nLet's say you are given a number like `10100`and want to convert it to decimal. We know that the 1 in the front means it's a negative number! However, we can't just discard that 1 and read the rest like a positive number. Instead, we have to **flip all the bits** and then **add one** to the result. So, `10100` flipped will become `01011`. Adding one will result in `01100`, which is the correct answer (12).\n\n**Why do we have to do this?** Read on to the next section to find out!\n\n## Two's Complement\n\n**Two's Complement** is a a method of storing negative numbers in a way that supports proper arithmetic. Here's how it works:\n\n1. Start with a binary number we want to negate, like `0101`, which is 5.\n2. Flip all the bits to make `1010`.\n3. Add one to make `1011`.\n\nAlthough it makes negative numbers harder to read, the benefits are much more significant- it allows addition and subtraction to work between positive and negative numbers.\n\nIf you want to see firsthand why simply flipping the signed bit doesn't work, try out some problems in [this worksheet](https://d1b10bmlvqabco.cloudfront.net/attach/k5eevxebzpj25b/jcaul3qcivh6kh/k8g51ayfl9ui/GuerillaSection2.pdf) ([solutions](https://d1b10bmlvqabco.cloudfront.net/attach/k5eevxebzpj25b/jcaul3qcivh6kh/k8g53zthgevk/GuerillaSection2Sols.pdf)).\n\n## Modular Arithmetic\n\nSince primitive types have a fixed number of bits, it is possible to **overflow** them if we add numbers that are too large. For example, if we add `01000000`(a byte) with itself, we'd need 9 bits to store the result!\n\nThis will cause lots of issues, so we use **modular arithmetic** to **wrap around to the largest negative version** and keep the number in bounds. For example, `(byte)128 == (byte)(127+1) == (byte)(-128)`**.**\n\n## Bit Operations\n\n**Mask: \u0026**\n\n* `A \u0026 B` will only keep the bits that are 1 in A **AND** B\n* Example: `00101100 \u0026 10100111 == 00100100`\n\n**Set: |**\n\n* `A | B` will keep the bits that are 1 in A **OR** B\n* Example: `00101100 | 10100111 == 10101111`\n\n**Flip: ^**\n\n* `A ^ B` will keep the bits that are 1 in A **XOR** B\n* In other words, 1 if bits are unequal in A and B, 0 otherwise\n* Example: `00101100 ^ 10100111 == 10001011`\n\n**Flip all: \\~**\n\n* `~A` will flip all the bits from 1 to 0 or 0 to 1 in A\n* Example: `~10100111 == 01011000`\n\n**Shift Left: \u003c\u003c**\n\n* `A \u003c\u003c n` will shift all bits left n places\n* All newly introduced bits are 0\n* Example: `10101101 \u003c\u003c 3 == 01001000`\n* `x \u003c\u003c n` is equal to x \\* 2^n\n\n**Arithmetic Right: \u003e\u003e**\n\n* `A \u003e\u003e n` will shift all bits **except for the signed bit** right n times\n* Newly introduced bits are the same as the signed bit\n* Example: `10101101 \u003e\u003e 3 == 11110101`\n\n**Logical Right: \u003e\u003e\u003e**\n\n* `A \u003e\u003e\u003e n` will shift ALL bits right n times\n* Newly introduced bits are 0\n* Example: `10101101 \u003e\u003e\u003e 3 == 00010101`\n* Another example: `(-1) \u003e\u003e\u003e 29 == 7` because it leaves 3 1-bits- ints are 32 bits\n\n## Why is this useful?\n\nJust looking at these obscure operations, it may be unclear as to why we need to use these at all.\n\nWell, [here's a massive list of bit twiddling hacks](https://graphics.stanford.edu/\\~seander/bithacks.html) that should demonstrate plenty of ways to use these simple operations to do some things really efficiently.\n\nThese operations are also the **building blocks for almost all operations done by a computer.** You'll see firsthand how these are used to construct CPU's in [61C](https://cs61c.org/).\n",
    "lastmodified": "2023-01-10T22:24:26.449137117Z",
    "tags": null
  },
  "/cs61b/misc-topics/more-resources": {
    "title": "",
    "content": "# More Resources\n\nHere are some more cool things to look at!\n\n* [Big O Cheat Sheet ](https://www.bigocheatsheet.com/)- complexities of sorting and common data structure operations\n* [Toptal Sorting Algorithm Animations ](https://www.toptal.com/developers/sorting-algorithms)- animations, pseudocode, and property summaries\n* [Josh Hug's 61B Playlist](https://www.youtube.com/channel/UC7FzTMO4rKvlqIyU5vwzFKQ/playlists) - concise video lectures for most 61B topics\n* [Balanced Search Demos](https://inst.eecs.berkeley.edu/\\~cs61b/sp20/materials/lectures/lect29/) - play around with balanced search structures and see how they work\n",
    "lastmodified": "2023-01-06T02:00:57.043237977Z",
    "tags": null
  },
  "/cs61b/oop/": {
    "title": "",
    "content": "",
    "lastmodified": "2023-01-06T09:23:38.226500272Z",
    "tags": null
  },
  "/cs61b/oop/access-control": {
    "title": "",
    "content": "\n## What is Access Control?\n\nIn Java, we can specify the **level of access** certain variables and methods have. With this power, we can show or hide these variables to other classes and references on demand!\n\nThere are **4** modifier levels that get progressively more open:\n\n* **Private:** Only this class can see it.\n* **Package Protected (the default level):** All classes in the **same package** can see it.\n* **Protected: Subclasses** (that inherit from the parent) can also see it.\n* **Public:** All classes in the program can see it.\n\n![A chart comparing the different access modifiers. The black bar is the default (\"package protected\").](\u003c../img/assets/image (5).png\u003e)\n\n## Why do we need access control?\n\nAccess control works really well with other OOP concepts to help structure programs better and make them easier to understand. Here are some of the major benefits:\n\n* Access control is **self documenting.** Usually, there's a reason for making certain variables private and others public, and no more needs to be said for that to be understood.\n* **It's safe to change private methods without worrying about breaking things.** If a method is private, we know that the only references are within the same class, so we can edit them however we want without making other classes error as well.\n* **Private/protected variables don't need to be understood by users.** If someone needs to use your program, they don't need to learn how to use any private methods since those will be hidden to them.\n\n## Practice\n\nLet's see how access control can be used to hide variables in different situations:\n\n```java\npackage P;\npublic class A {\n    int def; // Variable with default access\n    protected int prot; // Variable with protected access\n    private int priv; // Variable with private access\n    \n    static class NestedA { ... }\n}\n\npublic class B extends A { ... }\n\n===================\npackage Q;\npublic class C extends P.A { ... }\n\n```\n\n{{\u003c tabs \"q1\" \u003e}}\n{{\u003c tab \"Question 1\" \u003e}}\nWhich variables can be accessed in B?\n{{\u003c /tab \u003e}}\n\n{{\u003c tab \"Answer\" \u003e}}\n`def` and `prot` since B is in the same package as A.\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n{{\u003c tabs \"q2\" \u003e}}\n{{\u003c tab \"Question 2\" \u003e}}\nWhich variables can be accessed in C?\n{{\u003c /tab \u003e}}\n\n{{\u003c tab \"Answer\" \u003e}}\n`prot` only, since C is in a different package but extends A.\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n{{\u003c tabs \"q3\" \u003e}}\n{{\u003c tab \"Question 3\" \u003e}}\nWhich variables can be accessed in NestedA?\n{{\u003c /tab \u003e}}\n\n{{\u003c tab \"Answer\" \u003e}}\nNone of them, because NestedA is static and cannot reference any non-static variables.\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n",
    "lastmodified": "2023-01-06T09:56:54.299641698Z",
    "tags": null
  },
  "/cs61b/oop/dynamic-method-selection": {
    "title": "",
    "content": "# Dynamic Method Selection\n\n\u003e [!warning] Content Note\n\u003e\n\u003e This is a **very tricky topic**. Make sure you are comfortable with [inheritance](inheritance.md) and [access control](access-control.md)before proceeding!\n\nInheritance is great and all, but it does have some issues. One of the biggest issues lies in overriding: **if two methods have exactly the same name and signature, which one do we call?**\n\nIn a standard use case, this is a pretty simple answer: whichever one is in the class we want! Let's look at some basic examples.\n\n```java\npublic class Dog {\n    public void eat() { ... } // A\n}\n\npublic class Shiba extends Dog {\n    @Override\n    public void eat() { ... } // C\n}\n```\n\n{{\u003c tabs \"q1\" \u003e}}\n{{\u003c tab \"Question 1\" \u003e}}\nWhich method is called when we run:\n\n```java\nDog rarePupper = new Dog();\nrarePupper.eat();\n```\n{{\u003c /tab \u003e}}\n\n{{\u003c tab \"Q1 Answer\" \u003e}}\nIt's **A** 🐕 Dog doesn't know anything about `Shiba` or any other classes, so we can just look at the Dog.\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n{{\u003c tabs \"q2\" \u003e}}\n{{\u003c tab \"Question 2\" \u003e}}\nWhat about when we call:\n\n```java\nShiba doge = new Shiba();\nrarePupper.eat();\n```\n{{\u003c /tab \u003e}}\n\n{{\u003c tab \"Q2 Answer\" \u003e}}\nThis calls **C**! This works intuitively because `Shiba` overrides `Dog` so all `Shibas` will use C instead of A.\n\n![](\u003c../img/assets/image (8).png\u003e)\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n## Things Get Wonky: Mismatched Types\n\nThere's an interesting case that actually works in Java:\n\n```java\nDog confuzzled = new Shiba();\n```\n\nWhat??? Shouldn't this error because `Dog` is incompatible with `Shiba`?\n\nIt turns out that **subclasses can be assigned to superclasses.** In other words, `Parent p = new Child()` works fine. This is really useful for things like [Interfaces](inheritance.md#interfaces) and generic [Collections](../abstract-data-types/collections/) because we might only care about using generic methods, and not the specific implementation that users chose to provide.\n\nHowever, **it is important to note that it doesn't work the other way.** `Child c = new Parent()` will error because the child might have new methods that don't exist in the parent.\n\n**Let's see how this makes inheritance really tricky:**\n\n```java\n/** The following problems are inspired by Spring 2020 Exam Prep 5. */\n\npublic class Dog {\n    public void playWith(Dog d) { ... } // D\n}\n\npublic class Shiba extends Dog {\n    @Override\n    public void playWith(Dog d) { ... } // E\n    public void playWith(Shiba s) { ... } // F\n}\n```\n\n{{\u003c tabs \"q3\" \u003e}}\n{{\u003c tab \"Question 3\" \u003e}}\nWhich method(s) run when we call:\n\n```java\nDog rarePupper = new Shiba();\nrarePupper.playWith(rarePupper); // aww rarePupper is lonely :(\n```\n{{\u003c /tab \u003e}}\n\n{{\u003c tab \"Q3 Answer\" \u003e}}\n**E** is called! What happens is that the **dynamic type** is chosen to **select the method from,** but the **static type** is used to **select the parameters.** `rarePupper`'s **** dynamic type is `Shiba` but its static type is `Dog` so `Shiba.playWith(Dog)` is chosen as the method.\n\n![rarePupper in action](\u003c../img/assets/image (10).png\u003e)\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n{{\u003c tabs \"q4\" \u003e}}\n{{\u003c tab \"Question 4\" \u003e}}\nWhich is called when we run**:**\n\n```java\nDog rarePupper = new Shiba();\nShiba doge = new Shiba();\nrarePupper.playWith(doge); // rarePupper is happy :) borks all around\n```\n{{\u003c /tab \u003e}}\n\n{{\u003c tab \"Q4 Answer\" \u003e}}\n**E** is called again! Bet ya didn't see that coming 😎\n\n**Why is it not F? I thought doge and rarePupper were both** `Shiba`**?**\\\n****When the compiler chooses a method, it **always** starts at the **static method.** Then, it keeps going down the inheritance tree until it hits the **dynamic method.** Since F has a **different signature** than D, it isn't an **overriding method** and thus the compiler won't see it. But E is (since it has the same signature as D), so that is why it is chosen instead.\n\n![bork bork bork :DDD](\u003c../img/assets/image (11).png\u003e)\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n## Adding more insanity: Static vs. Dynamic\n\nBy now, you should have a pretty good understanding of the **method selection** part of DMS. But why is it **dynamic?**\n\nYou may have noticed that there are **two** type specifiers in an instantiation. For example, `Dog s = new Shiba()` has type `Dog` on the left and `Shiba` on the right.\n\nHere, `Dog` is the **static type** of `s`: it's what the compiler believes the type should be when the program is compiled. Since the program hasn't run yet, Java doesn't know what exactly it is- it just knows it has to be some type of `Dog`.\n\nConversely, `Shiba` is the **dynamic type:** it gets assigned during runtime.\n\n### The type rules\n\nJust remember: **like chooses like.** If a method is **static**, then choose the method from the **static type.** Likewise, if a method is **not static,** choose the corresponding method from the **dynamic type.**\n\nLet's try some examples!\n\n```java\npublic class Dog {\n    public static String getType() {\n        return \"cute doggo\";\n \n    @Override // Remember, all objects extend Object class!   \n    public String toString() {\n        return getType();\n    }\n}\n\npublic class Shiba extends Dog {\n    public static String getType() {\n        return \"shiba inu\";\n    }\n}\n```\n\n{{\u003c tabs \"q5\" \u003e}}\n{{\u003c tab \"Question 5\" \u003e}}\nWhat prints out when we run:\n\n```java\nDog d = new Shiba();\nSystem.out.println(d.getType());\n```\n{{\u003c /tab \u003e}}\n\n{{\u003c tab \"Q5 Answer\" \u003e}}\n`cute doggo` gets printed because `getType()` is a static method! Therefore, Java looks at the **static type** of `d`, which is `Dog`. \\\n(If `getType()` weren't static, then `shiba inu` would have been printed as usual.)\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n{{\u003c tabs \"q6\" \u003e}}\n{{\u003c tab \"Question 6\" \u003e}}\nWhat prints out when we run:\n\n```java\nShiba s = new Shiba();\nSystem.out.println(s);\n```\n{{\u003c /tab \u003e}}\n\n{{\u003c tab \"Q6 Answer\" \u003e}}\n`cute doggo` also gets printed!! This is because static methods **cannot be overridden.** When `toString()` is called in `Dog`, it doesn't choose `Shiba`'s `getType()` because `getType()` is static and the static type is `Dog`.\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n{{\u003c tabs \"q7\" \u003e}}\n{{\u003c tab \"Question 7\" \u003e}}\nWhat prints out when we run:\n\n```java\nDog d = new Shiba();\nSystem.out.println(((Shiba)d).getType());\n```\n{{\u003c /tab \u003e}}\n\n{{\u003c tab \"Q7 Answer\" \u003e}}\nThis time, `shiba inu` gets printed. This is because casting temporarily changes the **static type:** since the static type of `d` is `Shiba` in line 2, it chooses the `getType()` from `Shiba`.\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n## That's all, folks!\n\nIf you want some **even harder** problems, [check this out](https://inst.eecs.berkeley.edu/\\~cs61b/sp20/materials/disc/examprep5.pdf) and also [this](https://inst.eecs.berkeley.edu/\\~cs61b/sp20/materials/disc/examprep6.pdf).\n\n![bai bai!](\u003c../img/assets/image (12).png\u003e)\n",
    "lastmodified": "2023-01-06T10:01:31.8446118Z",
    "tags": null
  },
  "/cs61b/oop/generics": {
    "title": "Generic Types",
    "content": "\nSometimes, we want things to support **any type**, including user defined types that we don't know about! For example, it would make sense that we don't care what type we make a `List` out of, since it's just a whole bunch of objects put together.\n\nThe Java solution is **generics!** Generic types are denoted by a `\u003c\u003e` and can be appended to **methods and classes.** Here's an example with classes:\n\n```java\n/**\n  * Creates a type SomeClass that takes * in a generic SomeType. SomeType can * be named anything.\n*/\npublic class SomeClass\u003cSomeType\u003e {\n    private SomeType someThing;\n\n    public void someMethod(SomeType stuff) {\n        doStuff(stuff);\n    }\n}\n\n...\n/** Creates a new instance of SomeClass, setting SomeType to String.\n    We don't need to put the type on the right since it's already\n    defined on the left. */\nSomeClass\u003cString\u003e aClass = new SomeClass\u003c\u003e();\n```\n\nIn this example, `SomeType` is a **Generic Type Variable** that is not a real type, but can still be used inside the class as normal.\n\nOn the other hand, `String` is an **Actual Type Argument** that replaces `SomeType` during runtime. Now, every time `SomeType` is used in `SomeClass` Java treats it exactly like a `String`.\n\n## Generic Subtypes\n\nLike in [Dynamic Method Selection](dynamic-method-selection.md), adding inheritance makes things tricky! Let's look at an example:\n\n```java\nList\u003cString\u003e LS = new ArrayList\u003cString\u003e();\nList\u003cObject\u003e LO = LS; // Line 3\nLO.add(42); // Line 4\nString s = LS.get(0); // Line 5\n```\n{{\u003c tabs \"q1\" \u003e}}\n{{\u003c tab \"Question 1\" \u003e}}\nWill **line 3** error?\n{{\u003c /tab \u003e}}\n{{\u003c tab \"Q1 Answer\" \u003e}}\n**No**, line 3 is valid and will not error! This is because Object is a **superclass** of String. Generics work in a very similar way to the [inheritance rules](inheritance.md).\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n{{\u003c tabs \"q2\" \u003e}}\n{{\u003c tab \"Question 2\" \u003e}}\nWill **line 4** error?\n{{\u003c /tab \u003e}}\n\n{{\u003c tab \"Q2 Answer\" \u003e}}\n**No**, line 4 is valid and will not error! This is because LO is a **list of Objects** and integers are a **subtype** of Object, as all things are.\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n{{\u003c tabs \"q3\" \u003e}}\n{{\u003c tab \"Question 3\" \u003e}}\nWill **line 5** error?\n{{\u003c /tab \u003e}}\n\n{{\u003c tab \"Q3 Answer\" \u003e}}\n**Yes,** line 5 will error! This is because we put 42 into LO, which is an integer. Since LO is pointing to the same object as LS, 42 is also in LS! That means we are trying to assign a String equal to an integer.\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n\u003e [!info] Content Note\n\u003e\n\u003e Arrays have slightly different behavior than this and will throw an `ArrayStoreException` if types are mismatched in any way.\n\n## Type Bounds\n\nSometimes, we want to **put constraints** on what kinds of types can be passed into a generic type.\n\nOne way of doing is is to specify that a generic type must fit within a **type bound**: here, T must be some subtype of a specified type `Number`.\n\nWe can also do it the other way and specify that a type can be a **supertype** of a specified type. Both of these examples are shown below:\n\n```java\nclass SomeClass\u003cT extends Number\u003e {\n    // A method that takes a type parameter T and takes any SUPERCLASS\n    // of T as a list generic type.\n    static \u003cT\u003e void doSomething(List\u003c? super T\u003e L) { ... }\n}\n```\n\n## Limitations of Generic Types\n\nThe biggest limitation is that **primitive types cannot be used as generic types.** For example, `List\u003cint\u003e` is invalid and will not work!\n\nOne workaround to this is to use the reference-type counterparts to primitives, such as `Integer`, `Boolean`, `Character` and so on. However, converting between these types and primitive types, which is called **autoboxing,** has significant performance penalties that must be taken into consideration.\n\nAnother limitation is that **instanceof** does not work properly with generic types. For instance, `new List\u003cX\u003e() instanceof List\u003cY\u003e` will always be true regardless of what types X and Y are.\n",
    "lastmodified": "2023-01-06T10:06:11.733402098Z",
    "tags": null
  },
  "/cs61b/oop/inheritance": {
    "title": "",
    "content": "\n## What is inheritance?\n\nEssentially, it's a way of putting similar objects together to **generalize behavior.** Inheritance is best used with relating **subtypes** to larger categories. For example, an :tangerine:orange **is a** fruit (so it's a **subtype** of fruit).\n\nLet's say that a supermarket named _Jrader Toe's_ asks us to simulate fruits for them in an online system. We could do it like this:\n\n![The naive approach.](../img/assets/image.png)\n\nNow, every fruit would need some of the same properties- like cost, weight, and name! So we would need to do something like:\n\n```java\npublic class Orange {\n    private String name = \"Orange\";\n    private int cost;\n    ...\n    public Orange(int cost, ...) {\n        this.cost = cost;\n        ...\n    }\n    // lots of methods\n    public String getName() { ...\n```\n\nThis would be _really annoying_ to do for every single fruit. And they're all the same properties for every fruit so it would also be incredibly inefficient code-wise. **Inheritance gives a much better solution!**\n\nLet's make a **Fruit** class and have all of our fruits **inherit from** that class.\n\n![uwu inheritance is cool and good](\u003c../img/assets/image (1).png\u003e)\n\nThis does amazing things because we can just create one single Fruit class that has all of the properties we need, and simply make our specific fruits inherit those properties. (Side note: making multiple things inherit from one generic interface like this is called **polymorphism.**)\n\n```java\npublic class Fruit {\n    private String name;\n    private int cost;\n    ...\n    public Orange(String name, int cost, ...) {\n        this.name = name;\n        this.cost = cost;\n        ...\n    }\n    // lots of methods\n    public String getName() { ...\n}\n\n// Now for a very simple Orange method!\npublic class Orange extends Fruit {\n    public Orange(int cost,...) {\n        super(\"Orange\", cost, ...);\n    }\n}\n```\n\nWith only those 4 lines, :tangerine:Orange now has all of the same methods and properties that Fruit has!\n\n## Implementation Inheritance (\"Extends\")\n\nYou may have noticed the `extends` keyword being used to specify that an object **inherits** from another object. This is called **implementation inheritance** since an object takes all of the behaviors from its parent and can use them like its own.\n\nWhen `extends` is used, these are the things that are inherited:\n\n* All instance and static variables that are **not private** (see [Access Control](access-control.md) for more information)\n* All non-private methods\n* All nested classes\n\nThese are **not** inherited:\n\n* Any **private** variables and methods\n* All constructors\n\n\n\u003e [!info] **Quick sidenote!**\n\u003e \n\u003e All objects automatically extend the `Object` class whether you like it or not. See [References, Objects, and Types in Java](objects.md) for more about this behavior.\n\n### Constructor magic 🏗\n\nWhen an object `extends` another object, its constructor will **automatically call the parent's constructor.** However, this does have some limitations:\n\n* It will only call the **default** (no-argument) constructor in the parent.\n* Calling the constructor is the **first thing that is done** in the child constructor.\n\nBut what if we want to call another constructor? That's where the `super` keyword comes in! When `super` is called, Java will know to **not** call the default constructor anymore. Here's an example:\n\n```java\npublic class Parent {\n    public Parent() {\n        System.out.println(\"Default constructor\");\n    }\n    public Parent(String say) {\n        System.out.println(say);\n    }\n    void doStuff() { ... }\n}\n\n// Child inherits doStuff(), but not the constructors.\npublic class Child extends Parent {\n    public Child() {\n        System.out.println(\"Child\")\n    }\n    public Child(String say) {\n        super(say);\n    }\n}\n    \npublic static void Main(String[] args) {\n    Child c1 = new Child(); // will print \"Default constructor\" then \"Child\" !!!\n    Child c2 = new Child(\"Hi\"); // will print \"Hi\"\n}\n```\n\n## Method Overriding\n\nLet's say that _Jrader Toe's_ is running a promotion for 🍐pears and wants to make them 20% off normal pears! This poses a problem because **we want to inherit everything that normal pears have, but change only one behavior** (getPrice). Well I've got the solution for you!!! And it's called **overriding.**\n\n```java\npublic class PromoPear extends Pear {\n    public PromoPear(int cost, ...) {\n        super(cost, ...);\n    }\n    \n    // Overriding the getPrice to have a new behavior only for PromoPears!\n    @Override\n    public int getPrice() {\n        return super.getPrice() * 0.8;\n    }\n    ...\n}   \n```\n\nThe `@Override` tag is technically optional, but it's highly suggested because it makes sure that you are indeed overriding something and not just making a new method! (Remember, it has to have the **same name and parameters as a method in one of its parents**.)\n\n## **Method Overloading**\n\nSometimes, you want to take in **different parameters** into the **same method.** For instance, what if we wanted to create a method `getCount(Fruit fruit)` that counts how many fruits of that type we have? We might also want to allow users to pass in the name of the fruit to do the same thing- `getCount(String fruit)`. Java will allow us to make **both** of these methods in the same class!\n\nHowever, this has some major downsides that should be considered.\n\n* It's repetitive.\n* It requires maintaining more code- changing one overload won't change the others!\n* You can't handle any data types other than the ones you explicitly specify will work.\n\nWe'll discuss better solutions further down the page as well as in the [Generic Types](generics.md) page!\n\n### How is overriding different from overloading?\n\nThey have very similar names but pretty different uses!\n\nOverriding is for methods of the same name, **same parameters**, and **different classes.** If you can remember when you use the `@Override` tag, you can relate it back to this concept!\n\nOverloading is for methods of the same name, **different parameters**, in the **same class**.\n\n## Interfaces\n\nInterfaces are like **blueprints 📘** for objects- they tell you what an object needs, but not how to implement them.\n\nThey are very similar to normal classes except for some major differences:\n\n* **All variables are constants** (public static final).\n* **Methods have no body**- just a signature (like `void doStuff();`)\n* **Classes can inherit from multiple interfaces.**\n\nTypically, interfaces will not have any implemented methods whatsoever. This limitation can technically be removed using the [default keyword](https://stackoverflow.com/questions/31578427/what-is-the-purpose-of-the-default-keyword-in-java/31579210), but this is **not recommended** because abstract classes handle this much better.\n\nHere's an example of interfaces in the wild:\n\n```java\npublic interface AnInterface\u003cItem\u003e {\n  public void doStuff(Item x);\n  public Item getItem();\n  ...\n}\n\npublic class Something implements AnInterface\u003cItem\u003e { // Note the IMPLEMENTS!\n @Override\n public void doStuff(Item x) {\n     // implement method\n }\n\n @Override\n public void getItem() {\n     // implement method\n }\n}\n\npublic class MainClass {\n  public static void main(String[] args) {\n      AnInterface\u003cString\u003e smth = new AnInterface\u003c\u003e(); // ERROR!!\n      // (new can't be used with interfaces.)\n      AnInterface\u003cString\u003e smthElse = new Something\u003cString\u003e(); // Will not error!\n      smth.getItem();\n      ...\n  }\n}\n```\n\n## Abstract Classes\n\nAbstract classes live in the place **in between** interfaces and concrete classes. In a way, they get the best of both worlds- you can implement whichever methods you want, and leave the rest as **abstract** methods (same behavior as interface methods)!\n\nHere are some properties:\n\n* **Variables behave just like a concrete class.**\n* **Normal methods can be created like any other concrete class.**\n* **Abstract methods** (`abstract void doSomething()`) **behave just like methods in interfaces.**\n* Classes can only inherit from **one** abstract class.\n\nHere's the same example from the interfaces section, but implemented using an abstract class.\n\n```java\npublic abstract class AnAbstract\u003cItem\u003e {\n  public abstract void doStuff(Item x);\n  public abstract Item getItem();\n  ...\n}\n\npublic class Something extends AnAbstract\u003cItem\u003e { // EXTENDS, not implements!\n @Override\n public void doStuff(Item x) {\n     // implement method\n }\n\n @Override\n public void getItem() {\n     // implement method\n }\n}\n\npublic class MainClass {\n  public static void main(String[] args) {\n      AnAbstract\u003cString\u003e smth = new AnAbstract\u003c\u003e(); // ERROR!!\n      // (new can't be used with abstract classes, just like interfaces.)\n      AnAbstract\u003cString\u003e smthElse = new Something\u003cString\u003e(); // Will not error!\n      smth.getItem();\n      ...\n  }\n}\n```\n\n![A chart comparing the differences between the types of classes.](\u003c../img/assets/image (2).png\u003e)\n\n## Still not satisfied?\n\nWatch [Josh Hug's video lecture](https://www.youtube.com/watch?v=IaEq\\_fogI08\\\u0026list=PL8FaHk7qbOD6km6LlaHLWgRl9SbhlTHk2) about inheritance.\n\nOr, move onto an advanced application of inheritance concepts, [Dynamic Method Selection](dynamic-method-selection.md).\n",
    "lastmodified": "2023-01-06T09:55:29.228556989Z",
    "tags": null
  },
  "/cs61b/oop/objects": {
    "title": "Java Objects",
    "content": "\nThere are two main categories of objects in Java: **Primitive Types** and **Reference Types.** This page will give a brief overview of both, and close off with some info about the mystical **Object** class.\n\n## Primitive Types\n\n**Primitive types** are built in to Java and have **fixed memory sizes.** Different types require different amounts of memory.\n\nIf you remember [environment diagrams](http://albertwu.org/cs61a/notes/environments), you may recall that some variables are put straight into the boxes, while others have an arrow pointing to them. The reason for this is that it actually denotes primitive vs. reference types! **Primitive types go straight in the box** because they aren't mutable (i.e. you can't change the objects contained in the box since they're just constant literals like numbers).\n\n**There are 8 primitive types in Java.** Here's a table of their properties! (If you don't know what \"signed\" means, go to [Modular Arithmetic and Bit Manipulation](/cs61b/misc-topics/modular-arithmetic.md).)\n\n| Type    | Bits | Signed | Default | Examples                      |\n| ------- | ---- | ------ | ------- | ----------------------------- |\n| boolean | 1    | no     | false   | true, false                   |\n| byte    | 8    | yes    | 0       | 3, (int)17                    |\n| short   | 16   | yes    | 0       | None - must cast from int     |\n| char    | 16   | no     | \\u0000  | 'a', '\\n'                     |\n| int     | 32   | yes    | 0       | 123, 0100 (octal), 0xff (hex) |\n| long    | 64   | yes    | 0       | 123L, 0100L, 0xffL            |\n| float   | 32   | yes    | 0.0     | 1.23f, -1.23e10f, .001f       |\n| double  | 64   | yes    | 0.0     | 1.23e256d, 1e1d, 1.2e-10d     |\n\n\u003e [!hint]  A quick aside on Strings 🧵\n\u003e\n\u003e You may have noticed that strings are not on this list. That is because unlike in Python, they aren't a primitive type! Under the hood, Strings are a reference type that are very similar to a char array.\n\n## Type Conversion\n\nJava will automatically convert between primitive types if **no information is lost** (\nfrom byte to int).\n\nConversion in the other direction (from a larger to smaller container) requires an explicit cast (e.g., `(char) int`). The compiler will treat a cast object as though its static type is the cast type, but this will only work if the cast type is the same as or a parent of the dynamic type. However, relative to the assigned static type, the cast type could be a child of the static type or a parent of the static type.\n\n**Assignment statements are an exception to this**: `aByte = 10` is fine even though 10 is an int literal. This is because arithmetic operations (+, \\*, ...) automatically promote operands (e.g., `'A' + 2` is equivalent to `(int)'A' + 2`)\n\nHowever, **this doesn't work if you are trying to add a larger type to a smaller type** (e.g., `aByte = aByte + 1` since operands become an int type which cannot be set equal to a byte type. **But += works**!\n\n## Reference Types\n\nA **reference type** refers to basically anything that's not primitive 😅\n\nThis includes **user-defined objects** as well as many common Java built-in types such as **arrays, strings, and** [**collections**](../abstract-data-types/collections/)**.**\n\nHere are some major differences that set them apart from primitive types:\n\n* Reference types can take an **arbitrary amount of memory.** Unlike primitives which have a fixed memory for each type, objects like arrays can expand to hold lots of things inside it.\n* Reference types are referred to using **addresses.** When you say something like `int[] arr = new int[5]`, `arr` only stores a 64-bit **memory address** which **points** to the real object, a 5-length integer array. Again, think back to the arrow in environment diagrams, and how those work.\n* By default, reference types can be set to **null** which is represented as an **address of all zeroes.** Or, the **new** keyword can be used to set it to a specific address.\n* Reference objects can be **lost** if all pointers to it are reassigned. For example, if I now enter `arr = null;`, the original 5-length array still exists, but just has nothing to refer to it.\n\n## The Equals Sign\n\nThe assignment operator (`=`) has **different behaviors** for primitive types and references types.\n\nFor **primitive types,** `y = x` means \"**copy** **the bits** from y into a new location, then call them x\". Here, the **entire object** is copied- this means that changing y will NOT change x even though they are set \"equal\".\n\nFor **reference types,** `obj1 = obj2` means \"**copy the address** stored in obj1 to obj2\". Here, `obj1` and `obj2` are referring to the **exact same object,** and mutating one will change the other.\n\n\u003e [!info] A clarification on reference type assignment\n\u003e\n\u003e By mutating, I mean changing the **internals** of an object (for example, accessing an array index or doing something like `obj1.value = 1`. If you change the actual **address** of `obj2`, as in `obj2 = obj3`, this does **not** change `obj1` because `obj2` is now referring to a completely different object!\n{% endhint %}\n\n## The Object Class\n\nIn Java, **all objects inherit from the master Object class.** Here are some important properties of Object that will be useful to know:\n\n* `String toString()`: By default, this prints out the class name followed by the memory address (e.g., `Object@192c38f`). This can be overridden to make more user-friendly names for objects.\n* `boolean equals(Object obj)`: By default, this checks if the two objects are actually the same object (same memory address). This can be overridden to check if specific contents of objects are the same, rather than checking if they are literally the same object. (Like `\"foo\"` should equal `new String(\"foo\")`)\n* `int hashCode()`: Returns a numeric hash code for the object that should differentiate it from other objects. **This should be overridden if** **`equals()` is overridden** since `x.hashCode()` should equal `y.hashCode()` if `x.equals(y)` is true!\n* `Class\u003c?\u003e getClass()`: Returns the class of this object.\n\nObject has plenty of other methods and properties as well, but these aren't as important. If you want to learn about them, feel free to refer to the [Java documentation](https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html).\n",
    "lastmodified": "2023-01-10T22:22:30.622239377Z",
    "tags": null
  },
  "/cs70/": {
    "title": "",
    "content": "\n## Welcome to my CS70 Guide!\n\nThis is a **non-comprehensive** guide to discrete math and probability, specifically for computer science applications. It's based off of Berkeley's [CS70](https://www.eecs70.org/) material from Fall 2020 (and doubles as my notes for the course).\n\n### Who is this for?\n\nMostly me; making unnecessarily detailed guides is my goto method of making sure I understand everything😁But you are welcome to use it as well for reviewing for exams, touching up on discrete math, or whatever you want!\n\n### How to use this guide\n\nAgain, I will emphasize that this **isn't a textbook.** While I try to be as comprehensive as possible, I'm sure I missed plenty of important concepts or assume you know others. I don't have an army of peer reviewers and guinea pigs to test-read the thing, so it's also not guaranteed that everything is 100% accurate. Please [open an issue](https://github.com/64bitpandas/cs70-notes/issues) if you think something's wrong!\n\nThis content was ported from my original [CS70 Notes](https://cs70.bencuan.me), so you may see some strange formatting here and there. Again, please create an issue if you spot anything overly egregious.\n\n\n\u003e [!hint] Content Note\n\u003e\n\u003e For more difficult topics, I'll put a warning like this at the top of the page with links to prerequisites or supporting topics!\n\n### Probability Notice\n\nAlthough the discrete math notes are mostly complete, the probability notes are not (and likely will never be). If you like my style of notes, you should refer to the [Data 140 Textbook](https://prob140.org/textbook/content/README.html) for this half of the course.\n\n## How to contribute\n\nSee the [contributing guide](/contributing) for more details!\n\nFor LaTeX specifically, you can easily create expressions by surrounding them with double dollar signs. For example, `$\\lnot A \\iff B$` will create the equation $\\lnot A \\iff B$ when rendered. Check out the [LaTeX Reference](/cs70/latex-reference.md) for commonly used commands.\n\n#### Credits\n\n* [Ben Cuan](https://github.com/64bitpandas)\n",
    "lastmodified": "2023-01-12T02:22:35.301116268Z",
    "tags": null
  },
  "/cs70/discrete-math/": {
    "title": "Discrete Math",
    "content": "",
    "lastmodified": "2023-01-10T21:59:15.799431123Z",
    "tags": null
  },
  "/cs70/discrete-math/computability": {
    "title": "Computability",
    "content": "\nComputability is the study of a massively important question:  **do there exist any problems that are impossible for a computer to solve?**\n\n## **The Halting Problem**\n\nIt turns out that the above question itself is impossible to solve: in other words, **there cannot exist a program HALT which determines if a program can halt in finite time given a particular input.**\n\nThis was originally proposed by Alan Turing- he proved the nonexistence by attempting to feed the Halting Problem into itself: if the Halting Problem doesn't halt, then it is supposed to output an answer. That means that the Halting Problem would state that the Halting Problem halts, even though it didn't. This paradox led to demonstrating that the Halting Problem simply cannot be solved.\n\n\u003ciframe\n    width=\"640\"\n    height=\"480\"\n    src=\"https://www.youtube.com/embed/macM_MtS_w4\"\n    frameborder=\"0\"\n    allow=\"encrypted-media\"\n    allowfullscreen\n\u003e\n\u003c/iframe\u003e\n\n## Reductions\n\n**Reducing** a problem A to another problem B means that we can solve problem A if we know how to solve problem B.\n\nFor instance, we might be able to write psuedocode that has a whole bunch of known components, but rely on the output of problem B in order to determine the final output.\n\nOne application of reduction is to show that **a program cannot exist if it requires the Halting Problem as a component.**\n",
    "lastmodified": "2023-01-10T22:01:27.534199882Z",
    "tags": null
  },
  "/cs70/discrete-math/countability": {
    "title": "Countability",
    "content": "\n\n\n![But Buzz... which kind of infinity :?](\u003c../img/assets/image (17).png\u003e)\n\n**How big is infinity? Are some infinities bigger than others?** The $\\infty$is a rather mind-boggling concept; the principles of countability will hopefully make some sense out of it.\n\n## Bijections\n\nA **bijection** is a mapping between two sets such that there **exists** a **unique** pairing from a particular element of one set to another.\n\nThese ideas of **existence** and **uniqueness** can be formalized by considering some different types of maps:\n\nAn **injection**, otherwise known as a **one-to-one** mapping, is where each element in a set maps to a **unique** element in another set. (This does not, however, guarantee that the same is true the other way around- some elements in the second set may not have any mapping to them!) More formally: $(\\forall x,y \\in D)(f(x) = f(y) \\implies x = y)$\n\nA **surjection**, otherwise known as an **onto** mapping, is where there **exists an input corresponding to every output.** More formally: $(\\forall y \\in R)(\\exists x \\in D)( y = f(x))$\n\nFor an injection, $|A| \\le |B|$: there must be at least one input per output.\\\nFor a surjection, $|A| \\ge |B|$: there must be at least one output per input.\n\nA **bijection,** also known as an **isomorphism,** is a mapping that is **both one-to-one AND onto.** This guarantees that **the two sets must be the same size**, a statement known as the **isomorphism principle**\n\n![Source: http://www.eecs70.org/static/notes/n11.pdf ](\u003c../img/assets/image (18).png\u003e)\n\n## Countability\n\nA set $S$ is **countable** if there is a **bijection from S to the set of natural numbers** $\\mathbb{N}$**or a subset of N.** In other words, $S$and $\\mathbb{N}$have the **same cardinality.** \\\nThis should make intuitive sense because the natural numbers are, by definition, countable (we can start from 1, then 2, then 3... and hit them all), so if we can somehow number off some elements in a group and count them that way, then those elements are countable!\n\n#### Proving that something is countable:\n\n\n\n* Find a bijection from S to N or N to S (must prove one to one and onto). Note that a bijection in either direction is individually valid.\n* Find an injection from S to N, AND an injection from N to S.\n* **Enumeration**: list all elements of S.\n\n## Enumerability\n\nLet's now think about some ways we can list every element in a set. \\\nSome properties to keep in mind:\n\n* **Listing a set implies that it is countable.**\n* Every element must have a unique, finite position on the list. (You can number them off.)\n* Any infinite set that can be listed is as large as the set of natural numbers.\n\nOne method of enumerating is to find a **recursive definition** of the set: that is, given any one element in the set, we can define the element that immediately follows it.\n\nOne example of an enumerable set is the set of all binary strings$B = \\{0, 1\\}^* = \\{\\emptyset, 0, 1, 00, 01, 10, 11, 000 \\cdots \\}$ **.** This is enumerable because we can say that a string with $n$bits will be guaranteed to appear before position $2^{n+1}$.\n\nOne example of a non-enumerable set is the set of all rational numbers: we can't write fractions in an order such that you can get to the next fraction in a finite number of steps. However, the _are_ countably infinite (read on to find out why!)\n\n\n\n## Pairs of Natural Numbers\n\nA pair of natural numbers $N \\times N$ has size $|N| \\times |N|$so it is countably infinite. We can enumerate this: $(0,0), (1,0), (0,1), (2,0) \\cdots$which guarantees that the pair $(a,b)$is in the first $(\\frac{(a+b+1)(a+b)}{2}$elements in the list. (triangle)\n\n![](\u003c../img/assets/image (14).png\u003e)\n\n### Rational Numbers\n\nRationals are countably infinite by writing them all in the form $(p,q)$for a rational number $n=\\frac{p}{q}$. We determined that all pairs of natural numbers is countable so rational numbers are as well.\n\n## Cantor's Diagonalization Argument\n\n**Proof by contradiction:** assume that a set S is countable (even if it isn't). Then, there must exist a listing that contains all elements in the list (enumeration).\n\nWe can construct an item that isn't in the set by taking the diagonals of digits in the set:\n\n![](\u003c../img/assets/image (15).png\u003e)\n\nThis can be used to prove that real numbers are not countable.\n\n**Formal steps :**\n\n* Assume that a set S can be enumerated.\n* Consider an arbitrary list of all the elements of S.\n* Use the diagonal from the list to construct a new element t.\n* Show that t is not in the list, but that t is in S.\n* This is a contradiction.\n\nHere's a demonstration of the diagonalization argument in action:\n\n\u003ciframe\n    width=\"640\"\n    height=\"480\"\n    src=\"https://www.youtube.com/embed/elvOZm0d4H0\"\n    frameborder=\"0\"\n    allow=\"encrypted-media\"\n    allowfullscreen\n\u003e\n\u003c/iframe\u003e\n\n\n**Continuum hypothesis:** there is no set with cardinality between the naturals and the reals.\n\n**Generalized continuum hypothesis:** there is no infinite set whose cardinality is between the cardinality of an infinite set and its power set. (In other words, the power set of the natural numbers is not countable.)\n",
    "lastmodified": "2023-01-10T23:38:09.903182434Z",
    "tags": null
  },
  "/cs70/discrete-math/graphs": {
    "title": "",
    "content": "\n\u003e [!info] Content Note\n\u003e\n\u003e This is a second introduction to graphs that assumes you've at least seen them before. Take a look at the [61B version](/cs61b/abstract-data-types/graphs) if you feel lost!\n\n## What's a graph?\n\nFormally, a graph is a **set of vertices with a set of edges connecting them.** A graph can be defined as $G = (V, E)$ where $V = \\{A, B, \\cdots V_n\\}$ and $E = \\{\\{A, B\\}, \\{B, C\\} \\cdots \\}$\n\nFor an **ordered graph** where vertices are numbered, $E$could be represented as a set of ordered pairs instead: $E = \\{(A, B), (B, C) \\cdots \\}$\n\n(Insert image of graph)\n\n### Concepts and Definitions\n\nA **neighbor** of a vertex is another vertex that is next to the original vertex. Formally u is a neighbor of v if $\\{u, v\\} \\in E$.\n\nAn edge is **incident** to the two vertices that it connects\n\nThe **degree** of a vertex is the number of other vertices neighboring. If the graph is directed, the degree can be split into the **in-degree** (number of incoming connections) and the **out-degree** (number of outgoing connections).\n\n* The sum of vertex degrees is equal to $2 |E|$.\n  * Proof: Count the number of incidences. Each edge is incident to exactly two vertices, so the total number of edge-vertex incidences is $2|E|$(i.e. two times the number of edges).\n  * The degree can also be defined as the number of incidences corresponding to a particular vertex v. Therefore, the total incidences is the sum of all degrees for all vertices!\n\nA **path** is a sequence of edges. These edges must be connected, i.e. a path could be $(v_1, v_2), (v_2, v_3), (v_3, v_4)$.\n\n* If there are $k$vertices, then a path should have $k-1$edges!\n\nA **cycle** is a special path that begins and ends on the same vertex.\n\n* Unlike a noncyclic path, there should be the same number of vertices as edges in a cycle.\n\nA **walk** is a sequence of edges that could possibly repeat a vertex or edge.\n\nA **tour** is a walk that starts and ends on the same vertex. Additionally, it cannot have any repeated edges.\n\n* An **Eulerian walk** is a walk that uses **every edge** exactly once.\n  * Doesn't require all vertices to be connected! There could be an isolated vertex with 0 degree.\n* An **Eulerian tour** is a tour that visits **every edge** in a graph exactly once**.**\n  * Theorem: any undirected graph has an Eulerian tour if and only if all vertices have **even degree** and is connected.\n  * Proof: You need to use two incident edges every time you visit a node (to enter and leave). So when you enter, you need another edge to be able to leave! If a vertex has an odd number of edges, then you get stuck on that vertex with nowhere to go once you visit it.\n\nHere's a handy summary, adapted from an explanation by [Dustin Luong](https://github.com/dstnluong):\n\n|                          | end anywhere | start = end |\n|--------------------------|--------------|-------------|\n| repeated vertices ok     | walk         | tour*       |\n| repeated vertices not ok | path         | cycle*      |\n\n\\*Eulerian if it uses each edge exactly once.\n\nTwo vertices $u$and $v$are **connected** if there exists a **path** between them.\n\n* If all vertices are connected, then the graph is considered a **connected graph.**\n\nA **complete graph** is a graph where every vertex is connected to every other vertex by exactly one edge. Complete graphs have some nice properties:\n\n* Every vertex is incident to $n-1$edges (if there are $n$total vertices).\n* The sum of all degrees is $n(n-1)$.\n\nA **tree** is kind of like the opposite of a complete graph in that it has the **minimum number of edges** in order to ensure all vertices are connected ($v-1$ total edges). Here are some properties of trees, from a graph perspective (If you aren't already familiar with the recursive definition of trees, head over to the [61B guide](https://cs61b.bencuan.me/abstract-data-types/binary-trees) first to brush up on it!)\n\n* Trees are **acyclic** and **connected.**\n* **Leaves** are vertices that have degree 1.\n* In a tree in which each parent node has 2 children, the **root** is a single vertex that has degree 2 and **non-leaf vertices** have degree 3.\n\n## Hypercubes\n\nA **hypercube** is a specific class of graphs that have highly connected vertices. In order to understand them better, let's start building some up:\n\nEvery hypercube has a dimension $n$. A 1-dimensional hypercube is simply a line (2 vertices connected by 1 edge). Not too exciting:\n\nA 2-dimensional hypercube is a square (4 vertices connected by 4 edges). Still pretty familiar:\n\nA 3-dimensional hypercube is a cube (8 vertices, 12 edges):\n\nNow, let's get to the interesting stuff. How do we construct a 4-dimensional hypercube?? Well, let's figure out how we went from 2 to 3- we essentially **duplicated** the existing hypercube, then **connected corresponding vertices** (ones that are in the same relative position):\n\nIf we do this again for the 3-dimensional hypercube, we'll get this 4-dimensional hypercube, which has 16 vertices and 32 edges:\n\nYou might have noticed a pattern in how many vertices and edges a hypercube has. Here are those properties stated more formally:\n\n* A hypercube has $2^n$vertices.\n* A hypercube has $n2^{n-1}$edges.\n\nHypercubes are super useful, particularly for representing **bit strings.** If we have an $n$-dimensional hypercube, then we have enough vertices to represent all possible permutations of 1's and 0's of length $n$. Every edge would then represent the act of flipping exactly one bit.\n\n\n\n## Planar Graphs\n\nA **planar graph** is a graph that can be drawn without having two edges overlap.\n\n**Euler's Formula** states that a connected planar graph has two more vertices and faces than the number of edges:\n\n$\nv + f = e + 2\n$\n\nLet's take a look at some examples to convince ourselves of how this works:\n\n(A triangle has 3 edges and two faces: the inner face and outer face.)\n\n(This shape is connected, but there is no enclosed face so the only face is the outer face.)\n\n\n\nAnother consequence of Euler's Formula is the inequality that holds for connected planar graphs:\n\n$\n3f \\le 2e\n$\n\nThis inequality states that any planar graph with 2 or more vertices must have at most 3 faces for every 2 edges. We know this because the smallest possible face is a triangle. If we plug this into Euler's Formula, we can eliminate one variable to get $e \\le 3v - 6$. This makes it much easier to figure out if a graph is planar or not, since faces are often difficult to count.\n\n\n\n### Proof of Euler's Formula\n\nLet's use induction!\n\n**Base Case:** Let there be 0 edges and 1 vertex. This means there's only 1 (outer) face as well. In this case, $v + f = 1 + 1 = 0 + 2$. This works!\n\n**Induction Step:** \\\nLet's consider the case of a tree. Then, we know that there are always 1 fewer edges than vertices, and only one face:\\\n$v + 1 = (v-1) + 2$ works!\n\nWhat about something that's not a tree? Well, things get a bit tricker here.\n\n* Let's consider a graph:\n* Now, let's start with the tree corresponding to the same number of vertices as the original:\n* Now, we'll keep adding edges to enclose faces until we reach the number of edges in the original:\n* We'll notice here that for every edge we add, a new face is created!\n* Therefore, we can plug this fact into our inductive hypothesis (that Euler's formula works) to get $v + (f+1) = (e+1) + 2$.\n\n### Nonplanar Graphs\n\nAlthough nonplanar graphs don't share many of the nice properties planar graphs do, they're often more accurate representations of real life. They can also be used frequently in proofs to prove that a graph must either be planar or non-planar.\n\nThere are two famous non-planar graphs that are worth taking a look into:\n\n![nonplanar graphs](../img/assets/nonplanar.png)\n\n#### K3,3\n\n$K_{3,3}$is also known as the \"utility graph\" because of its connection to a popular puzzle: given 3 houses and 3 utilities (water, gas, electric), how can we draw a line connecting each house to every utility without having any of the lines cross?\n\nI'll save you an amount of suffering by spoiling the answer: **this is an impossible task when done on a standard (planar) paper.** (Want topical entertainment? [Watch some youtubers solve this problem on a mug.](https://www.youtube.com/watch?v=VvCytJvd4H0)) This is because $K_{3,3}$is **non-planar**, so by definition at least one of the lines has to cross!\n\n$K_{3,3}$is a **bipartite graph** since it has two groups of 3 vertices; and within each group, none of the vertices are directly connected to one another.\n\n#### K5\n\n$K_5$is the **complete graph** of 5 vertices. (This means that each vertex is connected to every other vertex.)\n\nWe can see that $K_5$has 5 vertices and 10 edges. Since we know that all planar graphs have $E \\le 3V - 6$, we can show that $K_5$certainly isn't planar (since 10 is greater than 3(5)).\n\n\n\nA striking fact: **ALL non-planar graphs contain either** $K_5$**or** $K_{3,3}$**!** This means that you can prove that a graph is either planar or nonplanar simply by showing that either of these component graphs can or cannot exist in a larger graph.\n\n## Graph Coloring\n\nA **graph coloring** assigns a color to each vertex such that **every edge has two different colors** on its two endpoints:\n\nOften, we would like to figure out the **minimum number of colors** (categories) it takes to properly color a graph. This could have many uses, from [register allocation](https://en.wikipedia.org/wiki/Register\\_allocation) to [solving sudoku puzzles](https://medium.com/code-science/sudoku-solver-graph-coloring-8f1b4df47072).\n\n### Six Color Theorem\n\nLet's propose that every **planar** graph can be colored with 6 colors or less.\n\nFrom Euler's Formula, recall that $e \\le 3v - 6$for any planar graph with more than 2 vertices. We also know that the degree of the graph is equal to $2e$.\n\nSo, the average degree of any given vertex is $\\frac{2e}{v} \\le \\frac{2(3v-6)}{v} \\le 6 - \\frac{12}{v}$. This proves that there **exists** a vertex with degree at most 5 (due to the property of averages). Let's try removing this vertex and see what happens.\n\nWell, now each of the 5 neighbors each are assigned a different color. If we add the vertex back, then it can assume the 6th color. We can use this proof inductively to show that adding any vertex will result in the same thing occurring.\n\n### Five and Four Color Theorem\n\nIt turns out that 6 is actually not the tightest bound we can put on the number of colors needed! It is possible to color all **vertices** with **5 colors** or less and all **faces** with **4 colors** or less in a **planar graph**. I won't go into the details of these proofs here, but check out the bottom of [Note 5](https://www.eecs70.org/assets/pdf/notes/n5.pdf) for the proof of the 5 color theorem, and [Wikipedia](https://en.wikipedia.org/wiki/Four_color_theorem) has a good introduction to the \\(highly technical\\) 4 color theorem proof.\n\n",
    "lastmodified": "2023-01-10T23:33:04.002195938Z",
    "tags": null
  },
  "/cs70/discrete-math/modular-arithmetic": {
    "title": "Modular Arithmetic",
    "content": "\n## What is Modular Arithmetic?\n\nModular arithmetic is \"clock math\" - that is, when numbers wrap around back to 0 if they get too big. You could think about it like a **remainder:** $21 \\pmod{10}$ for example can be read as \"what is the remainder of 21 when it is divided by 10?\" (it's 1, by the way.)\n\nThis is an important concept in many aspects of computer science, namely [cryptography](/cs70/discrete-math/rsa-cryptography.md) and [error correction](/cs70/discrete-math/polynomials.md) among many others.\n\n## Key Ideas\n\n**If d divides x and d divides y, then d divides (y-x)**. $d \\mid x, d \\mid y \\implies d \\mid (y-x)$\\\n(Reminder: $a \\mid b \\iff (\\exists q \\in \\mathbb{Z})(a = qb)$)\n\n**Modular Equivalence:** If you're looking at a clock and it becomes 25:00, you know it's actually the same as 1:00. Even if they're technically not the same number, they can be treated the same way.\n\n* More formally: **x is congruent to y modulo m:** $x \\equiv y \\pmod{m}$****\n\n**Important Notation Distinction:** $x \\pmod{m}$ is the **class of numbers** that follow the mod rule $m$. It can be used to write equivalences ($10 \\equiv 21 \\pmod{11}$). However, $\\mod(x, m)$is just a number (the remainder when dividing x by m). $\\mod(x,m) = x - \\lfloor{\\frac{x}{y}}\\rfloor \\cdot y$\n\n**Greatest Common Denominator (GCD Mod Corollary):** Modular arithmetic can be used to identify an important property of the GCD, which is that $GCD(x,y) = GCD(x \\mod y, y)$.\n\n## Arithmetic\n\n### Addition\n\nGiven that $a \\equiv b \\pmod{m}$, $a+c \\equiv b+c \\pmod{m}$. This result shouldn't be too surprising, and suggests that adding a constant value to both sides won't change the congruence, just like any other equation.\n\n### Multiplication\n\nMultiplication works pretty much how you'd expect it to work after seeing how addition works. Formally defined, if $a \\equiv b \\pmod{m}$, then $ka = kb \\pmod{m}$. Intuitively, this means that if you want to multiply a big number, you can take the mod of the big number before multiplying it, and that will be equivalent to multiplying before taking the mod.\n\nAs an example, let's try to figure out what day it is in 8 years. We know that there will be 2 leap years with 366 days each, and 6 normal years with 365 days each. We don't really feel like computing $(365 \\cdot 6) + (366 \\cdot 2) \\pmod{7}$, so we can instead take the mod of 365 and 366 first. This yields the much simpler expression $(1 \\cdot 6) + (2 \\cdot 2) \\pmod{7} \\equiv 1$. Therefore, the day in 8 years will be one day after today.\n\n### Division and Inverses\n\nIn normal number spaces, the **multiplicative inverse** of x is a y such that $xy = 1$. This concept still applies to modular arithmetic!\n\nIf we have $x \\pmod{m}$, then the multiplicative inverse is defined as a number y such that $xy = 1 \\pmod{m}$.\n\nFor example, let's take a look at $4x = 5 \\pmod{7}$. We can multiply both sides by 2 in order to get $8x = 10 \\pmod{7}$. At this point, we can use the $\\pmod{7}$to reduce the 8 into a 1 and the 10 into a 3, resulting in $x = 3 \\pmod{7}$.\n\nThere are some values where it's impossible to get an equivalence into the form $1 \\pmod{m}$. This usually happens when there is a common factor (like $8x \\equiv y \\pmod{12}$). In other words, **if the greatest common divisor of x and m is 1, then x has a multiplicative inverse modulo m. (x is relatively prime to y).**\n\n## Algorithms\n\nNow, let's explore three famous algorithms for computing useful information using modular arithmetic: **Euclid's Algorithm** for GCD and inverses, the **Chinese Remainder Theorem**, and **Fermat's Little Theorem.**\n\n## Euclid's Algorithm\n\n![](\u003c../img/assets/image (4).png\u003e)\n\n**Euclid's Algorithm** is a recursive procedure for calculating the greatest common denominator. Remember that $GCD(x,y) = GCD(x \\mod y, y)$ by the GCD Mod Corollary. We can prove that this works using induction:\n\n* Base Case: If y is 0, then any value for x is the GCD since everything can divide 0 to get 0.\n* Inductive Case: Proof of the GCD Mod Corollary.\n\nThis is a rather efficient algorithm: at every iteration, the value of x and y decrease dramatically- at least by a factor of 2. This makes it $\\theta(\\log_2(x))$(in other words, we need one division for each bit that is needed to represent $x$).\n\nFor an example of a computation, check out the Extended Algorithm section below (the computation is extremely similar).\n\n### Using Euclid's Extended Algorithm for Inverses\n\nGreat! We got the GCD. So what?\n\nRemember that **if the GCD of x and m is 1, then there is an inverse of x.** In more concrete terms, we can state **Euclid's Extended GCD Theorem (Bezout's Theorem)** as such:\n\n$\nax + by = gcd(x,y)\n$\n\nIn other words, the GCD can be written as a scalar multiple of x and y. Since we remember that the definition of the inverse is that $ax + by = 1$for some integers a and b, Euclid's Extended Theorem checks out for showing that the inverse exists if the GCD is 1.\n\n![](\u003c../img/assets/image (9).png\u003e)\n\nThe process can be tedious to compute by hand, but here's a nice video that walks through that process:\n\n\u003ciframe\n    width=\"640\"\n    height=\"480\"\n    src=\"https://www.youtube.com/embed/6KmhCKxFWOs\"\n    frameborder=\"0\"\n    allow=\"encrypted-media\"\n    allowfullscreen\n\u003e\n\u003c/iframe\u003e\n\n\n## The Chinese Remainder Theorem\n\nThe **Chinese Remainder Theorem (CRT)** guarantees **existence and uniqueness** of a solution to a system of modular congruences. More formally stated:\n\n\n\nThere is a unique solution $x \\pmod{mn}$such that $x = a \\pmod{m}$, $x = b \\pmod{n}$, and $gcd(m,n) = 1$. Here are a few ways to word it (see which one clicks better):\n\n#### Formal Statement of CRT:\n\nLet $n_1 \\cdots n_k$be positive coprime integers. (Any two of them must be relatively prime.) Then, for any combination of integers $a_1 \\cdots a_k$, a **unique** x exists such that $x \\equiv a_i \\mod n_i$for all $0 \u003c i \\le k$.\n\n**Alternative Statement of CRT:**\n\nLet $n_1, \\ldots n_k$ be pairwise co-prime, i.e. $n_i$ and $n_j$ are co-prime for all $i \\neq j$. The Chinese Remainder Theorem (CRT) tells us that there exist solutions to the following system of congruences:\n\n![crt](../img/assets/crt.jpg)\n\n#### Uniqueness of CRT Solution\n\nNot only do we know that there is a unique solution $x$, but we can actually write out its exact value! Here it is:\n\n$$\nx = \\sum_{i=1}^k a_i b_i \\pmod{N}\n$$\n\nIn this sum, $b_i = (\\frac{N}{n_i}) \\cdot (\\frac{N}{n_i})^{-1} \\mod n_i)$ , and $N$is the product of all primes $n_1, \\cdots n_k$.  This sum is congruent to $a_i \\mod n_i$for all valid values of $i$.\n\n#### Computation\n\nThe Chinese Remainder Theorem often ties well together with the Extended Euclidean Algorithm, since we would need to find lots of inverse mods for each $b_i$. Also like the Extended Euclidean Algorithm, it's very hard to demonstrate the computation on a static webpage so here's another good video walkthrough!\n\n\u003ciframe\n    width=\"640\"\n    height=\"480\"\n    src=\"https://www.youtube.com/embed/zIFehsBHB8o\"\n    frameborder=\"0\"\n    allow=\"encrypted-media\"\n    allowfullscreen\n\u003e\n\u003c/iframe\u003e\n\n## Fermat's Little Theorem\n\n**Fermat's Little Theorem** (not to be confused with [Fermat's Last Theorem](https://www.youtube.com/watch?v=nUN4NDVIfVI)) makes the observation that **exponentiation is periodic** when modulo is done by a **prime number.** This makes it reasonable to compute obscenely large numbers, like $2^{65535}$, when in a mod space.\n\n#### The Formal Definition\n\nFor prime $p$ and an integer $a \\in \\{1, 2, \\cdots, p - 1\\}$, $a^{p-1} \\equiv 1 \\pmod{p}$.\n\n#### An Alternative Definition\n\nIf we multiply both sides by $a$, we can actually drop the restriction to $a$ and allow it to be any integer. This version is sometimes more useful than the normal definition:\n\nFor prime $p$ and any integer $a$, $a^p \\equiv a \\pmod{p}$.\n\nFor an application of Fermat's Little Theorem, head over to [RSA Cryptography](/cs70/discrete-math/rsa-cryptography.md)!\n\n",
    "lastmodified": "2023-01-10T23:37:04.27183848Z",
    "tags": null
  },
  "/cs70/discrete-math/overview": {
    "title": "Discrete Math Overview",
    "content": "\n## What even is discrete math?\n\nAccording to [Wikipedia](https://en.wikipedia.org/wiki/Discrete\\_mathematics), \"_Discrete mathematics_ is the study of mathematical structures that are fundamentally discrete rather than continuous.\" Very helpful, thank you Wikipedia. The floor is indeed made of floor rather than sky.\n\nThe word **discrete** means \"distinct\" or \"countable\". This suggests that discrete math has to do with **countable numbers** like integers, rather than the continuous $f(x)$functions we're used to seeing that are defined for any real$x$, even ones we don't know the exact value of like $\\pi$.\n\nDealing with countable integers is nice because **that's how computers work.** Behind the scenes, every floating point number is actually just a whole bunch of bits, which are countable :) I would say that dealing with integers makes things nicer too (since we no longer have to deal with decimals), but you might be inclined to disagree.\n\n## A brief summary of the contents covered\n\nDiscrete math is an extremely wide field of mathematics. Here, we'll be covering the basics as well as a few important applications:\n\n* [**Propositional logic**](propositional-logic.md) and sets give us the **language** we need to talk about discrete math.\n* ****[**Proofs**](proofs.md) **** allow us to demonstrate **how** and **why** things work the way they do.\n* [**Stable Matching**](stable-matching.md) explores how we can apply sets to create optimal matches between two groups with preferences.\n* [**Graph theory** ](classes/cs70/discrete-math/graphs.md)provides a highly visual representation of a wide variety of mathematical relationships using vertices, edges, and faces. One of the most important concepts here is **Euler's Formula** which relates the number of vertices, edges, and faces together.\n* ****[**Modular arithmetic** ](modular-arithmetic.md)explores what happens when when all numbers are remainders of dividing itself by another number. There are some really important theorems here, like the **Chinese Remainder Theorem, Euclid's Algorithm,** and **Fermat's Little Theorem.**\n* ****[**RSA Cryptography**](rsa-cryptography.md) **** is an interesting application of how modular arithmetic is used to encrypt and decrypt messages using a public-private key pair.\n* [**Polynomials** ](polynomials.md)can be used in a discrete sense to create **secret sharing** schemes, and can be recovered from points using **Lagrange Interpolation.**\n",
    "lastmodified": "2023-01-10T21:59:01.759561954Z",
    "tags": null
  },
  "/cs70/discrete-math/polynomials": {
    "title": "Polynomials",
    "content": "\n## Introduction\n\n\"I learned this in 4th grade\", you say, \"and I already know how to do Taylor approximations and binomial expansions and get local minima... what else is there to do?\" (At least that was my first thought :stuck\\_out\\_tongue:)\n\nTurns out, polynomials are super useful in the world of discrete math. Here, we'll cover two applications in discrete space, which are **secret sharing** and **error correction.**\n\n### Important Properties\n\nGotta do some quick review first! Recall that all polynomials are in the form\n\n$\na_dx^d + a_{d-1}x^{d-1} + \\cdots + a_1x + a_0\n$\n\nwhere $d$is the **degree** of the polynomial (highest power) and $a_i$are the **coefficients.**\n\nPolynomials have some nice properties:\n\n* A nonzero polynomial of degree $d$has at most $d$real roots.\n* If we're given $d+1$distinct points (x y pairs), there is exactly one, unique polynomial of degree $d$that goes through all of those points.\n\n### Finite Fields\n\nLike many things in discrete math, polynomials can be taken to a modulo as well! When this happens and we have $p(x) \\pmod{m}$where $p(x)$is a polynomial and $m$is a prime number, we say that we're working in a **Galois Field** $GF(m)$.\n\nEven when working over a finite field, the two properties of polynomials still apply. Finite fields restrict the number of possible polynomials, which is actually necessary for some of the applications below.\n\n## Lagrange Interpolation\n\nWe have already established that $d+1$points only have one unique degree $d$polynomial that goes through all of them. But how do we find this one polynomial?\n\n**Lagrange Interpolation** is a method to recover this polynomial given your original points. It has a lot of interesting ties to previously covered concepts like the Chinese Remainder Theorem and linear algebra (which won't be covered here, but explore it further to find out more!). Here's how it works:\n\nFirst, let's find a polynomial that is degree $d$ and is equal to $1$at point $x_1$, but $0$everywhere else.  This isn't too hard to do: we can use $(x-x_2)(x-x_3)\\cdots(x-x_{d+1})$. Note here that we skipped $x_1$because adding that term would make the polynomial degree $d+1$! However, this alone would result in a number other than 1 at $x_1$, so we can normalize it by dividing by all $(x_1-x_j)$:\n\n$\n\\Delta_1(x) = \\frac{\\prod_{j \\ne 1} (x - x_j)}{\\prod_{j \\ne i} (x_1 - x_j)}\n$\n\nWhy are we doing this though? Well, you can think of it like creating a **basis** of polynomials so that we can take a linear combination of all of them to get the original. Since $\\Delta_1(x_1) = 1$, we can multiply it by $y_1$ to ensure that it passes through the original point. Combining all of the delta polynomials for all $d+1$original points yields\n\n$\np(x) = \\sum_{i=1}^{d+1} y_i \\Delta_i(x)\n$\n\n## Secret Sharing\n\nNow, let's take a look at a cool application of Lagrange interpolation!\n\nHere's the setup: let's say you're in the Super Secret Club and want to create a secret code for your Super Secret Vault™. However, you want to make sure that the Vault™ can only be opened if 30 of your 50 members agree. How would we pull this off?\n\nHere's the solution: **create a 29-degree polynomial** and give each person in the club a point on that polynomial $(x_i, y_i)$. **Make sure none of the x's are 0!** Then, set the secret code equal to $y_0$, the y-value of the polynomial corresponding to $x=0$.\n\nWe know that a 29-degree unique polynomial can be recovered with 30 distinct points. So, if 30 members agree and get together to share their points, we can use Lagrange interpolation to recover the original polynomial! Once you have this original polynomial, it is a simple matter to recover the secret code by plugging in 0 to the polynomial.\n\n## Error Correction\n\nLagrange interpolation can also be used to correct errors in data (if it gets erased or corrupted). There are two main types of errors: **erasure errors,** when the data is simply lost, and **general errors,** where the data is corrupted and displays something other than the original data.\n\n### Erasure Errors\n\nErasure errors aren't too tough to think about once we have a good grasp of polynomial properties. Since we know that a unique polynomial of degree $d$can be recovered with $d+1$points, we could simply tack on an additional $k$points in order to protect the original polynomial from $k$erased points.\n\n### General Errors\n\nGeneral errors, on the other hand, are slightly more difficult to consider because they could throw off the result wildly if we do not identify them. So how do we figure out which points are the errors?\n\nLet us construct an error-locator polynomial $E(x) = (x-e_1)(x-e_2) \\cdots (x-e_k)$ where an error $e_i$ represents the incorrect value given by one of the spies when in a larger group.\n\nFor any one point $i$ in the original polynomial $P(i)$, we know that $P(i)E(i) = r_iE(i)$ where $r_i$ is the original location of the point of the polynomial.\n\nIf we have $M$ original data points, this provides enough points for a $M-1$ degree polynomial, which we can call $Q(x)$. For any particular point, though, we know that $Q(i) = P(i)E(i)$ since the point given is either in the original polynomial, or is in the error-locator polynomial. Therefore, in order to solve for the true polynomial $P(x)$, we can take the ratio $\\frac{Q(x)}{E(x)}$ by definition of $Q(x)$. Since we do not know what each value $e_i$ is, we need to solve a system of linear equations for each point to identify what these are. **This requires** $M + 2k$ **equations**, because we require the polynomial $Q(x)E(x)$ to perform this calculation.\n\n****\n",
    "lastmodified": "2023-01-10T23:27:41.813189936Z",
    "tags": null
  },
  "/cs70/discrete-math/proofs": {
    "title": "",
    "content": "\n## Introduction\n\nA **proof** is a **set of logical deductions** that can be used to show how something is true. This is powerful because proofs can often be very **general,** allowing a truth to be used in a whole bunch of cases that don't individually need to be re-proven.\n\nThere are a number of common proof techniques (although these certainly aren't exhaustive!) outlined below.\n\n## Direct Proofs\n\nIn direct proofs, we can use the **definitions** directly to show that something is true. No trickery here, just straightforward navigation from point A to point B.\n\n**Direct Proof Form:**\n\n* **Goal:** $P \\iff Q$\n* **Assume P.**\n* Do a bunch of steps using the definitions and assumptions created by the values and operators used.\n* **Therefore Q.**\n\n**Example:**\n\nLet $D_3$be the set of 3 digit natural numbers. Show that for all $n \\in D_3$, if the alternating sum of digits of $n$is divisible by 11, then $11 \\mid n$. (Lecture 2)\n\n* First, let's make sure this makes sense. Let's try some examples:\n  * if $n=605$, then $n$is divisible by 11. Its alternate sum is $6 - 0 + 5 = 11$. $11$is indeed divisible by 11, so this looks like it could be true!\n* Next, let's write this in propositional logic:\n  * $\\forall n \\in D_3, (11 \\mid$ alt sum of digits of n $) \\implies 11 \\mid n$\n* Now, let's try to prove it starting with assuming that all $n$ are 3 digit natural numbers.\n  * Let $a, b,$and $c$ represent the three digits of $n$such that $n = 100a + 10b + c$.\n  * If the alternating sum of digits is divisible by 11, then $11 \\mid a - b + c$.\n  * Using the definition of division, $a - b + c = 11k$for some natural number k. We're trying to prove that $n = 100a + 10b + c = 11m$ for another integer $m$ as well!\n  * Solve for $c$using the alternating sum to get $c = 11k + b - a$. Substitute this value into the second equation to get $100a + 10b + 11k + b - a = 11m$. Simplifying, this equation is equivalent to $99a + 11b + 11k = 11m$.\n  * We know that **this must be true** because each individual term is multiplied by a number divisible by 11. Therefore, the entire number must also be divisible by 11.\n\n## Proof by Contraposition\n\nAs a reminder, the **contrapositive** of a statement $P \\implies Q$is $\\lnot Q \\implies \\lnot P$. **These two statements are logically equivalent!** Sometimes, it's easier to prove the contrapositive, which would in turn prove the original statement.\n\n**Contraposition Form:**\n\n* **Goal:** $P \\implies Q$\n* **Assume** $\\lnot Q$.\n* Do a bunch of steps using another type of proof.\n* **Therefore** $\\lnot P$.\n\n**Example:**\n\nFor every $n \\in \\mathbb{N}, n^2$ even $\\implies n$ even\n\n* If we try proving using a direct proof, we'll have to deal with the squared term (and square roots)! This might get nasty; we'd rather deal with the nicer right side.\n* First, let's find the **contrapositive of Q.** Q is \"n is even\", so the contrapositive is \"n is odd\".\n* Then, let's find the contrapositive of P. P is \"n squared is even\", so the contrapositive is \"n squared is odd\".\n* Let's use the definition of an odd number ($n = 2k + 1$for some natural number k) to work through this.\n  * If $n = 2k +1$, then $n^2 = 4k^2 + 4k + 1$ = $2(2k^2 + 2k) + 1$.\n  * Since this is also the form of an odd number, $n^2$must be odd!\n\n## Proof by Contradiction\n\nInstead of proving that $P$is true, maybe we could show that $\\lnot P$makes no sense at all! (We know that if $\\lnot P$is false, then $P$must be true.)\n\nContradiction is a great choice for proving things that have **infinitely many cases** (since you can just prove the opposite, which is finite!).\n\n**Contradiction Form:**\n\n* **Goal:** $P \\implies Q$\n* **Assume** $\\lnot P$.\n* Do some steps here.\n* **Therefore,** $\\lnot P$**is a contradiction.**\n\n**Example:**\n\nShow that there are infinitely many prime numbers.\n\n* First, let's assume the opposite - that there are a finite number of prime numbers, which can be represented by the set ${ p_1, \\cdots, p_k}$.\n* Let's define a number $q = (p_1 \\times p_2 \\cdots \\times p_k) + 1.$\n* Since $q$is larger than any prime number in our set, it can't be a prime number by our assumption.\n\nNote that we **did not prove that**$q = (p_1 \\times p_2 \\cdots \\times p_k) + 1$**is a prime number!** This is because we started with a false statement, so everything in the middle of a contradiction proof cannot be generalized to true statements.\n\n## Proof by Cases\n\nSometimes, we can break a statement down into smaller **cases** and prove each one individually. These cases could be something like \"a is odd\" and \"a is even\", where it is impossible for any other case to be true. If all possible cases are proven, then the entire statement is then proven.\n\n**Example:**\n\nShow that there exists an irrational x and y such that $x^y$is rational.\n\n* First, let's find some cases. The two cases could be that $x^y$is rational or $x^y$is irrational. If $x^y$is rational (the first case is true), then we're done! But if the second case is true, then we're back to where we started.\n* Since all we need to do is show existence, we can choose any irrational number for x and y. $\\sqrt{2}$seems like an easy choice!\n* $\\sqrt{2}^{\\sqrt{2}}$is irrational, but what about $(\\sqrt{2}^{\\sqrt{2}})^{\\sqrt{2}}$? That's just $2$!\n\n## Proof by Induction\n\nInduction is great for proving that something is true for everything in a set (often the natural numbers). If we prove the first value, then prove that the next value is true, then the value after that is _also_ true, and so on.\n\nThis can be likened to the **domino effect.** If the first one's true, then it knocks down the domino for the next value. If that's true, then it knocks out the next one, and so on until every possible value is covered.\n\n**Induction Form**\n\n* **Prove P(0).** (Base case)\n* **Assume P(k).** (Induction Hypothesis)\n* **Prove P(k+1).** (Induction Step)\n  * When proving the induction step, we can treat the induction hypothesis as a true statement!\n\n**Example: The Two Color Theorem**\n\nHere's a visually intuitive example of induction in action!\n\nThe Two Color Theorem states that for any collection of intersecting line segments, the regions that they divide can be assigned one of two colors such that a line never has the same color on both sides.\n\nIn order to prove this, let's start at the **base case**, where there is only one line:\n\n![](../img/assets/image.png)\n\nHere, it's pretty clear that it is indeed possible to put a different color on each side of the line, in this case let's just choose blue and red.\n\nNow, let's see what happens when we add a new line:\n\n![](\u003c../img/assets/image (1).png\u003e)\n\nLooks like we have a conflict now! The blues on the top and reds on the bottom are touching. However, it's not too hard to fix this. Let's just flip the blue and red on one of the sides:\n\n![](\u003c../img/assets/image (2).png\u003e)\n\nIt turns out that this process: drawing a new line and flipping all of the colors on one side, works in any configuration of lines! This is because of the fact that flipping the colors on one side of a line doesn't affect whether or not those colors are alternating.\n\n![](\u003c../img/assets/image (3).png\u003e)\n\n### Stronger Induction\n\nSometimes, an inductive proof can be rather elusive. It might be easier to **make the statement stronger** and prove that instead! (It should make sense that a stronger argument means that a weaker argument is also true.)\n\nFor example, take the statement \"The sum of the first _n_ odd numbers is the square of a natural number.\"\n\nAs we try to figure out a pattern, we might notice something:\n\n\u003e For n = 1: $1 = 1^2 = n^2$\n\u003e\n\u003e For n = 2: $1 + 3 = 2^2 = n^2$\n\u003e\n\u003e For n = 3: $1 + 3 + 5 = 3^2 = n^2$\n\nWow, looks like not only is the sum equal to some arbitrary square number, but it's actually equal to $n^2$! It's a lot easier to prove this fact than the original one, and proving this completely includes the original statement.\n\nAnother (aptly named) principle that might come in handy is the **Strong Induction Principle!** This principle is useful for when you don't want your base case to be $0$. The Strong Induction Principle states that if we prove all of the propositions from P(0) up to P(k), then P(k) can be used as a base case:\n\n$(\\forall k \\in \\mathbb{N})((P(0) \\land P(1) \\land \\cdots \\land P(k)) \\implies P(k+1)) \\implies (\\forall k \\in \\mathbb{N})(P(k))$\n\n### Proof of the Induction Principle\n\n$(\\lnot \\forall n)P(n) \\implies ((\\exists n) \\lnot (P(n - 1) \\implies P(n))$\n\nThe **Well Ordering Principle** states that for all subsets of natural numbers, there exists a smallest number in that subset.\n\n* **This is not trivial!** Think about rational numbers- it's impossible to get the smallest rational number because it extends to $-\\infty$.\n* **This principle justifies the use of induction** **for any set of natural numbers.** If the smallest number (base case) always exists, then we can just prove that and move upwards, rather than trying to prove both $k-1$and $k+1$.\n\n## More Resources\n\nNote 2: [https://www.eecs70.org/assets/pdf/notes/n2.pdf](https://www.eecs70.org/assets/pdf/notes/n2.pdf)\n\nNote 3: [https://www.eecs70.org/assets/pdf/notes/n3.pdf](https://www.eecs70.org/assets/pdf/notes/n2.pdf)\n\nLecture 2 Slides: [https://www.eecs70.org/assets/pdf/lec-2-handout.pdf](https://www.eecs70.org/assets/pdf/lec-2-handout.pdf)\n\n",
    "lastmodified": "2023-01-10T23:30:57.599399083Z",
    "tags": null
  },
  "/cs70/discrete-math/propositional-logic": {
    "title": "",
    "content": "\n## What are Propositions?\n\nPropositions are anything that can be **true** or **false.** This could include:\n\n* Statements like \"Birds can fly\".\n* Well defined equations with no free variables like $1 + 1 = 3$.\n\nPropositions are **not:**\n\n* Variables like $x$ or $5$.\n* Equations with free variables like $P(x) = y$.\n* Statements that aren't clearly true or false, like \"I like trains.\"\n\n### Connectives\n\nSimple propositions can be **joined together** to make complex statements. There are three basic ways to connect propositions together:\n\n* **Conjunction** is the **and** operation: for $P \\land Q$to be true, $P$and $Q$must **both** be true.\n* **Disjunction** is the **or** operation: for $P \\lor Q$to be true, **either** $P$or $Q$must be true.\n* **Negation** is the **not** operation: if $P$is true, then $\\lnot P$is false.\n  * The **law of the excluded middle** states that $P$and $\\lnot P$ _cannot both be true._\n\nOne example where we can see these components in action is in **De Morgan's Laws**, which state how negation can be **distributed** across conjunction or disjunction:\n\n$\n\\lnot(P \\lor Q) \\iff (\\lnot P \\land \\lnot Q)\n$\n\n\"If neither P nor Q are true, then P and Q must both be false.\"\n\n$\n\\lnot(\\forall x)(P(x)) \\iff (\\exists x)(\\lnot P(x))\n$\n\n\"If P(x) isn't true for every x, then there exists an x where P(x) is false.\"\n\n****\n\nAnother example of distribution is this congruence, which works for any combination of and's and or's.\n\n$\n(P \\lor Q) \\land R \\equiv (P \\land R) \\lor (Q \\land R)\n$\n\n****\n\n### Implication\n\nOne proposition can **imply** another, which looks like this:\n\n$\nP \\implies Q\n$\n\nRoughly, implication in plain English can be stated in the form **if P, then Q.** However, there are a lot of nuances to what this really means!\n\n#### Properties of Implication\n\n* **Reversible:** Q is true if P is true. However, be careful- _this doesn't necessary mean that Q implies P!_\n* **P is sufficient for Q:** Proving P allows us to say that Q is also true.\n* **Q is necessary for P:** For P to be true, it is necessary that Q is true. (If Q is false, then P is also false.)\n* **Contrapositive Equivalence:** If P implies Q, then $\\lnot Q \\implies \\lnot P$.\n  * Note that this is different from the **converse**, which is $Q \\implies P$. This statement is **not logically equivalent!**\n\n#### Truth Table\n\n| P | Q | P $\\implies$Q | P $\\iff$Q |\n| - | - | --------------- | ----------- |\n| T | T | T               | T           |\n| T | F | F               | F           |\n| F | T | T               | F           |\n| F | F | T               | T           |\n\n**Note that the truth table for** $P \\implies Q$ **is equivalent to the one for** $\\lnot P \\lor Q$**!**  That means this formula is logically the same as $P \\implies Q$.\n\n(If two propositions have the same truth table, then they are logically equivalent. However, it's still possible for a proposition to imply another even if their truth tables are different!)\n\n### Quantifiers\n\nSometimes, we need to define a specific type of variable to work with in a propositional clause. For instance, take the proposition, _\"There exists a natural number that is equal to the square of itself.\"_ We could write this as:\n\n$\n(\\exists x \\in \\mathbb{N})(x=x^2)\n$\n\nYou could think about the parentheses almost like defining a **scope** of variables, like what might happen in programming! Here, the first clause is _defining_ an arbitrary variable $x$to be any natural number.\n\n\n\n## Exercises\n\n{{\u003c tabs \"q1\" \u003e}}\n{{\u003c tab \"Q1\" \u003e}}\nIs the expression $\\forall x \\exists y (Q(x,y) \\implies P(x))$equivalent to the expression $\\forall x ((\\exists y \\ Q(x,y)) \\implies P(x))$?\\\n(Source: Discussion 0 2a)\n{{\u003c /tab \u003e}}\n\n{{\u003c tab \"Answer 1\" \u003e}}\n**No**, they are not equivalent. We can see this more clearly by converting the implication $Q \\implies P$ to $\\lnot Q \\lor P$ as was demonstrated in the Truth Table section above.\\\n\\\nOn the left side, this conversion is straightforward, yielding $\\forall x \\exists y (\\lnot Q(x,y) \\lor P(x))$.\n\nOn the right side, we'll need to invoke De Morgan's Laws to convert the 'exists' into a 'for all' since it was negated. This yields $\\forall x (\\forall y\\lnot(Q(x,y)) \\lor P(x))$which is not the same thing!\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n{{\u003c tabs \"q2\" \u003e}}\n{{\u003c tab \"Q2\" \u003e}}\nAn integer $a$is said to _divide_ another integer $b$ if $a$is a multiple of $b$. Write this idea out using propositional logic (a divides b can be written as $a \\mid b$).\n\n**Note:** This idea is going to be important for a lot of future sections!\n{{\u003c /tab \u003e}}\n\n{{\u003c tab \"Answer 2\" \u003e}}\n$a \\mid b \\iff (\\exists q \\in \\mathbb{Z})(a = qb)$\n\nIn plain English: \"There exists an integer $q$such that when we multiply $q$with $b$, we get $a$.\"\n{{\u003c /tab \u003e}}\n{{\u003c /tabs \u003e}}\n\n## Resources\n\nNote 1: [https://www.eecs70.org/assets/pdf/notes/n1.pdf](https://www.eecs70.org/assets/pdf/notes/n1.pdf)  \nDiscussion 0: [https://www.eecs70.org/assets/pdf/dis00a.pdf](https://www.eecs70.org/assets/pdf/dis00a.pdf)\n\n",
    "lastmodified": "2023-01-10T23:29:07.472419014Z",
    "tags": null
  },
  "/cs70/discrete-math/rsa-cryptography": {
    "title": "RSA Cryptography",
    "content": "\n## Introduction\n\nThe internet is built upon the fact that stuff needs to go from point A to point B quickly, accurately, and securely. We'll talk about the **secure** part of that now (the accurate part will be addressed [soon](/cs70/discrete-math/polynomials.md)!).\n\nOne of the ways we can make sure our top-secret messages can't get intercepted is to **encrypt** them- mix them up to become incomprehensible using some secret code, then decrypt it at the other end. This has a major problem though- how can you agree to use the same secret code as someone else if you've never met them before?\n\n**RSA** (named after creators Rivest, Shamir, Adleman) is an encryption scheme that takes advantage of **public keys** to solve this very problem. In the RSA system, everyone broadcasts their public key all over. When encrypting a message, the sender can lock their message using their **private key** paired with the _sender's_ public key, such that only the sender themselves can unlock the message using their own private key.\n\nThis poses yet another problem: how can we choose these public and private keys so that they work nicely with each other? Well, we can use modular arithmetic of course!! :smile:\n\n## The RSA Cheat Sheet\n\n**Variables:**\\\n **-**$p, q$are two distinct prime numbers.\\\n **-** $e$is relatively prime to $(p-1)(q-1)$.\\\n **-** $N = pq$\\\n \\- $x$is the original message; $y$is the encrypted message\n\n**Public Key:** $(N, e)$\\\n**Private Key:** $d = e^{-1} \\pmod{(p-1)(q-1)}$****\n\n**Encryption:** $E(x) = x^e \\pmod{N}$\\\n**Decryption:** $D(y) = y^d \\pmod{N}$****\n\n****\n\n## Example\n\nLet our two prime numbers be $p = 5, q = 11$. (In the real world, these would be much larger for security purposes- but let's not make this too hard on ourselves!)\n\nThe first step is to **choose our public key.** We know e must be relatively prime to $(p-1)(q-1) = (4)(10) = 40$. A small number that satisfies this is $3$, so we can go ahead and use that. Therefore, our public key is $(N, e) = (55, 3)$.\n\nThe next step is to **compute the private key.** Using the formula,  $d = 3^{-1} \\pmod{40}$. We could use [Euclid's Extended Algorithm](/cs70/discrete-math/modular-arithmetic.md#using-euclids-extended-algorithm-for-inverses) to compute this value, which ends up being $27$. Therefore, $d = 27$.\n\nAfter we have computed our keys, we must **encrypt the message.** This yields $y = x^3 \\pmod{55}$for some arbitrary message $x$.\n\nFinally, we must **decrypt the message** by passing $y$into the decryption formula. This yields $x = y^{27} \\pmod{55}$.\n\nIf all goes well, the decrypted message should be the same as the original message!\n",
    "lastmodified": "2023-01-10T23:37:37.55950628Z",
    "tags": null
  },
  "/cs70/discrete-math/stable-matching": {
    "title": "",
    "content": "\n## Introduction\n\nThe **stable matching problem** deals with how to match one group to another group while trying to maximize everyone's 'happiness'. \n\nIt works best when the two groups are **distinct** \\(nobody can be in both groups at once\\) and the orderings are **complete** \\(everyone in the other group has to show up in all orderings\\). Before we get to examples of when this might apply, I'll throw out a few examples where we **can't** use this algorithm so you don't get any wrong ideas:\n\n* We **cannot** use this for creating room groups based on roommate preferences \\(because everyone is in one big group\\).\n* We **cannot** use this for situations where people are limited to their top three choices in jobs.\n\n### Some Definitions\n\nIn order to more concretely set up the stable matching problem, let's define some terms formally:\n\nA **pairing** is a set of job-candidate pairs that uniquely \\(disjointly\\) matches each job to each candidate. For example, {\\(Esports, Joe\\), \\(Steakhouse, Donald\\)} is a valid pairing if we're trying to match Joe and Donald to two possible jobs.\n\nNote that 'job' and 'candidate' can be replaced with any two arbitrary groups, as long as one group doesn't contain any items from the other group!\n\nA **rogue couple** is a single pair where neither person in the pair wants to be with the other person. If a pairing is **stable**, it cannot contain any rogue couples.\n\n**x-optimal matching** is a stable pairing that favors the choices of group x over the other group. This group is **whichever group chooses**- In the example above, the pairing would be **job optimal**, and **candidate pessimal.** \\(More on why later.\\)\n\n## The Propose and Reject Algorithm\n\nThere are a good number of ways we can get stable matchings, but one of the most commonly used methods is the **propose-reject algorithm.** It goes like this:\n\n1. On the first day, each job sends an offer to their favorite candidate.\n2. Each candidate has their own set of preferences, though, so if they get multiple job offers they'll reject all but their favorite one.\n3. The candidate will then say to their favorite offer, \"I like it, but please wait until tomorrow so I can see if I get a better offer.\"\n4. Repeat until each job gets exactly one candidate.\n\n#### Important notes about this algorithm:\n\n* **It is guaranteed to terminate.** \\(Check the proofs section to see why\\)\n* **Every day, it gets better for candidates.** This is because candidates can choose their best offer, so as more offers keep rolling in they get more \\(and better\\) choices. This means that this particular algorithm is **job-optimal** and **candidate-pessimal.** Indeed, regardless of what the groups are, **whichever group proposes will have optimal results.**\n\n### An Example\n\nLet's say that three people **Alice \\(A\\), Bob \\(B\\),** and **Charlie \\(C\\)** applied to jobs in **Capitol One \\(1\\), Two Sigma \\(2\\),** and **3M \\(3\\)** . Their preferences are \\(in order from most to least favored\\):\n\nCANDIDATES                 JOBS  \nA \\|\\| 1 2 3                         1 \\|\\| C A B  \nB \\|\\| 1 2 3                         2 \\|\\| A B C  \nC \\|\\| 2 1 3                         3 \\|\\| A C B\n\nOn day 1,  Capitol One will send an offer to Charlie. Two Sigma and 3M will send job offers to Alice. Since Alice got multiple offers, they will reject 3M and keep Two Sigma on their list.  \n**Day 1: \\(1,C\\), \\(2, A\\)**\n\nOn day 2, Capitol One will send an offer to Charlie again, and Two Sigma will send an offer to Alice again. Since 3M was rejected yesterday, they'll move onto the next person on their list, Charlie. However, Charlie still prefers Capitol One over 3M so he will reject 3M.  \n**Day 2: \\(1,C\\), \\(2,A\\)**\n\nOn day 3, Capitol One will send an offer to Charlie again, and Two Sigma will send an offer to Alice again. Since 3M was rejected yesterday, they'll move onto their final person, Bob. **Since no more candidates or jobs are left unmatched, this algorithm terminates in the stable pairing \\(1, C\\), \\(2, A\\), \\(3, B\\).**\n\n### Proofs of the Propose-Reject Algorithm\n\n#### Existence \\(Termination\\)\n\n**We can prove this by contradiction:** suppose that a job isn't paired yet after the end of the algorithm. This would mean that the job must have made an offer to every single possible candidate and got rejected by all of them. But this is illegal! Those candidates must be matched with other jobs if they rejected this one, meaning there needs to be 1 more job than there actually is. Therefore, all jobs and candidates must be paired at the end of the algorithm.\n\n#### Stability\n\nLet's say a job J and candidate C are matched after the algorithm terminates. If J preferred another candidate C\\*, then that would mean C\\* were higher up on its list and must have made an offer to C\\* before C. However, the fact that J is matched with C and not C\\* means that C\\* rejected J, and thus prefers another job over J. This means that the pairing J and C is stable. \\(You can repeat this argument for any pair J and C.\\)\n\n#### Optimality\n\nTheorem: Job Propose, Candidate Reject produces a job-optimal pairing.\n\n* Proof by contradiction: assume that there's a job j that doesn't get an optimal candidate c.\n* Let t be the first day job j gets rejected by its optimal candidate g.\n* On that day, there was another job offer j\\* that c preferred.\n* Therefore, j\\* likes c at least as much as the optimal candidate. **This creates a rogue couple.** \n* By the Well Ordering Principle, this is the first day that job j was rejected\n\n**Pessimality**\n\nTheorem: Job Propose, Candidate Reject produces a candidate-pessimal pairing:\n\n* Let T be a pairing where \\(j, c\\) is a pair.\n* Let S be a stable pairing that is worse for c than T is. So \\(j, c\\*\\) is a pair.\n* Since j prefers c to c\\*, \\(j, c\\*\\) is a rogue couple for S which is a **contradiction.** Therefore, T is the worst possible pairing for c.\n\n### \n\n",
    "lastmodified": "2023-01-10T23:28:40.252666316Z",
    "tags": null
  },
  "/cs70/latex-reference": {
    "title": "LaTeX Reference",
    "content": "\n# \n\n### Basics\n\n| Symbol | Description | LaTeX |\n| :--- | :--- | :--- |\n| $\\cdot$ | Multiplication dot | `\\cdot` |\n| $\\cdots$ | Dots | `\\cdots` |\n| $\\frac{x}{y}$ | Fraction | `\\frac{x}{y}` |\n| $\\ge$ | Greater than or equal to | `\\ge` |\n| $\\le$ | Less than or equal to | `\\le` |\n| $\\ne$ | Not equal to | `\\ne` |\n| $\\sum_{i=0}^{n}$ | Summation | `\\sum_{i=0}^{n}` |\n| $\\infty$ | Infinity | `\\infty` |\n| $\\lim_{x \\to \\infty}$ | Limit | `\\lim_{x \\to \\infty}` |\n\n### Propositional Logic\n\n| Symbol | Description | LaTeX |\n| :--- | :--- | :--- |\n| $\\implies$ | Implication | `\\implies` |\n| $\\iff$ | Logical equivalence | `\\iff` |\n| $\\equiv$ | Congruence | `\\equiv` |\n| $\\exists$ | Existence | `\\exists` |\n| $\\in$ | Inclusion | `\\in` |\n| $\\land$ | Conjunction \\(and\\) | `\\land` |\n| $\\lor$ | Disjunction \\(or\\) | `\\lor` |\n| $\\lnot$ | Negation \\(not\\) | `\\lnot` |\n| $\\forall$ | For all | `\\forall` |\n| $\\oplus$ | Exclusive or \\(xor\\) | `\\oplus` |\n\n### Sets\n\n| Symbol | Description | LaTeX |\n| :--- | :--- | :--- |\n| $\\mathbb{C}$ | Complex numbers | `\\mathbb{C}` |\n| $\\mathbb{R}$ | Real numbers | `\\mathbb{R}` |\n| $\\mathbb{Q}$ | Rational numbers | `\\mathbb{Q}` |\n| $\\mathbb{Z}$ | Integers | `\\mathbb{Z}` |\n| $\\mathbb{N}$ | Natural numbers | `\\mathbb{N}` |\n| $\\mathscr{P}$ | Power set | `\\mathscr{P}` |\n| $\\cup$ | Union \\(set or\\) | `\\cup` |\n| $\\cap$ | Intersection \\(set and\\) | `\\cap` |\n| $\\emptyset$ | Empty Set | `\\emptyset` |\n| $\\setminus$ | Set Division | `\\setminus` |\n| $\\subseteq$ | Subset \\(inclusive\\) | `\\subseteq` |\n\n### Modular Arithmetic\n\n| Symbol | Description | LaTeX |\n| :--- | :--- | :--- |\n| $p \\mod q$ | Modulo | `\\mod` |\n| $p \\pmod{q}$ | Modulo in parentheses | `\\pmod{q}` |\n\n",
    "lastmodified": "2023-01-10T23:26:58.85356795Z",
    "tags": null
  },
  "/cs70/probability/": {
    "title": "Probability",
    "content": "",
    "lastmodified": "2023-01-10T21:59:27.631320801Z",
    "tags": null
  },
  "/cs70/probability/concentration-inequalities": {
    "title": "",
    "content": "\nAlso see the [Data 102 notes](\u003c/data102/concentration inequalities\u003e) on this topic.\n\nMarkov's Inequality: [http://prob140.org/textbook/content/Chapter\\_18/04\\_Chi\\_Squared\\_Distributions.html](http://prob140.org/textbook/content/Chapter\\_18/04\\_Chi\\_Squared\\_Distributions.html)\n\nChebyshev's Inequality: [http://prob140.org/textbook/content/Chapter\\_18/04\\_Chi\\_Squared\\_Distributions.html](http://prob140.org/textbook/content/Chapter\\_18/04\\_Chi\\_Squared\\_Distributions.html)\n\nChernoff Bound:[ http://prob140.org/textbook/content/Chapter\\_19/04\\_Chernoff\\_Bound.html?highlight=chernoff](http://prob140.org/textbook/content/Chapter\\_19/04\\_Chernoff\\_Bound.html?highlight=chernoff)\n",
    "lastmodified": "2023-01-10T23:42:12.776723059Z",
    "tags": null
  },
  "/cs70/probability/conditional-expectation-and-variance": {
    "title": "",
    "content": "\nProperties:\n\n### Conditional Expectation\n\n$E(X|Y)$is the conditional expectation of $X$given $Y$\n\n* $E(X|Y=y)$is a fixed value, but $E(X|Y)$is a random variable \\(it is a function of $Y$\\)\n* Iterated expectation: $E(E(X|Y)) = E(X)$\n* Additivity: $E(Y+Z | X) = E(Y|X) + E(Z|X)$\n  * **does not work** on the right hand side: $E(Y | X+Z) \\ne E(Y|X) + E(Y|Z)$\n* Linearity: $E(aX + b | Y) = aE(X|Y) + b$\n* Conditioning on the same variable: $E(g(S)T | S) = g(S)E(T|S)$\n\n### Conditional Variance\n\nIf $Var(Y)$is difficult to find directly, we can use the **variance decomposition** to condition the variance on another variable.\n\n$\nVar(Y) = E(Var(Y|X)) + Var(E(Y|X))\n$\n\n\n\n",
    "lastmodified": "2023-01-10T23:43:33.575896348Z",
    "tags": null
  },
  "/cs70/probability/continuous-probability": {
    "title": "",
    "content": "![Credit: Huiyi Zhang](\u003c../img/assets/image (21).png\u003e)\n\n(Credit: Huiyi Zhang)\n\nAll of the continuous probability distributions are deeply connected. Above is a chart describing some of their relationships.\n\n\n\nBelow are some links:\n\n* [Poisson](http://prob140.org/textbook/content/Chapter\\_07/01\\_Poisson\\_Distribution.html)\n* [Beta](http://prob140.org/textbook/content/Chapter\\_21/00\\_The\\_Beta\\_and\\_the\\_Binomial.html)\n* [Exponential](http://prob140.org/textbook/content/Chapter\\_15/04\\_Exponential\\_Distribution.html?highlight=exponential)\n* [Normal](http://prob140.org/textbook/content/Chapter\\_18/01\\_Standard\\_Normal\\_Basics.html)\n* [Gamma](http://prob140.org/textbook/content/Chapter\\_18/03\\_The\\_Gamma\\_Family.html)\n* [Chi-Squared](http://prob140.org/textbook/content/Chapter\\_18/04\\_Chi\\_Squared\\_Distributions.html)\n",
    "lastmodified": "2023-01-10T23:43:05.796180982Z",
    "tags": null
  },
  "/cs70/probability/counting": {
    "title": "",
    "content": "\n## Introduction\n\nIf you're reading this, I think it's safe to assume you already know how to count... (1, 2, 3, whatever) so what's the big deal about counting?\n\nWhen we say counting in this context, we mean **counting sequences of decisions.** For example, we might want to get the **total number of ways to choose toppings on a pizza** or something.\n\nThere are **two main types** of problems: those where **order matters** and those where it doesn't.\n\n## The First Rule of Counting: When the order matters\n\nHere's a sample problem: let's try to figure out the total number of unique 5-character strings we can make with the letters 'A' through 'E'. For instance, 'ABCDE' and 'DABBA' are both valid.\n\nLots of these types of problems can be visualized using **slots,** where each slot is one character or option: ****\n\n****![](\u003c../img/assets/image (19) (1).png\u003e)****\n\nTo get the total number of ways to fill the slots, we can **multiply the number of ways each individual slot can be filled together.**\n\nSo for the problem above, we get that there are 5 ways to fill each slot, and 5 slots in total. So, $5 \\times 5 \\times 5 \\times 5 \\times 5 = 3125$strings.\n\n## **The Second Rule: When the order doesn't matter**\n\nIn order to tackle these types of problems, we'll need to introduce the **combinatorial** $\\binom{n}{k} = \\frac{n!}{k!(n-k)!}$. When you see this, it means \"the number of ways we can choose $n$things from $k$total elements if order doesn't matter\".\n\n\n\n## Stars and Bars\n\n\u003ciframe\n    width=\"640\"\n    height=\"480\"\n    src=\"https://www.youtube.com/embed/UTCScjoPymA\"\n    frameborder=\"0\"\n    allow=\"encrypted-media\"\n    allowfullscreen\n\u003e\n\u003c/iframe\u003e\n\nWhen we need to split items into groups, it's sometimes nice to add **bars** that separate the items. This is great if there are particular classes of items rather than unique ones (if they're unique, just use slots.)\n\nHow this works is that we can treat each item as a **star**, and the stars are separated by **bars** that designate one group from another.\n\nThis means that if there are $n$stars and $k$groups, then there must be $\\binom{n+k-1}{k-1}$total ways to split the stars into groups.\n\nOne application of this is to get the total number of equations $y_0 + y_1 + \\cdots + y_k = n$for a fixed $n$. We can think of there being $n$number of ones (our stars), and $k$number of plus signs (our bars). There can also be an empty group (representing $y_i = 0$), which bumps us up to $k+1$groups. By the Stars and Bars principle, there are $\\binom{n+k}{k}$such equations for non-negative numbers.\n\n## The Inclusion-Exclusion Principle\n\nUsed to calculate the probability of the union of events.\n\n[http://prob140.org/textbook/content/Chapter\\_05/02\\_Inclusion\\_Exclusion.html](http://prob140.org/textbook/content/Chapter\\_05/02\\_Inclusion\\_Exclusion.html)\n",
    "lastmodified": "2023-01-10T23:40:57.521489647Z",
    "tags": null
  },
  "/cs70/probability/discrete-probability": {
    "title": "",
    "content": "\n## Probability Basics\n\n[http://prob140.org/textbook/content/Chapter\\_02/00\\_Calculating\\_Chances.html](http://prob140.org/textbook/content/Chapter\\_02/00\\_Calculating\\_Chances.html)\n\n - [Adding and subtracting probabilities](http://prob140.org/textbook/content/Chapter_02/01_Addition.html)\n -[Multiplying probabilities: random draws without replacement, conditional probabilities](http://prob140.org/textbook/content/Chapter_02/03_Multiplication.html)\n\n## Bayes' Rule\n\nBayes' Rule is used to re-express conditional probabilities $P(A|B)$.\n\n[http://prob140.org/textbook/content/Chapter\\_02/05\\_Updating\\_Probabilities.html#bayes-rule](http://prob140.org/textbook/content/Chapter\\_02/05\\_Updating\\_Probabilities.html#bayes-rule)\n\n## Random Variables\n\n###  Probability Spaces\n\nProbability spaces describe all of the possible values of a random variable, and how likely each of those outcomes are.\n\n[http://prob140.org/textbook/content/Chapter\\_02/00\\_Calculating\\_Chances.html](http://prob140.org/textbook/content/Chapter\\_02/00\\_Calculating\\_Chances.html)\n\n### Equality\nTwo variables are equal if $X(\\omega) = Y(\\omega)$ for all $\\omega \\in \\Omega$, where $\\Omega$ is a probability space (all possible values).\n\nhttp://prob140.org/textbook/content/Chapter_03/03_Equality.html",
    "lastmodified": "2023-01-10T23:41:06.389399501Z",
    "tags": null
  },
  "/cs70/probability/expectation-and-variance": {
    "title": "",
    "content": "\nThe expectation of a random variable, $E(X)$, is the average of possible values weighted by their probabilities. Formally, it can be defined in two ways:\n\n1. Domain definition: $E(X) = \\sum_{\\omega \\in \\Omega} X(\\omega) P(\\omega)$.\n2. Range definition: $E(X) = \\sum_x x P(X = x)$.\n\nExpectation has nice properties of linearity: $E(X + Y) = E(X) + E(Y)$ and $E(aX + b) = aE(x) + b$.\n\n[http://prob140.org/textbook/content/Chapter\\_08/01\\_Definition.html](http://prob140.org/textbook/content/Chapter\\_08/01\\_Definition.html)\n",
    "lastmodified": "2023-01-10T23:41:21.90524164Z",
    "tags": null
  },
  "/cs70/probability/hashing-and-the-union-bound": {
    "title": "",
    "content": "\nA hash function assigns a value to each member in a set. It's often useful to determine the probability of collisions: where two different items are assigned the same hash value.\n\n[http://prob140.org/textbook/content/Chapter\\_01/03\\_Collisions\\_in\\_Hashing.html](http://prob140.org/textbook/content/Chapter\\_01/03\\_Collisions\\_in\\_Hashing.html)\n\nAn interesting result is explored by the [Birthday Problem](http://prob140.org/textbook/content/Chapter\\_01/04\\_Birthday\\_Problem.html) (sometimes known as the Birthday Paradox, despite not actually being paradoxical), in which the probability of at least two people sharing the same birthday is much higher than expected.\n",
    "lastmodified": "2023-01-10T23:41:16.713294479Z",
    "tags": null
  },
  "/cs70/probability/markov-chains": {
    "title": "",
    "content": "\nMarkov Chains are a type of **stochastic process** (a collection of random variables that evolves over time) that satisfy the **Markov property** (the future state $n+1$ only depends on the current state $n$, and not any of the past states).\n\nMarkov chains are often used to model transitions between discrete states.\n\n[http://prob140.org/textbook/content/Chapter\\_10/00\\_Markov\\_Chains.html](http://prob140.org/textbook/content/Chapter\\_10/00\\_Markov\\_Chains.html)\n",
    "lastmodified": "2023-01-10T23:43:20.76802763Z",
    "tags": null
  },
  "/cs70/probability/probability-overview": {
    "title": "",
    "content": "\nThe probability section of this guide will likely never be fully completed, due to the fact that the [Prob 140 textbook](http://prob140.org/textbook/content/README.html) is such an excellent resource in probability theory. Go read it and do the problems!\n\nInstead of a full write-up, the pages in this section will typically just link to relevant sections from the textbook. Personally, I found everything I needed to do well in CS70 probability (and much more) here, including examples that are very similar to problems you might see on the homework.\n\nTL;DR don't use this section of the guide, just read the 140 textbook.\n\nHere is a running list of topics in this section:\n\n* [**Counting**](/cs70/probability/counting.md) provides us an intuitive method of figuring out how many possible ways there are to do something.\n* [**Discrete probability distributions**](/cs70/probability/discrete-probability.md), such as the Binomial or Geometric distributions, describe the probabilities of a finite set of outcomes.\n* [**Continuous probability distributions**](/cs70/probability/continuous-probability.md), such as the Poisson or Normal distributions, help us model real values, like lifetime or height.\n* [**Markov chains**](/cs70/probability/markov-chains.md) model transitions between discrete states.\n* [**Expectation and variance**](/cs70/probability/expectation-and-variance.md) are tools to describe the characteristics of a random variable or distribution.\n* [**Concentration inequalities**](/cs70/probability/concentration-inequalities.md) allow us to approximate bounds for random variables when we only know their expectation and/or variance.\n\nThere is far more to explore in learning the basics of probability- not everything is included in this list!\n\n### Reference\n\n[http://prob140.org/assets/final\\_reference\\_fa18.pdf](http://prob140.org/assets/final\\_reference\\_fa18.pdf)\n\n| Distribution                                                                                              | Values               | Density                                                      | Expectation           | Variance                                   | Links |\n| --------------------------------------------------------------------------------------------------------- | -------------------- | ------------------------------------------------------------ | --------------------- | ------------------------------------------ | ----- |\n| Uniform(m,n)                                                                                              | \\[m, n]              | $\\frac{1}{n-m+1}$                                          | $\\frac{m+n}{2}$     | $\\frac{(n-m+1)^2-1}{12}$                 |       |\n| \u003cp\u003eBernoulli(p)\u003c/p\u003e\u003cp\u003eIndicator\u003c/p\u003e                                                                       | 0, 1                 | \u003cp\u003eP(X=1) = p\u003c/p\u003e\u003cp\u003eP(X=0) = 1-p\u003c/p\u003e                         | $p$                 | $p(1-p)$                                 |       |\n| Binomial(n,p)                                                                                             | \\[0, n]              | $\\binom{n}{k}p^kq^{n-k}$                                   | $np$                | $np(1-p)$                                |       |\n| Poisson($\\mu$)                                                                                          | $x\\ge0$            | $e^{-\\mu}\\frac{\\mu^k}{k!}$                                 | $\\mu$               | $\\mu$                                    |       |\n| Geometric(p)                                                                                              | $x \\ge 1$          | $(1-p)^kp$                                                 | $\\frac{1}{p}$       | $\\frac{1-p}{p^2}$                        |       |\n| Hypergeom.(N,G,n)                                                                                         | \\[0, n]              | $\\frac{\\binom{G}{g}\\binom{B}{b}}{\\binom{N}{n}}$            | $n\\frac{G}{N}$      | $n\\frac{G}{N}\\frac{B}{N}\\frac{N-n}{N-1}$ |       |\n| Uniform Continuous                                                                                        | (a, b)               | $\\frac{1}{b-a}$                                            | $\\frac{a+b}{2}$     | $\\frac{(b-a)^2}{12}$                     |       |\n| Beta(r,s)                                                                                                 | (0, 1)               | $\\frac{\\Gamma(r+s)}{\\Gamma(r)\\Gamma(s)}x^{r-1}(1-x)^{s-1}$ | $\\frac{r}{r+s}$     | $\\frac{rs}{(r+s)^2(r+s)}$                |       |\n| \u003cp\u003eExponential(\u003cspan class=\"math\"\u003e\\lambda\u003c/span\u003e)\u003c/p\u003e\u003cp\u003e(Gamma(1, \u003cspan class=\"math\"\u003e\\lambda\u003c/span\u003e))\u003c/p\u003e | $x\\ge0$            | $\\lambda e^{-\\lambda x}$                                   | $\\frac{1}{\\lambda}$ | $\\frac{1}{\\lambda^2}$                    |       |\n| Gamma(r, $\\lambda$)                                                                                     | $x\\ge0$            | $\\frac{\\lambda^r}{\\Gamma(r)}x^{r-1}e^{\\lambda x}$          | $\\frac{r}{\\lambda}$ | $\\frac{r}{\\lambda^2}$                    |       |\n| Normal(0,1)                                                                                               | $x \\in \\mathbb{R}$ | $\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{1}{2}x^2}$                 | 0                     | 1                                          |       |\n\nWhere $\\binom{n}{k} = \\frac{n!}{k!(n-k)!}$and $\\Gamma(r) = \\int_0^\\infty x^{r-1}e^{-x}dx = (r-1)\\Gamma(r-1) = (r-1)!$\n",
    "lastmodified": "2023-01-10T23:39:33.202343988Z",
    "tags": null
  },
  "/cs70/probability/the-beta-family": {
    "title": "",
    "content": "\nThe Beta distribution is a family of continuous distributions on \\[0,1] with two parameters (commonly known as $\\alpha$ and $\\beta$, but also $r$ and $s$).\n\n![Credit: Wikipedia](\u003c../img/assets/image (19).png\u003e)\n\nBeta distributions are commonly used in situations where we want to continually update a prior distribution given new information.\n\n* The `beta (1,1)` distribution is identical to the uniform distribution.\n\n[http://prob140.org/textbook/content/Chapter\\_21/00\\_The\\_Beta\\_and\\_the\\_Binomial.html](http://prob140.org/textbook/content/Chapter\\_21/00\\_The\\_Beta\\_and\\_the\\_Binomial.html)\n",
    "lastmodified": "2023-01-10T23:43:26.607967781Z",
    "tags": null
  },
  "/data102/": {
    "title": "Data 102: Inference",
    "content": "\n## Data102 Notes\n\nHere are my notes for the Fall 2022 offering of [Data 102](https://data102.org/), Berkeley's Inference for Data Science course.\n\nData 102 explores two major concepts: **making decisions under uncertainty** and **modeling the real world**. This is all about making assumptions-- here are some definitions:\n - **Frequentist:** $y$ (data) is random, $\\theta$ (parameter) is fixed\n - **Bayesian:** $y$ is random, $\\theta$ is random\n - **Parametric:** Make assumptions about the relationship between $\\theta$ and $y$, then use these assumptions to find the best value of $\\theta$ given $y$\n - **Nonparametric:** Don't make any assumptions, and find any good function $f$ such that $\\theta = f(y)$\n\n## Table of Contents\n - [[Binary Decision Making]]: Confusion matrix, sensitivity, specificity, TPR/FPR/FNR/FDP etc.\n - [[Hypothesis Testing]]: Null/alternative hypotheses, multiple hypothesis testing, controlling FWER/FDR, online decision making, likelihood ratios\n - [[Decision Theory]]: Loss functions, risk, bias-variance tradeoff\n - [[Parameter Estimation]]: Likelihood, MLE, Bayesian parameter estimation, Bayesian hierarchical models\n - [[Sampling]]: Markov chains, MCMC, Metropolis-Hastings, Rejection sampling, Gibbs sampling\n - [[Regression and GLMs]]: Generalized linear models, posterior predictive check\n - [[Nonparametric Methods]]: K-Nearest Neighbors, decision trees, random forests, neural networks, gradient ascent/descent\n - [[Interpretability]]: Interpretability, explainability\n - [[Causality]]: Colliders, confounders, structural causal models, risk ratios, potential outcomes framework\n - [[Concentration Inequalities]]: Markov, Chebychev, Chernoff, Hoeffding\n - [[Bandits]]: Multi-Armed Bandit Framework, UCB/ETC, Thomson Sampling, Regret\n - [[Markov Decision Processes]]: Value iteration, Q-value iteration, Policy iteration\n - [[Reinforcement Learning]]: Q-Learning\n\n \n## How to contribute\n\nSee the [contributing guide](/contributing) for more details!\n\nFor the most part, these notes should be pretty complete in terms of content, but could use some cleaning up (as well as more examples).\n\n#### Credits\n\n* [Ben Cuan](https://github.com/64bitpandas)\n\n\n\n\n\n\n",
    "lastmodified": "2023-01-12T02:23:04.684819073Z",
    "tags": null
  },
  "/data102/Markov-Decision-Processes": {
    "title": "",
    "content": "## What is a Markov Decision Process?\n\nA Markov Decision Process is a Markov model that solves **nondeterministic search problems** (where an action can result in multiple possible successor states).\n\nA MDP is defined by:\n\n- A set of states $s$\n- A set of actions $a$\n- A transition model $T(s, a, s’)$ that represents the probability $P(s’ | s, a)$ - that the action $a$ taken at state $s$ will lead to a new state $s’$. (Allowed by memoryless property)\n- A reward function $R(s, a, s’)$ per transition\n- Discount factor $\\gamma \\in [0, 1]$\n- A start state\n- A terminal (absorbing state)\n\nThe utility function of an MDP can be calculated as follows:\n\n$$\nU([s_0, a_0, s_1, a_1, s_2, \\cdots]) = R(s_0, a_0, s_1) + \\gamma R(s_1, a_1, s_2) + \\gamma^2 R(s_2, a_2, s_3) + \\cdots\n$$\n\nIntuitively, the discount factor causes an exponential decay over time, so if an agent takes too long to reach a state it is automatically terminated. This also solves the problem of infinite reward streams. (**enforce a finite horizon)**\n\n- The reward is bounded by the value $\\frac{R_{\\max}}{1-\\gamma}$.\n\n**The primary goal for an MDP is to find an optimal policy** $\\pi^*$ that gives us an action for every state that results in the maximum expected utility.\n\n- The expected utility of a policy $U^{\\pi}(s_0)$ is equal to the sum  over all possible state sequences multiplied by the probability of them occurring.\n\n# Solving MDPs\n\n## The Bellman Equation\n\nSome values:\n\n- The utility of a state $s$ is equal to the expected utility when starting at $s$ and acting according to the optimal policy.\n- The utility of a Q-state $Q^*(s,a)$ is equal to the expected utility of taken action $a$ in state $s$, then acting optimally.\n\nThe Bellman Equation is as follows:\n\n$$\nU^*(s) = \\max_a \\sum_{s'} T(s, a, s')\\times(R(s, a,s') + \\gamma U^*(s'))  = \\max_a Q^*(s, a)\n$$\n\n- The equation finds the optimal value of the state $s$ by multiplying the transition probability to the next state by the reward for that transition plus the discounted utility of the next state.\n- The inner sum term is equivalent to the utility of the Q-state.\n- The equation creates a dynamic programming problem where the subproblem $U^*(s’)$ is used to calculate the current state’s utility.\n\n## Value Iteration\n\nUsed for computing the optimal values of states, by iterative updates until convergence.\n\nIn order to compute the value of a state. we can use the following algorithm:\n\n1. For all states $s \\in S$, initialize their starting value $U_0(s) = 0$.\n2. Until convergence (i.e. $U_{k+1} = U_k$), run the following update formula:\n    1. $\\forall s \\in S, U_{k+1}(s) = \\max_a \\sum_{s’} T(s, a, s’)\\times (R(s, a, s’) + \\gamma U_k(s’))$\n    2. Unlike the Bellman equation, which tests for optimality, this equation changes the value iteratively using dynamic programming.\n    3. In other words, this equation takes the max of the values of alll neighboring states, and multiplies it by the transition probability (if nondeterministic).\n    4. $U^*(s)$ for any terminal state must be $0$ (since no actions can be taken from these states).\n\nProperties:\n\n- Value iteration is guaranteed to converge for discounts less than 1.\n- Value iterations will converge to the same $U^*$ values regardless of initial values.\n- The runtime of value iteration is $O(|S|^2 |A|)$ since for every action, we need to compute each action’s Q-value which requires iterating over all states.\n\n![[/data102/img/Pasted image 20221115161107.png]]\n\n**Q-value iteration** is a similar update algorithm that computes Q-values instead:\n\n$$\nQ_{k+1}(s,a) = \\sum_{s'} T(s, a, s') \\times (R(s, a, s') + \\gamma \\max_{a'} Q_k (s', a'))\n$$\n\n- This is different because for value iteration, we select an action before transitioning, whereas in Q-value iteration, we make the transition before choosing the new state.\n\n**Policy extraction:** to determine the optimal policy from optimal state values (given a state value function), we can use the following equation:\n\n$$ \\forall s \\in S, \\pi^*(s) = \\argmax_a Q^*(s, a) = \\argmax_a \\sum_{s'} T(s, a, s') [R(s, a, s') + \\gamma U^*(s')]$$\n\nPolicy extraction is only optimal if the state value function is optimal. Used either after value iteration (to compute optimal policies from optimal state values) or as a subroutine in policy iteration (to compute the best policy for estimated state values).\n\n## Policy Iteration\n\nPolicy iteration has the same optimality guarantees as value iteration, but has better performance. The algorithm is as follows:\n\n1. Define an initial policy. The closer the initial policy is to the optimal policy, the faster it will converge.\n2. Compute $U^{\\pi}(s) = \\sum_{s’} T(s, \\pi(s), s’) [R(s, \\pi(s), s’) + \\gamma U^{\\pi}(s’)]$ for all states $s$ (the expected utility of starting in state $s$ when following the current policy $\\pi$).\n3. Generate the next iteration $i$ of policy values using the equation above for every state.\n4. Use policy improvement to generate a better policy: $\\pi_{i+1}(s) = \\argmax_a \\sum_{s'} T(s, a, s')[R(s, a, s') + \\gamma U^{\\pi_i}(s')]$\n5. Repeat steps 2-5 until $\\pi_{i+1} = \\pi_i = \\pi^*$.\n\n\n",
    "lastmodified": "2023-01-12T00:44:34.941794603Z",
    "tags": null
  },
  "/data102/Reinforcement-Learning": {
    "title": "",
    "content": "\n## Introduction\n\nReinforcement Learning (RL) is an example of **online planning,** where agents have no prior knowledge of rewards or transitions and must explore an environment before using an estimated policy.\n\n- Model-based learning: attempts to estimate transition and reward functions with samples attained during exploration before solving MDP with estimates using value or policy iteration\n- Model-free learning: attempts to estimate values/Q-values of states directly without construction a reward or transition model in MDP\n\nPassive reinforcement learning: agent is given a policy and learns the values of states under that policy.\n\n- direct evaluation, TD learning\n\nActive reinforcement learning: use feedback to iteratively update policy, eventually learning optimal policy\n\n- Q-learning\n\n## Direct Evaluation\n\n1. Fix a policy $\\pi$\n2. Have the agent experience several episodes (group of samples) \n3. Compute estimated value of any state $s$ by dividing total utility (reward from leaving state) by number of times visited\n\nDirect evaluation loses all transition information, since each state’s value is computed separately.\n\n## Temporal Difference (TD) Learning\n\nTD learning maintains an estimated value $V^\\pi(s)$ for each state by averaging returns achieved from $s$ across all samples.\n\n$$\nV^\\pi(s) \\leftarrow (1-\\alpha)V^\\pi(s) + \\alpha[R(s, \\pi(s), s') + \\gamma V^\\pi(s')]\n$$\n\n- $\\alpha$ is a learning rate: higher $\\alpha$ should be used when the current estimate is bad, and low $\\alpha$ should be used when the current estimate is good.\n- $\\pi(s)$ is an action sampled from the current policy. This action will lead to a new state $s’$, whose value will be used to calculate the new value of the current state.\n- $V^\\pi(s)$ will only converge to the optimal value $V^*(s)$ if the policy used is optimal. TD learning by itself cannot learn this optimal policy.\n\n## Q-Learning\n\nQ-learning is like TD learning, but using Q-values instead of normal utility values.\n\nRegardless of the optimality of the policy used or actions taken, Q-learning will still converge to the optimal policy given a reasonable learning rate and enough exploration.\n\n$$\nQ(s, a) \\leftarrow (1-\\alpha)Q(s,a) + \\alpha[R(s, a, s') + \\gamma \\max_{a'} Q(s', a')]\n$$\n\n**Approximate Q-learning** improves Q-learning by using a feature representation for states:\n\n- Let $\\textnormal{difference} = [R(s, a, s’) + \\gamma \\max_{a’} Q(s’, a’)] - Q(s, a)]$\n- Update weights using $w_I \\leftarrow w_i + \\alpha \\times \\textnormal{difference} \\times f_i(s, a)$\n- Update Q-values using $Q(s, a) \\leftarrow Q(s, a) + \\alpha \\cdot \\textnormal{difference}$\n- Define $Q(s, a) = w \\cdot f(s, a)$\n- Define $V(s) = w \\cdot f(s)$\n\n**SARSA variation:** use the action performed by the current policy to learn the Q-value.\n$$Q(s,a) \\leftarrow (1-\\alpha)Q(s,a) + \\alpha(R(s,a,s') + \\max_a Q(s', a))$$\n - only converges if $\\alpha$ approaches $0$ over time, and if trajectories include all states\n\n## Exploration vs Exploitation\n\nThe following methods distribute time between exploration and exploitation:\n\n### Epsilon-Greedy\n\nDefine some probability $\\epsilon \\in [0, 1]$. With probability $\\epsilon$, randomly explore. With probability $1 - \\epsilon$, choose the next state based on the current best policy.\n\n### Exploration Function\n\nDuring the Q-learning update, maximize over some exploration function instead of Q-values:\n\n$$\nQ(s, a) \\leftarrow (1-\\alpha)Q(s,a) + \\alpha[R(s,a,s') + \\gamma \\max_a' f(s', a')]\n$$\n\nwhere $f(s, a) = Q(s, a) + \\frac{k}{N(s, a)}$\n\n- $k$ is a constant determining the degree of exploration. Decrease towards 0 over time to decrease the amount of exploration being done.\n- $N(s, a)$ is the number of times the Q-state has been visited.",
    "lastmodified": "2023-01-12T00:35:12.55560859Z",
    "tags": null
  },
  "/data102/bandits": {
    "title": "",
    "content": "\n**Main idea:** making repeated decisions based on feedback, factoring in the tradeoff between exploring new decisions or keeping existing good decisions\n\n### Multi-Armed Bandit Framework\nThe Multi-Armed bandit problem arises when the following are true:\n - We need to get the data as a part of the process\n - Exploration/exploitation tradeoff (both have a cost)\n - Stochastic: rewards are random\n\n**Setup:**\n - Selection rounds $1, \\cdots, T$\n - Arms (choices) $1, \\cdots, K$\n - $P_i$: reward distribution for arm $i$\n - $\\mu_i$: mean reward for $P_i$ distribution\n - At each round $t$, choose an arm $A_t$ such that a reward $X_t \\sim P_{A_t}$ is procured\n - Define *pseudo-regret* at time $T$ as $\\bar R_t = \\sum_{t=1}^T (\\mu^* - \\mu_{A_t})$ where $\\mu^*$ is the best mean possible.\n\t - The term in the sum is also known as the **optimality gap**, $\\Delta_a$ (how much worse arm $a$ is than the best arm).\n\n**Goal:** maximize total expected reward\n\n**Known:** only $A_t$ and $X_t$\n\n**Examples:**\n- AB testing\n- Advertising\n- Gambling\n- Optimizing blog posts\n- Training hyperparameters for ML models\n\n**Algorithms:**\n - Explore then commit (ETC): choose the arm with the highest sample mean\n\t - not optimal: will never choose the true best arm if not explored\n - Upper Confidence Bound (UCB): choose arm with highest upper bound in the confidence interval\n\t - Confidence interval calculation (derived from Hoeffding's Inequality): $$UCB_i(t) = \\hat\\mu_i(t) + \\sqrt{\\frac{\\log(1/\\delta)}{2T_i(t)}}$$\n\t - (where $\\delta$) is something like .05, that specifies how wide our confidence interval should be\n\t - Choose a $\\delta$ as a decreasing function of $t$ to ensure that confidence intervals will get narrower as we explore something more\n\t - Hoeffding requires variables to be independent, which isn't actually true for the UCB algorithm (which arm we choose depends on which arms we chose before). However, the result still holds.\n\t\t - UCB regret is bounded by $3 \\sum_{a=1}^K \\Delta_a + 24 \\log(T) \\sum_{a=1}^K \\frac{1}{\\Delta_a}$ which says that the regret grows logarithmically with respect to $T$.\n - Thomson Sampling: draw a sample from the posterior for each arm, and choose arm according to $argmax_a \\bar\\mu_a$\n\n\n### Other Bandit Problems\n**Adversarial Bandits:** rewards are chosen by an adversarial actor\n**Contextual bandits:** rewards are correlated with confounding variables\n**Linear bandits:** arms are a vector of arm choices (online linear regression)\n**Non-stationary bandits:** arm reward distributions change over time\n**Structured bandits:** previous choices affect future choices (such as navigation on a road network)",
    "lastmodified": "2023-01-12T00:34:54.219797389Z",
    "tags": null
  },
  "/data102/binary-decision-making": {
    "title": "",
    "content": "\nBinary Decision Making is the simplest kind of decision we can make: 1 or 0, yes or now, true or false...\n\n## Setup\nIn reality, a value is either 0 or 1.\nHowever, we observe noisy data that isn't always 100% accurate. Given this noisy data, we make a decision (also either 0 or 1).\n\nSome examples of binary decisions are:\n - COVID testing (positive or negative)\n - Fraud detection (fraud or no fraud)\n\n## Confusion Matrix\nA 2x2 table that helps us evaluate how effective our predictions were (columns) given reality (rows).\n![[/data102/img/Untitled 24.png]]\n\n\n### Terminology\nhttps://en.wikipedia.org/wiki/Sensitivity_and_specificity\nSensitivity = True Positive Rate\nSpecificity = True Negative Rate\n\n\n**True Negative Rate (TNR):** $n_{TN}/(n_{TN} + n_{FP})$ (top row-wise, proportion correct out of all negative results)\n - 1 - TNR = False Positive Rate (FPR)\n - TNR = P(decision = 0 | reality = 0)\n -  FPR = P(decision = 1 | reality = 0)\n\n**True Positive Rate (TPR):** $n_{TP} / (n_{FN} + n_{TP})$ (bottom row-wise, proportion correct out of all positive results)\n - 1 - TPR = False Negative Rate (FNR)\n - TPR = P(decision = 1 | reality = 1)\n - FNR = P(decision = 0 | reality = 1)\n\n**False Discovery Proportion (FDP):**  $n_{FP} / (n_{FP} + n_{TP})$ (right column-wise, proportion of false positives out of all positive predictions)\n - Also known as False Discovery Rate (FDR)\n - P(reality = 0 | decision = 1)\n\n**False Omission Proportion (FOP):** $FN/(FN + TN)$ (left column-wise, proportion of false negatives out of all negative predictions)\n\n\n## Interpreting Row-wise and Column-wise rates\n\nHere's an example of interpreting values using COVID testing:\n - FPR: within people without COVID, how many test positive?\n - FDP: within positive tests, how many people don't have COVID? (when the algorithm predicts yes, how often is it wrong?)\n\nDepending on the context, some values are more useful than others.  \n\n\"Within reality\" = row-wise, \"Within tests\" = column-wise\nSensitivity, specificity, recall -\u003e row-wise\nprecision, positive predictive value -\u003e column-wise\n\n\n## Randomness: Bayesian vs Frequentist\nWe *always assume* that the data itself is random. Since decisions are based on data, decisions are also random.\n\nHowever, depending on our mindset, we can either treat reality as fixed or random.\n\nIf reality is *random* (Bayesian mindset):\n - We need to specify how exactly reality is random (probability distribution for P(R=0), P(R=1)\n - $P(R=1) = \\pi_1$ (**base rate** or **prevalence** - how often a positive value actually occurs)\n\t - $\\pi_1 = 1 - \\pi_0$\n\nIf reality is *fixed* (Frequentist mindset):\n - Need row-wise error rates (FPR, FNR) to be as small as possible (need some tradeoffs)\n - Column-wise rates fixed\n\t - P(R=0|D=0) is not defined (since it's not a probability!)\n\t - TNR can still be defined as a proportion of values though\n\n## Relating column-wise and row-wise rates\n\nUsing Bayes' rule:\n$$FDP = P(R=0|D=1) = \\frac{P(D=1|R=0)P(R=0)}{P(D=1)}$$\n$$ = \\frac{P(D=1|R=0)P(R=0)}{P(D=1|R=0)P(R=0) + P(D=1|R=1)P(R=1)}$$\n$$FDP = \\frac{FPR \\cdot \\pi_0}{FPR \\cdot \\pi_0 + TPR \\cdot \\pi_1} = \\frac{1}{1+ \\frac{TPR}{FPR} \\cdot \\frac{\\pi_1}{\\pi_0}}$$\n\nThis expresses FDP, a column-wise rate, to TPR and FPR, which are both row-wise rates. Recall that $\\pi_0$ and $\\pi_1$ are the probabilities of the reality being 0 and 1, respectively.\n\nThe primary implication is that FDP approaches 0 as $\\pi_1 \u003e\u003e \\pi_0$, and approaches 1 as $\\pi_1 \u003c\u003c \\pi_0$.\n\nA secondary implication is that as TPR increases, FDP decreases (good); as FPR increases, FDP increases (bad).\n\nSummary of implications:\n - The worse the test is (large FPR), the higher the FDP.\n - The less prevalent an event is (small $\\pi_1$), the higher the FDP.\n\n\n",
    "lastmodified": "2023-01-12T00:46:01.436897741Z",
    "tags": null
  },
  "/data102/causality": {
    "title": "",
    "content": " \n ## Prediction vs Causality\n\n**Prediction:** using $X$ data, can we guess what $y$ will be?\n\n**Causation:** does X cause y to change?\n - Affects decisions\n - Typically established via randomized experiments\n\n## Case Studies in Causality\n\n### Confounding Factor\n\nA Martian comes to Earth and observes that people using umbrellas have a higher probability of getting wet than people who do not. They infer that using an umbrella causes people to get wet.\n\nThis is an example of a confounding factor (rain) impacting both the independent and dependent variables. In reality, this third factor explains both of the observed factors (umbrella usage and getting wet)\n\n\n### Time and Causality\nAnother martian observes that movies at a movie theater start after a group of people arrive and sit down. They conclude that people sitting down causes the movie to start.\n\nThis is an example of causality not always going forward in time: in this case, the movie being scheduled for a certain time actually caused the people to arrive and sit down, not the other way around.\n\n### Zero correlation\nA third martian observes an expert sailor moving the rudder a lot, as the boat continues in a straight line despite heavy winds. The martian concludes that moving the rudder has no effect on the direction of the boat.\n\nThis is an example of variables with zero correlation still having a causal relationship.\n\n\n## Structural Causal Models\nStructural Causal Models (SCMs, Graphical Models, Causal DAGs) are similar to [[04 Bayes Nets]], except that arrows show causality in addition to dependence.\n\n![[/data102/img/Pasted image 20221019224955.png]]\n\n\n\n## Quantifying Association\n\n### Pearson Correlation Coefficient\nThe Pearson Correlation Coefficient $\\rho_{Z,Y}$ between two variables $Z$ and $Y$ can be described below:\n$$\\rho_{Z,Y} = \\frac{cov(Z,Y)}{\\sqrt{var(Z)var(Y)}}$$\nwhere $cov(X,Y)$ is the [covariance](http://prob140.org/textbook/content/Chapter_13/01_Covariance.html). $\\rho$ is between -1 (perfect negative correlation) and 1 (perfect correlation).\n\n### Regression Coefficient\nSuppose we have a linear regression $Y = \\alpha + \\beta Z + \\epsilon$. \n$\\epsilon$ is the error, where $E[\\epsilon] = 0$ and $cov(Z, \\epsilon) = 0$.\n\n The regression coefficient $\\beta$ is described as follows:\n $$\\beta = \\rho_{Z,Y} \\cdot \\frac{\\sigma_Y}{\\sigma_Z} = \\frac{cov(Z,Y)}{var(Z)}$$\n\nIf we introduce another variable (i.e. $Y = \\alpha + \\beta Z + \\gamma X)$, then $\\beta$ describes the effect of $Z$ on $Y$ while adjusting for the effects of $X$.\n\n\n### Risk Differences and Risk Ratio\nIf in a binary situation (either the result $Y$ is $1$ or $0$), then we can quantify association using three methods:\n\n**Risk Difference:** $P(Y=1|Z=1) -  P(Y=1|Z=0)$\n**Risk Ratio:** $P(Y=1|Z=1)/P(Y=1|Z=0)$ \n**Odds Ratio:**\n$$\\frac{P(Y=1|Z=1)/P(Y=0|Z=1)}{P(Y=1|Z=0)/P(Y=0|Z=0)}$$\n\n\n## Paradoxes\n\n### Simpson's Paradox\nAggregated data and disaggregated data create different conclusions.\n\nFor example, suppose two restaurants were rated as follows:![[/data102/img/Pasted image 20221019230752.png|200]]\nClearly, Restaurant B is better since it received a higher ratio of positive reviews.\n\nHowever, if we break up the data by year, the following is observed:\n![[/data102/img/Pasted image 20221019230832.png|400]]\nNow, Restaurant A looks clearly better since it performed better in both 2019 and 2020.\n\nSimpson's Paradox isn't really a paradox, since it just occurs due to a confounding variable. In the example above, the confounding variable is the effect of the COVID-19 pandemic on making reviews more negative overall: ![[/data102/img/Pasted image 20221019230924.png|300]]\nIf we only look at the bottom half of this causal DAG, we can observe the results that we saw above without understanding why it occurs.\n\nIf a confounding variable is present, we should condition on it and draw conclusions based on the disaggregated results.\n\n\n### Berkson's Paradox\nBerkson's Paradox is very similar to Simpson's Paradox, but acts on a **collider** variable rather than a confounding variable. \n\nFor instance, only plotting perceived flavor with perceived appearance for bread at a bakery could seem to show no correlation:\n\n![[/data102/img/Pasted image 20221019231326.png]]\n\nHowever, if we split the bread on display with the bread in the back, the following occurs:\n![[/data102/img/Pasted image 20221019231348.png]]\n\n\nThe DAG looks like the following.\n\n![[/data102/img/Pasted image 20221019231220.png]]\n\n\n## Potential Outcomes Framework\nIn the Potential Outcomes Framework, we construct universes under the assumption that no confounding variables exist. \n\nSuppose we have two universes, 0 and 1, where one has a treatment and one has a control in completely identical conditions. The outcomes are Y(0) and Y(1) respectively. The **Individual Treatment Effect** is equal to $Y(1) - Y(0)$. \n\nThis attempts to mitigate the fundamental problem of causal inference, which is that we can never truly compute the individual treatment effect in the real world since it's impossible to fully replicate a particular situation and only change one variable.\n\nSince the ITE is impossible to compute, we'll try to find the **average treatment effect (ATE)**, $E[Y(1) - Y(0)]$, which expands to $E[Y(1) | Z=1] P(Z=1) - E[Y(0)|Z=1] P(Z=1) + E[Y(1)|Z=0] P(Z=0) - E[Y(0)|Z=0]P(Z=0)$. In most cases, this value is also impossible to compute because of the non-matching $Y$ and $Z$ terms (in the treatment case, what would have happened if they didn't actually receive the treatment). \n\nAn attempt to make this computable is the **Simple Difference in Observed Means (SDO)** which is simply $E[Y(1)|Z=1] - E[Y(0)|Z=0]$.  This would only be equal to the ATE if $Y$ and $Z$ are independent (if $A$ and $B$ are independent, then $E[A|B] = E[A]$). This is true in a randomized experiment.\n\n\nA **unit** is a single data point that we're trying to make causal inferences on. For example, the unit in a drug test could be one person.\n - Each unit has three random variables $(Z_i, Y_i(0), Y_i(1))$ where $Z$ is $1$ if the treatment was applied, $0$ otherwise.\n - **superpopulation model:** units are i.i.d. (newer framework)\n - **fixed-sample model**: $Z_i$ are i.i.d, $Y$ are fixed and unknown (traditional)\n\n**Science Table:** displays units in a table. In reality, we can't observe the $Y$ corresponding to the outcome that didn't happen; the problem we need to solve is how we can fill these values in.\n![[/data102/img/Pasted image 20221025225351.png]]\n\n\n\n**Stable Unit Treatment Value Assumption (SUTVA):** \n - The same treatment is applied to all units\n\t - Example: surgery outcomes do not follow this assumption because some surgeons could be more skiilled than others\n - Units do not affect each other\n\t - Example: social media influencers may affect the behaviors of their followers\n\n\n## Causal Inference in Observational Studies\nSince we can't truly randomize treatments in observational studies, it's often difficult to find causality. \n\nThere are two main categories of methods for establishing causal inference:\n\n**Unconfoundedness (conditional independence):** Consider all confounding variables $X$, then assume $Z$ and $Y$ are conditionally independent given $X$. \n - Matching, outcome regression, propensity weighting\n\n**Natrual experiments:** Find natural sources of randomness and use these to get around the confound\n - Instrumental variables, regression discontinuity, difference in differences\n\n\n\n### Linear Structural Model\n$$Y = \\alpha + \\beta X + \\tau Z + \\epsilon$$\n - $E[\\epsilon] = 0$, and $\\epsilon$ is independent of $Z$ and $X$. \n - $X$ is the confounder, $Y$ is the outcome, and $Z$ is the treatment.\n\t - ![[/data102/img/Pasted image 20221026123414.png|300]]\n - Assume we can't know $X$ (too many considerations).\n - The ATE is equal to $\\tau$.\n - Using ordinary least squares, $\\hat\\tau = cov(Y,Z)/var(Z) = cov(\\tau Z, Z)/var(Z) + cov(\\beta X, Z)/var(Z)$.\n   $$\\hat\\tau_{OLS} = \\tau + \\beta \\frac{cov(X,Z)}{var(Z)}$$ where the second term is the **omitted variable bias**.\n\n\n### Instrumental Variables\nIf there exists a truly random variable $W$, we may be able to take advantage of it in the model above. Certain conditions are required:\n - W is independent of $X$.\n - $W$ only affects $Y$ through $Z$.\nOne example of an instrumental variable is the Vietnam War draft lottery system, where individuals were selected for service based on their birthday. This would directly affect whether or not the individual served in the lottery independent of other confounding factors, which could then be used to establish causality between military service and another variable. \n\n**Simple ratio of regression coefficients:**\n - First, fit $Z$ from $W$ to get $\\gamma$.\n - Then, fit Y from W to get $\\tau \\times \\gamma$.\n - Divide the two values to get $\\tau$ which is equal to the ATE.\n\n**Two Stage Least Squares:** first predict $Z$ from $W$, then fit $Y$ from the predictions of $Z$ to get $\\tau$ (ATE).\n$$Y = \\alpha + \\beta X + \\tau Z + \\epsilon$$\n$$Z = \\alpha' + \\gamma W + \\eta X + \\delta$$\n\n### Conditional Independence Assumption\nIf we know the confounder, then the treatment and potentials might be independent (Z is independent of Y given X). This is also known as **unconfoundedness**.\n\nLet the **Conditional ATE** be equal to $\\tau(x) = E(Y(1) - Y(0) | X=x)$ such that $\\tau = E(\\tau(X))$ by the [tower property](https://en.wikipedia.org/wiki/Law_of_total_expectation).\n\n\n**Outcome regression:** compute $\\tau(x)$ for every $x$ and take the average. This is simple for binary variables or linear relationships (where $Y = aX + \\tau Z)$, but is difficult for nonlinear or higher dimensional relationships.\n\n**Matching:** for every treated unit where $Z_i = 1$, find an untreated unit that has the same confounder values, and subtract their $Y$ values to estimate individual effect. Repeat this for every untreated unit, and average overall units to estiamte ATE.\n\nThis only works if there happen to be exact matches; approximate matching gets messy and requires additional assumptions.\n\n\n### Inverse Propensity Score Weighting\n\nMain idea: reweight the population to approximate the true potential outcome averages E(Y(0)) and E(Y(1)).\n\n\n![[/data102/img/Pasted image 20221028161315.png]] \nIPW formula: 4 possibilities for values of $y_i$ and $z_i$. Sum up number of times each possibility occurs and divide them by how likely they are to be treated ($e(x)$).\n - The propensity score $e(X) = P(Z=1|X=x)$\n - Strategy:\n\t - make a table of all possible values of X and Z\n\t - divide each one by how likely it is to occur, and sum them all together\n\t - divide the whole result by $n$",
    "lastmodified": "2023-01-12T00:43:14.698626192Z",
    "tags": null
  },
  "/data102/concentration-inequalities": {
    "title": "",
    "content": "\nThe goal of concentration inequalities is to provide bounds on the probability of a random variable taking values in its tail (regions farthest away from the mean).\n\nThis is especially useful when we don't know the distribution of a random variable, or we have a combination of other random variables (sample mean, quicksort, multi-arm bandit...).\n\n## Markov's Inequality\nIf $X$ is a non-negative random variable with expectation $\\mu$, then\n$$P(X \\ge t) \\le \\frac{\\mu}{t}$$\n\n## Chebyshev's Inequality\nIf we know the mean $\\mu$ and the variance $\\sigma^2$ of a random variable $X$, then the probability of a result being $t$ standard deviations away from the mean can be expressed as\n$$P(|X - \\mu| \\ge t \\sigma) \\le \\frac{1}{t^2}$$\nAlternatively,\n$$P(|X - \\mu| \\ge c) \\le \\frac{\\sigma^2}{c^2}$$\n\n\n## Chernoff Bound\n\n\n$$P(X \\ge t) = P(e^{\\lambda X} \\ge e^{\\lambda t}) \\le \\frac{E[e^{\\lambda x}]}{e^{\\lambda t}}$$\nOptimized form:\n$$P(X \\ge c) \\le min_{t \u003e 0} M_X(t) e^{-tc}$$\n\nwhere $M_X(t) = E(e^{tX})$ (moment generating function)\n\n\n## Hoeffding's Inequality\nHoeffding's inquality is a special case of the Chernoff bound where the bounds of a random variable are known.\n\n**Hoeffding's Lemma:** if $X$ is a bounded random variable between $a$ and $b$ with mean $\\mu$, then \n$$M_X(t) \\le \\exp(\\frac{(b-a)^2}{8} \\lambda^2 + \\mu \\lambda)$$\n\n**Hoeffding's Inequality:** If we have $n$ independent (may not be identically distributed) bounded random variables between $a$ and $b$, \n$$P(\\frac{1}{n} \\sum_{i=1}^n (X_i - E(X_i)) \\ge t) \\le \\exp(-\\frac{2nt^2}{(a-b)^2})$$\n\n### Proof\nLet $Y$ be $\\frac{1}{n} \\sum_{i=1}^n (X_i - E(X_i))$. Then, the MGF $E[e^{\\lambda Y}]$ = $E[\\exp(\\lambda/n \\sum_{i=1}^n X_i)]$.\n\nUsing the properties of exponentials (exponential of sum is product of exponentials),\n$E[e^{\\lambda Y}] = E[\\prod^n_{i=1} exp(\\lambda/n X_i)]$.\n\nUsing independence rules, $E[\\prod^n_{i=1} exp(\\lambda/n X_i)] = \\prod_{i=1}^n E[exp(\\frac{\\lambda}{n} X_i)]$\n\nUsing Hoefding's Lemma, the MGF must then be bounded by $\\prod_{i=1}^n\\exp(\\frac{(b-a)^2}{8} \\lambda^2 + \\mu \\lambda)$.\n\n\n\n",
    "lastmodified": "2023-01-12T00:34:49.86784219Z",
    "tags": null
  },
  "/data102/decision-theory": {
    "title": "",
    "content": "\nSo far, in [[binary decision making]] and [[hypothesis testing]], we've explored how to make as few mistakes as possible when making binary predictions.\n\n## Intro to Decision Theory\nWe can generalize a decision problem to the following:\n - Suppose there is some unknown quantity of interest $\\theta$.\n\t - $\\theta$ is random under a Bayesian approach, and fixed if frequentist.\n - We collect/observe some data $X$.\n - There is some true distribution that the data is drawn from, $p(X | \\theta)$.\n - We are tasked to create a good **estimator** $\\delta(x)$ (also known as $\\hat\\theta$, which makes decisions based on the data.\n - In order to quantify how good/bad our estimator is, we can use a loss function $l(\\delta(x), \\theta)$, where higher loss values are worse.\n\n\n## Loss Functions\n### 0/1 Loss\nIn the case of binary decisions:\n - $\\theta$ is either $0$ or $1$ and represents our reality.\n - $\\sigma(x)$ is also either $0$ or $1$ and represents our decision.\n - A very simple loss function is to return $0$ if the decision matches reality, $1$ otherwise. This is known as **0/1 Loss**.\n\n### L2 Loss\nIf our data is continuous, then 0/1 loss cannot be used.\nInstead, we can define the loss as follows:\n$$ l(\\sigma(x), \\theta) = (\\sigma(x) - \\theta)^2$$\nThis is known as $L_2$ loss.\n\n\n## Applying Loss Functions\n\n### Frequentist Risk\nUnder frequentist assumptions, the risk of choosing $\\theta$ is equivalent to the expectation of the loss function:\n$$R(\\theta) = E_{x|\\theta}[l(\\sigma(x), \\theta)] = \\int l(\\sigma(x), \\theta) p(x|\\theta) dx$$\nIn other words, take the average loss for every possible value, and weight it by how likely it is to get that value.\n\n\n### Bayesian Posterior Risk\nSyntactically, Bayesian risk looks very similar to frequentist risk:\n$$\\rho(\\theta) = E_{\\theta|x}[l(\\sigma(x), \\theta)] = \\int l(\\sigma(x), \\theta) p(\\theta|x) d\\theta$$\nThe main difference is that rather than iterating over every possible value of data weighted by its probability, we iterate over every possible distribution weighted by how likely it is to get our data from it.\n\n### Bayes Risk\n$$E_{\\theta, x}[l(\\sigma(x), \\theta)] = E_\\theta[E_{x|\\theta}[l(\\sigma(x), \\theta)]] = E_x[E_{\\theta|x}[l(\\sigma(x), \\theta)]]$$\nBayes risk is the joint expectation of the loss function over all possible data and distributions. It can be represented using either the Frequentist risk or the Bayesian posterior risk.\n\n\n\n\n### Bias-Variance Decomposition\n\nBelow is the calculation for the frequentist risk of the L2 loss function:\n$$\n\\begin{align}\nR(\\theta) \n\u0026= E_{x|\\theta}\\Big[\\big(\n    \\delta(x) - E_{x|\\theta}[\\delta(x)] + E_{x|\\theta}[\\delta(x)] - \\theta\n\\big)^2\\Big] \\\\\n\u0026= E_{x|\\theta}\\Big[\\big(\n    \\delta - \\bar{\\delta} + \\bar{\\delta} - \\theta\n\\big)^2\\Big] \\\\\n\u0026= E_{x|\\theta}\\Big[\n    \\big(\\delta - \\bar{\\delta}\\big)^2 +\n    \\underbrace{2\\big(\\delta - \\bar{\\delta}\\big)\\big(\\bar{\\delta} - \\theta\\big)}_{=0} + \n    \\big(\\bar{\\delta} - \\theta\\big)^2\n\\Big] \\\\\n\u0026= E_{x|\\theta}\\Big[\\big(\\delta - \\bar{\\delta}\\big)^2\\Big] + \n     E_{x|\\theta}\\Big[\\big(\\bar{\\delta} - \\theta\\big)^2\\Big] \\\\\n\u0026= \\underbrace{E_{x|\\theta}\\Big[\\big(\\delta - \\bar{\\delta}\\big)^2\\Big]}_{\\text{variance of }\\delta(x)} + \n     \\big(\\underbrace{\\bar{\\delta} - \\theta}_{\\text{bias of }\\delta(x))}\\big)^2 \\\\\n\\end{align}\n$$\nThe **variance** of the estimator is a measurement for how spread out the data is when compared ot the average. Larger variance means that the model is more sensitive to randomness in the data.\n\nThe **bias** of the estimator is a measurement for how far the average of the estimator is from the true value of $\\theta$. In other words, if we average out all of the randomness in the data, how close is our model to reality?\n\n\nIf the estimator were perfect, then the expectation of $\\delta - \\theta$ should be $0$, which would make the bias $0$.\n\n",
    "lastmodified": "2023-01-12T00:33:34.36461879Z",
    "tags": null
  },
  "/data102/hypothesis-testing": {
    "title": "",
    "content": "\n## Hypothesis Testing\nHypothesis testing is a form of [[binary decision making]] (do we accept or reject the null hypothesis?).\n\n1. Formulate null hypothesis, alternate hypothesis, and test statistic\n2. Compute value of test statistic based on data\n3. Simulate test statistic under null hypothesis many times\n4. Compare results to determine likelihood of result\n\nAs an example of how this relates to binary decision making:\n - Null hypothesis true: reality = 0\n - Alternative hypothesis true: reality = 1\n - Fail to reject null: decision = 0\n - Reject null: decision = 1\nSo if the null hypothesis is actually true but we end up rejecting it, then a false positive result has occurred.\n\n### P Value\nThe P-value is the chance if the null hypothesis is true, that the test statistic is equal to or more extreme than the value observed in the data.\n\nIf the null hypothesis is actually true, then the probability of obtaining any particular p-value follows a uniform distribution.\n\n\n## Making decision from P-values\n\n### Null Hypothesis Testing\n**Null hypothesis statistical testing (NHST)**: choose a p-value threshold, and see whether p-value is above or below it.\n - If above: fail to reject; if below: reject null hypothesis\n - Issue: if we choose $p = 0.05$, we should expect that 1 in 20 tests will have a false positive result (https://xkcd.com/882/).\n - This is linked to the replication crisis (scientists pick and choose one test out of many, which increases the likelihood that it is a false positive).\n - Choosing the threshold = balancing false positives and false negatives. This tradeoff is context dependent. \n\t - Larger threshold = fewer false negatives, more false positives (we don't actually know in most cases though) ![[/data102/img/Pasted image 20220902134338.png|400]]\n\n### Multiple Hypothesis Testing\nWhen conducting multiple NHST's, we need a way to measure an error rate that's related to *all* of the tests (since we're likely to see false positives).\n\nThere are two rates that we can use:\n - **Family Wise Error Rate (FWER)** : the probability that there is at least one FP over all tests\n\t - Factors in randomness from dataset selection over entire population\n - **False Discovery Rate (FDR)** : the expectation of the FDP\n\n**So what do FWER and FDR actually mean? How are they different?**\nIntuitively, FWER is a lot more conservative than FDR, because it encodes the probability that even a single test out of potentially millions creates a false positive. As a result, if we want a small FWER threshold, we'd probably have to make a lot of false negatives.\n\nFWER is good for use cases where making a false positive error is really bad (e.g. missile detection, where FP = launch missile by accident, start nuclear war). \n\nOn the other hand, FDR describes the expected proportion of discoveries that are wrong. FDR is good for use cases where the act of discovering something is more impactful than any false positives or negatives that come out of false discoveries. As an example, UX testing would use FDR since we'd rather detect all possible changes that could improve a user's experience, even if some don't actually do anything.\n\n### Bonferroni Correction\nBonferroni correction is a way to control the FWER.\nThe main principle is that we use a fixed $p$ value, and set a threshold $\\alpha$. We'd like FWER $\\le \\alpha$.\n\nDefine an indicator variable $E_i$, which is $1$ if test $i$ is a false positive, 0 otherwise.\nThen, FWER = $P(\\bigcup_{i=1}^m E_i)$ (probability that $E_1 = 1$ or $E_2 = 1$ ... or $E_m = 1$ )\n\nWe can use Boole's inequality to say that $P(\\bigcup_{i=1}^m E_i) \\le \\sum_{i=1}^m P(E_i)$ (i.e. union is at most the sum of individual probabilities, if every event is independent).\n\nIf the $p$-value threshold is $a$, then $P(E_i) = a$, and the sum of $m$ tests is therefore $ma$.\nSo, $\\alpha = ma$ which suggests that if we want FWER $\\le \\alpha$, then we can choose the p-value threshold $\\frac{\\alpha}{m}$.\n\n### Benjamini-Hochberg Formula\nB-H is used to control the False Discovery Rate. (recall that FDR is the expected value of the proportion of incorrect decisions out of those the algorithm detected to be true.)\n\nGeneral steps:\n1. Sort p-values indexed by k\n\t1. Smallest p-value has $k=1$ and largest has $k=m$ \n2. Draw the line $y = k \\cdot \\alpha/m$\n3. Find the largest p-value under the line and use this as the threshold\n\nIn the below example, we would set the B-H threshold to around .008, since that's where the biggest p-value exists still under the line.\n![[/data102/img/Pasted image 20220902140526.png]]\n\n**Proof of Benjamini-Hochberg**: why does B-H control FDR?\n\nRecall that $FDR = E[FDP] = E[P(R=0|D=1)$.\nUsing Bayes' rule we can expand $P(R=0|D=1) = \\frac{P(D=1|R=0)P(R=0)}{P(D=1)}$.\n\nDefine the following quantities:\n - $m$ = number of tests\n - $m_0$ = number of true nulls\n - $k^*$ = index of last p-value below the line\n - $\\alpha^*$ = value of line (not p-value) at $k^*$\n\nWe want to show that $FDR \\le \\alpha$.\n\nLet's start by making some substitutions:\n - $P(R=0) = \\frac{m_0}{m}$ (probability that reality is null)\n - $P(D=1) = \\frac{k^*}{m}$ (all tests greater than p-value threshold are classified as 1)\n - $P(D=1|R=0)$ = p-value $\\le \\alpha^*$ by B-H\n\nPutting this all together, we get this:\n$$FDP \\le \\frac{\\alpha^* \\cdot \\frac{m_0}{m}}{\\frac{k^*}{m}}$$\nwhich simplifies to\n$$FDP \\le \\frac{\\alpha^*}{k^*} \\cdot m_0$$\nwhere $\\frac{\\alpha^*}{k^*}$ is the slope of the line. Since $k^*$ is an index and is thus always at most the last test index $m$, $FDP \\le \\frac{\\alpha}{m} \\cdot m_0$.\nIn turn, we know that $m_0 \\le m$ so $FDP \\le \\alpha$, which demonstrates a relationship between FDP and the $\\alpha$ treshold determined using B-H.\n\n\n## Online Decision-Making\nSometimes, we must make decisions as the data comes in. We don't see all the data upfront, and current decisions may influence future ones.\n\nIntuitively, if we see a lot of small p-values and then an ambigous p-value, we should be more likely to make a D=1 decision. On the other hand, if we see a lot of large p-values and then the same p-value, we should make a D=0 decision instead.\n\nOne example of online decision making is A/B tests, where we might want to change the website after 100 users view it, rather than waiting for all 1000 for the test to complete.\n\nIf we know the total number of tests, Bonferroni correction can be used to get FWER.\nHowever, we can't use B-H because we need to sort all of the tests' p-values before making a decision about the threshold.\n\n\n### LORD Procedure\n![[/data102/img/Pasted image 20220906144024.png]]\n\nBreaking down this algorithm:\n- $\\gamma_t$ gets smaller (decays) over time.\n- $\\alpha$ is some FDR value we'd like this decision-making process to achieve. At each timestep, we'll adjust $\\alpha$ based on the new values.\n- At each iteration, we'll sum over all rejections so far and weight this value by both $\\alpha$ and $\\gamma_t$. The further away a discovery is from the current time, the more decayed its value is (so it's worth less in the calculation). \n- As more discoveries are made, the threshold $\\alpha_t$ should increase.\n- The p-value threshold is known as the \"wealth\", and encodes how optimistic we are. The higher the wealth, the easier it is to make a discovery.\n\nBasic summary of LORD: at each timestep, update $\\alpha$ by multiplying the decay function with the original weight, and adding this to $\\alpha$ multiplied by all timesteps with a rejection, weighted by the difference between the current timestep and the time of rejection.\nThen, compare the current $\\alpha$ value to the p-value obtained to make a decision about whether or not to reject.\n\n\n## Neyman-Pearson Framework\n - If we have a defined distribution for both the null and alternative hypotheses, we can define the **likelihood ratio** to be the probability of getting the test statistic given that the alternative is true, divided by the probability of getting the test statistic given that the null is true.\n\n\n## Hypothesis Testing vs Binary Classification\nHypothesis testing is a type of binary decision making because there's only two classes: either we reject the null, or we don't.\n\nIn hypothesis testing, we usually work with p-values (p = P(data | R=0)). \nOn the other hand, in binary classification, we work with arbitrary numbers and a threshold picked from some curve.",
    "lastmodified": "2023-01-12T00:33:25.90070576Z",
    "tags": null
  },
  "/data102/interpretability": {
    "title": "",
    "content": "## What do we look for in predictions?\n**Accuracy:** We want predictions to be close to the true values.\n**Simplicity:** We want the model to be easy to understand and trust.\n**Interpretability:** We want to be able to explain why the model behaved the way it did.\n\n\n## Components of interpretability\n\n**What is it?**\n - transparency: understanding the model\n - explanations: understanding the predictions\n\n**When and why do we care?**  \n - high stakes decisions have major impacts, and need to be understood\n - regulations such as GDPR requires explanations for algorithms\n\n**What do we get from interpretability?**\n - Trust that the models will make accurate predictions\n - Causality: whether x actually causes y\n - Transferability: whether the model will do well in the real world\n - Informativeness: whether predictions can be used for decision making\n - Ethics: whether the model is fair from a human perspective\n\n## Explanability\nFor black-box models such as deep decision trees and random forests, thousands of parameters can be involved, and it is difficult or impossible to explain how all of them relate to one another.\n\nInstead of interpretability, we can go for explainability instead:\n - Surrogate models: approximate the model with a simpler model, and interpret that simpler model\n - Permutation-based approach: measure importance of a feature by modelling without that feature and interpreting the difference",
    "lastmodified": "2023-01-12T00:34:28.928057697Z",
    "tags": null
  },
  "/data102/nonparametric-methods": {
    "title": "",
    "content": "## What does nonparametric mean?\n\nNonparametric methods make no assumptions about the distribution of the data or parameters; the null hypothesis is solely generated based on the data.\n\nIn some other contexts, the number of parameters in a nonparametric method is either infinite or grows with the number of data points. \n\nSupposing the true state of the world is $\\theta$ and our data is $x$, parametric/forward models attempt to make some assumptions about $\\theta$ that make us most likely to see the data $x$. Nonparametric models go the other direction, allowing us to directly infer $\\theta$ based on the observed data.\n\n\n\n## Logistic Regression vs K-Nearest Neighbors\n\nLogistic regression is the example of a parametric model, where we try to categorize inputs into either 0 or 1:\n\n$$y = \\sigma(\\beta_1 x_1 + \\beta_2 x_2 + \\cdots + \\beta_k x_k)$$\nIn this case, we must assume several things, such as linearity of data and the fact that the distribution can be roughly modelled using a sigmoid function. \n\n**Pros:**\n - Simple (only $k$ parameters needed)\n - Interpretable (gives either 0 or 1 as output)\n - Convex loss function (guarantees an answer)\n - Easy to solve\n\n**Cons:**\n - Makes assumption of linear data\n - Requires feature engineering to model complex/nonlinear data\n - Too simple for some data sets\n\n---\nOn the other hand, K-nearest neighbors finds the $k$ points in the training set closest to a particular value, and uses majority vote at their $y$ values. KNN makes no assumptions about the underlying distribution other than that the training data is representative of the population/test data.\n\nHere's an example of some data that's not linearly separable in which logistic regression fails, but KNN is effective:\n![[/data102/img/Pasted image 20221017132113.png]]\n\n\n**Pros:**\n - No assumptions made about the data/world\n - Simple algorithm\n\n**Cons:**\n - Must save all training points\n - More difficult to interpret results (less compelling explanation)\n\n\n## Decision Trees\n\nStart at some value $(x_1, x_2, \\cdots, x_n)$.\nDecide which feature $i$ to split on, and create two paths, for $x_i \u003c z$ and $x_i \u003e z$ where $z$ is some meaningful boundary.\nRepeat the previous step, making a binary decision once for each feature.\n\n\nDecision trees are very effective if clear boundaries exist in between data of different categories, but they are sensitive to variability in the data set. To mitigate this issue, we can take multiple decision trees, and average all of their results. \n\n### Random Forests\nUsing bootstrap aggregation (bagging), do the following:\n - independently train a large number of trees on a bootstrap sample of the data using a subset of the features.\n - Specifically, if there are $K$ features, each tree gets $K/3$ features if performing regression and $\\sqrt K$ features for classification.\n\nRandom forests also have the benefit of controlling the depth of trees: when there are thousands of features, using a single decision tree would have an incredibly large number of decisions to make.\n\n\n## Neural Networks\n\n**General idea:** Combine multiple simple regression models together to increase complexity of the overall model.\n\n### Gradient Ascent and Descent\n\n**The difference:** gradient ascent maximizes a log-likelihood function; gradient descent minimizes a loss function.\n\nGradient Ascent algorithm:\n\n```python\nrandomly init w\nwhile w not converged:\n\tfor weight in w:\n\t\tweight = weight + learning_rate * gradient(log_likelihood(w), weight)\n```\n\n- convergence is when gradient = 0, or no change occurs between two runs\n- $w$ is a vector of $N$ weights\n- `gradient(log_liklihood(w), weight)` represents the operation $\\nabla_{weight} \\log l(\\bold{w})$, which returns a vector of $N$ partial derivatives $\\partial_{weight} \\log l(w_i)$ for every weight $w_i$.\n\nGradient Descent algorithm:\n\n```python\nrandomly init w\nwhile w not converged:\n\tfor weight in w:\n\t\tweight = weight - learning_rate * gradient(loss(y, x, w), weight)\n```\n\n- Basically the same as gradient ascent, except subtract the gradient of loss instead of adding the gradient of log likelihood.\n\n**Stochastic gradient ascent/descent:** only take one data point at a time to calculate the gradient. May cause inaccurate results.\n\n**Batch gradient ascent/descent:** Randomly takes a batch size of $m$ data points each time to compute the gradients. Good compromise in terms of performance and accuracy.\n\n### Multilayer Perceptron\n\n**Main idea:** make perceptrons take outputs from other perceptrons as their input.\n\n![Untitled](img/Untitled.png)\n\n**Universal functional approximator theorem:** a two-layer neural network with enough neurons can approximate any continuous function to any desired accuracy.\n\nIn order to approximate nonlinear functions, each layer is separated by a nonlinear operator. Traditional neural nets have used the sigmoid function $\\sigma(x) = \\frac{1}{1 + e^{-w^Tx}}$, but due to faster computation the ReLU (rectified linear unit) function is often used instead. The graphs of these two functions are as follows:\n\nFor every layer, we wrap the parameters around a function call. For example, here is a 2-layer network:\n\n$$\nf(x) = relu(x \\cdot W_1 + b_1) \\cdot W_2 + b_2\n$$\n\n- $x$ is an $1 \\times i$ input vector\n- $W_1$ and $W_2$ are $i \\times h$ weight parameter matrices, where $h$ is the hidden layer size parameter\n- $b_1$ and $b_2$ are $1 \\times h$ bias parameter vectors",
    "lastmodified": "2023-01-12T00:41:53.079471509Z",
    "tags": null
  },
  "/data102/parameter-estimation": {
    "title": "",
    "content": "\n\nSuppose we observe $n$ data points ($x_1$ to $x_n$).\nLet $\\theta$ be some unknown parameter that describes the distribution the data points were sampled from.\n\nAs an example, let's say we are trying to quantify how good a product is based on how many positive and negative reviews it has.\n - This means that data $x_i$ is either $0$ (bad review) or $1$ (good review)\n - Let $p(x_i | \\theta) = \\theta^{x_i} (1-\\theta)^{1-x_i}$. This means that reviews are positive with probability $\\theta$, and negative with probability $1-\\theta$.\n\n\n## Maximum Likelihood Estimation (MLE)\n[http://prob140.org/textbook/content/Chapter_20/01_Maximum_Likelihood.html](http://prob140.org/textbook/content/Chapter_20/01_Maximum_Likelihood.html)\n\n\nIn a Frequentist approach, $\\theta$ is fixed, so our goal is to find the best estimate for $\\theta$ using the data given.\n\nRecall that **likelihood** is the probability of the data given the parameter, $$p(x_i | \\theta)$$\n\n\n**Goal:** Given an iid sample of $N$ points $x_1, \\cdots, x_N$, and a distribution described by a parameter $\\theta$, what’s the value of $\\theta$ that gives the highest probability of this set of points occurring in the probability distribution? (i.e. we want to maximize likelihood value)\n\n- Formal definition: find $\\theta$ that maximizes $L(\\theta) = \\prod_{i=1}^N P_\\theta(x_i)$, where $P_\\theta$ is the probability of one data point $x_i$ occurring given a value of $\\theta$.\n- $MLE(\\theta | X=x) = argmax_\\theta P(X=x|\\theta) = argmax_\\theta \\ln P(X=x | \\theta)$\n- Occurs when $\\frac{\\partial}{\\partial \\theta} L(\\theta) = 0$\n- Calculating derivatives of products is pain, so we can monotonically transform the likelihood function using $\\log$. Since $\\max(f(x)) = \\max(\\log(f(x))$ we can find the maximum of the **log likelihood function:** $\\log L(\\theta)$\n\nUsing MLE to predict CPT values given data points:\n\n- $P(Y=y) = MLE(\\theta | (X,Y))$ = (# data points with $X=x$) / (# data points total)\n- $P(X=x|Y=y) = MLE(\\theta | (X,Y))$ = (# data pooints where ($X=x, Y=y$) ) / (# data points where $Y=y$)\n\n## Bayesian Parameter Estimation\nNow, $\\theta$ is random. We then need to specify a **prior** $p(\\theta)$ that represents what we believe the distribution for $\\theta$ might look like.\n\nIn a Bayesian approach, we calculate the **posterior** distribution $p(\\theta|x)$, which is an update to the prior now that we have observed some data.\n\nThrough Bayes' Rule, $p(\\theta|x) = \\frac{p(x|\\theta)p(\\theta)}{p(x)}$.\n - $p(x|\\theta)$ is the likelihood.\n - $p(\\theta)$ is the prior.\n - $p(x) = \\int p(x|\\theta)p(\\theta)d\\theta$. This integral is often impossible to compute, especially for high-dimensional data. \n\nRather than needing to compute $p(x)$, we can simply state that $p(\\theta|x)$ is proportional to the likelihood times the prior, $p(x|\\theta)p(\\theta)$.\n\n\nA convenient choice for the prior is the Beta distribution.\n\n$$p(\\theta) \\propto \\theta^{\\alpha - 1}(1-\\theta)^{\\beta - 1} = Beta(\\alpha,\\beta)$$\nThe Beta(1,1) distribution is equivalent to the Uniform distribution.\n\n\nGiven that the data $x_i$ are sampled from a Bernoulli($\\theta$) distribution, which has a likelihood function $p(x|\\theta) = \\theta^{k} (1-\\theta)^{n - k}$ (where $k$ is the number of positive values out of $n$ total values), and a prior of Beta($\\alpha, \\beta)$, we can compute the posterior as such:\n$$p(\\theta|x) \\propto p(x|\\theta)p(\\theta) \\propto (\\theta^{k} (1-\\theta)^{n - k}) \\cdot (\\theta^{\\alpha - 1}(1 - \\theta)^{\\beta - 1})$$\n$$\\propto \\theta^{k+\\alpha-1} (1-\\theta)^{n-k+\\beta - 1}$$\nwhich is a $Beta(k + \\alpha, n-k+\\beta)$ distribution.\n\n\n\n## Maximum A Posteriori (MAP)\nPoint estimators, one of which is the MAP method, reduce a posterior distribution into a single number.\n\nWe can calculate it as the argmax of the posterior with respect to $\\theta$, i.e. the value of $\\theta$ that gives us the largest value for the posterior.\n\nMAP is analogous to the mode of the distribution.\n\n\n## Minimum Mean-Squared Error (MMSE)\nMMSE is another point estimator that finds the value of $\\theta$ that gives the smallest mean squared error:\n\n$$\\hat\\theta = argmax_{\\hat\\theta} E_{\\theta|x} (\\hat\\theta - \\theta)^2$$\nMMSE is analogous to the mean of the distribution.\n\n\n## Example: Estimating the Mean with Gaussian (Normal) Likelihood\nSuppose we're given that $n$ people have heights $x_1, \\cdots, x_n$ distributed normally.\nWe're trying to find $\\mu$, which is the population mean.\n\nThen, the likelihood $p(x_i | \\mu) = N(x_i; \\mu, \\sigma)$ describes the probability of getting any one height given the mean.\n\nUnder a frequentist approach, we can calculate the MLE to be $\\hat\\mu_{MLE} = \\frac{1}{n} \\sum_{i=1}^n x_i$.\n\nUnder a Bayesian approach, we're trying to find the posterior $p(\\mu | x) \\propto p(x | \\mu) p(\\mu)$.\n\nIf the likelhiood and prior ar both normal, then the posterior is also normal. This (along with the beta example with Bernoulli distributions) is an example of a **conjugate prior**: in general, conuugate priors have the same family as the posterior.\n\n",
    "lastmodified": "2023-01-12T00:39:18.869066918Z",
    "tags": null
  },
  "/data102/regression-and-glms": {
    "title": "Regression and GLMs",
    "content": "\n## Posterior Predictive Distribution\n\n**Posterior Predictive Distribution:** \"if we saw some data, what future data might we expect?\"\n - $P(x_{n+1}|x_1,\\cdots,x_n)$ = $\\int P(x_{n+1}|\\theta)P(\\theta|x_1,\\cdots,x_n)d\\theta$\n - $= E_{\\theta|X}(P(x_{n+1}|\\theta))$, which is an average with respect to the posterior.\n\nIn practice, the posterior component is estimated.\n\n\n\n## Linear Regression\n\n$$Y = X\\beta + \\epsilon$$\nwhere $Y$ is a $n \\times 1$ vector, $X$ is a $n \\times d$ matrix,\n* $Y$ is unknown and fixed,\n* $X$ is known and fixed,\n* $\\epsilon$ is unknown and random (sampled from i.i.d Normal distributions).\n\n\nWe can calculate the squared ($L_2$) loss by using $L = \\frac{1}{n}||Y-X\\beta||^2$ to find that $\\hat\\beta = (X^TX)^{-1}X^TY$.\n\nThe distribution of Y is Normal, centered around $X\\beta$ with the same variance as $\\epsilon$ which is a Normal($0, \\sigma^2 I_N$) distribution:\n$$Y \\sim N(X\\beta, \\sigma^2I_N)$$\n\n## Nonlinear Regression\nIn linear regression, we assume that the error is normally distributed. However, when the model is not linear, the error may not be normal.\n\nBayesian regression creates models whose parameters are described by distributions rather than exact values.\n\nNormal distribution is more sensitive to outliers, which can increase the spread\n\nPoisson distribution assumes that the mean and variance of the distribution are roughly the same. If the variance is actually much greater than the mean, overdispersion can occur.\n\n\n\n## Generalized Linear Models (GLMs)\nSome things that many common regression models (linear, logistic, etc) have in common:\n - The data $X$ is linearly transformed by $\\beta$.\n - The value $X^T\\beta$ is transformed using some function. (The inverse of this function is known as the **link function**.)\n - $f(X^T\\beta)$ is a parameter to some probability model.\n\n### GLMs Step by Step\n1. Formulate prediction problem: define $X$ and $Y$ \n2. Gather training data in (x, y) pairs\n3. Choose an inverse link function and likelihood that makes sense\n4. Fit model using training data (using pymc3)\n5. Verify that the model is a good fit for the data (use [[#Model Checking]])\n6. Generate predictions when y is unknown\n7. Report uncertainty for new predictions (use [[#Credible Intervals]])\n\n\n## Credible Intervals\nCredible intervals are a way to quantify our uncertainty after applying a posterior distribution to test data. They are the Bayesian equivalent of confidence intervals.\n\nA $X$% credible interval is any $X$% mass density under the posterior distribution for a parameter. It can be interpreted as \"according to the posterior distribution, there is an $X$% chance that the parameter lies within this interval\".\n\nCredible intervals are not unique, since we can choose any value to be the lower bound. However, we are primarily interested in the narrowest credible interval (since this would have the most certainty). The narrowest credible interval is known as the **highest posteior density (HPD) interval**, or sometimes the Highest density interval (HDI).\n\nIdeally, we want credible intervals to be just wide enough to capture the total range of known data, while having a relatively small uncertainty. In the example below, Poisson is too narrow and Gaussian is too wide; negative binomial fits the data well.\n![[/data102/img/Pasted image 20221004131313.png]]\n\n## Model Checking\nIn order to determine if a model is a good fit for our data, we need to 1) make sure it fits the training data, and 2) evaluate it on new data.\n\n\nPosterior Predictive Check:\n1. sample from posterior\n2. sample $Y'|X$ (posterior predictive distribution)\n3. Check if $Y'$ looks like $Y$ \n\n### Goodness of Fit for Frequentist Models\n1. Look at log-likelihood of the data\n   * Problem: very hard to compare between log-likelihoods of different function classes\n2. Chi-Squared Statistic: quantifies two layers of uncertainty in both the inverse link function and the likelihood model\n   - In frequentist models, the parameter $\\beta$ is fixed and unknown. We can estimate it using MLE: $$\\hat\\beta_{MLE} = argmax_\\beta \\ Likelihood(y|x,\\beta)$$\n   - The **chi-squared statistic** can be calculated as such: $$\\sum_i\\frac{(y_i - InvLink(x_i^T\\hat\\beta))^2}{var(y|x_i, \\beta)}$$ where the $InvLink \\cdots$ term is equivalent to $E[y|x_i, \\hat\\beta]$. \n - An ideal chi-squared value should be equal to $n$ (the number of observations made) minus the number of parameters in $\\beta$. If the chi-squared is much higher than this, then the model is a poor fit for the data.\n\n\n### Quantifying Uncertainty in Frequentist Models\n**Main idea:** even though the parameter we're estimating is fixed in frequentist settings, the estimate is random (due to it depending on the data). Therefore, we can quantify uncertainty using the distribution of the random estimate.\n\n**Central Limit Theorem:**\nhttp://prob140.org/textbook/content/Chapter_14/03_Central_Limit_Theorem.html\nIf we have $n$ i.i.d. distributions with mean $\\mu$ and standard deviation $\\sigma$, as $n$ becomes large the distribution of the sum approaches a normal distribution with mean $n \\mu$ and SD $\\sqrt n \\sigma$, regardless of what the original distribution was.\n\n**Putting it together:**\nIf we get a large number of estimates for $\\theta$ using MLE, we can quantify the uncertainty of $\\theta$ using a confidence interval over the normally distributed $\\hat\\theta$ values.\n(a confidence interval is where the data has a t% probability of generating an interval that contains the true parameter.)\n\n\n\n\n",
    "lastmodified": "2023-01-12T00:34:13.648214897Z",
    "tags": null
  },
  "/data102/sampling": {
    "title": "",
    "content": "\n## Intro\nIn practice, getting the exact probability of an inference is not required as long as we get a rough estimate (80% chance is basically the same as 80.15%, etc.). \n\nIn order to cut down on the resources required to make inferences from a Bayes Net, we can use sampling techniques to approximate the true probability of a query.\n\n### Prior Sampling\n\nFor all $i$ in topological order , sample $X_i$ from the CPT of $P(X_i | parents(X_i))$. \n\nThen, return the tuple of all $x_i$ sampled.\n\nThe probability of getting an exact tuple $(S(x_1, \\cdots, x_n)$ is equal to $P(x_1, \\cdots, x_n)$ from the original Bayes Net.\n\nAs the number of samples taken gets larger, the number of samples that equal a particular tuple divided by the total number of samples approaches the true probability. This means that prior sampling is **consistent.**\n\n### Rejection Sampling\n\nIf we’re trying to evaluate a particular query $P(Q | e)$ using prior sampling, it’s possible that the vast majority of samples taken don’t actually reflect the conditional we want (i.e. $e$ is a different value from desired).\n\nWe can save on computation by immediately rejecting all samples that don’t match the query, and not fully calculating their probabilities.\n\n### Likelihood Weighting\n\nNow, one issue that arises from rejection sampling is that if the evidence is unlikely, then we will have to reject lots of samples and the total number of relevant samples will be very low. This is common in real-world problems where variable domain sizes can be massive (millions or billions of possible value).\n\n**Main idea:** assign weights to each sample corresponding to their likelihood of matching the query. When adding up samples, multiply them by their weight.\n\nMathematical representation:\n\n$S(z,e) \\cdot w(z,e) = \\prod_j P(z_j | parents(Z_j)) \\prod_k P(e_k | parents(E_k)) = P(z, e)$\n\n- For example, if estimating $P(-a | +b, -d)$, then  the sample `-a +b +c -d` would have a weight equal to $P(+b|-a)P(-d|+c)$.\n- Pseudocode:\n\n```python\nweight = 1.0\nsample = []\nfor every variable X:\n\tif X is an evidence variable:\n\t\tadd X to sample\n\t\tweight *= P(X | parents)\n\telse:\n\t\tsample X from P(X | parents) using random number generator\n\t\tadd X to sample\n```\n\n- To estimate the probability using likelihood sampling:\n$P(q | E)$ = sum of weights of samples that match query+evidence divided by sum of weights of all samples that match evidence\n\n### Gibbs Sampling\n\n A particular kind of Markov Chain Monte Carlo:\n\n- A state is a complete assignment to all variables.\n- To generate the next state, pick a variable and sample a value for it conditioned on the other variables.\n- $P(X_i | x_1, \\cdots, x_{i-1}, x_{i+1}, \\cdots)= P(X_i | markov\\_blanket(X_i))$\n\n## Markov Chains\nhttp://prob140.org/textbook/content/Chapter_10/01_Transitions.html\n\nMarkov chains are sequences of random variables, typically indexed by time. Each possible value is a state.\n\nMarkov chains follow the **Markov property:** each random variable only depends on the previous one.\n\nAnother property of Markov chains is that the transition probabilities between states are known and constant over time.\n\nThe steady state distribution is one that describes the probability of being at each state $x$ at time $\n\n\n## Gibbs Sampling Revisited\nSuppose we have $\\theta_1, \\cdots, \\theta_n$ and we want $p(\\theta_1, \\cdots, \\theta_n | x)$. Here's the general algoritm:\n1. Sample a $p(\\theta_1 | x, \\theta_2, \\cdots, \\theta_n)$\n2. Initialize $\\theta^{(0)}$\n3. Resample $\\theta_1^{(1)}$ from $p(\\theta_1 | x, \\theta_2^{(0)}, \\cdots, \\theta_n^{(0)})$\n4. Continue for all $\\theta_i^{(1)}$\n5. Repeat for each time step\n\n\n\n## Metropolis-Hastings\nThe Metropolis-Hastings algorithm is a method to sample from an unnormalized target distribution $q(\\theta)$. \n\n1. Generate a proposal $V(\\theta' | \\theta)$ (some distribution that depends on the current sample).\n2. Accept or reject the new proposal:\n\t1. If $q(\\theta') \u003e q(\\theta)$, immediately accept.\n\t2. Otherwise, accept with probability $q(\\theta')/q(\\theta)$.\n\nRecall that $q(\\theta) \\propto(\\theta | x) = p(\\theta)p(x|\\theta)$. Therefore, the ratio $q(\\theta')/q(\\theta)$ is equivalent to $P(\\theta'|x)/P(\\theta|x)$. So, the Metropolis-Hastings algorithm will reach the steady state distribution of the actual density.\n\n### Choosing a Proposal\nA poor proposal distribution for Metropolis-Hastings can create a large amount of unnecessary rejections. Here's an example:\n![[/data102/img/Pasted image 20220928153000.png]]\nSuppose we have four possible proposals to choose from:\n - A: uniform distribution of width 1 centered at the current t: Uniform[t-½, t+½]\n - B: shifted exponential distribution starting at the current t with lambda=1\n - C: normal distribution with mean at the current t and standard deviation 500\n - D: normal distribution with mean at the current t and standard deviation 40\n\nIn this example:\n - B is the worst because it's impossible to sample values from smaller $t$ than the current value.\n - A is poor because it will take a long time to converge.\n - C is poor because many proposals will be rejected.\n - D is the best because it allows us to generate samples across the entirety of the domain without having too many rejections.",
    "lastmodified": "2023-01-12T00:40:07.152567665Z",
    "tags": null
  }
}